"AwardNumber","Title","NSFOrganization","Program(s)","StartDate","LastAmendmentDate","PrincipalInvestigator","State","Organization","AwardInstrument","ProgramManager","EndDate","AwardedAmountToDate","Co-PIName(s)","PIEmailAddress","OrganizationStreet","OrganizationCity","OrganizationState","OrganizationZip","OrganizationPhone","NSFDirectorate","ProgramElementCode(s)","ProgramReferenceCode(s)","ARRAAmount","Abstract"
"9708421","Mathematical Studies in Colloid Transport","DMS","COMPUTATIONAL MATHEMATICS, ENVIRO GEOCHEM AND BIOGEOCHEM","09/01/1997","08/21/1997","David Logan","NE","University of Nebraska-Lincoln","Standard Grant","Michael Steuerwalt","08/31/1999","$75,000.00","Steven Cohn","dlogan@math.unl.edu","2200 VINE ST BOX 830861","LINCOLN","NE","685032427","4024723171","MPS","1271, 1584","1584, 9189, 9263, EGCH","$0.00","Logan  9708421       The principal investigators and their colleagues undertake a  systematic study of nonlinear phenomena in the transport of  bacterial and other colloidal substances through domains of  variable porosity.  They assume that the porosity is a function  of the colloid concentration, which places a nonlinearity in the  time-derivative term of the resulting  reaction-diffusion-convection equations that govern the flow.  The investigators address issues of well-posedness and  qualitative behavior for some of these types of biofilm problems,  using techniques such as energy arguments and semigroup analysis.  They also study the existence of traveling wavefronts in these  systems using dynamical systems methods.  A significant part of  their effort is to interact with colleagues in the geosciences in  order to be certain that the models they study are physically  well-founded.       The presence of colloids, of which some bacterial substances  are examples, in subsurface aquifer systems can have a profound  effect on the transport of contaminants.  For example,  hydrocarbons can form a substrate for microbial growth which can  then result in the formation of a biofilm on the solid surfaces  of the aquifer.  The behavior of biofilms in important in the  mining industry for the leaching of metals from ores, in the  petroleum industry for the control of biofilm accumulation to  prevent plugging in oil recovery, and especially in the  environmental water resources area for in-situ bioremediation.  It  has been demonstrated experimentally that the presence of  bacterial substances can enhance the transport of harmful  chemicals, like DDT, through the soil; in other cases, biofilms  can form barriers that block the transport of such contaminants.  The investigators study mathematical equations that model the  interaction of contaminants and colloidal particles and the  effects of these interactions on the flow characteristics of  subsurface domains.  One goal is to understand, through exami ming  the validity of various models, how different mechanisms affect  the hydrodynamic flow."
"9707015","A Posteriori Error Estimation and Up-Scaling for Mixed      Finite Element Methods","DMS","COMPUTATIONAL MATHEMATICS","08/01/1997","08/05/1997","Todd Arbogast","TX","University of Texas at Austin","Standard Grant","Jong-Shi Pang","07/31/2000","$75,000.00","","arbogast@ices.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271","9216, 9263, HPCC","$0.00","9707015  Todd Arbogast    A POSTERIORI ERROR ESTIMATION AND  UP-SCALING FOR MIXED FINITE ELEMENT METHODS      This project concerns the approximation of second order elliptic and parabolic  partial differential equations by mixed finite element methods on logically  rectangular grids.  The first objective is to develop a local a posteriori  error estimator or indicator, so that spatial errors can be localized.  We  propose to estimate the error by exploiting the equivalence between mixed and  non-conforming methods for rectangular elements.  The second objective is to  develop up-scaling or homogenization techniques for highly variable  coefficients and point-like sources, i.e., for resolving fine length scales in  the model system that are below the size of a practical computational mesh.  The error associated with using these up-scaling techniques must be  quantifiable.  We propose to base our techniques on the discrete equations, and  use the coarse scale Raviart-Thomas projection operator which preserves the  flux across any element face.  The third objective is to demonstrate the  applicability of the techniques in a practical setting; we consider the  simulation of subsurface flow.  The first two objectives are complementary.  Error estimation would allow us to refine the mesh where the solution is ill  behaved, as near sharp fronts, local heterogeneity, or sources (i.e., wells),  so that computational effort can be concentrated to resolve the major length  scales in both the data and the solution.  Up-scaling would allow us to further  resolve some scales below the mesh size.      Our understanding of fluid flow underground is important to a range of  activities, including the clean-up of ground-water contamination and oil and  gas production.  Ground-water supplies are increasingly threatened by  contaminants introduced into the environment by improper disposal or accidental  release.  U.S. petroleum production has declined markedly in recent years.  These problems can be ameliorated by  complex engineering processes that require  careful design and monitoring, which in turn depend on our ability to simulate  on a computer the movement of fluids underground.  Our computer simulations  must be sufficiently detailed that we can further predict physical, chemical,  and biological processes and the consequences of human intervention.  Such  simulation requires that we approximate accurately the differential equations  governing the movement and interaction of the fluids.  It is difficult to do  this for a number of reasons, but the most basic is a lack of resolution: we  can only use data and compute fluid velocities at a small number of grid points  in space.  To date there has been no effective way to estimate the error in the  approximation to the fluid velocity.  If we knew that our errors were large, we  could take corrective action by increasing the grid resolution, up to the  limits of the computer resources available.  Beyond that limit, it is necessary  to approximate certain very small-scale quantities below the grid scale (such  as local variations in rock properties) by replacing them by some appropriately  defined average quantities.  We address these concerns in this proposal, and  demonstrate the applicability of our techniques in practical settings to gain  their acceptance by engineers."
"9704899","Differentiable Optimization Techniques for the Recovery of  Sharp Features of Solutions to Inverse Problems","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/15/1997","02/26/2001","Patricia Lamm","MI","Michigan State University","Standard Grant","Deborah Lockhart","06/30/2002","$78,633.00","","lamm@math.msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1266, 1271","0000, 9146, 9161, 9216, 9263, AMPP, HPCC, MANU, OTHR","$0.00","9704899  Lamm    The main goal of this project is to develop local regularization methods for   the solution of ill-posed inverse problems such as those arising in   applications of inverse heat conduction and image reconstruction.  The   ideas of local regularization developed by the P.I. naturally lead to a   ""predictor-corrector"" type of solution method.  The idea is that a regularized   solution is first obtained on a small part of the domain of the solution, after   which subsequent correction is applied in order to avoid oversmoothing.    This method has been seen to be as effective as standard Tikhonov   regularization for Volterra problems, with improved computational   performance.  In addition, the scheme naturally suggests a ""variable   regularization"" approach in which a functional regularization parameter is   used to apply more smoothing in some parts of the domain and less in   others.  In this project the P.I. plans to continue to develop the existing   theory for Volterra problems, and to extend this theory to non-Volterra   problems of the type arising in image reconstruction and image deblurring.    The design of a theoretically-sound adaptive process of selecting the   functional parameter is an essential and difficult part of this project.     Inverse problems naturally arise in numerous scientific applications,   including biomedical imaging (Magnetic Resonance Imaging and CAT   scans), the nondestructive thermal testing and analysis of materials, satellite   sensing of remote images, and geophysical applications such as seismic and   reservoir engineering.  These problems are of considerable challenge to   scientists because they often lead to very large computational problems   which are extremely sensitive to errors in data.  The aim of this project is to   develop new methods for the stable and efficient solution of such inverse   problems.  The successful attainment of this goal would have an important   impact on applications such as biotechnology, remote imaging, and    materials science."
"9707261","Third Mississippi State Conference on Differential Equations and Computational Simulations, May 16-17, 1997","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","05/01/1997","05/08/1997","Ratnasingham Shivaji","MS","Mississippi State University","Standard Grant","John C. Strikwerda","04/30/1998","$4,000.00","Bharat Soni, Jianping Zhu","r_shivaj@uncg.edu","245 BARR AVE","MISSISSIPPI STATE","MS","39762","6623257404","MPS","1266, 1271","9216, 9263, HPCC","$0.00","9707261  Shivaji  The Third Mississippi State Conference on DIFFERENTIAL EQUATIONS & COMPUTATIONAL SIMULATIONS will be held May 16 and 17, 1997 at Mississippi State University.  There are nine invited principle speakers.  These are:  Walter Allegretto, University of Alberta, Canada, Microsensor Analysis and Simulation  Jerry L. Bona,University of Texas, Stability and Instability of Solitary Waves and Associated Singularity Formation  Djairo de Figueiredo, University of Campinas, Brazil, Decay, Symmetry and Existence of Positive Solutions of Semilinear Elliptic Systems  S. Godunov, Sobolev Institute of Mathematics, Russia, Spectral Stratification in Models of Finite Elements for Elliptic Problems  Anthony Jameson, Princeton University, Title to be announced  Jean Mawhin, Universite de Louvain, Belgium, Floquet Boundary Value Problems for Nonlinear Differential Equations: A Blend of Topology and Symmetry     Stanley Osher, University of California, The Level Set Method: What's In It For You?  Klaus Schmitt, University of Utah, Bifurcation Problems for Variational Inequalities  Joseph Shang, Wright Patterson Air Force Base, High Resolution Schemes  for Computational Electromagnetics in the Time Domain  This interdisciplinary conference will provide a joint forum where mathematicians, scientists, and engineers from academia and industry can exchange research ideas involving theoretical and applied developments in differential equations and computational   simulations.  In addition to the nine principal lecturers, there will be sessions of contributed talks.  This conference is held bi-annually.  Reviewed manuscripts will be published as a special issue of the  Electronic Journal of Differential Equations.  Information on the conference is available on the conference home web page: http://www.msstate.edu/Dept/Math/conf.html"
"9706916","A Finite Difference Approach to Pseudospectral Methods","DMS","COMPUTATIONAL MATHEMATICS","08/01/1997","07/25/1997","Bengt Fornberg","CO","University of Colorado at Boulder","Standard Grant","John C. Strikwerda","07/31/2001","$81,000.00","","fornberg@colorado.edu","3100 MARINE ST","BOULDER","CO","803090001","3034926221","MPS","1271","9216, 9263, HPCC","$0.00","9706916  B. Fornberg     Pseudospectral (PS) methods - a high-accuracy alternative to finite  difference (FD) and finite elemnt methods - are particularly effective for  solving convection-dominated PDEs over long times and in relatively simple  geometries. Both the algorithms themselves and their analysis have usually  been closely tied to expansions in different classes of orthogonal  functions. The recent book ""A Practical Guide to Pseudospectral Methods""  (by the present investigator)  notes that a large body of generalizations,  enhancements and insights can be gained by viewing PS methods instead as  special cases of FD methods.  These opportunities will now be explored  further, in particular with the aim of combining the PS approach with  domain decomposition for time-dependent computational electromagnetics.          Pseudospectral (PS) methods were first proposed in the early 1970's (in  connection with meteorology and turbulence modeling). They are now  routinely used in many fields such as nonlinear wave motions, weather  forecasting, fluid mechanics, computational chemistry, and with  time-domain computational electromagnetics (TD CEM) emerging as a new and  potentially major application area. This present investigation will  explore how a series of new leads for PS methods can be developed further  and then brought to bear on applications, in particular in the field of TD  CEM. Such applications include simulations of the radar visibility of  objects and of how electromagnetic fields are generated by/ interact with  components on integrated circuits."
"9709266","IUTAM Symposium on Computational Methods for Unbounded      Domains, July 27-31, 1997, Boulder, Colorado","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/01/1997","06/16/1997","Thomas Geers","CO","University of Colorado at Boulder","Standard Grant","John C. Strikwerda","12/31/1997","$10,000.00","","geers@spot.colorado.edu","3100 MARINE ST","BOULDER","CO","803090001","3034926221","MPS","1266, 1271","0000, 9198, 9216, 9283, EGCH, HPCC, OTHR","$0.00","  IUTAM SYMPOSIUM ON COMPUTATIONAL  METHODS FOR UNBOUNDED DOMAINS    This symposium will be held on July 27-31, 1997 at the University of  Colorado in Boulder.   Sponsored by the International Union of Theoretical  and Applied Mechanics and attended by sixty researchers from fifteen  countries, the symposium will focus on the use of non-reflecting computational  boundaries to address wave-propagation problems in unbounded domains.  Such  problems frequently arise in acoustics, aeronautics, electrical  engineering, meteorology, oceanography, ultrasonics, and seismology &  earthquake engineering.  The objectives of this symposium are to improve  communication on this topic across several scientific and engineering  disciplines, illuminate the performance characteristics of recently  developed methods, and facilitate the formulation of improved methods,  especially for highly challenging problems.  In pursuit of these  objectives, participants will propose and then agree on some generic benchmark  problems with which to compare the characteristics of existing methods, and  brainstorm promising approaches for the development new methods."
"9706866","Numerical Methods in Large-Scale Computation","DMS","COMPUTATIONAL MATHEMATICS","08/15/1997","06/17/1999","Steve McCormick","CO","University of Colorado at Boulder","Continuing Grant","John C. Strikwerda","01/31/2001","$482,402.00","Thomas Russell, Thomas Manteuffel","stevem@colorado.edu","3100 MARINE ST","BOULDER","CO","803090001","3034926221","MPS","1271","0000, 9197, 9216, 9263, EGCH, HPCC, OTHR","$0.00","9706866  McCormick     The main thrust of the proposed research is the development of efficient numerical techniques for simulation of a wide variety of physical processes. Important applications include aerodynamics, meteorology, elasticity, electromagnetics, porous media, and particle transport.  The general goal is to develop accurate discretization methods and fast algebraic solvers for the partial differential equations that govern these and other applications.  The research topics include: multilevel first-order system least squares, which involves reformulation of partial differential equations as well-posed minimization principles to allow for robust and efficient solution methods; porous media problems, which will be treated by Eulerian-Lagrangian localized adjoint methods that have been successful for such multiparty and reactive flows; transport phenomena, which will be simulated using efficient and robust least-squares methods for the three-dimensional Boltzmann transport equations; and iterative methods, which is aimed at developing effective algebraic solvers for the equations that arise in many applications.    The focus of this project is research in the field of computational mathematics.  The purpose is to improve our understanding of the mathematics behind computer simulation of complex physical phenomena.  Such simulations are key to the study and control of many important processes, including groundwater flow, global change, energy production, and material science.  One of the challenges in such simulations is the development of improved mathematical methods for solving the equations that arise in these models.  The basic aim of this research is dramatic improvement in our ability to model increasingly more complicated and sophisticated processes with much greater accuracy and efficiency.  This will pave the way for simulations that can provide scientists, engineers, and policy-makers with much more powerful tools to understand and improve our industry, science, and environm ent."
"9707359","Weighted Approximation in the Complex Plane and Iterative   Methods, via Potential Theory and Function Theory","DMS","COMPUTATIONAL MATHEMATICS, ANALYSIS PROGRAM, CENTRAL & EASTERN EUROPE PROGR","08/01/1997","04/01/1999","Richard Varga","OH","Kent State University","Continuing Grant","Jong-Shi Pang","07/31/2001","$84,827.00","Igor Pritsker","varga@mcs.kent.edu","1500 HORNING RD","KENT","OH","442420001","3306722070","MPS","1271, 1281, 5979","0000, 5998, 9263, OTHR","$0.00","9707359  Richard S. Varga      The goal of this proposal is to attack basic problems in polynomial and   rational approximation, with varying weights, in the complex plane, by means  of potential theoretic techniques. Recently, the proposers have begun fruitful  initial investigations in this area, resulting in a number of new research   manuscripts, which we consider to be of break-through character. We clearly  feel that these initial investigations are so promising as to warrant the   submission of this research proposal to the National Science Foundation.   But, an important and novel feature of this proposal is that connections,  with the efficientsolution of large nonsingular systems of linear equations  by iterative methods, are directly associated with this theoretical work in   the complex plane by potential theoretic methods. Thus, the proposed research  bridges research in complex function theory and numerical analysis, and will  have a strong numerical component.      Problems arising in large-scale circuit design, oil recovery via petroleum  reservoir machanics, and the design of nuclear reactors for generating   electrical power, all have the following item in common: the modeling of   these physical phenomena leads to massive nonsingular systems of linear   equations, whose unknowns can exceed one million. To efficently solve these  systems, iterative methods are commonly used. One aim of this proposal is to  use tools, from the fields of potential theory anddd complex function theory,  to theoretically attack a specific question on how best to iteratively   such large systems of equations."
"9796208","Mathematical Sciences:  Analysis, Algorithms, and           Computations for Models of High-Temperature                 Superconductivity","DMS","COMPUTATIONAL MATHEMATICS","08/01/1997","06/18/1997","Qiang Du","IA","Iowa State University","Standard Grant","Michael Steuerwalt","07/31/1999","$14,453.00","","qd2125@columbia.edu","1350 BEARDSHEAR HALL","AMES","IA","500112103","5152945225","MPS","1271","0000, 9263, OTHR","$0.00",""
"9707750","Mathematical Models for Cell Locomotion","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/01/1997","09/12/1997","Alexander Mogilner","CA","University of California-Davis","Standard Grant","Michael Steuerwalt","08/31/2000","$110,000.00","","mogilner@cims.nyu.edu","1850 RESEARCH PARK DR, STE 300","DAVIS","CA","956186153","5307547700","MPS","1266, 1271","0000, 9263, OTHR","$0.00","Mogilner  9707750       Certain kinds of cellular movements are driven by actin  polymerization.  The most conspicuous examples are the  lamellipodia of spreading and migrating embryonic and metastatic  cells.  A variety of pathogenic bacteria also propel themselves by  constructing behind them a polymerized tail of cross-linked actin  filaments.  Collective cellular movements mediated by cell-cell  interactions can generate interesting spatial patterns.  These  patterns can shed light on intercellular communication and can be  used as novel assays for understanding the molecular mechanisms  of cell signaling.  The goal of this research is to understand at  the molecular level (i) the mechanochemical basis of force  generation by polymerizing and depolymerizing actin networks,  (ii) the mechanisms of spatio-angular cytoskeletal organization,  (iii) patterns of collective cell motion.  The investigator and  his colleagues formulate a mechanochemical theory of how the  thermal fluctuations of the filament tips and the membrane can be  rectified by actin polymerization to generate a propulsive force.  This force is controlled by soluble and transmembrane proteins  that stimulate actin polymerization.  The investigators also  formulate a theory for retrograde flow of lamellar cytoplasm.  This theory is based on two sources of contractile force: (i) the  contraction of the actin gel that must accompany  depolymerization, and (ii) actin filament contraction driven by  myosin.  The results of these models determine the relative roles  of actin polymerization and myosin crosslinking and contraction  during cell locomotion.  These studies help forge a link between  the basic biophysics of cell motility and the chemical control of  cell motion.       The crawling of cells over surfaces is the basis for the  vitally important phenomena of phagocytosis and the migration of  metastatic cells.  Despite the ubiquity of cellular motions, the  molecular mechanisms underlying these movements remain  mysterious.   The investigators undertake theoretical modeling that  provides a solid quantitative basis for understanding the  detailed working cycle of the cell's molecular engines.  This  description provides a new interdisciplinary level of  understanding cell movements and new methods of predicting cell  behavior in medically and technologically important situations."
"9706964","Evolution PDEs in Inhomogeneous Media: Low-Dimensional      Dynamics, Computation and Applications","DMS","COMPUTATIONAL MATHEMATICS","08/15/1997","08/05/1997","Edriss Titi","CA","University of California-Irvine","Standard Grant","Michael Steuerwalt","07/31/2001","$85,000.00","","etiti@math.uci.edu","160 ALDRICH HALL","IRVINE","CA","926970001","9498247295","MPS","1271","0000, 9263, OTHR","$0.00","Titi  9706964       The investigator and his collaborator I.  Kevrekidis of  Princeton University study the long-time behavior of solutions to  dissipative evolution partial differential equations under  perturbations; they undertake a combined theoretical and  computer-assisted approach, with a number of illustrative  applications in mind.  These spatiotemporal perturbations are  motivated physically by phenomena occurring in media with varying  properties, such as reaction and diffusion in inhomogeneous media  (leading to PDEs with spatially or spatiotemporally dependent  coefficients).  They may also be the result of a feedback control  loop on a spatially distributed system.  In the project, they are  interested in maintaining / exploiting / prescribing  low-dimensional dynamics through large amplitude perturbations  and/or scale variation effects.  The tools they build upon are the  global machinery of inertial and approximate inertial manifolds,  as well as scientific computing for the simulation and the  bifurcation and stability analysis of nonlinear evolution PDEs.  The new set of questions they address requires the extension and  combination of these tools with aspects of separation of time  scales in control theory (e.g. persistence of inertial or  approximate inertial manifolds in closed loop systems) or in  homogenization theory (when coefficients in the PDE representing  properties of the medium vary on disparate spatial scales).       This project extends, develops and implements mathematical  and computational tools that enhance our ability to study  reaction and transport processes (modeled by dissipative  nonlinear evolution partial differential equations) under  inhomogeneous conditions.  Such conditions constitute more the  rule than the exception under realistic physical circumstances,  whether due to imperfections in the process (in which case we  want to guarantee a certain level of performance) or due to  intentional design of composite media, or to feedback control  (whe re we attempt to optimize a process, like the selectivity of  a chemical reaction).  The method and algorithm development part  of the project is applicable to a wide class of such systems.  The  particular applications, however, focus on the modeling, analysis  and design of novel composite catalysts for heterogeneous  reactions, and on the exploitation of modeling for the control of  spatially extended systems (such as fluid flows)."
"9704535","Mathematical Sciences:  Topology, Arithmetic Groups         and Toric Varieties","DMS","TOPOLOGY, COMPUTATIONAL MATHEMATICS","08/15/1997","02/16/2000","Weiping Li","OK","Oklahoma State University","Standard Grant","Benjamin M. Mann","01/31/2001","$78,000.00","","wli@math.okstate.edu","401 WHITEHURST HALL","STILLWATER","OK","740781031","4057449995","MPS","1267, 1271","0000, 9216, 9263, HPCC, OTHR","$0.00","9704535  McConnell       The project has three parts.  First, let G = SL(n,R), let Gamma  be an arithmetic subgroup of G, and let X be the symmetric space for G.  The spaces X/Gamma are one setting where automorphic forms can be  defined; they provide a topological approach to parts of the Langlands  conjectures.  For each Hecke operator T on the cohomology of X/Gamma,  MacPherson and McConnell have defined a cell complex W(T) which allows  one to find the operator by cellular techniques, i.e., using only a  finite amount of combinatorial data.  They will investigate W(T) and  extend the definition to more G.  In the second part, Ash and  McConnell are computing the cohomology of X/Gamma in degree five for  certain Gamma for SL(4).  The goal is to determine the cuspidal  classes and the Hecke action on them.  The third part concerns  Sheafhom, a suite of computer programs McConnell has developed.  Sheafhom provides models of chain complexes, spectral sequences,  sheaves, and other objects.  The largest application to date is its  algorithm for finding the intersection homology (IH) of toric  varieties in any perversity.  One goal is to compute the intersection  product on IH of toric varieties, with applications to convex  polytopes.  Sheafhom has also been used in the Ash-McConnell work.       A computer algebra system is a program for calculation with  algebra, as opposed to numbers.  Any program can find 2 + 2, but a  computer algebra system combines whole formulas: the input  (2x + 7) + (4x - 3) becomes 6x + 4 automatically.  This capacity is  more abstract, hence more flexible.  Excellent general-purpose systems,  like Maple or Mathematica, are available, but of course they don't have  everything that every mathematician needs.  In recent years, several  disciplines have been given their own special-purpose systems--  Cayley/Magma for algebraists, Pari for number theorists, and a dozen  others.  McConnell has written Sheafhom, a computer algebra system for  algebraic topology.  The program,  some 10,000 lines long, is written  in Lisp, one of the liveliest (and most efficient) programming  languages.  The goal is to apply Sheafhom to study convex polytopes.  Convex polyhedra are solid bodies with flat faces, like cubes, pyramids,  or hundred-faced diamonds.  A convex polytope is the same kind of body  in the fourth or higher dimension.  Since 1980, algebraic geometry has  become a major tool for studying polytopes.  This is surprising,  because algebraic geometry includes some of the most abstract  mathematics known, while polytopes, like crystals, are very concrete  objects.  Sheafhom will make possible some difficult computations in  algebraic topology and geometry; these will advance our understanding  of convex polytopes.  McConnell's project actually has two other  parts that are more loosely related to Sheafhom.  These are connected  with the Langlands conjectures, a very deep set of ideas that relates  number theory to other, more geometric parts of mathematics.  ***"
"9706949","Theory and Application of Numerical Methods for Partial     Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","08/01/1997","04/12/1999","Jinchao Xu","PA","Pennsylvania State Univ University Park","Continuing Grant","Jong-Shi Pang","07/31/2001","$150,000.00","","xu@math.psu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271","9216, HPCC","$0.00","9706949  Jinchao Xu    The proposed research is on the development, analysis and applications of advanced numerical methods for solving partial differential equations arising in sciences and engineering.  The focus of research is on efficient multigrid and domain decomposition methods and other relevant algorithms that are suited for parallel and high performance computers.  One major object is to try to make multigrid and domain decomposition methods be more practical and more easily used.  In particular, efficient and practical multigrid methods will be developed for unstructured grids and also for grids that are currently available from existing (commercial) finite element software.  Special techniques under development include the agglomeration method and auxiliary space (grid) methods.  Theoretical analysis will also be carried out to justify the efficiency of various methods and also to motivate the development of more sophisticated methods.  A major portion of the proposed research will be devoted to the development of efficient multigrid methods for convection-dominated convection-diffusion problems, Navier-Stokes equations and hyperbolic equations and also to the theoretical justifications of the efficiency of some special multigrid methods which use some carefully designed domain decomposition methods as smoothers.  Some of the proposed research will be carried out in collaboration with computational scientists and engineers to develop practical and efficient methods for solving some real life problems.    Because of the advent of high performance computers, it becomes more and more feasible to use computers to simulate real life problems.  In fact it has become a more and more common practice to use computer simulations to replace the traditional and oftentimes very expensive laboratory experiments.  Most of the real life problems can be modeled and described by the so-called partial differential equations.  These equations can become more and more complicated if we want to have more  and more accurate and more realistic modeling of the real life situations.  Hence it is a constant challenge to develop efficient numerical methods for solving these equations.  The proposed research is precisely for the study of a class of most advanced numerical algorithms for effectively solving partial differential equations on parallel and high performance computers.  Our research has been directly tired to various practical applications such as environment protection and the design of medical material and devise.  In fact, for example, one numerical package that we have helped develop (based on research related to this proposal) have been adopted by U.S. EPA for environmental assessment and protection."
"9711050","Godunov's Method for Gas Dynamics: Current Applications and Future Development (Symposium)","DMS","COMPUTATIONAL MATHEMATICS","08/01/1997","08/13/1997","Bram van Leer","MI","Regents of the University of Michigan - Ann Arbor","Standard Grant","Michael Steuerwalt","07/31/1999","$11,600.00","","bram@umich.edu","1109 GEDDES AVE, SUITE 3300","ANN ARBOR","MI","481091079","7347636438","MPS","1271","0000, 9263, OTHR","$0.00","van Leer  9711050       The investigator and colleagues organize an international  symposium on Godunov-type methods, which are widely used to  compute continuum processes dominated by wave propagation.  The  conference gives an overview of the current state of development  and use of Godunov-type methods in science and engineering, and  it offers a perspective of their future development and use.  The  symposium brings together senior researchers who are experts in  the development and use of Godunov-type methods, junior  researchers who are currently making significant contributions in  this field, graduate students just entering the field, and other  interested individuals.  It also includes experts from application  areas.       Many important physical problems involve flow of a  compressible fluid; they can be described by differential  equations whose solutions have jumps in their values.  Computing  such a solution is usually difficult.  Godunov-type methods are a  class of methods that compute the solution by making particular  local approximations to it, moving the local approximations  forward in time, and piecing together these advanced values in  certain ways.  Extensions of the original method include higher  accuracy in time or in space, higher-dimensional problems,  problems with more complicated equations.  This meeting is devoted  to recent developments in Godunov methods, including not only  mathematical and numerical advances but also advances in  applications areas.  Examples are mesoscale meteorology, the  modeling of plasma flows arising in the heliosphere, and a  variety of engineering fluid flows."
"9706951","Dynamic Control and Parametric Resonance in Hydrodynamic    Systems:  A Theoretical, Computational, and Experimental    Investigation","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","08/15/1997","11/19/1998","Juan Lopez","PA","Pennsylvania State Univ University Park","Standard Grant","John C. Strikwerda","07/31/2000","$94,000.00","Jie Shen","jmlopez@asu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1266, 1271","0000, 9148, 9161, 9263, AMPP, MANU, OTHR","$0.00","9706961   Lopez and Shen      This project is to study dynamic control and parametric excitations in  hydrodynamic systems and to examine the interplay between parametric  resonance and stabilization/destabilization of  transitions/bifurcations, through an integrated program of analysis,  computation and experiment. Two basic flow sets, namely the  Taylor-Couette flow and vortex breakdown flow, have been chosen in  order to develop a general understanding of the complex hydrodynamics  and control strategies. These generic flows are attractive because the  degree of complexity can be precisely controlled by relatively simple  changes in the flow state or boundary conditions, and at the same time  they possess rich dynamics which are representative of a wide class of  general hydrodynamic systems that may respond to dynamic control in a  complex manner. In particular, these classes of flows may respond  resonantly to the parametric excitation of the applied control. An  investigation of the behavior of these generic flows will help to form  a better understanding of more general time-dependent hydrodynamic  systems. The interplay between dynamic control mechanisms and  parametric resonance will be investigated using (linear) Floquet theory  as a first step in understanding the dynamics at the point of  transition or bifurcation. Flows beyond the validity of the Floquet  analysis will be studied using three different nonlinear computational  approaches, each with distinct advantages and limitations. Their  combined implementation is capable of resolving a wide range of  problems and addressing distinct issues within each problem. The  results from the experiment will be used to refine the analysis and  control implementation.    This research will not only result in a deeper understanding of the  complex spatio-temporal dynamics of hydrodynamic systems, but will also  make a significant practical impact. For example, in the aerodynamics  industry, the control strategies will aid in drag reduction a nd reduced  fatigue due to aero-acoustic structural resonances; in fact, parametric  excitation in the form of span-wise oscillations of the boundary has  recently been demonstrated experimentally to reduce drag in turbulent  boundary layers by researchers at the University of Texas and others.  In the materials and chemical processing industries, many of the  manufacturing processes rely on an effective control of transitions and  instabilities. The new fundamental and practical insights on control  dynamics of complex systems anticipated from this research can provide  U.S. industry with a competitive edge."
"9701755","Mathematical Sciences Research Institute","DMS","INFRASTRUCTURE PROGRAM, COMPUTATIONAL MATHEMATICS, AMERICAS PROGRAM","07/01/1997","08/18/1999","William Thurston","CA","Mathematical Sciences Research Institute","Continuing Grant","Christopher Stark","06/30/2001","$10,194,700.00","Tsit-Yuen Lam, Hugo Rossi","wpt4@cornell.edu","17 GAUSS WAY","BERKELEY","CA","947200001","5106420143","MPS","1260, 1271, 5977","0000, 5922, 9263, OTHR","$0.00","Thurston  9701755    This award provides core support to the Mathematical Sciences Research Institute located in Berkeley, California.  The fundamental goal of the Mathematical Sciences Research Institute (MSRI) is to stimulate research in the mathematical sciences by bringing together, in a programmatically focused scientific environment, the top mathematical scientists, nationally and internationally, in given research subjects.  The interaction of senior and mid-level scholars and the very best postdoctoral fellows in a given field produces a stimulating  environment where new ideas can be exploited and developed. The training of postdoctoral researchers is a priority of MSRI, and the scientific structure and budgetary allocations of funds reflect this.  Normally, two academic-year scientific research programs take place each year.  In addition to these academic year programs, MSRI conducts workshops and conferences.  MSRI also supports summer research and training programs for graduate students. Programs are scheduled that reflect timely research interest and opportunities for cross-programmatic collaboration and scientific exchange."
"9617148","Mathematical Sciences:  Workshop:  Statistical Physics      Methods in Discrete Probability, Combinatorics and          Theoretical Computer Science","DMS","PROBABILITY, ALGEBRA,NUMBER THEORY,AND COM, COMPUTATIONAL MATHEMATICS, THEORY OF COMPUTING","03/15/1997","03/06/1997","Fred Roberts","NJ","Rutgers University New Brunswick","Standard Grant","K Crank","08/31/1997","$14,000.00","Jennifer Chayes, Dana Randall","froberts@dimacs.rutgers.edu","3 RUTGERS PLZ","NEW BRUNSWICK","NJ","089018559","8489320150","MPS","1263, 1264, 1271, 2860","0000, 9263, OTHR","$0.00","9617148  Roberts   This award provides funds to partially support the five day workshop, ""Statistical   Physics Methods in Discrete Probability, Combinatorics, and Theoretical Computer   Science"" to be held March 23-27, 1997 at the Institute for Advanced Study in Princeton.   The goal of the workshop is to bring together researchers working at the interface of   statistical physics, probability, combinatorics and theoretical computer science with the   intention of developing a common language and recognizing parallels among the   fundamental problems being addressed in these disciplines. There will be several   introductory lectures surveying some of the major themes of the workshop. In addition,   there will be more advanced lectures giving junior and senior researchers opportunities to   present recent results. There will be ample time for discussion of open problems."
"9706931","Computations and Analysis of Fluids and Materials","DMS","COMPUTATIONAL MATHEMATICS","08/15/1997","08/11/1997","John Lowengrub","MN","University of Minnesota-Twin Cities","Standard Grant","John C. Strikwerda","07/31/2001","$138,000.00","","lowengrb@math.uci.edu","200 OAK ST SE","MINNEAPOLIS","MN","554552009","6126245599","MPS","1271","9161, 9216, 9263, AMPP, HPCC","$0.00","9706931  Lowengrub      The main objective of this proposal is to investigate the dynamics of  fluid-fluid and solid-solid interfaces by (1) developing and applying  state-of-the-art numerical methods to large scale computation and (2)  performing analytical, numerical and modelling studies of important  constituent processes. Specifically, the focus will be on studying  topological transitions in fluids and the diffusional evolution of  microstructure in solids. These areas involve fundamental physical  processes whose phenomenology is basic to understanding the behavior of  real fluids and the material properties of solids. Both are  characterized by the presence of multiple constitutive components,  complex pattern formation and/or singularities (i.e. spatial  complexity).  Although these processes arise in very different physical  phenomena (fluids versus solids), both involve free boundary problems  where the motion of a bounding interface, separating the different  components, is driven by a competition between surface energy and  either an instability or multi-body interactions.  As such, they can be  treated using a common set of analytical and computational tools. The  highly nonlinear nature of these problems makes fast, accurate and  robust numerical methods essential to their study.    In this proposal, we bring together mathematical and numerical  analysis, modelling, and large-scale scientific computation to study  certain fundamental problems in fluid dynamics and materials science.  For instance, one problem we will consider concerns changes in the  topology of interfaces between different fluids. Such changes occur,  for example, when liquid jets pinch off into droplets and when droplets  of one fluid reconnect with another. These topological transitions  occur in many practical applications involving transport, mixing, and  separation of petroleum, chemical, and food products as well as in  environmental applications such as oil spills. Often, reaction and  mixing rates within  these systems are controlled directly by the  detailed dynamics of the transition processes.  Thus, there is a need  to understand these dynamics in order to develop accurate engineering  models for mixing and reaction rate prediction. We will use analysis,  modelling and large scale scientific computation to investigate the  detailed dynamics of break-up and reconnection of fluid interfaces.  Another problem we will consider involves solid-state diffusional phase  transformations. These transformations are an important method of  processing multicomponent metallic alloys such such as steels. The  result of this process is the formation of a multiphase microstructure,  which is a key variable in setting the macroscopic mechanical  properties (i.e. stiffness, strength and toughness) of the alloy. The  microstructure is characterized by regions of different metallic  components separated from one another by interfaces. The goal of our  research is to accurately model and simulate the formation of  microstructure in alloys in order to provide metallurgists with a  recipe for generating new alloys with desirable material properties.  Although the two problems described above arise from very different  physical processes (fluids versus solids), they are similar in the  sense that the relevant phenomena is strongly influenced by surface  tension at the respective interfaces.  Consequently, they can be  studied using common analytical and computational tools.  The highly  complex nature of these problems makes fast, accurate and robust  numerical methods essential to their study."
"9727525","Copper Mountain Conference on Multigrid Methods, Copper Mountain, Colorado, March 29-April 4, 1998","DMS","COMPUTATIONAL MATHEMATICS","09/15/1997","09/16/1997","Thomas Manteuffel","AZ","Front Range Scientific Computations, Inc.","Standard Grant","Michael Steuerwalt","08/31/1998","$10,000.00","","tmanteuf@colorado.edu","8865 E CALLE BUENA VIS","SCOTTSDALE","AZ","852558364","3035541232","MPS","1271","0000, 9263, OTHR","$0.00","Manteuffel   9727525           The researcher and his colleagues organize a conference   devoted to iterative methods for the solution of linear and   nonlinear systems of equations.  Particular themes are   nonsymmetric linear systems, globally convergent algorithms for   nonlinear systems, algorithms of optimal order of work, saddle   point problems, and applications on multiprocessor computer   architectures.        The mathematical description of real-world problems leads   inevitably to equations to solve.  Many times the equations are   nonlinear ones, arising because the underlying problem is   nonlinear.  Often, however, the original problem is linear and   the mathematical equations are too.  Such problems arise in all   areas of science and technology, and are of special interest in   biology, materials, environmental studies, and manufacturing.     Progress in these areas requires solution of more comprehensive   modeling equations --- such models are usually more nonlinear   than simpler models ---, or more accurate solution of existing   models --- increasing the size of the numerical problem to be   solved.  In certain problems, notably in fluid flow and in   elasticity, computational methods for the equations describing   the phenomena yield numerical systems having a saddle point;   the solution is on a surface that looks locally like a saddle.   Computational methods for such problems offer special   difficulties.  The conference addresses advances in algorithms   to deal with larger numerical systems, nonlinearities, the   amount of time and work needed to get a solution, saddle points,   and the use of multiprocessor computers."
"9614997","Eighth Copper Mountain Conference on Multigrid Methods","DMS","COMPUTATIONAL MATHEMATICS","07/01/1997","07/21/1997","Steve McCormick","AZ","Front Range Scientific Computations, Inc.","Standard Grant","Michael Steuerwalt","06/30/1998","$10,000.00","","stevem@colorado.edu","8865 E CALLE BUENA VIS","SCOTTSDALE","AZ","852558364","3035541232","MPS","1271","0000, 9263, OTHR","$0.00","McCormick  9614997       The principal investigator and his colleagues organize the eighth Copper Mountain conference on multigrid methods, in cooperation with the Society of Industrial and Applied Mathematics.   This grant provides support for students to participate in the conference.         Numerical methods for solving a differential equation usually begin by imposing a grid on the region where the equation holds.  From the differential equation, algebraic equations are then developed; their solution represents the solution of the differential equation.  The accuracy of the approximate solution commonly is measured by the fineness of the grid.  Multigrid methods are numerical methods for solving partial differential equations that systematically exploit the relationship between approximate solutions on different grids to arrive at a solution whose accuracy is consistent with the finest grid but for considerably less work.  The methods are often dramatically more efficient than others.  Research in the past dozen years has extended the methods to a broad range of problems of considerable practical import in engineering, manufacturing, materials, physics, and fluid dynamics.  This project supports student participants at the eighth Copper Mountain conference on multigrid methods.  The students present a talk on their research in the regular sessions of the conference.  The primary objective here is to encourage student participation in this rapidly evolving field, and to provide an excellent opportunity for these students to demonstrate their new results, to learn more about the field from its experts, and to become a more integral part of the discipline.  Supporting student participation is critical for improving the infrastructure of this important field and for advancing the quality of its core contributors."
"9706792","Numerical Simulation of Quantum Transport in Semiconductor  Devices","DMS","COMPUTATIONAL MATHEMATICS","08/01/1997","08/01/1997","Carl Gardner","AZ","Arizona State University","Standard Grant","Michael Steuerwalt","07/31/2001","$144,294.00","Christian Ringhofer","carl.gardner@asu.edu","660 S MILL AVENUE STE 204","TEMPE","AZ","852813670","4809655479","MPS","1271","0000, 9161, 9216, 9263, AMPP, HPCC, OTHR","$0.00","Gardner  9706792       The propagation of electrons in quantum semiconductor  devices (e.g. resonant tunneling diodes, superlattices, and HEMT  and MODFET transistors) can be modeled as the flow of a  continuous charged quantum gas in a potential that has  discontinuous jumps at heterojunction barriers.  Quantum fluid  dynamical equations can be derived by assuming the gas is near  thermal equilibrium, but are expected to be more generally valid.  The investigator and his colleague focus on theoretical  modeling, simulation, and analysis of the flow of electrons in  one and two spatial dimensions in quantum semiconductor devices  based on the ``smooth'' quantum hydrodynamic model and quantum  kinetic equations (including the Bloch equation and the  Wigner-Boltzmann equation).  The development of modern upwind  numerical methods for simulating these equations on high  performance computers is emphasized.       Semiconductor devices --- like resonant tunneling diodes and  transistors --- that rely on quantum tunneling are playing an  increasingly important role in advanced microelectronic  applications, including multiple-state logic and memory devices  and high frequency oscillators.  The investigators model the  behavior of quantum semiconductor devices by treating electron  flow by means of quantum hydrodynamic and quantum kinetic  equations.  The models and numerical methods are implemented in a  high-performance industrial computer program that can be used by  the semiconductor manufacturing industry.  In this way,  semiconductor design engineers can efficiently explore the  behavior of various device materials and structures on the  computer before actually fabricating the semiconductor device."
"9706090","Heirarchical Basis Multigrid/ILU Algorithms for Solving     Finite Element Equations","DMS","COMPUTATIONAL MATHEMATICS","08/01/1997","06/07/1999","Randolph Bank","CA","University of California-San Diego","Continuing Grant","Jong-Shi Pang","07/31/2001","$174,036.00","","rbank@ucsd.edu","9500 GILMAN DRIVE","LA JOLLA","CA","920930021","8585344896","MPS","1271","9216, 9218, 9263, HPCC","$0.00","9706090  Bank           Hierarchical Basis Multigrid/ILU Algorithms for         Solving Finite Element Equations            Randolph E. Bank Department of Mathematics       University of California at San Diego         La Jolla, CA 92093    This proposal has two main components. First, we will study algebraic  hierarchical basis multigrid algorithms (HBMG/ILU).   These methods  solve sparse sets of linear equations arising from finite difference,  finite volume and finite element discretizations of partial  differential equations.  They are differentiated from classical HBMG  and MG methods in that they do not require a coarse grid and sequence  of mesh refinements.  This allows application to problems with  geometrically complex domains that require many elements just for the  geometric definition, and problems where the adaptivity comes from  moving the mesh points rather than from refinement.  Preliminary  numerical experiments indicate that the methods are potentially very  powerful and robust. The second component of the of proposal concerns  the continuing software development of the finite element program  PLTMG. Various versions of this program have been in the public domain  since the late 1970's, and it is widely used in education and research  environments.  PLTMG solves scalar, parameter dependent, nonlinear  elliptic PDE's in  general regions of the plane.  The principle  features are adaptive mesh generation, a posteriori error estimation,  HBMG (soon to be HBMG/ILU) iteration for linear systems of equations,  Newton's method for nonlinearities, and continuation for parameter  dependencies. The code also includes an initial mesh generator, a  skeleton generator, and several graphics routines. Although the name  PLTMG has remained the same, typically 80% or more of the package is  revised with each new release.    In many systems modeled by partial differential equations, the critical  phenomena occur only in a small part of the physical domain, and may  move as a function of time ( e.g. as a flame front). Even with the great  advances in hardware, it is not adequate to address difficult  grand-challenge class problems of this type using software based on  simple uniform meshes; the demands of the problem require that  computing resources be focused on the regions of most interest.  The  motivation for adaptive mesh algorithms is that the algorithm itself  can and should identify these critical regions and respond with an  appropriate mesh with little or no human intervention.  The ``brains''  of adaptive algorithms are a posterior error indicators, which both  estimate the current error, and indicate where additional resources  should be focused. The very nonuniform and unstructured meshes  resulting from adaptive algorithms require sophisticated methods, such  as multigrid or the proposed HBMG/ILU, to efficiently and reliably  solve the resulting systems of equations. Overall, this field provides  a mosaic of important and interrelated scientific questions ranging  from difficult problems in mathematical analysis to difficult  computational challenges in implementing these procedures on modern  computer architectures."
"9706768","Moving Node Finite Element Methods","DMS","COMPUTATIONAL MATHEMATICS","08/01/1997","08/05/1997","Neil Carlson","IN","Purdue Research Foundation","Standard Grant","Junping Wang","07/31/2000","$75,000.00","","","1281 WIN HENTSCHEL BLVD","WEST LAFAYETTE","IN","479064182","3174946200","MPS","1271","9216, 9263, HPCC","$0.00","9706768   Neil N. Carlson     ABSTRACT (Moving Node Finite Element Methods)    The gradient-weighted moving finite element method (GWMFE) is an adaptive  method well-suited to problems which develop sharp moving fronts, especially  those problems where one must resolve the fine-scale structure of the front.  Three works related to the method are planned.  First, development of GWMFE  in 3-D will continue.  The recently completed scalar code will be extended  to systems of equations and the direct linear solver will be replaced by  iterative techniques based on the work of Miller and Xaba.  The code will be  applied to a variety of difficult PDEs and PDE systems: Stefan-type problems,  drift-diffusion equations from semiconductor device modeling, the time  dependent Ginzburg-Landau equation, are some possible examples.  A parallel  version of the code will also be developed.  Second, a new moving mixed finite  element method will be implemented in 2-D and 3-D.  Here, in the spirit of  the mixed finite element method, the diffusive flux is approximated in an  independent finite element space (BDM or RT) and a coupled system of ODEs  is then obtained via the same variational argument used in the moving finite  element method.  This new method gives a more rigorous treatment of diffusion  terms, and in 1-D gives superior grid adaptivity.  Third, in collaboration  with Miller (Berkeley), global adaptivity will be added to GWMFE in 2-D.  This global adaptivity will be achieved through the periodic addition,  deletion, and reconnection of nodes based upon geometric criteria, which  are easily identifiable through simple eigenvalue analysis, and upon local  projection error estimates.  This complements the very fine local adaptivity  GWMFE achieves through the continuous motion of its nodes, and is essential  for a robust method.    Many physical processes are modeled by partial differential equations.  A solution of such an equation might give, for example, the concentration of  of arsenic in a semicon ductor substrate at each instant of time and each  point in one, two, or three dimensional space.  Because it is generally  impossible to find the exact solution of such an equation, approximate  solutions must be sought using some computer-based technique.  For a large  class of difficult problems standard techniques are extremely wasteful and  inefficient, making computations in two, and especially three, dimensions  very difficult if not altogether impossible.  More sophisticated adaptive  techniques seek to overcome this difficulty.  The gradient-weighted moving  finite element method (GWMFE) is one such technique, and it offers some  significant advantages over more conventional adaptive methods.  This project  seeks to advance GWMFE and related methods in several directions.  First,  a full implementation of GWMFE in the computationally challenging three  dimensional case will be completed, and applied to a variety of challenging  problems.  Second, a variant of the method which gives a more accurate  treatment of some problems will be investigated.  And last, a complementary  global adaptivity will be added to GWMFE in two dimensions which will  substantially enhance the robustness of the method.  GWMFE has been applied  to a variety of difficult problems with great success, including problems  from semiconductor device manufacture and device simulation, groundwater  transport and oil reservoir engineering, and time dependent models of  superconductors.  Being able to computationally model problems like these  is becoming ever more important to scientists and engineers.  GWMFE shows  great promise in making some of these difficult problems efficiently  computable in two and three dimensions, some of which are currently  inaccessible with existing techniques."
"9704458","Models of Biological Transport in Ionic Channels","DMS","Molecular Biophysics, COMPUTATIONAL MATHEMATICS","09/01/1997","08/22/1997","Joseph Jerome","IL","Northwestern University","Standard Grant","Michael Steuerwalt","08/31/2000","$58,761.00","","jwj@math.northwestern.edu","633 CLARK STREET","EVANSTON","IL","602080001","3125037955","MPS","1144, 1271","0000, 9263, OTHR","$0.00","Jerome  9704458       The investigator develops, analyzes, and computes with  models of biological transport for ionic channels.  Ionic channels  are now known to mediate significant electrical activity through  cellular membranes.  The discovery of the patch clamp has made  experimental verification of such electrical currents possible.  Theoretical predictions proceed through a hierarchy of models.  For the simpler models, categorization of possible behavior is  sought, and the dynamics carefully studied.  In particular, gating  is analyzed in great detail; this includes both regular and  anomalous behavior.  An understanding of the relation of the  channel to its ambient environment is achieved through the  calculation of the heat exchange of the protein.  In addition, a  complex asymptotic procedure yields a high field model,  particularly appropriate for channels, yet originally developed  for semiconductors.  This proposal benefits from the  investigators' previous experience in semiconductor modeling.  The  common thread of electro-diffusion leads to mathematical models  of surprising similarity.  This analogy has facilitated some  interesting studies, as well as some provocative conjectures.  One  of these deals with the role of temperature in channels.  Another  deals with so-called active transport, and the association with  the molecule ATP.       Ionic channels are protein molecules in cell membranes, and  have been linked to such diverse applications as drug receptors  on the one hand, and irregular gating in the brain and mental  illness on the other hand.  The investigator and colleagues in  mathematics and biology model the electrical and energetic  activity of channels.  The project greatly benefits from the  similarity in the mathematical models developed for both ionic  channels and semiconductor devices.  Whereas electrical currents  are induced by ions in channels, a similar role is played by  electrons and holes in semiconductors.  Powerful electric fields  coexist with int ense biological activity in the channel pore.  The  principal investigator and his colleagues study these analogies,  as well as separate issues of biological import, including the  possibility of explaining, in mathematical terms, the pulses  associated with the opening and closing of channels and the  energetics associated with active transport, including the action  of various ion ""pumps."" The work aims to clarify details  surrounding energy exchange, heating, and temperature variation.  The project uses both mathematical analysis and extensive  computer simulations."
"9704911","Nonlinear Dynamic Forecasting for Signal Processing         Applications","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/01/1997","06/26/1997","Kevin Short","NH","University of New Hampshire","Standard Grant","Henry Warchall","06/30/2001","$70,594.00","","kevin.short@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","MPS","1266, 1271","9216, 9263, HPCC","$0.00","9704911  Short    This project will attempt to develop signal processing techniques based on   nonlinear dynamic (NLD) forecasting. Traditional signal processing   approaches have generally relied upon the assumption that systems are   either periodic/quasi-periodic or random.  The NLD forecasting approach   attempts to bridge the gap between these approaches by assuming that there   may be a deterministic component which is responsible for the observed   complex behavior.  Prior work on a test case has shown that it is possible to   use NLD forecasting to predict seismic background noise sufficiently well   that it is possible to reduce the noise by over an order of magnitude, making   it possible to see hidden teleseismic events.  In other applications, NLD   forecasting has been used to unmask secure chaotic communication   schemes by predicting the dynamics of the chaotic carrier with sufficient   accuracy that the hidden messages may be extracted.  The proposed research   will expand the use of multi-step forecasting methods so that predictions   can be made for longer times, and so that signal extraction may be   improved.  Resumming techniques will also be studied, where a series of   short-term predictions will be used to rebuild the hidden signals.  Seismic   data from various sites will be examined to explore the limits of   predictability, and an attempt will be made to develop real-time processing   techniques which will aid in monitoring of nuclear treaties.  The link   between spectral signal processing methods and NLD processing will be   studied so that the tools can be used in a complementary and integrated   manner.  Curvature-based methods of NLD processing will be developed   for time series where it is difficult to get a nice phase space reconstruction.    NLD forecasting will be used to create statistical ensembles which can then   be considered from a statistical processing perspective.  Success in these   research areas will represent significant progress in the developme nt of   NLD signal processing as an important new technology.    This project will attempt to develop a new signal processing technology   based on nonlinear dynamic (NLD) forecasting. Traditional signal   processing approaches have generally relied upon the assumption that   systems are either periodic or random.  NLD signal processing recognizes   that many systems which appear to be random may be produced by   processes which are inherently predictable, at least in the short-term.  In   fact, it is the ability to make accurate short-term predictions which   distinguishes nonlinear dynamic systems (also known as chaotic systems)   from typical random systems.  These NLD prediction techniques have   already been used on a test case of seismic background noise provided by   the Air Force Technical Applications Center (AFTAC), where it was shown   that the background noise could be predicted so well that after the predicted   background was removed, one could clearly see the presence of hidden   signals which were essentially equivalent to distant nuclear test detonations.    In another application, NLD prediction techniques have been used to extract   hidden messages from chaotic communication systems, where the   predictions about the behavior of the chaotic carrier signal were so accurate   that when they were removed, the hidden message signal could be observed.    The proposed research will expand these NLD forecasting methods to   improve the extraction of signals from noisy environments.  The seismic   problem will be examined using various data sources to determine the limits   of predictability, and a parallel processing implementation will be used to   attempt to develop a real-time processing system which may be useful for   monitoring of nuclear treaties.  Further research will examine the   connection between NLD techniques and traditional signal processing   techniques.  Success in these research areas will represent significant   progress in the development of NLD signal processing  as an important new   technology."
"9706865","Research at Undergraduate Institutions, Collaborative       Research:  Physical Knot Theory","DMS","COMPUTATIONAL MATHEMATICS","08/01/1997","08/07/2001","Gregory Buck","NH","Saint Anselm College","Standard Grant","Junping Wang","07/31/2001","$65,184.00","","gbuck@anselm.edu","100 SAINT ANSELMS DR","MANCHESTER","NH","031021310","6036417174","MPS","1271","9139, 9178, 9229, 9263, SMET","$0.00","Buck  9706865       The investigator collaborates with Prof. J. Simon,  University of Iowa, to study knots and their applications.  Knots  are closed loops in space that may be tangled in complicated and  essential ways.  While knots usually have been studied as  idealized one dimensional filaments, the focus here is on  ""physical knots,"" knots made of real physical stuff, from rope to  DNA or other large flexible molecules.  These are modeled as  mathematical knots endowed with physical like properties such as  self repelling energy or thickness.  The twin goals of physical  knot theory are to mathematically model and help understand the  real physical systems, and to use the physically inspired  measures of knot-complexity to develop novel methods for knot  recognition and classification.  The specific targets of this  project include: determining precise relations between different  measures of knot complexity, understanding critical points and  the configuration space of polygonal knots, understanding the  connections between parametrizations and topological properties  of harmonic knots, extending knot energy ideas to other  structures such as graphs, modeling gel electrophoresis of DNA  loops, and using knot energies to help understand physics  phenomena such as self-radiating tubes and knotted vortices.       Knotting and tangling happen at every scale studied by  science, from microscopic DNA loops to everyday rope to tangled  magnetic field loops in the solar corona.  The investigators and  their students will study problems that are fundamental and arise  in all the physical systems:  How are knots and tangles created?  What mathematical properties of the physical systems lead to  knots becoming simplified or completely untangled?  How do the  mathematical properties of different kinds of knots influence  their physical behavior?  One focus task is to gain a better  understanding of gel electrophoresis of DNA loops, hence of the  gel process itself; this is one of the most important  b iotechnology techniques, so a solid understanding is important.  The project requires powerful computing and visualization, so it  will train students, as well as stretch the technology, in these  areas."
"9616920","Mathematical Sciences:  Continuous Complexity and Dynamical Systems","DMS","COMPUTATIONAL MATHEMATICS, ANALYSIS PROGRAM","08/15/1997","08/21/1997","Michael Shub","NY","IBM Thomas J Watson Research Center","Standard Grant","Michael Steuerwalt","02/28/2001","$61,000.00","","shub.michael@gmail.com","1101 KITCHAWAN RD","YORKTOWN HEIGHTS","NY","10598","7137974625","MPS","1271, 1281","0000, 9263, OTHR","$0.00","Shub  9616920       The investigator continues studies of the complexity theory  of continuous problems and dynamical systems.  The main issues  are: 1) the construction of a theory of computation and  complexity which speaks to scientific computation and numerical  analysis, and 2) the extent of validity of statistical robustness  as a property of dynamical systems, especially chaotic dynamical  systems.  The research involved is of interest to a large class of  mathematicians and has implications for the relations between  abstract mathematics and computer science on the one hand and  abstract mathematics and physics and engineering on the other.       Complexity theory develops bounds on how much work a method  requires to produce the solution to a typical problem in a class  of problems.  Common and important examples include methods to  find the solutions of a system of linear or nonlinear equations.  Part of the project indeed at aims at just this issue.  Equation  solving is at the heart of much of mathematics and, together with  its computational aspects, is a main way that mathematics is used  by engineering, physics, economics, and many other disciplines.  The other part of the project studies questions about much alike  certain kinds of chaotic systems may be.  Predicting the specific  behavior of a chaotic system is difficult, because small errors  in any measurement of the system are amplified.  But chaotic  systems may be relatively nice in a statistical sense; if so,  then sets of samples measurements may provide useful information  about the system's behavior even though any single measurement is  error-prone.  The investigator studies these properties in  dynamical systems and particularly in chaotic systems.  There are  important implications for the statistical analysis of chaotic  systems --- hence practical consequences for weather and climate  studies, agriculture, and engineering."
"9706566","Applications of Variational Level Set Methods to Some       Multiphase Problems","DMS","COMPUTATIONAL MATHEMATICS","08/01/1997","07/25/1997","Hong-Kai Zhao","CA","Stanford University","Standard Grant","John C. Strikwerda","07/31/2001","$65,606.00","","zhao@math.duke.edu","450 JANE STANFORD WAY","STANFORD","CA","943052004","6507232300","MPS","1271","9148, 9216, 9263, HPCC, MANU","$0.00","9706566  Hongkai Zhao      The study and numerical computation of free boundary or interface   problems are quite challenging (especially in three dimensions) when   either there are topological changes in the free boundaries or there   are more than two phases that share a common boundary (triple junction).   This project will use the variational level set approach, which can   handle these difficulties easily and naturally to some extent, to model   several multiphase problems such as the configurations of clustered soap   bubbles, the formation of droplets on the ceiling or at the end of a  nozzle and their topological transitions. The effects of surface tension,   bulk energy and external forces will be included in the variational   formulation. Using appropriate abstract 'surface' energy, applications   to some optimal graph partitioning problems will also be made. At the   same time, robust and efficient numerical schemes will be developed for   numerical computation in 2D and 3D for these problems.      Surface energy plays an important role in many physical phenomena due  to the micro-structure of molecules, such as soap bubbles, thin films,   droplets formation, wetting and dewetting process, etc. They are also   related to minimal surface problems in mathematical literature. It is   well known that among all possible configurations of closed surfaces  which enclose a fixed volume, the sphere has the minimal surface area.  This explain why soap bubbles or oranges are rounded. The understanding   of the surface effects, its interactions with other physical effects   and numerical simulation of these free boundary problems in quite   complicated physical settings are the motivations for this project.   It will provide extremely useful information and tools for many practical  applications such as optimal shape design, etching and deposition in   microchip fabrication, plating and manufacturing of ink jet printer.  It can also be used in some optimization problems when the surface   energy  is properly interpreted, such as the optimal domain decomposition  cut for efficient parallel computing, landscape dividing or metal cuttings."
"9706789","Physical Knot Theory","DMS","COMPUTATIONAL MATHEMATICS","08/01/1997","08/06/1997","Jonathan Simon","IA","University of Iowa","Standard Grant","Michael Steuerwalt","07/31/2001","$129,000.00","","jsimon@math.uiowa.edu","105 JESSUP HALL","IOWA CITY","IA","522421316","3193352123","MPS","1271","0000, 9139, 9263, HPCC, OTHR","$0.00","Simon  9706789       The investigator collaborates with Prof. G. Buck, St. Anselm  College, to study knots and their applications.  Knots are closed  loops in space that may be tangled in complicated and essential  ways.  While knots usually have been studied as idealized one  dimensional filaments, the focus here is on ""physical knots,""  knots made of real physical stuff, from rope to DNA or other  large flexible molecules.  These are modeled as mathematical  knots endowed with physical like properties such as self  repelling energy or thickness.  The twin goals of physical knot  theory are to mathematically model and help understand the real  physical systems, and to use the physically inspired measures of  knot-complexity to develop novel methods for knot recognition and  classification.  The specific targets of this project include:  determining precise relations between different measures of knot  complexity, understanding critical points and the configuration  space of polygonal knots, understanding the connections between  parametrizations and topological properties of harmonic knots,  extending knot energy ideas to other structures such as graphs,  modeling gel electrophoresis of DNA loops, and using knot  energies to help understand physics phenomena such as  self-radiating tubes and knotted vortices.       Knotting and tangling happen at every scale studied by  science, from microscopic DNA loops to everyday rope to tangled  magnetic field loops in the solar corona.  The investigators and  their students will study problems that are fundamental and arise  in all the physical systems:  How are knots and tangles created?  What mathematical properties of the physical systems lead to  knots becoming simplified or completely untangled?  How do the  mathematical properties of different kinds of knots influence  their physical behavior?  One focus task is to gain a better  understanding of gel electrophoresis of DNA loops, hence of the  gel process itself; this is one of the most important  b iotechnology techniques, so a solid understanding is important.  The project requires powerful computing and visualization, so it  will train students, as well as stretch the technology, in these  areas."
"9727128","Iterative Methods for Large Scale Nonlinear and Linear      Systems","DMS","COMPUTATIONAL MATHEMATICS","08/15/1997","08/21/1997","Homer Walker","MA","Worcester Polytechnic Institute","Standard Grant","John C. Strikwerda","07/31/2001","$75,000.00","","walker@wpi.edu","100 INSTITUTE RD","WORCESTER","MA","016092247","5088315000","MPS","1271","9216, 9263, HPCC","$0.00","9727128  Homer Walker   Large-scale systems of linear and nonlinear equations occur almost   ubiquitously in the computational modeling of physical phenomena through   the discretization of partial differential equations, integral equations,   etc. Krylov subspace methods make up a large class of iterative linear   algebra methods that have been widely used for these large-scale linear   systems. These methods have been adapted to large-scale nonlinear systems   through Newton-Krylov implementations, in which they are used to solve   the linear systems that characterize Newton steps. This research is a   continuation of an ongoing program aimed at developing more robust and   efficient Newton-Krylov methods for nonlinear problems and, concomitantly,   more effective Krylov subspace methods for linear problems. The current   research focusses primarily on Newton-Krylov methods and related methods   for large-scale nonlinear problems. Specific objectives are to develop   more robust globalizations, to implement and test additional and more   effective Krylov solvers, to improve preconditioning strategies and options,   and to explore new techniques such as automatic differentiation. A major   extension of the previous program goals is to develop effective methods   for large-scale continuation problems. The approach is based on certain   ways of adapting Krylov subspace methods and Newton-Krylov methodology   to the continuation setting that allow the use of existing preconditioners   and other previously developed problem technology.   A particular aim of this work is to develop improved methods for large-scale   computational modeling of complex physical phenomena on high performance   computers. Particular target applications include full-physics modeling of   reactive flows (combustion and other chemically reacting flows) and related   problems in computational fluid dynamics. Success in these applications   will have great potential benefits in the design and operation of industrial   facilit ies such as furnaces for heat and power generation and chemical vapor   deposition reactors for semiconductor manufacturing. This work will build   on previously established collaborative activities with researchers at Sandia   National Laboratories, Lawrence Livermore National Laboratory, and the   University of Utah Center for High Performance Computing, in which the   methods under development have been successfully applied to a number of   realistic flow problems involving heat and mass transport on massively   parallel computers. Likely future collaborations are with researchers at   the University of Utah on modeling accidental fires and explosions and at   Lawrence Livermore National Laboratory on modeling contaminant transport in   aquifers, with applications to environmental management and bioremediation."
"9727177","Collaborative Project: Analysis of Pattern Formation        in Drosophila by Importance Sampling on Parallel Processors","DMS","Animal Developmental Mechanism, OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","08/01/1997","08/06/1997","Yuefan Deng","NY","SUNY at Stony Brook","Standard Grant","Michael Steuerwalt","07/31/2000","$75,000.00","","Yuefan.Deng@StonyBrook.edu","W5510 FRANKS MELVILLE MEMORIAL L","STONY BROOK","NY","117940001","6316329949","MPS","1119, 1253, 1271","9216, 9263, HPCC","$0.00","Deng  9727177       The investigator with John Reinitz of Mt. Sinai School of  Medicine and their colleagues study large scale optimization  methods applied to problems concerning gene networks and pattern  formation in the fruit fly Drosophila.  These optimization  problems arise in a method known as ""gene circuits"", which was  developed by one of the principal investigators and his  coworkers.  The essence of this method is the numerical inversion  of a set of nonlinear ordinary differential equations by least  squares fits of the trajectories of the equations to gene  expression data obtained by fluorescence microscopy.  In the  past, these fits were performed by simulated annealing on serial  computers using the Metropolis algorithm under the control of the  Lam cooling schedule.  They are computationally intensive, and the  range of problems that can be considered was limited by the speed  of available serial processors.  The investigators are developing  new computational methods for the solution of these problems on  parallel processors.  Importance sampling is the most efficient,  or the most important, ingredient of an algorithm in treating  complex continuum optimization problems such as the pattern  formation analysis undertaken here.  Simulated annealing is one  method for importance sampling; the investigators are developing  a general method for parallel simulated annealing on nonseparable  problems.  Other importance sampling methods are derived from  methods that make use of the continuum properties of the problem  at hand, such as Newton's method.  The investigators develop a  family of parallel importance sampling methods and then  synergistically combine them.  This family of methods includes  genetic algorithms, continuum methods, a Lagrangian reformulation  of the fitting problem, and simulated annealing.       Networks of interacting genes lie at the heart of the  problems that will face biologists and biotechnologists in the  twenty first century.  Processes ranging from e mbryonic  development to cell division and cell death are controlled by  networks of genes.  In order to understand how these networks  work, it is necessary to understand their internal ""wiring  diagrams"".  In particular, it is important to know how genes turn  each other on and off.  Modern molecular biology allows  investigators to see which genes are on or off at a given moment,  but in order to understand the ""wiring"" between genes, it is  necessary to analyze changes in gene activity over time and  analyze them by computer.  The method of analysis can be reduced  to an ""optimization"" problem, in which the smallest value of a  complicated function is sought.  In this project, the  investigators are finding new ways to solve optimization problems  on large scale parallel high-performance computers.  Particular  emphasis is placed on parallel methods for simulated annealing,  an exceptionally powerful optimization method.  This research is  important to many areas beyond gene networks.  Simulated annealing  and related methods are used in structural biology and other  biotechnology areas related to drug discovery.  It is also used in  the design of integrated circuits.  These and other areas are  likely to benefit from this work.  Funding for the project is  provided by the program of Computational Mathematics and the  Office of Multidisciplinary Activities in MPS and by the  Developmental Biology program in BIO."
"9700867","Pilot Projects to Explore Large Data Sets","DMS","OFFICE OF MULTIDISCIPLINARY AC, STATISTICS, COMPUTATIONAL MATHEMATICS","06/15/1997","03/27/1998","Jerome Sacks","NC","National Institute of Statistical Sciences","Standard Grant","Michael Steuerwalt","05/31/2001","$810,582.00","Alan Karr","sacks@niss.org","19 TW ALEXANDER DR","RESEARCH TRIANGLE PARK","NC","277090152","9196859300","MPS","1253, 1269, 1271","0000, 1504, 9263, OTHR","$0.00","Large data sets are a given in modern industry, technology and  science, and demand statistical attention to treat such central  issues as detecting new patterns and relationships in a reliable  and computationally feasible way.  While the need is apparent,  paths to bringing statistical science to bear on large data sets  are not clearly mapped, in part because the sheer volume of the  data prevents direct use of standard techniques.      This proposal comprises a pair of interconnected pilot projects  targeted to stimulate statistical science entree to this rapidly  changing terrain.  Each has a major industria;l partner, which  has committed substantial resources.  The projects and partners  are Drug Discovery (Glaxo Wellcome, Research Traingle Park, NC)  and Telecommunications Fraud (AT&T Laboratories, Murray Hill,  NJ).  In both instances there are specific scientific isues with  high-stakes implications for the industry at large; each is  speculative, in the sense that the path from data to information  to knowledge is not known in advance.    In drug discovery, the critical problem is to find new potent,  non-toxic compounds.  New statistical methods will be developed  to search substantial data sets generated by recent advances in  robotic synthesis and screening in order to identify key features  of compounds, leading to better ones, in the presence of highly  complex (and very high-dimensional) descriptions of the  molecules.    Within the hundreds of millions of long distance calls per day a  small fraction are illegal or unauthorized, but result in costs  of hundreds of millions of dollars annually.  The problem is to  detect and characterize, as rapidly as possible, patterns of  transactions that are unusual, and potentially fraudulent, with  special attention to controlling error rates (false alarms,  failures to detect), an issue exacerbated by the enormous  multiplicity of decisions made on a continual basis.    The two problem areas have common features: sequential  statistical  search for important or unusual patters in the data;  data that are highly complex in sheer quantity, in high-dimensional description of each data point, or in the diversity  of their sources.  Approaching these issues will be done by teams  of cross-disciplinary researchers at distributed sites and  closely managed by NISS.    This GOALI project is jointly supported by the MPS Office of  Multidisciplinary Activities (OMA) and the Division of  Mathematical Sciences (DMS)."
"9722814","Characterization of Spatiotemporal Chaos","DMS","COMPUTATIONAL MATHEMATICS, MATHEMATICAL PHYSICS","08/01/1997","08/06/1999","Henry Greenside","NC","Duke University","Continuing Grant","Junping Wang","07/31/2001","$104,063.00","","hsg@phy.duke.edu","2200 W MAIN ST","DURHAM","NC","277054640","9196843030","MPS","1271, 1287","0000, 9178, 9216, 9263, HPCC, OTHR, SMET","$0.00","9722814  Henry Greenside           ""CHARACTERIZATION OF SPATIOTEMPORAL CHAOS""         Renewal of support is requested for interdisciplinary research     (nonequilibrium physics, nonlinear dynamics, and computational     mathematics) concerning the characterization of spatiotemporal     chaos in large nonequilibrium systems such as those found in     biological, chemical, fluid, and laser systems. The research     will use numerical methods, parallel computers, and carefully     chosen mathematical models to explore two questions: (1) how     is spatiotemporal chaos related to the mathematical structure     of attractors in phase space? and, (2), can the infinite     hierarchy of unstable periodic orbits associated with a     strange attractor be used to characterize and control     high-dimensional chaos? The proposed research will: (a) yield     new methods for analyzing spatiotemporal data accumulated by     experimentalists and by computational scientists; (b) provide     new information about unstable periodic orbits (UPOs)     associated with extensive chaos and suggest new strategies for     their stabilization; (c) provide new insights about parallel     numerical algorithms for finding unstable periodic orbits of     partial differential equations in large spatial domains ; and     (d) give valuable training to students and postdocs at Duke in     the numerical analysis, simulation, and theory of complex     nonlinear dynamical systems.             Many problems in basic and applied science require a deeper     understanding of sustained nonequilibrium systems in which     complicated time-dependent behavior is caused by a steady flux     of energy and matter into a system. Examples can be found in     almost all areas of science but might include fluid     turbulence, fibrillation in a heart, epilepsy in a brain, the     design of high-power lasers, and instabilities of electrical     power grids. A fundamental question of high current interest     for many areas of science is how to re late the spatial     structure of a complex nonequilibrium medium to its temporal     state, especially when the system varies nonperiodically     (chaotically) in time. The proposed research suggests two ways     of addressing this question that have yet been incompletely     explored by previous research. This research will use applied     mathematics and computer simulation to study simplified     mathematical models in which spatial and temporal structure     can be examined in detail, and then various insights will be     tested with experimental data. Eventually, this research     should improve engineering control and design of complex     systems as well as provide a foundation for developing a     fundamental theory of sustained nonequilibrium systems."
"9703720","Expanding the Spectral Envelope","DMS","STATISTICS, COMPUTATIONAL MATHEMATICS","07/15/1997","02/01/1999","David Stoffer","PA","University of Pittsburgh","Continuing Grant","Joseph M. Rosenblatt","06/30/2001","$150,000.00","","stoffer@pitt.edu","4200 FIFTH AVENUE","PITTSBURGH","PA","152600001","4126247400","MPS","1269, 1271","0000, 9216, 9263, HPCC, OTHR","$0.00","Stoffer   DMS-9703720    The concept of the spectral envelope was recently introduced as a general statistical method for the frequency domain analysis and scaling of qualitative-valued time series.  In the process of developing the technology, many other interesting extensions became evident.  This research involves the extension of the fundamental concept in various directions.  The first extension   involves matching two categorical sequences in an effort to discover whether they contain similar patterns and is motivated by the problem of matching of two DNA sequences.  The approach builds on the ideas used in defining the spectral envelope and focuses on what could be called coherency envelopes for measuring the similarity between two categorical time series.  Estimation is based on the fast Fourier transform so that the methods are computationally simple and fast, and can be applied to long sequences.  In another direction, the technology is extended to the analysis of qualitative spatial data.  The applications that motivate this project are automated image retrieval and pattern recognition with potential use in computer vision.  Specifically, this part of the research will focus on the analysis of categorical random fields via optimal scaling and the wave number spectral envelope.  Since many of the applications where the spectral envelope methodology has been an asset are situations where the assumptions of stationarity and homogeneity are not realistic, this research will explore the benefits of wavelet-based analysis over dynamic Fourier analysis.  Another extension of this research is to apply the concept to the analysis of real-valued time series collected in an experimental design where the primary interest is whether any, and how many, have common cyclic components.  This problem is motivated by numerous applications in the medical and behavioral sciences.    A statistical concept called the spectral envelope was recently introduced as a general method to study patterns in long seq uences of letters or symbols (such as codes).  The most well known application of this methodology is in biotechnology, specifically in the analysis of DNA.  In the process of developing the concept, many other practical extensions became evident.  This research involves the extension of the fundamental concept in various directions.  The first extension involves matching two non-numeric sequences in an effort to discover whether they contain similar patterns and is motivated by the biotechnical problem of finding similarities in two otherwise different genetic codes.  Another direction is to extend the technology to qualitative spatial data (such as images) with applications in automated image retrieval, automated pattern recognition, and computer vision.  This research will have an impact on robotics and automation technologies that will be useful, for example, in industrial manufacturing processes.  Moreover, the methodology used in matching sequences could have applications in computer vision and robotics where the problem is to automatically and quickly align two pictures of the same scene taken from different camera angles.  In addition, this research will focus on ways to incorporate this new technology into current medical applications such as understanding changes in biorythms in stressful situations."
"9706903","Approximation of the Global Attractors of Evolution         Equations","DMS","COMPUTATIONAL MATHEMATICS","08/01/1997","08/17/2000","Michael Jolly","IN","Indiana University","Continuing Grant","Michael Steuerwalt","07/31/2001","$182,145.00","Ciprian Foias","msjolly@indiana.edu","107 S INDIANA AVE","BLOOMINGTON","IN","474057000","3172783473","MPS","1271","0000, 9216, 9263, HPCC, OTHR","$0.00","9706903   M. Jolly            Abstract    This project concerns the long time behavior of certain dissipative  physical systems.  One major component seeks to locate global  attractors by interpolatory means rather than by direct numerical  solution of initial value problems.  It would extend our previous work  which used a Taylor expansion in complexified time at a single point in  phase space.  The new approach will use several points, typically those  on solutions provided either by independent computations or from  experimental data.  The main mathematical tool in this effort will be  Nevalinna-Pick interpolation.  The systems on which this will be tested  include the 2-D Navier-Stokes (NS), Kuramoto-Sivashinsky (KS) Lorenz  equations as well as simple geostrophic models.  Another major  component is to compute invariant manifolds to arbitrary accuracy.  We  will use the visualization of 2-D (un)stable manifolds to help  understand the geometric mechanisms behind certain global bifurcations  in 3-D phase space.  This involves computing a major portion of global  manifolds.  Other applications require only that the manifold be  computed along particular trajectories.  In one case a center manifold  will be treated in this way to compute bounded solutions to an elliptic  partial differential equation (PDE) in an infinite cylinder.  In  another, the dimension of phase space for the KS equation will be  effectively reduced to three dimensions by restricting the flow to an  inertial manifold of that dimension.  Such a reduction will allow us to  study global bifurcations as described above.  The algorithms developed  to compute these manifolds will also be applied to the sets  (conjectured to be manifolds) of a prescribed exponential growth rate  backward in time for the NS equation.  In fact we will construct such  sets as stable ""manifolds"" for an inverted form of the NS equation in  which infinity and the origin of phase space are swapped.  These sets  play a role in the interpolatory approach  to locating global  attractors, and thus bring our research full circle.    The main purpose of this work is to develop reliable methods to  determine whether certain dynamic behavior in physical systems is  permanent, or merely temporary.  The ultimate application will be to  climatology.  Since the earth's weather system has been evolving for  millions of years, one would expect that unless sudden external events  take place, the patterns we are living through now will more or less  continue for a reasonable period of time. This is not about accurate  long time forecasting, rather it is about confirming basic assumptions  regarding the mathematical models used in making those predictions.  The scientific community makes a tremendous effort in deriving  appropriate mathematical equations, and discretizing them so they can  be solved on a computer, all to produce a function of time, which  should describe some aspect of the weather.  We all know how often this  computed function of time deviates from the actual weather after a  relatively short time period.  The major source of this error is not  clear.  Is it in the model itself?  Is it from the numerical  approximation in the computer solution?  Or is it that both the model  and the approximation are valid, but the actual solution is very  sensitive to small changes in the initial data, and we simply need to  tighten the tolerance of error in that data and in the algorithm used  at each time step.  Our work is directed at distinguishing between the  first two cases and the third.  Indeed we seek to validate the  model-algorithm pair which produces the forecast, as producing a  pattern which is of a permanent nature, even if it is not the  particular pattern we are experiencing after several days time.  The  failure of such a test will indicate that either the model and/or the  method of solution are faulty.  This approach can be applied to other  physical problems.  Indeed the initial testing of the methods will be  done on systems less invol ved than that of the weather, but which are  nevertheless of current scientific interest.  In particular we consider  fundamental models of combustion, fluid flow, and turbulence."
"9705229","Theoretical and Computational Problems in Fluid Mechanics   and Climatology","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, LARGE-SCALE DYNAMIC METEOROLOG, PHYSICAL OCEANOGRAPHY","09/01/1997","08/04/1998","Roger Temam","IN","Indiana University","Standard Grant","Michael Steuerwalt","08/31/2000","$382,500.00","Ciprian Foias","temam@indiana.edu","107 S INDIANA AVE","BLOOMINGTON","IN","474057000","3172783473","MPS","1266, 1271, 1527, 1610","0000, 1303, 9216, 9263, EGCH, HPCC, OTHR","$0.00","Temam  9705229       The understanding of the equations of fluid mechanics and  turbulence as well as the development of efficient numerical  codes for the solution of these equations are challenging  problems of considerable importance, in particular in industry or  for studies in meteorology or global climate change.  The aims  for this project are to explore what can be learned about these  problems from the theoretical and computational viewpoints, using  the dynamical systems approach to turbulence.  More specifically  the investigators and their colleagues intend: (i)  to develop  new efficient computational algorithms taking into account the  physics of turbulence and well adapted to the current evolution  of large scale computing towards parallel computing; (ii)  to  devote special attention to the problems related to the study of  the climate and global changes.  For (i), new multilevel  algorithms related to the concept of attractor and approximate  inertial manifolds have been introduced during the past years.  The analysis of these algorithms is developed, their performances  improved, and their range of application extended, in particular  towards problems of practical relevance.  During the period of  this grant a book will be published on this subject, describing  the state of the art on the theoretical side, and including many  aspects of their actual implementation on parallel computers.  For  (ii), a significant part of this project is devoted to the study  of models for the atmosphere, the ocean and their coupling.  Involved models based on the primitive equations are considered,  as well as simpler models such as multilayer or quasi-geostrophic  models.  The study includes the development of the models and the  mathematical and numerical problems that they raise.       The interaction of meteorology and mathematics has very long  traditions going back to such famous names as Leonard da Vinci,  Pierre Simon Laplace or, in this century, after WWII, John Von  Neumann.  At a more  modest level, the investigators pursue a  program of research initiated a few years ago and aimed at  developing interactions between geosciences and mathematics.  These interactions can be mutually beneficial.  Meteorology and  oceanography raise very challenging mathematical problems very  useful for mathematicians and other scientists (for example  scientists have learned much from the experience of E.  Lorenz in  chaos).  Conversely, mathematicians might help scientists of the  geoscience communities in choosing their models by determining if  they are well posed.  In the long range they might help also  develop new efficient numerical procedures; although the codes  (programs) used in meteorology and oceanography are very involved  codes written over a long period of time, eventually new codes  will be written responding to new needs or new opportunities, and  new insights could become useful; it is hoped to contribute to  this daunting task."
"9706847","Efficient, High Resolution, Numerical Methods for           Free-boundry Problems with Surface Tension","DMS","COMPUTATIONAL MATHEMATICS","08/01/1997","07/25/1997","Mark Sussman","CA","University of California-Davis","Standard Grant","John C. Strikwerda","07/26/1999","$67,603.00","Elbridge Puckett","sussman@math.fsu.edu","1850 RESEARCH PARK DR, STE 300","DAVIS","CA","956186153","5307547700","MPS","1271","9148, 9216, 9263, HPCC, MANU","$0.00","9706847  Sussman    This research concerns the analysis and development of numerical techniques for modeling solutions of the Navier-Stokes equations for two-phase incompressible flow.  This methodology is specifically targeted at problems characterized by large density and viscosity jumps (e.g.  air/water) and stiff, singular source terms, such as those due to the surface tension force.  Problems with these features are extremely important in science and industry.  Casting, mold filling, thin film processes, extrusion, spray deposition and jets are just a few examples.  These problems present considerable challenges.  Standard finite difference methods can either be too dissipative or too oscillatory near regions of large density variations.  The resulting elliptic equation for enforcing the divergence free condition on the velocity field (projection step) has coefficients that exhibit a large jump at material interfaces.  The resulting elliptic equation will also have a widely varying source term at material interfaces, since the divergence of the surface tension term will appear as a singular source term for the projection equation.  In this research, the proposers plan to work in close collaboration with Dr. John Andrews of Xerox and David Wallace of Microfab technologies in developing numerical methods for modeling jetting devices.  In an ink-jet device, it is important to study the characteristics of droplet formation.  Because surface tension plays a large role in the droplet formation process, it is important for a numerical method to accurately model the surface tension effects during break-up of a droplet.  It is also important for a numerical method to accurately predict the size of emitted droplets.  Currently an adaptive level set method and a second order volume-of-fluid method have been developed for computing two-phase flows as characterized above.  Objectives of the proposed research include improved numerical modeling of the interface between material boundaries and improved mo deling of surface tension, especially at points of droplet break-up.  In the process of this study, the proposers will compare the behavior of the levelset method to that of the volume of fluid method which use a very similar formulation for the surface tension force.  The proposers will also compare numerical solutions to solutions obtained  via asymptotic methods and drop experiments conducted by Xerox.     This research concerns the analysis and development of numerical techniques for modeling incompressible two-phase flow (such as air and water).  Problems in two-phase flow are extremely important in science and industry.  Casting, mold filling, thin film processes, extrusion, spray deposition and jets are just a few examples.  In this research, the proposers plan to work in close collaboration with Dr. John Andrews of Xerox and David Wallace of Microfab technologies in developing numerical methods for modeling jetting devices.  These companies develop jetting devices used in ink-jet printers, solder deposition and the fabrication of micro-optical elements.  In a jetting device, it is important to study the characteristics of droplet formation.  Because surface tension plays a large role in the droplet formation process, it is important for a numerical method to accurately model the surface tension effects during break-up of a droplet.  It is also important for a numerical method to accurately predict the size of emitted droplets.  Objectives of the proposed research include improved numerical modeling of the interface between material boundaries and improved modeling of surface tension, especially at points of droplet break-up.  In the process of this study, the proposers will compare the behavior of the computational method with drop experiments conducted by Xerox."
"9711224","Evolution PDEs in Inhomogeneous Media: Low-Dimensional      Dynamics, Computation and Applications","DMS","COMPUTATIONAL MATHEMATICS","08/15/1997","08/05/1997","Yannis Kevrekidis","NJ","Princeton University","Standard Grant","Michael Steuerwalt","07/31/2000","$214,000.00","","yannis@princeton.edu","1 NASSAU HALL","PRINCETON","NJ","085442001","6092583090","MPS","1271","0000, 9263, OTHR","$0.00","Kevrekidis  9711224       The investigator and his collaborator Edriss Titi of the  University of California, Irvine, study the long-time behavior of  solutions to dissipative evolution partial differential equations  under perturbations; they undertake a combined theoretical and  computer-assisted approach, with a number of illustrative  applications in mind.  These spatiotemporal perturbations are  motivated physically by phenomena occurring in media with varying  properties, such as reaction and diffusion in inhomogeneous media  (leading to PDEs with spatially or spatiotemporally dependent  coefficients).  They may also be the result of a feedback control  loop on a spatially distributed system.  In the project, they are  interested in maintaining / exploiting / prescribing  low-dimensional dynamics through large amplitude perturbations  and/or scale variation effects.  The tools they build upon are the  global machinery of inertial and approximate inertial manifolds,  as well as scientific computing for the simulation and the  bifurcation and stability analysis of nonlinear evolution PDEs.  The new set of questions they address requires the extension and  combination of these tools with aspects of separation of time  scales in control theory (e.g. persistence of inertial or  approximate inertial manifolds in closed loop systems) or in  homogenization theory (when coefficients in the PDE representing  properties of the medium vary on disparate spatial scales).       This project extends, develops and implements mathematical  and computational tools that enhance our ability to study  reaction and transport processes (modeled by dissipative  nonlinear evolution partial differential equations) under  inhomogeneous conditions.  Such conditions constitute more the  rule than the exception under realistic physical circumstances,  whether due to imperfections in the process (in which case we  want to guarantee a certain level of performance) or due to  intentional design of composite media, or to fe edback control  (where we attempt to optimize a process, like the selectivity of  a chemical reaction).  The method and algorithm development part  of the project is applicable to a wide class of such systems.  The  particular applications, however, focus on the modeling, analysis  and design of novel composite catalysts for heterogeneous  reactions, and on the exploitation of modeling for the control of  spatially extended systems (such as fluid flows)."
"9706950","Interior Point Methods for NLP Problems in Process          Engineering","DMS","COMPUTATIONAL MATHEMATICS, Proc Sys, Reac Eng & Mol Therm","08/15/1997","08/11/1997","Lorenz Biegler","PA","Carnegie-Mellon University","Standard Grant","John C. Strikwerda","07/31/2000","$99,000.00","Reha Tutuncu","lb01@andrew.cmu.edu","5000 FORBES AVE","PITTSBURGH","PA","152133815","4122688746","MPS","1271, 1403","9146, 9216, 9263, HPCC, MANU","$0.00","9706950    Biegler    This proposal deals with the development and application of  interior-point methods (IPMs) to nonlinear programming (NLP) problems.  Particular attention will be devoted to large-scale and structured  quadratic programming problems that are encountered as subproblems in  the solution of NLPs coming from chemical process engineering.  The  proposed research will focus on exploiting the structure of various  classes of process engineering problems through efficient decomposition  methods in large-scale linear algebra.  In addition, principal  investigators will develop and refine an interior-point strategy that  has close parallels with successive quadratic programming (SQP)  algorithms and address some open questions related to the efficient use  of warm-starts in IPMs.  Finally, these algorithms will be implemented  to demonstrate their performance on large-scale problems in process  engineering.    Increased international competition along with environmental  constraints and resource limitations require much more sophisticated  design and manufacturing strategies for chemical process industries.  Over the past decade these needs have started to be addressed by  efficient optimization strategies. Nevertheless, the size and  complexity of these problems (with sizes approaching a million  variables) impose a heavy burden on current optimization algorithms.  The proposed research will allow the solution of much larger  optimization problems faced by this industry. Through the development  and application of interior point methods for nonlinear programming, we  will be able to develop tailored solution strategies for the  optimization of large-scale steady state and dynamic process models.  This will lead to consideration of much larger and more difficult  process engineering models, as well as the integration of multiple  processes. The result will lead to chemical processes that are  environmentally benign, very efficient in the conversion of raw  materials to products and hi ghly competitive in today's marketplace."
"9706594","hp Finite Element Methods for Shells and Partitioned        Domains","DMS","COMPUTATIONAL MATHEMATICS","08/01/1997","08/01/1997","Manil Suri","MD","University of Maryland Baltimore County","Standard Grant","Michael Steuerwalt","07/31/2000","$76,000.00","","suri@math.umbc.edu","1000 HILLTOP CIR","BALTIMORE","MD","212500001","4104553140","MPS","1271","9216, 9263, HPCC","$0.00","Suri  9706594       The investigator studies problems arising in the h-p finite  element method.  The first problem investigated is how h-p  discretization of a complicated domain can be accomplished by  partitioning it to several independent workers, and then  reassembling the pieces, without assuming compatibility of the  sub-meshes.  The objective is to develop algorithms that use  Lagrange multipliers at the interface together with proper  mesh/degree combinations, and preserve the (exponential) h-p  convergence rates obtained when the domain is analyzed without  partitioning.  The second problem is obtaining robust,  mathematically certified h-p methods for shells.  Finite element  modeling of shells is complicated by boundary layers and locking  phenomena, which seriously affect convergence rates when the  shell is thin.  The goal is to design methods free of locking  (such as mixed methods), which resolve the boundary layers as  well.       The finite element method for solving differential equations  incorporates a mesh --- a quilt of small pieces that fit together  to make up the region where the equation holds --- and a set of  functions, usually polynomials, for each piece of the quilt.  Accuracy of the method depends on how fine the mesh is and how  high the degree of the polynomials may be.  The h-p finite element  method couples mesh refinement with polynomial degree increase  for enhanced accuracy and convergence.  Finite element modeling is  used extensively in industry, from aircraft and automobile  manufacture, to structural analysis in civil engineering, to the  precision design and fitting of e.g. electronic components.  Many  large or complicated problems (such as the modeling of an  aircraft) must be first broken into separate pieces (such as the  fuselage, wings, etc.), to be meshed separately.  This project  develops methods by which such components can be accurately and  efficiently reassembled for the final modeling.  Also, individual  components (for example wings) are  often ``thin'' and therefore  modeled as plates and shells.  The finite element modeling of  shells poses special problems, and robust methods are developed  and analyzed to address them.  The research affects  state-of-the-art engineering by influencing the development of  (and finding application in) updated versions of commercial codes  that have incorporated the new h-p finite element technology."
"9704509","Efficient Algorithms for Large-Scale Linear and Nonlinear   Finite Element Computations with Applications to Thin Shell Structures","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS, ADVANCED COMP RESEARCH PROGRAM","08/15/1997","07/14/1999","Thomas Coleman","NY","Cornell University","Continuing Grant","Michael Steuerwalt","07/31/2000","$441,000.00","Timothy Healey","coleman@tc.cornell.edu","341 PINE TREE RD","ITHACA","NY","148502820","6072555014","MPS","1253, 1271, 4080","9216, 9263, HPCC","$0.00","Coleman  9704509       The investigator and his colleagues focus on the efficient  numerical computation of global solutions of problems of  nonlinear elastostatics in a high-performance computational  environment.  Particular attention is paid to the global  post-critical behavior of symmetric imperfection-free elastic  shell structures --- the analysis of which has great significance  in understanding the large deformation response and ultimate  collapse scenario of realistic engineering structures.  A major  theme of the work is to exploit the natural parallelism, via  group theoretic techniques, in an important class of engineering  problems characterized by underlying symmetries.  They also  investigate the use of automatic differentiation software in the  context of those problems.  Finally, they study the effectiveness  of symmetry-motivated preconditioners, within the context of  Krylov iterative subspace methods, for a class of  ``almost-symmetric'' problems in structural mechanics.       Due to their high strength-to-weight ratios, thin shell  structures have been used extensively in aerospace, civil,  mechanical and nuclear engineering applications, e.g., dome  roofs, aerospace vehicles, pressure vessels, containment vessels,  etc.   Yet the ability of engineers to predict the ultimate  failure of such systems has heretofore been more of an art than a  science (relying heavily upon costly experimental verification --  see ""Computerized Buckling Analysis of Shells"", by D. Bushnell,  Martinus Nijhoff 1985).  The investigators combine new  mathematical ideas of symmeytry and nonlinear analysis with  high-performance computing methodology to analyze such systems  efficiently and systematically.  A long-term goal is to provide  engineers with useful tools for the sytematic analysis (and  ultimately better design) for this important class of structures.  Funding for the project is provided by the Computational  Mathematics program and the Office of Multidisciplinary  Activities in MPS and b y the New Technologies program in CISE."
"9705793","Finite Element Methods of Least-Squares Types","DMS","COMPUTATIONAL MATHEMATICS","08/01/1997","07/21/1997","Pavel Bochev","TX","University of Texas at Arlington","Standard Grant","John C. Strikwerda","07/31/2000","$81,000.00","","bochev@uta.edu","701 S. NEDDERMAN DR","ARLINGTON","TX","760199800","8172722105","MPS","1271","9148, 9216, 9263, HPCC, MANU","$0.00","9705793  P.Bochev        The main focus of this research is directed at the design of fast,   robust and accurate algorithms for the numerical solution of nonlinear   partial differential equations. To accomplish these objectives we   consider finite element methods based on application of least-squares   variational principles. Such principles offer significant computational   and theoretical advantages that are not present in other discretization   schemes, e.g., mixed Galerkin methods. Most notably, corresponding   least-squares methods are not subject to stability constraints, such as   the inf-sup condition, and lead to symmetric and positive definite   algebraic problems. The principal objective of the research will be to   develop, analyze and implement finite element methods that can fully  exploit the inherent advantages of the least-squares formalism,   especially in the context of realistic applications. Our efforts here   will be guided by the impact of both the mathematical structure of model   problems and the computational features of least-squares principles   upon the algorithmic design of the methods. The research will be carried   in the context of systems of partial differential equations that are   compact perturbations of linear elliptic operators. Least-squares   principles for these systems are obtained through minimization of    problem-dependent, norm-equivalent functionals. As a result,   discretization   of the associated Euler-Lagrange equations leads to systems of nonlinear   algebraic equations having symmetric and positive definite Jacobians.  These equations are solved using Newton linearization combined with   robust continuation techniques. To address large-scale computations, at   each Newton step the linearized systems are solved using robust   preconditioned iterative methods implemented without assembly of the   discretization matrix. Design of efficient preconditioners for these   iterative solvers will exploit novel ideas, including the use of negative    norms in the least-squares functionals.    With the advent of new and more powerful digital computers numerical   simulation is emerging as a viable and cost-effective alternative to   expensive field experiments and tests. However, despite the increased   computational power there is still a real and existing need to develop   fast and robust computer algorithms for a wide range of industrial   applications. This is especially true for applications involving numerical   solution of the Navier-Stokes equations. The tremendous practical   importance of these equations stems from their fundamental role    in the modeling of fluid flows arising in such diverse applications as   atmospheric motions, flow of air around aircraft, and lubrication of ball   bearings. At the same time numerical solution of the Navier-Stokes   equations in realistic settings remains difficult and computationally   challenging. Indeed, large-scale solution of these equations in three   dimensions required in applications such as weather forecast, hurricane  tracking, and modeling of air pollution, continues to be an outstanding   problem which motivates this research project. Our principal goal is to   develop new, reliable and accurate numerical algorithms for the Navier-Stokes   equations that can be used for computations carried in realistic settings. To   accomplish this we explore alternative ways to discretize the model problem,   i.e., to replace this model by a set of equations that can be solved on a   computer. The research will focus on the development of novel discretization   techniques leading to equations that require less computational resources and   that are easier to solve than the equations obtained by standard methods. This   allows us to develop more robust, faster and easier to use codes. In addition   to fluid flow problems the research will also target numerical solution of  mathematical models arising in elasticity, electromagnetics and   reaction-diffusion applications, among others."
"9896073","Mathematical Sciences:  Collaborative Research on Iterative Methods for Image Restoration","DMS","COMPUTATIONAL MATHEMATICS","10/01/1997","12/17/1997","Daniela Calvetti","OH","Case Western Reserve University","Standard Grant","Michael Steuerwalt","12/31/1998","$18,780.00","","dxc57@case.edu","10900 EUCLID AVE","CLEVELAND","OH","441061712","2163684510","MPS","1271","9216, 9263, HPCC","$0.00",""
"9706985","New Mathematics and Innovative Numerical Methods for the    Valuation of Options","DMS","COMPUTATIONAL MATHEMATICS, Economics","08/01/1997","07/25/1997","Junping Wang","TX","Texas A&M Engineering Experiment Station","Standard Grant","Henry Warchall","07/31/2001","$75,000.00","William Rundell, Richard Ewing","jwang@mines.edu","3124 TAMU","COLLEGE STATION","TX","778433124","9798626777","MPS","1271, 1320","0000, 9263, OTHR","$0.00","9706985  Junping Wang    Five important aspects on the valuation of options will be addressed.  First, we propose a new mathematical formulation for the free boundary value problem.  Second, we investigate the uniqueness and existence of the solution.  Third, we use finite element methods to compute the option price based on our proposed formulas.  Fourth, we provide iterative schemes to effectively solve the system of nonlinear algebraic equations arising from the finite element method.  Fifth, we will develop a code package that is computationally efficient and robust.  The proposed new mathematics features a weak variational approach to the time value of the option by using a Hilbert space method.  The weak form for the valuation of options opens a door to the use of finite element methods together with grid local refinement in the approximation of the option pricing function and the free boundary by efficient numerical techniques such as domain decomposition and multigrid methods.  In particular, this approach provides a very promising future for the computation of financial products involving multi-assets and securities, as the computational domain will be of multi-dimension in those applications.    Financial derivatives are a major and fast growing area in modern financial markets.  For example, according to the Swaps Monitor, the size of swaps alone, a particular kind of derivatives, was approximately $9 trillion in 1993,almost the size of the annual gross national income of the United States.  The valuation of these derivatives is practically useful, important, and mathematically challenging.  Advanced techniques in mathematics have been playing an important role in the understanding and valuation of various derivative securities ever since the first trading of these financial products.  With increasing complexity of new and exotic financial products, the demand for new and efficient techniques in mathematics and computation becomes greater type derivatives, but also has far-reaching im pact on derivative valuations in general.  The methods can be extended to currency options, interest rate options and exotic options such as Asian options and lookback options which have added difficulties due to the path-dependence of the payoff function. In particular, the methods can yield the value of various bonds based on the new and empirically relevant interest rate diffusions, resulting in the value of swaps and various mortgage-backed securities."
"9707494","Mathematical Sciences: Computations in Fluids and Materials","DMS","COMPUTATIONAL MATHEMATICS","08/01/1997","08/13/1999","Michael Shelley","NY","New York University","Continuing Grant","John C. Strikwerda","07/31/2001","$231,000.00","","shelley@cims.nyu.edu","70 WASHINGTON SQ S","NEW YORK","NY","100121019","2129982121","MPS","1271","0000, 9216, 9263, HPCC, OTHR","$0.00","9707494  Michael Shelley    These projects concern dynamics and pattern formation in complex  fluids, and singularity formation and topological transitions in  Newtonian fluids.  The first project considers the hydrodynamics of  slender elastic filaments, such as arise in liquid crystal flows, the  dynamics of phospho-lipid bilayer tubes, and in the dynamics of  biological polymers.  Building tractable computational models, that  account for hydrodynamic interactions of the filament with itself,  relies on discriminating exploitation of slenderness.  This still  gives a computationally intensive problem with high-order time-step  constraints from elasticity, interaction integrals with singular  kernels, and integral equations to be solved at every time-step.  The  second project continues towards an understanding of topological  transitions of fluid/fluid interfaces between immiscible liquids.  The  fundamental questions are: How does surface tension provoke or mediate  transitions?  What characterizes the singularity?  What physics needs  to be added to follow the transition?  And what is left of the  singularity in its aftermath?  Building upon previous work on such  singularities in the Kelvin-Helmholtz instability between immiscible  fluids, it is proposed to study, computationally and analytically,  singularities and transitions in jets that separate immiscible fluids,  both by using sharp interface models, and fluid models that have  viscosity and allow some miscibility.  The third project studies the  effect of shear-thinning, a property shared with many non-Newtonian  fluids and liquid crystal flows, on the development of the  Saffman-Taylor instability.  Some of the modelling work has already  been done, yielding a natural non-Newtonian version of Darcy's law,  relating the fluid velocity to the solution of a nonlinear elliptic  problem.  It is proposed to now simulate the full nonlinear dynamics  of such a bubble expanding into a shear-thinning liquid.  This is a  very challenging comp utational problem as it involves the solution of  nonlinear elliptic problems on an evolving domain.    Much of the fundamental dynamics of fluids and materials --  singularity and pattern formation are two central examples -- will be  understood by a progression from mathematical modelling, to developing  computational methods and relevant mathematical understanding, and  thence to large-scale simulation and data analysis through  high-performance computing.  The three projects to be pursued here all  lie at the intersection of fluid dynamics and materials science, and  all illustrate the above statement.  In the first project, it is  proposed to understand and simulate the dynamics of filamentary  structures, as arise in phase transitions of liquid crystalline  fluids, the dynamics of phospho-lipid bilayer tubes, and in the  dynamics of biological polymers.  In first example, such filaments are  of potential technological importance in the manufacture of  high-strength filaments.  The second project continues towards a  theoretical understanding of what drives the break-up into droplets of  a jet of fluid into a second, different fluid (say, oil and water).  While easy and common to observe, such behavior is strongly associated  with surface tension, an effect that is still ill-understood, and yet  lies at the heart of much basic fluid phenomena.  This will be studied  by a combination of modelling, analysis, and large-scale computation.  The final project concerns the dynamics of shear-thinning liquids  flowing in thin gaps.  Such flows are important to display device  design, and to injection molding.  Of particular interest is the  instability and pattern formation associated with a gas/liquid  interface which is driven but mediated by surface tension.  This is an  extremely challenging computational problem, requiring the development  of new simulational methods."
"9727859","Theory and Computation of Optimal Geometries","DMS","COMPUTATIONAL MATHEMATICS","09/01/1997","08/22/1997","John Sullivan","IL","University of Illinois at Urbana-Champaign","Standard Grant","Michael Steuerwalt","08/31/2000","$80,000.00","","jms@math.uiuc.edu","506 S WRIGHT ST","URBANA","IL","618013620","2173332187","MPS","1271","0000, 9263, OTHR","$0.00","Sullivan  9727859    The investigator, with his collaborators, studies geometric optimization  problems like finding minimum-energy shapes for surfaces and knots  in space.  This project completes the classification of embedded  constant-mean-curvature surfaces with three ends and extends  these results to greater numbers of ends.  The elastic bending  energy of Willmore is used computationally to drive several different  sphere eversions, and to discover new minimal surfaces in euclidean  and spherical space.  The investigator also studies the singularities  found in minimizers like soap films in higher dimensions; the foams  likely to provide solutions to Kelvin's partioning problem; and  configurations for knots that minimize energy or ropelength.    Many real-world problems can be cast in the form of optimizing some  feature of a shape; mathematically, these become variational problems  for geometric energies.  For instance, the films between cells in a  foam minimize their area and thus are constant-mean curvature surfaces.  Understanding these geometries will lead to better knowledge of important  structural properties of foam materials.  Cell membranes are more  complicated bilayer surfaces, which seem to minimize an elastic bending  energy known mathematically as the Willmore energy.  Knotted curves  achieve an optimal shape when a rope is pulled tight, or if a charged  knotted wire repels itself electrostatically; understanding such  configurations helps explain the behavior of biological molecules like  DNA.  This project explores such phsically natural problems that  are still challenging from both theoretical and computational standpoints."
"9705782","Algorithmic and Combinatorial Extensions of Continued       Fractions","DMS","COMPUTATIONAL MATHEMATICS","09/01/1997","09/04/1997","Douglas Bowman","IL","University of Illinois at Urbana-Champaign","Standard Grant","Michael Steuerwalt","08/31/2000","$75,000.00","","bowman@math.niu.edu","506 S WRIGHT ST","URBANA","IL","618013620","2173332187","MPS","1271","0000, 9216, 9263, HPCC, OTHR","$0.00","Bowman  9705782       The continued fraction algorithm is one of the most  important fundamental algorithms in mathematics.  It returns for  any given real number a sequence of rational numbers that in a  very specific sense are the best possible approximations to the  given real number.  As a consequence continued fractions have  applications throughout mathematics including, but not limited  to: finding units in quadratic fields, solving linear  congruences, identifying a rational number in a floating point  calculation, and factoring large composite numbers.  Part of this  investigation deals with finding other algorithms similar to the  continued fraction algorithm, but that give approximations that  are best in other senses.  One part of the research deals with the  problem of determining an algorithm to return best approximations  in some previously specified sense.  Another deals with  determining in what way some known algorithms are giving ""best""  results.  In much of the research, computers are used to aid in  the discovery and analysis of algorithms -- and this is necessary  as many of the algorithms of interest are quite complex.  One way  of understanding these algorithms is through their combinatorial  properties.  Thus one avenue of research being studied is into the  combinatorics of the algorithms.  Applications of the  combinatorics of the algorithms to other areas of mathematics is  also considered.       Algorithms are recipes, descriptions of how to solve a  problem step by step.  They are the basis for programs that tell  a computer what to do.  The speed of an algorithm usually depends  on the size of the problem.  For instance, the usual algorithm for  solving a linear system of equations takes about 1000 times  longer to solve a problem with 10 times more unknown variables;  algorithms for sorting a list of items may take 100 times longer  to sort a list that is 10 times longer.  For any significant  problem (modeling the earth or atmosphere, understanding the  security  of cryptosystems, protein folding, etc.) creating more  efficient algorithms is an important goal.  This project looks for  best possible algorithms for several kinds of problems.  Employing  such algorithms can make the difference between solving a problem  in five years or in five hours."
"9704852","The Numerical Solution of Elliptic Equations","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/15/1997","08/08/1997","Seymour Parter","WI","University of Wisconsin-Madison","Standard Grant","Henry Warchall","06/30/2000","$17,280.00","","parter@cs.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","MPS","1266, 1271","9216, 9263, HPCC","$0.00","9704852  Parter    These investigations will focus on three specific projects:  (1) First Order   Systems Least Square (FOSLS) methods with a special emphasis on   problems in elasticity, (2) the general over-lapping grid problem, and (3)   preconditioning strategies for Spectral Collocation Methods. At this time   computational methods for problems in elasticity are primarily based on   mixed methods which lead to indefinite problems which have proven   difficult to solve.  The FOSLS approach leads to large systems which are   generally much easier to solve.  However, despite the efforts of several   independent groups, a useful FOSLS  formulation of the elasticity problems   for general boundary conditions is still a major problem.  The overlapping   grid method has proven itself an effective tool for problems set in regions   with complicated geometry.  Further, the analysis of these methods has been   lacking until a recent breakthrough for difference equations of positive type.   Since there are limitations on the order of accuracy of such difference   methods there is a need for further analysis. Spectral Collocation methods   are extremely accurate and very badly conditioned.  Hence preconditioning   strategies are essential. There are over twenty-five years of experience and   study of preconditioning methods. And, still, there is a need for better   approaches.  Moreover, the mathematical justification for some of these   methods is incomplete.    The basic theme of this research can be stated simply ""Find effective   numerical methods to solve the important boundary-value problems of   mechanics and material science, and provide mathematical proofs of their   validity.""  In the problems of elasticity most of the methods now in use are   expensive to implement.  Hence, a new formulation is sought which will   provide accurate approximations which can be computed at a reasonable   cost. In the other two cases one is dealing with established methods which   are either difficult to impleme nt or whose mathematical basis is incomplete.   This research is aimed at a more complete mathematical understanding   which will both clarify the existing methods and provide a basis for the   development of new, more effective methods."
"9729158","Formation Process and 3-D Dynamics of Vortex Rings","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/01/1997","09/11/1997","Monika Nitsche","MA","Tufts University","Standard Grant","Deborah Lockhart","05/03/1999","$32,000.00","","nitsche@math.unm.edu","136 Harrison Ave","Boston","MA","021111817","6176273696","MPS","1266, 1271","9216, HPCC","$0.00","9729158  Nitsche    The goal of the present project is to perform numerical investigations to develop a   better understanding of vortex ring dynamics.  The case is considered in which a   vortex ring is formed by ejecting an amount of fluid from an opening.  In the first   part of the project, the focus will be on the initial formation process of   axisymmetric rings.  Viscous effects dominate the flow in an initial time interval   and affect the vortex trajectory and total shed circulation.  The effects of viscosity   by adapting a successful 2-dimensional Navier Stokes solver for high Reynolds   number flow to the axisymmetric case will be investigated.  Inviscid effects of the   flow using a vortex sheet model will also be studied in order to determine whether   present similarity theory predictions can be adjusted to better predict the initial   flow.  The second part of the project concerns 3-dimensional dynamics of vortex   rings formed at an opening.  The development of a numerical method to compute   3-dimensional vortex sheet separation at an edge will enable the study of the   stability of these flows, as well as the effects of nonaxisymmetric openings and   nonaxisymmetric forcing.  For this purpose, a 3-dimensional vortex filament   method will be developed which incorporates vortex separation at a sharp edge   and implements a fast summation algorithm to enable high resolution calculations.    Understanding the dynamics of vortex rings is essential to understand more   complicated flows such as those that occur in combustion processes, or in the   airborne vortex structures presenting a hazard to aircraft.  An inviscid numerical   model has been developed for axisymmetric vortex rings generated at a circular   opening.  This model was proven by comparison with experiment to recover   detailed information about the real flow.  In the present work, this model will be   extended to 3-dimensional flows, and will be used to study the stability of the   flows, the effects of non-axisymme tric openings and nonaxisymmetric forcing, as   well as the potential applicability of present theoretical results to predict the flow.    Several of these aspects of the flow are difficult to understand experimentally or   analytically, and the computations promise to give a deeper insight into the flow   dynamics. In order to perform this work, current numerical tools available for   2-dimensional flows will be expanded to 3-dimensions."
"9706827","Development, Analysis and Application of Numerical Methods  for Nonlinear Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","08/15/1997","06/17/1999","Stanley Osher","CA","University of California-Los Angeles","Continuing Grant","John C. Strikwerda","07/31/2001","$435,997.00","Bjorn Engquist, Eitan Tadmor","sjo@math.ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","MPS","1271","9216, 9263, HPCC","$0.00","9706827  Stanley Osher    This research is concerned with the accurate and efficient computation of ""irregular"" solutions of partial differential equations (PDEs).  This includes solutions with discontinuities, singularities, fine scale structure, or persistent oscillations.  The main topics include (1) kinetic formulations of nonlinear PDE's and applications; (2) interface capturing through the level set method; (3) discontinuity capturing based on ideas developed for the numerical solution of conservation laws; and (4) numerical and analytical study of oscillations and critical threshold phenomena.    The proposed research will impact numerous areas of science and technology.  With the advent of modern computers, formerly intractable problems can be solved accurately.  This, of course, requires accurate and convergent algorithms for these difficult nonlinear and computationally intense problems.  The algorithms formerly developed by this group are already in wide use throughout the country in national laboratories and industry.  The proposed methods to be developed here will be useful in a host of applications including combustion, oil recovery, crystal growth, electromagnetic and acoustic scattering, thin film semiconductor growth, aircraft design, to name just a few."
"9704758","Statistical Model Building with Generalized Splines","DMS","STATISTICS, COMPUTATIONAL MATHEMATICS","07/15/1997","06/24/1999","Grace Wahba","WI","University of Wisconsin-Madison","Continuing Grant","Joseph M. Rosenblatt","06/30/2001","$218,420.00","","wahba@stat.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","MPS","1269, 1271","0000, 9197, 9263, EGCH, OTHR","$0.00","Wahba  9704758    This research involves the development and testing of improved methods for estimating functions of many variables, given scattered, noisy, heterogeneous direct and indirect observations and prior information of various kinds.  Theoretical properties of the methods under development are established, and properties of the methods are also studied in test beds with simulated data where the `truth' is known.  Efficient numerical algorithms are developed which simultaneously implement statistical and computational objectives.  Finally the methods are tested on real observational data sets.  A unifying theme in all of the research is the exploitation of reproducing kernel Hilbert space methods, combined with cross validation, unbiased risk and likelihood techniques.    The statistical and numerical methods being developed have applicability in several broad areas:  (1) to the analysis of complicated medical and demographic data sets for the purpose of risk factor estimation (2) to the analysis of very large environmental data sets with the goal of extracting and presenting the maximal amount of information available in the data set; particular emphasis is on application to climate change (3) to the improvement and better understanding of methods used in supervised machine learning, and (4) to the analysis of data that is obtained from dynamical systems such as the evolving atmosphere or ocean, and the analysis of the strengths and weaknesses of mathematical models (such as numerical weather prediction or ocean models) that are used in the analysis of such data."
"9704874","Applications of Qualitative Analysis of Nonlinear PDE's","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","08/01/1997","08/05/1997","Bjorn Birnir","CA","University of California-Santa Barbara","Standard Grant","Deborah Lockhart","07/31/2001","$103,000.00","","birnir@math.ucsb.edu","Office of Research","Santa Barbara","CA","931062050","8058934188","MPS","1266, 1271","0000, 9263, OTHR","$0.00","9704874    Birnir      The dynamics of surge, stall, and flutter in jet engines will be investigated   using the qualitative theory of nonlinear partial differential equations (  PDE's). The Moore-Greitzer equations modelling the flow through a compressor  will be used to analyze surge and stall. First it will be determined whether   the  dynamics are high or low-dimensional, then the bifurcation that causes   stagnation  stall identified and methods developed to control stall and surge. The results  will be applied to the study of laboratory compressors and the analysis of   laboratory data. A simple model for flutter in rotor (and stator) rings   of blades is  developed and used to study the possible flutter modes, then control strategies  for these modes will be developed. This will first be done numerically and  then analytically. Finally these methods will be used to study a realistic  model of rotor rings and the real flutter modes and their bifurcations   analyzed and methods developed to control them.   The qualitative analysis of nonlinear PDE's will be extended to dimensions  two and greater, numerically and analytically, first by studying damped   and driven wave equations, and applications of the higher dimensional theory   will be implemented.     The purpose of the research is to help design jet engines that are lighter and  can be operated more efficiently and safely than contemporary jet engines.   These engines will be used in the airplanes of the 20th century and will make  air travel faster, cheaper, and safer."
"9707006","Research and Training in Vision and Computational           Neuroscience","DMS","TOPOLOGY, COMPUTATIONAL MATHEMATICS","08/15/1997","08/25/1997","Amir Assadi","WI","University of Wisconsin-Madison","Standard Grant","Michael Steuerwalt","07/31/1999","$50,000.00","","ahassadi@wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","MPS","1267, 1271","0000, 9237, 9263, OTHR","$0.00","Assadi  9707006       Visual perception of surfaces is crucial for 3D object  recognition.  All surfaces in natural scenes are endowed with  texture.  In this project, the investigator develops new  algorithms to estimate shape (geometric characteristics of  surfaces) from texture in natural and synthetic scenes.  The new  geometric models use piecewise Riemannian foliations, in the  sense of differential topology, with additional structure.  Given  a 3D-textured surface, not necessarily piecewise smooth, one  constructs a foliation whose leaves form a one-parameter family  of 2D-textured and piecewise smooth mathematical surfaces  approximating the given object.  Together with an objective  function defined on their leaves, such 2D-textured foliations are  fundamental geometric objects that model 3D-textured surfaces in  the world.  One can use algorithms to recover shape from texture  for the piecewise smooth leaves, e.g. curvature and slant.  Several scene-based methods are explored to construct textured  foliations, ranging from analytic (e.g. Hamilton-Jacobi  equations) and topological techniques (e.g. integrable  distributions) to statistical estimation methods.  The  psychophysical experiments to test the theory and compare  different algorithms are explored with colleagues who are  neuroscience experimentalists.  In particular, the objective  function can be numerically approximated based on psychophysical  data.  The new models are applied to perception of symmetry.  The  problem of modeling computational strategies employed by the  visual cortex to estimate shape from texture, and their  comparison with the new computational algorithms, is pursues.  The  investigator outlines a concrete training program and research  collaboration with his senior colleagues in vision and  neuroscience at UC Berkeley in order to achieve the cognitive and  computational objectives of the project.       How do we see?  This simple question does not have a simple  answer.  Vision is a complex series of eve nts that begins when  light enters the eyes and ends with perception.  People are able  to discriminate between objects of different size, contrast and  color with precision.  They can estimate curvature and orientation  of surfaces with varying roughness and multitudes of texture, as  well as describe within short time intervals properties of  surfaces such as symmetry and similarity to other familiar  objects.  The human visual system easily outperforms any man-made  machine.  Decades of research in vision demonstrate the wisdom of  the following approach: Key insights generally come from models  that are well-suited for exploring a specific research question.  Geometric models coupled with computational techniques have  formed a cornerstone of modern theories of biological as well as  robot vision, and of their diverse applications.  In this project,  the principal investigator and his colleagues establish a new  link between advanced geometric theories in pure mathematics  (theory of foliations from differential topology) and visual  perception and estimation of shape of surfaces in natural and  synthetic environments.  Among applications of the theory, one  could mention: robot motion planning and navigation of manless  vehicles in rough terrain or unreachable environments; visual  shape estimation of images of materials obtained by atomic force  microscopy in scientific research and design of advanced  materials; long-term computerized inspection of surfaces subject  to ballistic deposition and erosion in environmental studies and  ecology; and computational inspection of large databases of  images from infrared radio astronomy in order to locate specific  features.  Just as the neurons in human visual system perform  their tasks in parallel, the above-mentioned theory lends itself  to parallel processing implementation."
"9704919","1997 Industrial Mathematics Modeling Workshop for Graduate  Students","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","08/15/1997","08/11/1997","Jeffrey Scroggs","NC","North Carolina State University","Standard Grant","Lloyd E. Douglas","01/31/1999","$45,802.00","Hien Tran, Fernando Reitich","scroggs@unity.ncsu.edu","2601 Wolf Village Way","Raleigh","NC","276957514","9195152444","MPS","1253, 1271","1504, 9179, 9263, SMET","$0.00","  For the 1997 Industrial Mathematics Modeling Workshop for  Graduate Students (IMMW97), an applied scientist or mathematician  leads a team of approximately 6 graduate students in the solution  of an actual problem from industry. Thus, applied mathematics  graduate students are exposed both to the types of problems  arising in industry and to the team approach of problem solving.   This enriches their graduate educational experience, and can  provide valuable training in the event the students choose a  non-academic career. Boeing, Kodak, Michelin, and the NSA are  likely to be represented by the industrial problem presenters at  IMMW97.  We strongly believe that workshops, such as the one  proposed here, are one of the best ways to heighten students  interest in industrial mathematics, to improve students vision  about the type of mathematics and science that should be learned,  and to accelerate the cross-fertilization between the applied  sciences and mathematics.    This workshop is modeled after the successful workshops,  ``Industrial Mathematics Modeling Workshop for Graduate  Students,'' held the past two summers at North Carolina State  University.  Last year's workshop was organized by Professors  Tran, Reitich, and Scroggs. In addition, Prof. Reitich, in  cooperation with Lord Corporation, was one of the problem  presenters.  This workshop series started in the summers of  1993 and 1994 at the Claremont Graduate School. Both of these  workshops were organized by Professor Ellis Cumberbatch of the  Claremont Graduate School.    This GOALI project is jointly supported by the MPS Office of  Multidisciplinary Activities (OMA) and the Division of  Mathematical Sciences (DMS)."
"9706353","Local Plus Global Adaptivity in Moving Node Finite Element  Methods","DMS","COMPUTATIONAL MATHEMATICS","07/15/1997","10/11/2001","Keith Miller","CA","University of California-Berkeley","Standard Grant","Junping Wang","06/30/2002","$70,680.00","","kmiller@math.berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947101749","5106433891","MPS","1271","9148, 9216, HPCC, MANU","$0.00","9706353  Keith Miller      Miller plans to work on local plus global adaptivity for moving node  finite element methods. He plans first (in collaboration with Neil  Carlson of Purdue) to combine the local adaptivity of 2-D gradient-weighted  Moving Finite Elements (through the continuous movement of its nodes) with  an improved global adaptivity (through addition, deletion and reconnection  of nodes, based upon enriched geometric criteria and upon local error  estimates). Here they are building upon their longstanding and fruitful  collaboration in developing the GWMFE method. This method is especially  suited to problems which develop sharp moving fronts, especially problems  where one needs to resolve the fine-scale structure of the fronts. GWMFE  does an extremely fine job of moving its nodes around locally to resolve  the sharp features of the solution, but clearly global adaptivity is  needed if we are to have truly robust and flexible codes. Here they  would be making fundamental changes and additions to the partial global  adaptivity introduced by Miller's student Kuprat in his thesis of '92,  which added so greatly to the robustness of the method. Miller plans  second to develop a revised GWMFE with streamline diffusion; this should  correct some problems which the present method has on certain steady-state  convection problems in which the GWMFE grid drifts downstream with the  flow rather than coming to a steady-state. This revised GWMFE works  extremely well in 1-D; success in extending it to multidimensions would  be a significant advance for slow-transient and near steady-state fluid  computations.    Finite element (FE) methods with a triangular grid in 2-D typically compute  a piecewise linear approximation to the solution of a partial differential  equation (PDE) or system of PDEs; that is, the graph of the approximate  solution is an evolving surface with planar triangular faces. For standard  FE methods the grid is specified and fixed; however, for the GWMFE method  the grid is  allowed to deform and the nodes of the grid decide for  themselves how to move. On problems with sharp moving fronts the nodes can   thus automatically concentrate in the front and move with it. In this way  one attains high resolution in the critical regions of the solution  while using far fewer nodes and far larger time steps than with standard  methods. Examples are the highly nonlinear diffusion of doped arsenic  ions in the manufacture of silicon chips, the drift-diffusion equations  for the nanosecond evolution of holes, electrons and voltages as a  semiconductor device switches states, and the ""black oil"" equations  for flooding of oil reservoirs. The GWMFE method has been strikingly  successful on these and many other problems even within the constraints  of a logically-fixed grid; that is, the grid deforms automatically, but  the number and interconnections of its nodes remain fixed. However, a  logically-fixed grid is inadequate for many important problems and it is  apparent that the efficiency and robustness of the method can be  greatly enhanced by adding global adaptivity (the insertion and deletion  of nodes as needed). This requires a good deal of code development,  but the combination of local plus global adaptivity in GWMFE should  yield a combined method which is accurate and robust, which uses far   fewer nodes, and which thereby renders efficiently computable important  classes of problems with moving sharp features which are presently  inaccessible to numerical computation."
"9618651","Collaborative Project:Analysis of Pattern Formation in      Drosophila by Importance Sampling on Parallel Processors","DMS","Animal Developmental Mechanism, OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","08/01/1997","08/06/1997","John Reinitz","NY","Icahn School of Medicine at Mount Sinai","Standard Grant","Junping Wang","07/31/2000","$75,000.00","","reintz@kruppel.molbio.mssm.edu","1 GUSTAVE L LEVY PL","New York","NY","100296504","2128248300","MPS","1119, 1253, 1271","9216, 9263, HPCC","$0.00","Reinitz  9618651       The investigator with Yuefan Deng of SUNY Stony Brook and  their colleagues study large scale optimization methods applied  to problems concerning gene networks and pattern formation in the  fruit fly Drosophila.  These optimization problems arise in a  method known as ""gene circuits"", which was developed by one of  the principal investigators and his coworkers.  The essence of  this method is the numerical inversion of a set of nonlinear  ordinary differential equations by least squares fits of the  trajectories of the equations to gene expression data obtained by  fluorescence microscopy.  In the past, these fits were performed  by simulated annealing on serial computers using the Metropolis  algorithm under the control of the Lam cooling schedule.  They are  computationally intensive, and the range of problems that can be  considered was limited by the speed of available serial  processors.  The investigators are developing new computational  methods for the solution of these problems on parallel  processors.  Importance sampling is the most efficient, or the  most important, ingredient of an algorithm in treating complex  continuum optimization problems such as the pattern formation  analysis undertaken here.  Simulated annealing is one method for  importance sampling; the investigators are developing a general  method for parallel simulated annealing on nonseparable problems.  Other importance sampling methods are derived from methods that  make use of the continuum properties of the problem at hand, such  as Newton's method.  The investigators develop a family of  parallel importance sampling methods and then synergistically  combine them.  This family of methods includes genetic  algorithms, continuum methods, a Lagrangian reformulation of the  fitting problem, and simulated annealing.       Networks of interacting genes lie at the heart of the  problems that will face biologists and biotechnologists in the  twenty first century.  Processes ranging from embryonic  d evelopment to cell division and cell death are controlled by  networks of genes.  In order to understand how these networks  work, it is necessary to understand their internal ""wiring  diagrams"".  In particular, it is important to know how genes turn  each other on and off.  Modern molecular biology allows  investigators to see which genes are on or off at a given moment,  but in order to understand the ""wiring"" between genes, it is  necessary to analyze changes in gene activity over time and  analyze them by computer.  The method of analysis can be reduced  to an ""optimization"" problem, in which the smallest value of a  complicated function is sought.  In this project, the  investigators are finding new ways to solve optimization problems  on large scale parallel high-performance computers.  Particular  emphasis is placed on parallel methods for simulated annealing,  an exceptionally powerful optimization method.  This research is  important to many areas beyond gene networks.  Simulated annealing  and related methods are used in structural biology and other  biotechnology areas related to drug discovery.  It is also used in  the design of integrated circuits.  These and other areas are  likely to benefit from this work.  Funding for the project is  provided by the program of Computational Mathematics and the  Office of Multidisciplinary Activities in MPS and by the  Developmental Biology program in BIO."
"9626804","Computational Methods in Mathematics and the Physical       Sciences","DMS","COMPUTATIONAL MATHEMATICS","07/01/1997","07/02/1999","Peter Norman","MA","University of Massachusetts Amherst","Continuing Grant","Michael Steuerwalt","06/30/2001","$450,000.00","William Meeks, Nathaniel Whitaker, Franz Pedit, Markos Katsoulakis, Robert Kusner","norman@math.umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","MPS","1271","0000, 9216, 9263, HPCC, OTHR","$0.00","Norman  9626804       The investigator and his colleagues pursue interdisciplinary research and training in an environment supporting modern scientific computation and advanced computer graphics.  The areas  of investigation involve partial differential equations, integrable systems, and variational problems in geometry and topology.  Particular topics include: spin structures on surfaces  with applications to the geometry of immersions, particularly to rigidity and period problems; surfaces that minimize bending energy subject to natural constraints; the moduli spaces of  constant mean curvature embeddings and immersions, using mechanics, symplectic geometry and integrable systems; construction of embedded minimal surfaces by desingularizing  immersed minimal surfaces; elastic curves and their higher order soliton analogues; electrostatic energies associated with knots and links, and the behavior of their gradient flows; curve and  surface interfaces between distinct thermodynamic phases in disequilibrium; and statistical equilibrium solutions to the Euler equations for incompressible fluid flow.         The Center for Geometry, Analysis, Numerics & Graphics (GANG) pursues interdisciplinary research and training in an environment supporting modern scientific computation and advanced computer graphics.  The mathematical work at GANG is motivated by - and can shed light upon - many interesting natural systems that arise in both ""applied"" and ""basic"" research.  For example, the folding and entanglement of long molecules, like proteins, DNA or synthetic polymers, can be dynamically modeled using elastic and electrostatic curve energies that were originally developed at GANG to study the geometry and topology of knots and links; such models may be useful in predicting the strength of polymer materials or the biochemical effect of pharmaceuticals.  And a quite unexpected and fundamental new phenomenon - the ""conformal diffusion"" of tiny phospholipid vesicles, reported by French physicists in the Augu st 1995 issue of Science - was stimulated by work at GANG on the bending energy of surfaces.  The computation and visualization facilities at the GANG laboratory serve an important and interrelated triple duty by permitting the pioneering mathematical experiments to be carried out in the first place, providing a fertile environment for the education and training of students, and aiding communication with the general public (to paraphrase the late physicist, Eugene Wigner) on the remarkable effectiveness of mathematics in the natural world."
"9701540","Computational Refinement and Existence Proofs for           Singularities","DMS","COMPUTATIONAL MATHEMATICS","08/01/1997","06/14/1999","R Kearfott","LA","University of Louisiana at Lafayette","Standard Grant","John C. Strikwerda","07/31/2000","$44,947.00","","rbk@louisiana.edu","104 E University Ave","Lafayette","LA","705032014","3374825811","MPS","1271","0000, 9216, 9263, HPCC, OTHR","$0.00","9701540  R. Baker Kearfott      During the past two decades, understanding of singularities, bifurcations  and related phenomena, and relevance to the physical world have increased.  At the same time, tools for bounding discretization and roundoff error have  improved, to allow automatic result verification based on classical  fixed point theory.  Traditionally, such verification proceeds by   linearization, then bounding with interval arithmetic.  However, in  methods developed to date, existence and uniqueness verification   necessarily must fail when the system is singular at solutions.  Goals  of this project are to (1) develop new, simple and natural modifications  to existing verification techniques, to prove existence and uniqueness  when the nonlinear system is singular; (2) investigate the power of  the resulting tools, first for finite-dimensional problems (algebraic  systems), then for infinite-dimensional problems (differential and  integral equations); (3) increase understanding of singularities.      Many complex systems throughout the sciences and engineering, ranging from  load-bearing civil engineering structures to ecological systems to  human heart rythms,  are modeled by sets of nonlinear equations that   exhibit singularities and bifurcations.  Such bifurcations correspond   to changes in behavior  as conditions (the load, a temperature, etc.) change.  Understanding of such phenomena has blossomed in recent years, but analytical  problems remain.  This study will provide tools to enable an efficient and  automated, yet mathematically airtight analysis.  This in turn will  lead to more predictability in the physical world."
"9727879","International Conference on Spectral & High Order Methods   1998","DMS","COMPUTATIONAL MATHEMATICS","09/01/1997","09/11/1997","David Gottlieb","RI","Brown University","Standard Grant","John C. Strikwerda","08/31/1998","$10,861.00","","dig@dam.brown.edu","BOX 1929","Providence","RI","029129002","4018632777","MPS","1271","0000, 9263, OTHR","$0.00","  DMS 9727879    International Conference on Spectral and High Order Methods, 1998    ICOSAHOM98 will be the fourth International Conference On Spectral And  High Order Methods. The first three meetings were held in Como, Italy  in June 1989, Montpellier France in June 1992 and Houston Texas in June  1995. With a frequency of three years ICOSAHOM has played the role of  an international focal point in the field of spectral and high order  methods and the conference and its proceedings have proven to be  essential to researchers active in developing new algorithms as well as  those that implement high order methods to solve realistic problems of  interest to scientists and engineers.  The objective of the conference  is to bring together researchers with interest in the theoretical,  applied and computational aspects of high order and spectral methods.  Subjects include, but are not limited to, spectral methods, high-order  finite difference and finite element methods, h-p finite element  methods and wavelet based methods for the solution of partial  differential equations. Applications include electromagnetics, fluid  and structural dynamics problems, efficient solvers and preconditioners  for high order methods and parallel aspects of spectral and high order  methods. It is anticipated that the participants will include  physicists, mathematicians, scientists and engineers from many other  areas involving and utilizing spectral and high order methods."
"9612077","Mathematical Sciences:  Aspects of Discrete Tomography","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, CENTRAL & EASTERN EUROPE PROGR","09/01/1997","02/25/1999","Gabor Herman","PA","University of Pennsylvania","Standard Grant","Michael Steuerwalt","12/31/2000","$114,888.00","","gabortherman@yahoo.com","Research Services","Philadelphia","PA","191046205","2158987293","MPS","1266, 1271, 5979","0000, 5916, 9216, 9263, HPCC, OTHR","$0.00","Herman  9612077       The investigator studies how to determine functions defined  over three-dimensional space from physically measured (and hence  only approximate) values of their line integrals, using ideas  from discrete tomography.  In discrete tomography there is a  domain --- which may itself be discrete (such as a set of ordered  pairs of integers) or continuous (such as Euclidean space) ---  and an unknown function whose range is known to be a given  discrete set (usually of real numbers).  The problems of discrete  tomography have to do with determining the function (perhaps only  partially or approximately) from weighted sums over subsets of  its domain in the discrete case and from weighted integrals over  subspaces of its domain in the continuous case.  The essential  aspect of discrete tomography is that knowing the discrete range  of the function may allow determining its value at points where  without this knowledge it could not be determined.  Discrete  tomography is full of mathematically fascinating questions (e.g.,  what shapes are uniquely determined by their x-rays?) and it has  many interesting applications (e.g., electron microscopy and  nondestructive testing).       The investigator studies how to determine three-dimensional  objects from physically measured (and hence only approximate)  values of what are essentially averages along one-dimensional  slices of the objects.  Mathematically, this is the problem of  determining functions defined over ordinary three-dimensional  space from approximate values of their line integrals.  Such  physical measurements may be taken of biological macromolecules  using an electron microscope or of industrial objects using high  energy x-rays.  What is shared by these two (and many other)  applications is that the object to be determined may be known to  have only finitely many possible values.  The distinguishing  feature of discrete tomography is that by making use of such  knowledge we may succeed in determining the structure of th e  object from data that is not in itself sufficient for determining  the structure without the prior information.  While the emphasis  of the project is on the development of an appropriate  mathematical theory (including computational procedures for the  solution of specific instances of the general problems under  investigation), these will be developed so that they can be  applied in the field of recovering the structure of biological  macromolecules from sets of electron microscopic images by making  use of the truly discrete nature of the objects to be  reconstructed.  What this boils done to is the following: certain  methods of data collection do not allow us to determine the  structure of a totally unknown object (e.g., the electron  microscopes destroys a macromolecule before sufficient data can  be collected).  Discrete tomography allows us to overcome such a  technical difficulty in those cases when the object is known to  have only finitely many values.  The project has applications to  imaging problems in medicine, biology, and chemistry."
"9704923","A Fast Numerical Method for Imaging Small Abnormalities in  Diffusion Tomography","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/01/1997","09/04/1997","Michael Klibanov","NC","University of North Carolina at Charlotte","Standard Grant","Michael H. Steuerwalt","08/31/2000","$90,000.00","Thomas Lucas","mklibanv@uncc.edu","9201 University City Boulevard","CHARLOTTE","NC","282230001","7046871888","MPS","1266, 1271","0000, 9216, 9263, HPCC, OTHR","$0.00","Klibanov  9704923       A fundamental challenge in inverse problems is the  determination of the composition of an unknown medium given the  boundary measurements of radiation by an outside source into the  medium.  The investigator and his collaborator make a theoretical  and numerical study of this problem from situations modeled by  the parabolic/diffusion equation using a novel approach -- the  Elliptic Systems Method (ESM).  The ESM involves the derivation  and solution of a system of coupled elliptic partial differential  equations with boundary conditions developed from a normalized  form of the temporal data.  The diffusion and absorption  coefficients of the medium are then reconstructed from the above  normalized solution, yielding the composition.  This project  involves a number of explorations, extensions, improvements and  testing of this new method applied to a variety of situations.  It  provides a fast and accurate new approach to the important  problem of reconstructing images from scattered data.       In a recently published report by the National Research  Council (Mathematics and Physics of Emerging Biomedical Imaging),  a call is made for the development of new effective medical  imaging algorithms.  An example is the early imaging of small  cancerous breast tumors using optical (near infrared laser)  methods.  Cancerous tumors are more light-absorbing than the bulk  of breast tissue, leading to an increased interest in developing  early detection methods by ""optical"" mammography.  The difficulty  is that unlike x-rays, which travel in essentially straight  lines, light is highly scattered, making reconstruction  difficult.  The investigators develop their new approach to this  problem, which uses the methods of numerical solutions of partial  differential equations to achieve rapid and accurate  reconstructions.  This approach, among other applications, has a  very good potential to lead to an optical alternative to x-ray  mammography exams or to a decrease in the number  of biopsies  resulting from false positives."
"9627330","Mathematical Sciences:  Stabilized Geometric Integrators    with Applications to Molecular Simulation","DMS","COMPUTATIONAL BIOLOGY ACTIVITI, OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS, STATISTICAL AND SIMULATIONS","06/01/1997","05/21/1997","Benedict Leimkuhler","KS","University of Kansas Main Campus","Standard Grant","Michael H. Steuerwalt","05/31/2001","$287,000.00","Brian Laird, Krzysztof Kuczera","leimkuhl@math.ukans.edu","2385 Irving Hill Road","Lawrence","KS","660457563","7858643441","MPS","1107, 1253, 1271, 1956","9216, HPCC","$0.00","Leimkuhler  9627330       The investigator and collaborators form a multidisciplinary  team from biochemistry, chemistry and mathematics that seeks new,  more efficient numerical integrators for problems of molecular  simulation.  They develop timestepping schemes that are based on  detailed study of the structure and force laws of these molecular  systems, and that respect invariants and symmetries such as the  symplectic structure and time-reversibility associated to the  flow map.  The project extends the range of dynamical phenomena  accessible to simulation studies by increasing the allowable  timestep and improving stability of numerical integrators.  Moreover, by automating the selection of timestep in molecular  dynamics simulations, this work seeks to remove an outstanding  inefficiency and push forward the state-of-the-art in molecular  dynamics software.  The specific problems considered include (1)  the development of combined coordinate and time-transformations  as a tool for stabilizing the local dynamics of close particle  pairs, (2) exploration of the relationship between timestep and  numerical behavior for molecular dynamics and the design of  time-reversible stepsize variation mechanisms, and (3) the study  of timestepping schemes appropriate to spin dynamics, constrained  systems, and related problems and their application in chemical  and physical dynamics problems.  The new techniques are used to  simulate biological macromolecules and for problems concerning  the structure and dynamics of solid-liquid interfaces as well as  studies of transitions in glasses and spin-glasses.       Important challenges to our understanding of physical,  chemical and biochemical processes are being tackled through the  use of computer simulations, but many difficult problems remain  well beyond the reach of today's hardware and software  technology.  Even improvements in computer power of several  orders of magnitude will not enable the direct simulation of  complex proteins or DNA chains on  the longest relevant timescales  unless substantial improvements are also obtained in computer  algorithms and software.  A key component of simulation software  for many large-scale problems in biochemistry, chemistry,  physics, and materials science is the fundamental molecular  dynamics integration scheme, which approximates the changing  positions and velocities of the constituent atoms of a substance  from one moment in time to the next.  In this project an  interdisciplinary team from biochemistry, chemistry and  mathematics develops new molecular dynamics integrators in order  to improve the efficiency and accuracy of simulations.  Funding  for the project is provided by programs of Computational  Mathematics, Theoretical and Computational Chemistry, and the  Office of Multidisciplinary Activities in MPS and by the  Computational Biology program in BIO."
"9703918","Importance Weighting in Dynamic and Static Monte Carlo","DMS","STATISTICS, COMPUTATIONAL MATHEMATICS","08/15/1997","04/29/1999","Wing Hung Wong","CA","University of California-Los Angeles","Continuing grant","Joseph M. Rosenblatt","07/31/2001","$300,000.00","","whwong@stanford.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","MPS","1269, 1271","0000, 9216, 9263, HPCC, OTHR","$0.00","9703918  Wong    In this research, dynamic weighting is developed as a method for dynamic Monte Carlo simulation that has the capability to efficiently sample relevant parts of the configuration space in the presence of many steep energy minima.  This method relies on an additional dynamic variable, namely the importance weight, to help the system overcome steep barriers. A new, non-Metropolis theory is introduced to guide the construction of such weighted samplers.  The method is designed to work in combination with the complementary idea of sampling a complexity ladder.  A second topic studied in this research is the use of rejection control in sequential importance sampling.  This is introduced in order to cope with difficulties of having highly skewed weights in static importance sampling Monte Carlo.  It will enhance the usefulness of static Monte Carlo in the simulation of high dimensional systems.    In statistics, Monte Carlo is an essential computational tool in the evaluation and study of likelihoods and posterior distributions.  The importance of this technique in practical Bayesian inference cannot be overstated.  Furthermore, the advances in Monte Carlo theory and method resulting from this investigation are of a general nature and have significance to many other areas in modern science and technology.  In physical sciences, dynamic Monte Carlo has long been an indispensible tool in the study of fluids, spin systems, phase transitions and critical phenomena, material growth and defect, and the behavior of polymers.  In biology, Monte Carlo advances our understanding of protein conformations, and plays an important role in genetic and evolutionary analysis.  In engineering, partly through its pivotal role in stochastic search methods, Monte Carlo is useful in such diverse areas as expert system, network optimization, machine learning and chip design.  Therefore, the findings of this research are expected to bring considerable benefit to many current areas of strategic importance rang ing from material research to protein engineering."
"9722121","Full-Scale Three-Dimensional Numerical Experiments on       High-Intensity Laser Matter Interactions","DMS","COMPUTATIONAL MATHEMATICS, , ","08/15/1997","09/07/1999","Warren Mori","CA","University of California-Los Angeles","Continuing grant","Jong-Shi Pang","07/31/2000","$443,250.00","Viktor Decyk","mori@physics.ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","MPS","1271, X222, Y826","9216, 9263, HPCC","$0.00","Mori  DMS- 9722121    This is a highly multi-disciplinary proposal for research in modeling high intensity laser-matter interactions.  The experiments being modeled are rich and varied in phenomena, such as relativistic self-focusing/self-phase modulation, Raman scattering, and photon acceleration.  In this work we will develop a three-dimensional particle-in-cell code to accurately simulate these interactions.  The accurate modeling of these experiments will lead to new understanding of laser-matter interactions.  The research requires expertise in high-intensity laser-plasma physics, laser plasma accelerations, large scale particle-in-cell computer modeling, and manipulation of large data sets.    Recently short-pulse laser technology has advanced to where there has been a great profusion of experimental results and the theoretical understanding of what is happening has not kept pace.  In this research, we will develop the capability to accurately simulate what happens when a high intensity short laser pulse interacts with matter.  The capability to model these interactions will help experimentalists interpret their results and increase our understanding of the physical processes involved."
"9705780","Multiple Time Scales in Neuronal Models","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/15/1997","09/17/1997","John Guckenheimer","NY","Cornell University","Standard Grant","Michael H. Steuerwalt","08/31/2001","$128,000.00","","jmg16@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","MPS","1266, 1271","0000, 9263, OTHR","$0.00","Guckenheimer    9705780         The investigator studies dynamical systems with multiple    time scales as models of neural systems.  Data and models from a    small invertebrate neural network, the stomatogastric ganglion of    lobsters, guide the work and provide case studies.  Phenomena    observed in the stomatogastric ganglion, such as bursting    oscillations and spike frequency adaptation, can best be modeled    as dynamical systems with multiple time scales.  Previous    mathematical analyses of qualitative properties of multiple time    scale dynamical systems have dealt mainly with local phenomena    that occur in low dimensions.  The dynamics of neural systems    raise questions that are not addressed by existing theories of    multiple time scale systems.  The aim here is to extend the theory    by classifying qualitative features of the global dynamics and    bifurcations for systems with two time scales.  This is an    ambitious endeavor to extend theories of nonlinear dynamical    systems and singularly perturbed systems of ordinary differential    equations that have been developed over the past thirty years.    Using numerical investigations as a guide, the dictionary of    patterns that occur in this setting is described and their    analytical properties are characterized.  This work draws heavily    upon the theories of bifurcations of dynamical systems and models    of hybrid dynamical systems that combine continuous and discrete    components.  As needed, numerical algorithms are developed that    facilitate the simulation and analysis of multiple time scale    systems.  The initial emphasis of the mathematical work is upon    systems that have two slow variables and two fast variables.    Numerical investigations of conductance-based models for the    stomatogastric ganglion also are performed.  The results of these    studies are compared with data and used to guide the refinement    of the models.         Nervous systems of animals regulate and control muscular    activi ty such as locomotion.  Well developed theories enable the    construction of models for the electrical properties of nerve    membranes in these processes, but there is little understanding    of the dynamical principles used by organisms.  This project    investigates dynamical models of a small neural system consisting    of fourteen neurons that control rhythmic motions of the foregut    of lobsters.  This system is used because it is small enough that    unique properties of each neuron within the system have been    identified, but large enough that the network architecture of the    interactions among neurons is also important.  The system displays    a rich repertoire of rhythmic behavior.  The focus of this project    is on features of the behavior that involve different time    scales.  Mathematical theories have been successful at describing    universal properties of the dynamics observed in an astounding    array of physical and natural systems, but these theories need to    be extended to systems with more than one time scale.  The goal is    to construct classifications of dynamical patterns that are the    components from which the complex behaviors of neural systems are    formed.  Models of these systems are also complex.  Computational    investigations are required to predict their dynamical behavior.    This project seeks to implement algorithms that improve our    ability to extract useful information from the models and guide    the improvement of their fidelity.  Both the theoretical analysis    and the numerical methods that are developed encompass all models    of dynamical systems with multiple time scales and can be used    far beyond the context of the neural system that is the focus of    this study."
"9705672","Further Investigation of the Nonlinear Rescaling Principle in Constrained Optimization","DMS","COMPUTATIONAL MATHEMATICS","08/01/1997","07/24/1997","Roman Polyak","VA","George Mason University","Standard Grant","John C. Strikwerda","07/31/2000","$117,000.00","","rpolyak@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","MPS","1271","0000, 9148, 9216, 9263, HPCC, MANU, OTHR","$0.00","9705672 Polyak ABSTRACT The main purpose of this proposal is to develop new aspects of the Nonlinear Rescaling (NR) theory and new methods, that are based on this theory, for solving constrained optimization problems. Developing software, which will take into account the special structure of unconstrained optimization problems typical for the NR approach is our second goal. Solving real world large scale nonlinear optimization problems is our third main target. The ability to solve large scale nonlinear optimization problems is critical in mechanics, structural engineering, optimal control, tomography, image recognition, power system optimization, and economics, to mention a few. Recently the NR type methods have been used with great success for solving very complex Truss Topology Design (TTD) problems. The TTD problems arise in structural optimization, in particular, in creating bridges, cantilevers, and inner skeletons of airplane wings capable of carrying external loads under different loading scenarios. Funding a structure, which is able to withstand external forces, have certain characteristics of rigidity and at the same time to have minimal cost is a typical large scale nonlinear constrained optimization problem. Our research is aimed to find efficient methods for solving such problems."
"9704935","Mathematical Modeling of Sulfide Corrosion of Concrete in Wastewater Collection Systems - Analysis, Experimental Validation, Parameter Estimation and Control","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","08/15/1997","08/21/1997","I.Gary Rosen","CA","University of Southern California","Standard Grant","Michael H. Steuerwalt","07/31/1999","$60,000.00","Florian Mansfeld, Joseph Devinny, Chunming Wang","grosen@math.usc.edu","University Park","Los Angeles","CA","900890001","2137407762","MPS","1266, 1271","1037, 9263, CVIS","$0.00","Rosen 9704935 Sulfide corrosion of concrete in wastewater collection systems occurs when microorganisms in anaerobic films below the water surface produce hydrogen sulfide. The sulfide evaporates into the atmosphere and redissolves in moisture that has condensed on the portions of the pipe above the wastewater. Microorganisms in this environment convert the sulfide to sulfuric acid. The acid reacts with calcium hydroxide and calcium carbonate in the cement, producing sulfate minerals and causing the concrete to corrode. The investigators develop a mathematical model of the corrosion process that is tuned, tested, identified and validated via field data and laboratory experiment. The effort includes the analysis of the model equations (which take the form of a system of coupled partial differential equations with moving or free boundaries) from the point of view of well-posedness (existence, uniqueness, regularity of weak, strong, local, global solutions, etc.) and the sensitivity of solutions with respect to parameters. It also includes the development, analysis and testing of efficient, convergent and robust numerical integration schemes for numerical simulation, parameter estimation and control. In addition to using available field data to verify the model, a laboratory test-bed to provide additional data for model verification and parameter estimation is designed and fabricated. Electrochemical techniques applied to instrumented concrete samples are used to (i) characterize the concrete structures using electrochemical impedance spectroscopy (EIS), and (ii) sense the diffusion profiles of corrosive species. Correlation of the results of these two studies allows investigation of relationships between concrete microstructure and diffusion processes. Computational schemes are developed to use the field and laboratory data to identify unmeasurable parameters that appear in the model, and to test corrosion slowing control schemes based upon the model. Sulfide corrosion causes millions of dollars in damage in the U.S. each year. Attempts have been made to control sulfide corrosion in sewers. Most try to prevent the release of hydrogen sulfide into the pipe atmosphere. Strong base has been used to kill the biofilm, and cleaning has been used to remove it. The addition of trace metals precipitates the sulfide, preventing its release to the atmosphere. However, the biofilms are tenacious, and grow back rapidly, requiring additional treatment. Any anti-biofilm treatment is constrained because it must not damage the similar microorganisms that are the basis of the wastewater treatment system. Chemical precipitation requires continuous treatment. Any effort involving chemical addition must contend with the very large volumes of water flowing through wastewater collection systems: no matter how cheap the chemical, the colossal amounts that must be purchased and fed into the system are expensive. Thus an effort to first understand and to then interrupt (i.e. control) the corrosion process is needed, and may provide the only possible remedy for some cases. The results of the study should yield a deeper understanding of the corrosion process, and provide a powerful tool for engineers to use in the design of concrete wastewater systems and in the formulation, testing, tuning and evaluation of corrosion abatement procedures. The model and results should guide improvements in protection techniques where sulfide corrosion is a problem, and provide insight into the corrosion processes of other concrete structures and the substantial damage caused. They could also potentially reduce maintenance costs. The modeling ideas developed as a part of this project should be transferable to other corrosion problems, and the analytical and computational techniques that result should be of use in the area of moving boundary problems, their analysis, numerical solution, identification and control."
"9720145","Complexity of Neural Networks for Applications","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","08/15/1997","08/29/2001","Mark Kon","MA","Trustees of Boston University","Standard Grant","Michael H. Steuerwalt","03/31/2002","$75,000.00","","mkon@bu.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","MPS","1266, 1271","0000, 9263, OTHR","$0.00","Kon 9720145 The investigator studies neural network architectures and applications of wavelet techniques to investigate neural networks' complexity. Wavelets have been established as a rich and useful family of expansion functions. The investigator studies further the recovery of functions (in particular representations of visual images) from their wavelet transforms. Issues of stability and complexity, which have not up to now been addressed in his proof of the Marr conjecture and related analysis of the Mallat conjecture, are studied. An important current question regards the complexity of such networks (i.e., their essential size) for the completion of desired tasks. The investigator studies two types, so-called functional and logical networks. Functional networks have received a good deal of attention, and a coherent theory has established that they are essentially orthogonal (or more general) expansion engines. The homology between the structure of networks and expansion tasks has allowed establishing the connection of wavelet convergence results with network complexity issues. The investigator examines the class of so-called logical networks as a needed completion of available network architectures for the execution of intelligent tasks. In addition he works to show that wavelet-based neural networks achieve lower bounds on complexities of neural nets for given tasks. These results move toward a general complexity theory for neural nets on the order of current computational complexity theory for serial and parallel computer architectures. Such a complexity theory is expected to be a hybrid of current discrete and continuous computational complexity theories. The global purpose of this project is a mathematical study of neural network architectures that implement some of the theoretical complexity results that the investigator obtains. Neural networks as models of parallel distributed computing are currently the leading architectures holdi ng a promise of artificially emulating intelligent systems, as has been indicated in many of their current applications (including mortgage decisions, commercial stock market analysis applications, chemical and thermal homeostasis control systems, satellite image analysis, etc.). A major unanswered question in the development of such systems is the fundamental issue of how large a network needs to be in order to perform specific intelligent functions. One type of task that current so-called ""functional"" neural architectures have difficulty in dealing with is artificial visual recognition and related tasks involved in the general area of robotics. This difficulty seems to be an inherent part of the functional neural architectures under current study, and the investigator develops architectures involving so-called ""logical"" components, which act essentially as algorithmic engines. In particular such network architectures are necessary for artificial vision tasks, and prototypes of such tasks are simulated computationally with the aid of graduate students working on the project. Wavelets are currently considered to be one of the most useful tools for representing the types of input-output functions implemented in neural networks. A more general question regarding the complexity and size of neural networks accomplishing real-world tasks is addressed through application of wavelet techniques to network construction. In particular, functional neural networks may achieve their optimal performance using wavelets as activation functions. There is a larger question here regarding whether wavelet techniques are the best possible for the implementation of functional neural network architectures, which is a conjecture the investigator has made and investigates. The computational aspects of the project are aided by associated groups at Howard University and Bryn Mawr College, the Howard group involving a number of graduate students."
