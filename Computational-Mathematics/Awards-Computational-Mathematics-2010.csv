"AwardNumber","Title","NSFOrganization","Program(s)","StartDate","LastAmendmentDate","PrincipalInvestigator","State","Organization","AwardInstrument","ProgramManager","EndDate","AwardedAmountToDate","Co-PIName(s)","PIEmailAddress","OrganizationStreet","OrganizationCity","OrganizationState","OrganizationZip","OrganizationPhone","NSFDirectorate","ProgramElementCode(s)","ProgramReferenceCode(s)","ARRAAmount","Abstract"
"1011791","IMA Participating Institution Graduate Summer School 2010:  Computational Wave Propagation, Michigan State University","DMS","COMPUTATIONAL MATHEMATICS","10/01/2010","09/20/2010","Jianliang Qian","MI","Michigan State University","Standard Grant","Leland Jameson","09/30/2011","$27,435.00","","qian@math.msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1271","7556, 9263","$0.00","The investigator and his collaborators are organizing the 2010 IMA participating institutes graduate summer school. <br/>Additional support from the NSF will enable the investigators to bring in students from non-IMA affiliated <br/>institutions  and invite domestic and international speakers to give lectures. The 2010 summer school on computational wave propagation covers three different topics: advanced numerical methods for full wave propagation, contemporary asymptotic methods for wave equations, and applications of wave equations. The part of the advanced numerical methods for full wave propagation will be led by Jean-Claude Nedelec of Polytechnique, France. <br/>The part of the contemporary asymptotic methods for wave equations will be led by Robert Burridge. The part of applications of wave equations will consist of roughly twelve lectures by active researchers in wave propagation. <br/>This is a unique and timely synthesis of disciplines that will position future researchers for the next step in <br/>computational wave propagation. In turn, this will have long-term impact in applied mathematics, engineering <br/>and industrial applications. <br/><br/>The IMA graduate summer school has a 19-year record of excellent programs that have jump-started the <br/>careers of many young mathematicians. Average attendance for these events in recent years has been <br/>58 participants, including  organizers and speakers. The 2010 graduate summer school brings students <br/>together with outstanding researchers in an intimate and intensive setting which will lead students to <br/>the frontiers of mathematical research. Students have a chance to get to know world-class mathematicians <br/>on a less formal basis than their interactions with the faculty at their home institutions. Feedback from <br/>participants of past programs has been unequivocally positive. The IMA summer schools are an important <br/>option for graduate students in mathematics as they reach for advanced degrees, and they are an attractive <br/>feature of affiliate institutions' graduate programs. The IMA and its affiliates are particularly committed to <br/>helping to advance the careers of mathematics students from under-represented groups. In addition, the <br/>focus of the 2010 graduate summer school is on computational wave propagation which has many important <br/>applications in nanotechnology, material sciences, and radar technology."
"1009951","Nonlinear Approximations for Inverse Problems","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/01/2010","06/25/2010","Gregory Beylkin","CO","University of Colorado at Boulder","Standard Grant","Pedro Embid","06/30/2013","$301,491.00","Lucas Monzon","gregory.beylkin@colorado.edu","3100 MARINE ST","BOULDER","CO","803090001","3034926221","MPS","1266, 1271","9263","$0.00","This project aims to develop a new class of methods for solving inverse problems in their different modalities, for example to develop new methods for non-destructive evaluation, such as X-ray Tomography, Magnetic Resonance Imaging (MRI), Synthetic Aperture Radar, Diffraction Tomography, Electron Microscopy, and many others. In these problems, data may be collected directly in the Fourier domain (as in MRI), or may be transformed into the Fourier domain for the purpose of image formation (as in X-ray Tomography or Electron Microscopy). In all cases, the image resolution is controlled by the largest wave-number present in the measured data. In order to minimize the distortion due to Gibbs phenomenon, current imaging methods either collect data in a large enough area of the Fourier domain or window the data to force an artificial decay. It can be shown that current methods require collecting more data than necessary or negatively impact the resolution near spatial singularities of recovered functions of interest. These singularities are, typically, the most informative part of the final image. In contrast, this proposal relies on nonlinear, near optimal approximation by exponentials to extrapolate the available Fourier data, also yielding a near optimal rational representation in space. This approach not only improves the resolution near singularities and achieves a near optimal performance, but also detects the level of noise in data and provides a practical technique for signal/noise separation.  These new algorithms already yield a significant improvement over existing techniques in one-dimensional problems and this project intends to extend the approach to problems in two or three dimensions. Such an extension is highly nontrivial since the mathematical tools used in one dimension are only of limited use.<br/><br/>Inverse problems arise in a wide variety of scientific and engineering disciplines as a way to analyze biological or inorganic specimens, analyze manufactured devices for defects, perform remote sensing or geophysical exploration among many other applications. In all of these modalities, from processing multiple radar data to biomedical imaging such as MRI, the collected data is processed by algorithms implementing the solution of an inverse problem based on a specific mathematical model. The investigators propose a method of developing and algorithmically implementing new mathematical models applicable to many, if not all, of these problems. The reason for such wide applicability is the fact that in the new mathematical models the functions of interest are represented with a near optimal number of parameters, thus significantly improving the recovery of information from the measured data. The mathematical and practical significance of this project as well as its challenge lies in extending the methods developed by investigators in one dimension to multiple dimensions. Since techniques of non-destructive evaluation play a vital role in natural sciences, engineering, medical diagnostics as well as such visible applications as airport security, we expect a wide impact of these new mathematical models based on nonlinear approximations.  The numerical methods developed within this project should provide scientists with computational tools to efficiently solve problems beyond the capabilities of many of today's algorithms."
"1016094","Adaptive FEM for elliptic and parabolic problems","DMS","COMPUTATIONAL MATHEMATICS","09/01/2010","08/05/2010","Alan Demlow","KY","University of Kentucky Research Foundation","Standard Grant","Junping Wang","08/31/2014","$152,361.00","","demlow@math.tamu.edu","500 S LIMESTONE","LEXINGTON","KY","405260001","8592579420","MPS","1271","6863, 9150, 9263","$0.00","The goal of this project is the development and analysis of adaptive finite element methods (AFEM) for various elliptic and parabolic partial differential equations.  The project has three main parts.  The first involves theoretical investigation of convergence properties of AFEM for controlling non-standard norms and related applications.  It is only in the past few years that quasi-optimality results for adaptive methods for controlling global energy norms have appeared.  The investigator has developed techniques for similarly analyzing AFEM designed to control other norms.  He will apply these techniques to prove optimality of an AFEM for controlling local energy norms and use them to analyze convergence of parallel adaptive algorithms of Bank-Holst type.  In the second set of projects the investigator  will develop AFEM for efficiently controlling local and global maximum errors in several classes of parabolic problems where such error control is desirable.  These efforts will result in sharp new a posteriori error estimates and adaptive finite element methods for controlling local pointwise errors in linear parabolic problems and maximum-norm a posteriori error analyses of semilinear parabolic problems for which such estimates are of practical interest.  The third project involves development of AFEM for solving elliptic and parabolic PDE on surfaces.  The investigator will develop a surface AFEM for stationary problems which will be useful for problems in which surface and bulk effects are coupled.  He will also study linear parabolic surface PDE in order to provide foundational knowledge about AFEM on evolving surfaces.<br/><br/>Partial differential equations are widely used in science and engineering in order to model various physical phenomena.  In order to gain usable information from these mathematical models, it is necessary to approximate their solutions using numerical (computer) algorithms.  Adaptive finite element methods are numerical algorithms that use available information in order to automatically and efficiently improve the quality of the approximation to the solution.  The investigator's research concerns the mathematical theory of such adaptive algorithms.  This project has three main goals.  The first is to investigate basic theoretical questions concerning convergence of these algorithms, that is, to prove that they work correctly.  The second part of the project involves controlling maximum errors in certain adaptive calculations, that is, ensuring that the computation is correct everywhere and not just ""on the average"" as is standard.  Finally, many important physical models involve partial differential equations on surfaces.  Examples include oil dispersion on a rotating brake drum and the effects of surface tension in fluid flows with multiple phases, such as oil and water.  The investigator will also develop adaptive algorithms for solving such equations."
"0964344","IMA PIP Workshop on Numerical Modeling of Complex Fluids and MHD","DMS","COMPUTATIONAL MATHEMATICS","06/01/2010","05/18/2010","James Brannick","PA","Pennsylvania State Univ University Park","Standard Grant","Junping Wang","05/31/2011","$11,200.00","Ludmil Zikatanov","brannick@psu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271","7556, 9263","$0.00","The most common origin and manifestation of anomalous phenomena in complex fluids are different ``elastic'' effects. These can be ascribed to the elasticity of deformable particles, elastic repulsion between charged liquid crystals, polarization  of colloids or multi-component phases, elastic effects  due to microstructures formation, or bulk elastic effects due to the presence of polymer molecules in viscoelastic complex fluids.  Mathematically, such elastic effects can be represented in terms of internal variables. Examples of such internal variables are: the orientational order parameter in liquid crystals, the distribution density function in the dumb-bell model for polymeric materials, the magnetic field in magnetohydrodynamic fluids, and the volume fraction in mixtures of different materials. The different rheological and hydrodynamic properties of these materials can in turn be attributed to the special coupling between the transport of these internal variables and the induced elastic stresses which typically manifest on all scales, and to a large extent determine the specific properties of the system, such as the stability and regularity of particle configurations and the likelihood of specific pattern formations in the system. The understanding of such complex mechanisms which couple different physical scales is crucial in designing accurate mathematical and numerical models and algorithms in order to simulate such systems.  This workshop is based on the premise that gaining significant new results and thereby obtaining deeper insight and understanding of materials described by complex fluids (e.g., polymers, emulsions, liquid crystals, magnetorheological fluids, blood suspensions) requires a combined approach consisting of experiment, modeling, analysis, and simulation.  The primary objective of the workshop is thus to gather students, junior faculty, and experts to discuss new integrated modeling techniques that properly address the fundamental unresolved issues common to studies of complex fluids: consistency of models with physics, rigorous analysis of the models, numerical and scientific computing issues, and the experimental verification and validation of the predictive capabilities  of the mathematical and numerical models. <br/><br/>Modeling and simulating the rich pool of designer and smart materials described by complex fluids requires marshaling interdisciplinary research forces to develop and analyze mathematical models and computational tools for such problems.  Recently, numerous methodologies and frameworks have been developed in an aim to capture the various time and length scales involved in studies of such complex materials.  This workshop will gather key contributors to the development of these new multiscale modeling and simulations techniques, with the aim of introducing these ideas to students and young researchers and also promoting interdisciplinary research on complex fluids applications amongst participants in the future.  The workshop will highlight topics from interrelated research areas for both deterministic and stochastic computational approaches, concentrating on: an Energetic Variational approach for multiscale modeling and simulation; computationally and experimentally guided model validation and further development of robust adaptive numerical models and solution methods."
"1015984","Approximation techiques for MHD flows in highly heterogeneous domains","DMS","COMPUTATIONAL MATHEMATICS","09/15/2010","09/15/2010","Jean-Luc Guermond","TX","Texas A&M Research Foundation","Standard Grant","Leland Jameson","08/31/2015","$269,991.00","","guermond@math.tamu.edu","400 HARVEY MITCHELL PKWY S STE 3","COLLEGE STATION","TX","778454375","9798626777","MPS","1271","9263","$0.00","The objective of this research program is to develop solution methods for<br/>solving magneto-hydrodynamics flows in three-dimensional domains comprising conducting<br/>and nonconducting regions and variable/discontinuous magnetic<br/>permeability.  The method to be developed will be robust enough to<br/>handle High Reynolds flows and high Prandtl numbers. Lagrange finite elements <br/>will be used and novel mathematical formulations will be developed<br/>to make Lagrange finite elements to converge<br/>in non-smooth domains and with non-smooth interfaces. <br/>The code to be developed will be fully parallel.<br/>The applications targeted<br/>are the geodynamo, sea-water/oil separation and liquid metal flows.<br/>The solution strategy to be developed will be<br/>flexible enough so as to be easily modifiable to simulate plasma flows<br/>in Tokamak geometries and thus to contribute to the ongoing global<br/>international effort on magnetic confinement of plasmas.<br/><br/><br/>The focus of the research program is to propose and analyze new<br/>numerical strategies for simulating three-dimensional fluid flows<br/>interacting with electromagnetic fields in heterogeneous media at high<br/>speed. One phenomenon of interest is the so-called fluid dynamo<br/>effect.  The dynamo phenomenon arises in astrophysics. It is<br/>responsible for the magnetic fields that are observed around stars and<br/>planets with liquid cores. This phenomenon arises also in experimental<br/>setups aiming at reproducing the dynamo effect. The fluid may be<br/>plasma in stars and in tokamaks, molten iron in planets, or liquid<br/>gallium or sodium in experimental setups. The dynamo effect may have<br/>undesired consequence on heat extraction processes from fast breeder<br/>reactors. This research will also prepare the ground for further<br/>developments on plasma flows in Tokamak geometries. This research<br/>project will involve large scale parallel computing and will lead to new<br/>numerical strategies to simulate high speed flows interacting with<br/>magnetic fields."
"1027656","Poly and Polymer Electrolytes for Energy Conversion","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","08/15/2010","08/04/2010","Keith Promislow","MI","Michigan State University","Standard Grant","Henry Warchall","07/31/2011","$20,000.00","Stephen Paddison","kpromisl@math.msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1266, 1271","7237, 7556, 9263","$0.00","This award supports travel of U.S. participants in the workshop ""Poly and Polymer Electrolytes for Energy Conversion: Ab Initio, Molecular, and Continuum Models,"" held at the Lorenz Center within the University of Leiden, The Netherlands, 23-27 August 2010.  <br/><br/>The goal of the workshop is to facilitate communication among the disparate groups of researchers applying ab initio, molecular, and continuum approaches to the modeling of nanostructured polymer electrolyte materials used in energy conversion and storage devices.  The meeting features invited talks by leading researchers, as well as formal directed discussion sessions and a session of presentations contributed by junior participants.<br/><br/>The workshop brings together mathematicians, computational chemists, computational materials scientists, and experimentalists to facilitate research progress in areas that address the pressing need for a more efficient energy infrastructure to reduce reliance on fossil fuels.  Funding is directed to ensure broad participation by students, postdocs, junior faculty, and members of groups underrepresented in mathematics.<br/><br/>Conference web site:  http://www.lorentzcenter.nl/lc/web/2010/404/info.php3?wsid=404"
"1016525","Subgrid Discontinuous Galerkin Approximations of Brinkman Equation with Highly Heterogeneous Coefficients","DMS","COMPUTATIONAL MATHEMATICS","08/15/2010","08/13/2012","Raytcho Lazarov","TX","Texas A&M Research Foundation","Continuing Grant","Junping Wang","07/31/2015","$339,199.00","Joerg Willems","lazarov@math.tamu.edu","400 HARVEY MITCHELL PKWY S STE 3","COLLEGE STATION","TX","778454375","9798626777","MPS","1271","6863, 9263","$0.00","There is an abundance of challenging problems in physics and engineering, such <br/>as fluid flow in industrial foams and vuggy reservoirs, which are <br/>characterized by high porosity and complex material structure. Traditionally, <br/>these flows are modeled by Darcy's law relating the macroscopic pressure <br/>gradient to the macroscopic fluid velocity. For highly permeable media a more <br/>suitable model is given by Brinkman's equations, considered in this project. <br/>The internal structure  involves multiple spatial scales and permeabilities <br/>varying over many orders of magnitude (high contrast). Thus, the development <br/>of numerical methods for Brinkman's equations that are robust with respect to <br/>the contrast and accurately capture the fine scales is a difficult theoretical <br/>problem with important applications to engineering and geosciences. There are <br/>numerous methods for efficiently computing multi-scale porous media flows <br/>governed by Darcy's law. These include in particular multi-scale finite <br/>element methods, subgrid approximation, multi-grid, and domain decomposition <br/>methods. Developing an efficient multi-scale approximation for Brinkman is a <br/>challenging task, which cannot be addressed using methods available in the <br/>Darcy case. The first objective of this project is a development and study of <br/>numerical subgrid method for Brinkman's system. The second goal is to <br/>represent accurately the fine features of the solution, which cannot be <br/>captured by the numerical subgrid approach alone. An extension of the <br/>algorithm by alternating Schwarz iterations in order to resolve these features <br/>will be developed, theoretically justified and practically tested. The third <br/>main objective is to utilize a multi-scale finite element space and an <br/>enrichment of the coarse space by adding basis functions resulting from the <br/>approximate solution of certain small local generalized eigenvalue problems. <br/>This will allow to devise an iterative method that converges independently of <br/>the contrast.<br/><br/><br/>Phenomena in engineering such as heat and mass transfer, fluid flows, and <br/>materials, are routinely modeled by partial differential equations (PDEs). The <br/>solutions of the PDEs are subsequently used to design and develop new <br/>materials or new technologies with wide range of applications. These <br/>applications require complex models with multiple space scales, which in turn <br/>make the solution task challenging and computationally very intensive. The <br/>proposed  work is motivated by the needs for design and manufacturing of new <br/>materials and/or more accurate description of oil reservoirs or aquifers. <br/>However, developing efficient and robust solution techniques for computing <br/>flows in media with complex internal structures will significantly broaden the <br/>areas of application for which the numerical simulation is feasible. Since <br/>numerical simulations are key to better understand, control, and optimize the <br/>modeled processes the proposed research will eventually benefit other areas in <br/>science and engineering."
"0968360","FRG:  Collaborative Research:  Modeling, Computation, and Analysis of Optical Responses of Nano Structures","DMS","COMPUTATIONAL MATHEMATICS","06/01/2010","01/08/2015","Gang Bao","MI","Michigan State University","Standard Grant","Junping Wang","12/31/2015","$900,000.00","Di Liu, Jeffrey Schenker, Zhengfang Zhou","bao@math.msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1271","1616, 9263","$0.00","The interdisciplinary FRG team will develop mathematical techniques and computational methods for the light-matter interactions for nanoscale structures motivated by recent scientic and industrial applications. Critical issues on multi-physics modeling, multi-scale simulations as well as mathematical analysis of the coupled Maxwell and Schrodinger equations will be investigated. Our proposed mathematical modeling techniques and computational methods will address key scientific challenges in applied mathematics including multi-physics modeling, multi-scale computation, density functional theory, efficient numerical solution of Maxwell's equations, and well-posedness of the associated new nonlinear PDE models. Advanced tools in computational electromagnetics for  simulations and optimizations of nanophotonic structures will be developed, with a specific focus on those tools that enable multi-physics and multi-scale computations. The initial efforts will be directed towards developing  tools that enable efficient simulations of dynamically modulated photonic  structures, where there is a critical need to overcome the numerical challenges resulting from the large time-scale separations  between the electronic and the optical processes. The development here will contribute directly to increasing speed and reducing energy consumption in optical information processing applications. Partners in this FRG will collaborate to enable the applications of multi-physics simulations towards impacts in practical technologies such as sensing or energy conversion. <br/><br/>The capabilities for controlling light are of paramount importances for many aspects of modern society, and have applications in critical areas such as energy, sensing and information technology. The use of nanophotonic structures, where individual structure is at the nanoscale, is at the very forefront in our quest to control light. Nano-optics is a fundamental and vigorously growing technology with diverse applications including fast optical switches, plasmonic materials, photonic nanocircuits, optical microscopy, Ramam spectroscopy, and optical metamaterials. The recent enabling technologies of high-performance computing facilities and modern lithographic techniques have led to a substantial surge of applications of subwavelength and nano structures, establishing nano-optics as one of the most rapidly advancing areas of current research in optical science. A grand challenge encountered when optical fields meet nano structures is a fundamental mismatch in scales, which gives rise to phenomena not encountered in conventional optics and presents a challenge in interacting with such structures. The future development of nano-optics will clearly benefit from the availability of an efficient computational modeling tool and mathematical analysis techniques. The computational tools developed in this program will allow us to better understand and design these structures, potentially leading to faster information processing devices that consume less power, sensors with higher sensitivity, and solar cells with better conversion efficiency."
"1016556","Numerical treatment of singularities and the Generalized Finite Element Method: theory, algorithms, and applications","DMS","COMPUTATIONAL MATHEMATICS","08/15/2010","08/05/2010","Victor Nistor","PA","Pennsylvania State Univ University Park","Standard Grant","Junping Wang","07/31/2014","$180,000.00","","nistor@math.psu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271","6863, 9263","$0.00","Numerical Methods for Partial Differential Equations (PDEs) are an<br/>essential ingredient in many areas of Sciences and Engineering. Often<br/>in the applications of PDEs, one has to deal with additional<br/>difficulties caused by the singularities in the geometry, the<br/>coefficients, or the boundary conditions. The main goals of this<br/>proposal are to obtain more efficient numerical methods for equations<br/>with singular solutions and to develop user friendly implementations.<br/>The PI and his collaborators will design improved meshes that provide<br/>optimal rates of convergence for the Finite Element Method in three<br/>dimensions for elliptic equations on polyhedral domains with<br/>non-smooth interfaces. These equations form one of the basic<br/>ingredients in many other applications. The results will be extended<br/>to quasi-linear elliptic equations and to evolution equations. For<br/>some of these equations, spaces with higher smoothness or other additional<br/>properties are sometimes needed, and the Generalized Finite Element<br/>Method will be used for these purposes.<br/><br/><br/><br/>The proposal will contribute to the formation of graduate and<br/>undergraduate students by advising and mentoring them and by<br/>integrating them in research projects. The PI also plans to continue<br/>to run an Interdisciplinary Seminar featuring outside speakers,<br/>including non-mathematicians. The proposed research will lead to the<br/>design and testing of new and improved numerical methods for Partial<br/>Differential Equations (PDEs) of interest in Sciences and<br/>Engineering. The resulting numerical methods will be presented and<br/>implemented in a way that makes them accessible to<br/>non-mathematicians. It will also contribute to applying mathematical<br/>results in practice by interaction with researchers from other fields,<br/>including the private sector. It will also contribute to the creation<br/>of specialists able to use advanced theoretical tools to handle<br/>practical problems. He will also introduce numerical methods and the<br/>use of computers in more traditional undergraduate courses. The PI<br/>also plans to popularize mathematical questions that arise from<br/>practice among mathematicians. The theoretical results and the<br/>resulting numerical methods will have applications in Mathematical<br/>Physics, Quantum Chemistry, Biology, Finance (Risk Management and<br/>pricing of Financial Derivatives, or Options), and other areas."
"1016332","Fast Interior Penalty Methods","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS, Information Technology Researc, Special Projects - CCF","09/01/2010","08/26/2010","Susanne Brenner","LA","Louisiana State University","Standard Grant","Junping Wang","08/31/2014","$300,951.00","Li-yeng Sung","brenner@math.lsu.edu","202 HIMES HALL","BATON ROUGE","LA","708030001","2255782760","MPS","1253, 1271, 1640, 2878","6863, 9150, 9263","$0.00","This project will develop fast numerical methods for fourth and higher order partial differential equations using the interior penalty approach.  The interior penalty approach has advantages over the classical approaches that use conforming, nonconforming or mixed finite elements in terms of the computational complexity, the existence of natuaral hierarchies of elements, the preservation of the symetric positive definiteness of the continuous problem, and the ease of deriving convergent schemes for complicated problems.  Another significant advantage of interior penalty methods for higher order problems is due to the fact that discontinuous finite elements for higher order problems are also suitable for lower order problems. Therefore multigrid algorithms for interior penalty methods can be developed recursively through the hierarchy of elliptic problems.  Namely, multigrid algorithms for second order problems can be embedded naturally in multigrid algorithms for fourth order problems, which can then be embedded naturally in multigrid algorithms for sixth order problems, and so on. The performance of these multigrid methods for higher order problems is comparable to the performance of multigrid methods for second order problems.  This project will initiate a comprehensive study of interior penalty methods for higher order problems together with multigrid, domain decomposition and adaptive algorithms that will provide fast solvers for the resulting discrete problems. The results of this project will make it feasible to solve problems of order six and higher on general domains. Applications of these methods to strain gradient elasticity, plate buckling, the Monge-Ampere equations and the Cahn-Hilliard equations will also be investigated.<br/><br/>The fast algorithms developed in this project will make it practical for scientists and engineers to model complex phenomena by higher order partial differential equations. These algorithms will enhance the performance of numerical simulations in diverse areas such as structural mechanics, fluid mechanics, image processing, nanoscience, geometric optics, meteorology, optimal transport, differential geometry, and crystal growth, among many others."
"1016571","Fast First-Order Methods for Large-Scale Structured and Sparse Optimization","DMS","COMPUTATIONAL MATHEMATICS, OPERATIONS RESEARCH","09/01/2010","08/16/2010","Donald Goldfarb","NY","Columbia University","Standard Grant","Junping Wang","08/31/2014","$450,000.00","Katya Scheinberg, Garud Iyengar","goldfarb@columbia.edu","202 LOW LIBRARY 535 W 116 ST MC","NEW YORK","NY","10027","2128546851","MPS","1271, 5514","9263","$0.00","Algorithms for large-scale optimization have traditionally exploited<br/>sparsity and structure in problem data. Many important optimization <br/>problems today, such as those that arise in  statistical machine <br/>learning (ML) and in compressive sensing (CS) are extremely large-scale convex<br/>problems with completely dense and/or unstructured problem data. <br/>However, there is often sparsity and structure in the solutions to <br/>these problems. The goal of this research project is the development of<br/>first-order algorithms, including gradient methods for non-smooth functions,<br/>smoothed penalty methods for constrained problems, multiple splitting methods,<br/>alternating-direction augmented-Lagrangian methods, and<br/>block coordinate descent methods, for extremely large-scale convex <br/>optimization problems that take advantage of solution structure and/or <br/>sparsity. Rigorous convergence analysis for these methods will be provided and<br/>robust software implementations will be developed. Although these <br/>methods are expected to have wide applicability, the focus will be on <br/>applications in CS and ML. Specifically, the investigators propose to <br/>develop  and analyze new scalable algorithms for (i) CS signal <br/>recovery, including algorithms that are able to exploit more detailed <br/>a priori knowledge in addition to sparsity; (ii) matrix rank minimization, the <br/>matrix analog of CS, and its variants; and (iii) a broad array of ML problems that exploit <br/>the special sparsity/structure of the solutions to these <br/>problems.<br/><br/>The research that is proposed under this grant is focused on the development of <br/>algorithms with provable performance guarantees that are capable of <br/>solving extremely large scale optimization problems whose solutions are <br/>either sparse or have special structure.  Such problems arise under the paradigm of <br/>compressive sensing, which allows signals (e.g., radar) and images <br/>(e.g., CT and MRI scans) to be obtained with far fewer measurements <br/>than predicted by traditional theory, various extensions of CS, and in <br/>a broad array of problems in machine learning. All of these problems are <br/>aimed at extracting a ""sparse"" or low-dimensional true model from a <br/>high dimensional or dense empirical model or data. They have important applications <br/>in extracting information from surveillance video and hyper-spectral images, face <br/>recognition, medical imaging and data mining,as well as many other areas <br/>of strategic interest such as national security and biotechnology."
"0956072","CAREER: New Paradigms in Geometric Analysis of Data Sets and their Applications","DMS","COMPUTATIONAL MATHEMATICS","07/01/2010","05/18/2010","Gilad Lerman","MN","University of Minnesota-Twin Cities","Standard Grant","Junping Wang","06/30/2016","$551,568.00","","lerman@umn.edu","200 OAK ST SE","MINNEAPOLIS","MN","554552009","6126245599","MPS","1271","1045, 1187, 9263","$0.00","The PI and his collaborators will develop algorithms for detecting and recovering underlying sparse geometric structures from massive high-dimensional data sets. In particular, they plan to explore the following frameworks: geometric optimization for the purpose of detecting  low-dimensional geometric structures within point clouds; multiscale methods for the effective detection of local scales and their combination for capturing the most relevant local and global geometric information; online and adaptive algorithms for organizing data as mixtures of manifolds while separating outliers. The proposed methodologies will be justified by theoretical guarantees on performance, and these methodologies will be applied to a variety of data sets, many of which will be provided by industrial collaborators. The applications include: automatic detection of moving objects in video surveillance cameras;  motion segmentation of video images,  automatic segmentation of blood vessels in the brain taken via dynamic CT scans into arteries and veins. <br/>  <br/>Recently there has been a fundamental shift in the analysis and manipulation of certain types of data sets such as digital satellite images and magnetic resonance images (MRI).  This revolution relies on the fact that while such images seemingly have a complex and high-dimensional structure, in fact they are relatively low-dimensional  or ""sparse"". The basic observation was that this sparsity could be exploited  to more rapidly acquire, transmit, reconstruct, and analyze such images.  The PI and his collaborators are extending such ""dimensionality reduction"" techniques to more general instances of data sets with the aim of identifying when seemingly high-dimensional collections of data are actually much more simple, and to then get a grip on what the simplified structure is.  Such research has several important applications related to making computer aided decisions about data which has both security and medical significance.  The hope is that the research yields speedy, efficient, and proven algorithms for separating various and important features of data which is changing in time.   The practical benefits of the research would include reliable automation of security cameras.  Many of the applications and themes suggested in this proposal are accessible to a broad community. The PI plans to take advantage of this accessibility in order to integrate the research effort with the education of younger researchers and students. In particular, the PI is committed to provide material to mathematics educators at all levels and involve undergraduate and graduate students in emerging industrial research. The PI will share his joint findings through publications and software, all available online to the scientific and engineering  communities as well as the public at large."
"1015114","Sage:  Unifying Mathematical Software for Scientists, Engineers, and Mathematicians","DMS","ALGEBRA,NUMBER THEORY,AND COM, COMPUTATIONAL MATHEMATICS, CI REUSE, Combinatorics","09/15/2010","09/13/2010","William Stein","WA","University of Washington","Standard Grant","Tie Luo","08/31/2014","$140,000.00","John Palmieri","wstein@math.washington.edu","4333 BROOKLYN AVE NE","SEATTLE","WA","981950001","2065434043","MPS","1264, 1271, 6892, 7970","9263","$0.00","Sage is comprehensive unified open source software for mathematical and scientific computing that builds on high-quality mainstream methodologies and tools.  This proposal would further the development of Sage by funding a series of three Sage Days workshops per year.  The primary thrust of these workshops would be to improve the usability and value of Sage for scientists, engineers, and mathematicians, and especially as a tool to support research and education by undergraduate and graduate students. Morever, many graduate students would receive funding via their involvement in the workshops.<br/><br/>Sage has the potential to have a transformative impact on the computational sciences, by helping to set a high standard for reproducible computational research and peer reviewed publication of code.  Sage excels at supporting cutting edge research in a broad range of areas of computational mathematics, ranging from applied numerical computation to the most abstract realms of number theory. All data and software that comes out of this project will be made freely available over the Internet.  This will result in tools that may transform how researchers in mathematics share and manipulate their data and collaborate."
"1016073","Mathematical and Computational Studies of Interfaces and Defects","DMS","COMPUTATIONAL MATHEMATICS, COFFES","09/01/2010","08/05/2010","Qiang Du","PA","Pennsylvania State Univ University Park","Standard Grant","Junping Wang","08/31/2013","$264,183.00","","qd2125@columbia.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271, 7552","6863, 9263","$0.00","This project will focus on the development and analysis of numerical methods <br/>to probe the complex energy landscapes related to various interface and defect <br/>problems, such as microstructures in materials undergoing phase transitions, <br/>quantized vortices in geometrically frustrated configurations, and so on. <br/>The associated stochastic dynamics and hydrodynamics, as well as their <br/>numerical approximations will also be investigated.<br/>He will also study robust and adaptive algorithms that are useful in the <br/>statistical analysis of the underlying structures and important features. <br/>These research issues, on one hand, are driven by practical applications <br/>through collaborations with other scientists, and on the other hand, also <br/>motivate new studies of mathematical subjects ranging from geometry and <br/>topology to numerical and stochastic analysis. The research to be carried out is of interdisciplinary nature, encompassing subjects like computational mathematics, physics, information, materials and biological sciences. <br/>There are many mathematical and numerical challenges involved in the research <br/>such as the understanding of the collective behaviors of families and paths of <br/>solutions of nonlinear PDEs and stochastic dynamics, and the exploration of <br/>the hidden structures and statistics in the simulated results.<br/><br/>The research on the algorithmic development and numerical simulations can help <br/>enhancing the capability as well as the predictive power of scientific <br/>computations, which has potentially significant scientific, social and <br/>economic impact and is one of the top research priorities internationally. <br/>Meanwhile, interfaces and defects are also ubiquitous in nature which play <br/>fundamental roles in many aspects of physical and biological systems. A better <br/>mathematical and computational understanding of interfaces and defects,  <br/>especially in a stochastic setting,  will enrich the scientific knowledge base, which in turn may  aid the efforts by physicists, materials scientists and engineers in discovering new materials with desirable properties and in <br/>developing new scientific devices and commercial instruments. This project <br/>will also provide valuable interdisciplinary research opportunities for the <br/>future generation of workforce and researchers. With an emphasis on the TEAMS <br/>(Training in Experiments, Analysis, Modeling and Simulations) spirit, young <br/>students can be better prepared to conduct interdisciplinary research in their <br/>career."
"1016582","Coarse-grained Molecular Dynamics Models for Crystalline Solids at Finite Temperature","DMS","COMPUTATIONAL MATHEMATICS","07/01/2010","07/01/2010","Xiantao Li","PA","Pennsylvania State Univ University Park","Standard Grant","Junping Wang","08/31/2013","$165,000.00","","xli@math.psu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271","9263","$0.00","Atomistic models, such as molecular dynamics, have been very useful computational tools in many applications, especially where atomic-scale structures are crucial to the overall properties. A full atomistic model is often computationally intractable due to the huge number of degrees of freedom.  The main objective of this project is to develop coarse-grained models so that computer simulations can be conducted at a much reduced cost. Rather than relying on empirical constitutive laws, this work aims to derive the coarse-scale model directly based on molecular dynamics using a projection formalism. As an application, the coarse-grained models will be applied to dislocation dynamics, to study the response of a solid system with a mixture of dislocations.<br/><br/>At the atomic scale, crystalline solids contain many defects of delicate structures, and the detailed configurations, e.g. the type of defects,  orientations, and concentrations, are ultimately responsible for the mechanical properties of the material at the macroscopic scale.   Atomistic models, such as molecular dynamics, directly take into account the interaction of the constituting atoms.  The main challenge, however, is that such a system is usually too large to fit in any practical computation. In addition, it is not clear how macroscopic quantities of interest are related to the position of the atoms. This work offers a systematic approach to reduce the size of atomistic models, without compromising the accuracy. The reduced model will make it possible to simulate systems of realistic size, and provide valuable insight on the microscopic mechanism underlying many material processes."
"1015346","Semidefinite Programming Relaxation: Approximation Algorithms, Performance Analysis and Applications","DMS","COMPUTATIONAL MATHEMATICS","09/15/2010","09/08/2010","Zhi-Quan Luo","MN","University of Minnesota-Twin Cities","Standard Grant","Junping Wang","08/31/2013","$120,000.00","","luozq@ece.umn.edu","200 OAK ST SE","MINNEAPOLIS","MN","554552009","6126245599","MPS","1271","9263","$0.00","The PI's research to be carried out through this award consists of a systematic study of a symmetric matrix lifting technique to solve nonconvex polynomial optimization problems. This includes a complete complexity-theoretic analysis as well as the design of polynomial time approximation algorithms. Central to this study is to identify what classes of polynomial optimization problems are computationally intractable, and how well they can be approximately solved with a complexity that is polynomial in size and solution accuracy. In each case, the research focus will be on the development of a fundamental theory for an in-depth understanding of the problems under study, and the design, implementation, and analysis of robust and efficient numerical methods for solving these problems. The proposed research aims to develop polynomial time approximation algorithms which can deliver guaranteed high quality approximate solutions for some classes of polynomial optimization problems. These approximation algorithms are based on a symmetric matrix lifting technique and semidefinite programming relaxation, followed by special procedure to obtain a provably high quality feasible solution. The proposed approach leads to nonlinear semidefinite programs whose size is significantly smaller than those obtained from the Sum of Squares relaxation approach, and is therefore expected to be much more efficient computationally. Computational testing will be conducted to verify the efficiency and accuracy of the proposed approximation approach.<br/> <br/>The  research to be performed by the PI for this award is strongly motivated by  applications of polynomial optimization in wireless communication and ad hoc wireless sensor networks. His research is expected to not only advance the field of nonconvex polynomial optimization, but also significantly impact design of computational methods for interference management in multi-user communication, compressive sensing and sparse principal component analysis."
"1016268","Collaborative Research: A posteriori error analysis and adaptivity  for discontinuous interface problems","DMS","COMPUTATIONAL MATHEMATICS","10/01/2010","09/19/2011","Simon Tavener","CO","Colorado State University","Standard Grant","Junping Wang","09/30/2014","$95,975.00","Donald Estep","tavener@math.colostate.edu","601 S HOWES ST","FORT COLLINS","CO","805212807","9704916355","MPS","1271","9263","$0.00","There are many practical physical situations that can be modeled by partial differential equations in which some of the coefficients in the problem, e.g. those describing material properties, are discontinuous across an interface. Such problems arise in a very broad range of scientific and engineering disciplines, including computational biology, ground water flow and reservoir simulation, environmental remediation studies, crystal growth, wave propagation, sedimentation phenomena, and the preparation of nuclear fuel rods. Such problems cause notorious difficulties for classic numerical methods as a direct result of the lack of smoothness. At the same time, numerical methods for efficiently solving interface problems using a fixed Cartesian grid have attracted considerable attention because they offer a number of computational advantages and a number of approaches have been pursued. Unfortunately, regular-shape discretizations are generally problematic because the interface ?cuts? through the cells without respecting the regular geometry of the discretization, which has a strongly negative impact on the accuracy of the resulting approximations. Consequently, it is critically important to provide computational error estimates that quantify the accuracy of a computed quantity of interest in terms of various sources of discretization and modeling error. <br/><br/>This project will develop variational finite element frameworks for several discrete interface methods that identify both a discretization and a modeling component to the model and use the variational framework to derive accurate a posteriori error estimates for specified quantities of interest. Both stationary and evolutionary problems in two and three space dimensions will be considered. The development of efficient adaptive discretization methods for both stationary and evolution problems will be addressed. The methodology and analytic tools to be developed in this proposal will provide a powerful tool for the systematic treatment of problems in which interfaces have complex geometry and the material properties vary considerably on a scale smaller than the overall scale of the discretization. The project will yield a systematic approach to deriving computable and accurate error estimates for quantities of interest and further, provide detailed information about the relative contributions to the error arising from discretization and modeling."
"1016266","Confidence and Misplaced Confidence in Image Reconstruction","DMS","COMPUTATIONAL MATHEMATICS","09/15/2010","06/05/2012","Dianne O'Leary","MD","University of Maryland, College Park","Continuing Grant","Leland Jameson","08/31/2014","$495,489.00","","oleary@cs.umd.edu","3112 LEE BLDG 7809 REGENTS DR","College Park","MD","207420001","3014056269","MPS","1271","9263","$0.00","The underlying problem considered here is the solution of a discretization of  an integral equation of the first kind.  Even with complete information, the problem is ill-posed, in the sense that small changes in the data can make arbitrarily large changes in the solution.  Unfortunately, complete information is not available in applications such as medical imaging (CAT, MRI), astronomical imaging, spectroscopy, or non-destructive testing for cracks in a structure, and the problem becomes a discretized version of the ill-posed problem.  Solution algorithms regularize the problem, replacing the ill-posed problem by one that is well-posed in order to compute a solution.  The basic idea behind all regularization methods is to impose additional constraints on the model in order to make the problem well-posed.  There are two very different kinds of constraints, which are typically not well differentiated: data constraints that are guaranteed to hold with 100% certainty, and bias constraints, arising from what the observer expects to see.  If the observer is wrong about the bias constraints, then the solution algorithm might produce a solution that is is quite believable but very misleading.  This work focuses on three major open questions in the solution to ill-posed problems: development of diagnostics to validate candidate solutions and identify bias; development of improved algorithms that produce validated solutions through discovery of new filtering methods, reliable choice of parameters, better understanding of Krylov methods, and unification of algorithms for data least squares, least squares, and total least squares problems; and computation of confidence bounds for the solutions, making use of data constraints (e.g., nonnegativity).<br/><br/>The broader impact of the work arises from its potential to produce more reliable images for medical applications (CAT, MRI, etc.), astronomy, spectroscopy, locating oil reservoirs, testing structures for hidden cracks, and other applications.  The techniques involve effective use of extra information known about the image (for example, that each pixel value is nonnegative) in order to constrain the solution image.  The focus is on improved methods and on more precise knowledge of the solution through the construction of statistical confidence intervals.  The work also has great value in education.  A graduate course in advanced numerical linear algebra will be offered that will include a section on discrete ill-posed problems.  This work will be presented at Maryland's SPIRAL summer program for undergraduate students from Historically Black Colleges and Universities, since it provides a visually-appealing and easily-explained introduction to ill-posed problems."
"0955078","CAREER: Optimization and continuation methods in fluid mechanics","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","06/01/2010","05/11/2010","Jon Wilkening","CA","University of California-Berkeley","Standard Grant","Henry Warchall","05/31/2015","$404,941.00","","wilken@math.berkeley.edu","1608 4TH ST STE 201","BERKELEY","CA","947101749","5106433891","MPS","1266, 1271","1045, 1187, 9263","$0.00","Shape optimization in fluid mechanics is the study of how to design a body, such as a wing or propeller, to maximize lift or thrust while minimizing drag.  Tools developed for shape optimization can also be used to dramatically improve the performance of shooting methods for two-point boundary value problems governed by nonlinear partial differential equations.  This project concerns the development and implementation of new algorithms for shape optimization of Newtonian and viscoelastic fluids in nearly singular geometries, and for the computation of time-periodic solutions in fluid mechanics.  New adjoint-based optimal control methods will be developed to compute gradients of objective functions and constraints governed by partial differential equations featuring singular integrals, non-local operators, or hysteresis.  The solutions of these optimization and boundary value problems occur in multi-parameter families that will be studied using numerical continuation algorithms capable of identifying bifurcations and following folds in the manifold of solutions.<br/><br/>Shape optimization is fundamental in the design of a wide range of engineering systems such as fuel-efficient vehicles and aircraft or micro-fluidic ""lab on a chip"" devices used in chemistry and molecular biology.  One of the goals of this research is to develop shape optimization techniques for materials that behave partly as viscous fluids and partly as elastic solids.  Applications include designing inkjet printers, recycling and manufacturing plastics, and understanding bio-locomotion in invertebrates.  Another goal of this research is to develop numerical methods for computing solutions of the equations of fluid mechanics that evolve to an exact copy of their initial state at a later time and then repeat themselves forever. These solutions are helpful in understanding complex phenomena such as ocean waves or the onset of turbulence in a pipe.  They should also prove useful in dynamic shape optimization problems, where the goal might be to optimize the average speed over one cycle of a swimming stroke.  Broader impacts of this project include course and curriculum development, organization of seminars and minisymposia, community outreach, advising of students and postdocs, and hosting of DOE Computational Science Graduate Fellows who wish to do a summer practicum at Lawrence Berkeley National Laboratory."
"0939995","Special Meeting at Copper Mountain on Multigrid and Iterative Methods","DMS","COMPUTATIONAL MATHEMATICS, NUM, SYMBOL, & ALGEBRA COMPUT","10/01/2010","08/10/2012","Van Henson","AZ","Front Range Scientific Computations, Inc.","Continuing Grant","Junping Wang","09/30/2013","$149,784.00","","henson5@llnl.gov","8865 E CALLE BUENA VIS","SCOTTSDALE","AZ","852558364","3035541232","MPS","1271, 7933","7556, 9263","$0.00","This project is a three-year effort to support participation in the 2010 and 2012 Copper Mountain Conferences on Iterative Methods and the 2011 Copper Mountain Conference on Multigrid Methods. The funding in this award is specifically intended to support the participation of students, women, and minority scientists. The Copper Mountain Conferences have graduate students forming a very large fraction of the attendees (typically 30%-40%), many of them full participants who co-author papers and give presentations. Women and minorities are growing fractions of the attendees (e.g., 27 of 49 students participating in 2008 were women); this award funding is targeted to further enhance their proportions. Support for the students, women, and minority scientists from this award is in the form of reduced registration fees, travel support, and subsidized meals and lodging. The funding also supports a ""Student Paper Competition"", which draws entries from a significant fraction of the student attendees and results in extraordinarily high-quality papers on scientific discovery from the students, working in tandem with and under the guidance of their faculty advisors. These results, like the conferences as a whole, span wideranging and important theoretical and applications areas, such as techniques of convergence analysis, implementation and development of mathematical software, and use of such ideas in novel settings, including advanced computer architectures and new applications such as uncertainty quantification.<br/><br/>The Copper Mountain Conference series form arguably the premier conferences in two closely related mathematical fields: iterative and multigrid methods. These two fields provide computational support for numerical simulation of a very wide host of endeavors, including environmental and energy research, medical and biological applications, and many other areas critical to the U. S. and international science and engineering community. This award supports the participation of students, women, and minority scientists at those Conferences. The Conferences? traditionally work to ensure the future vitality of the fields of iterative and multigrid methods by facilitating development and nurturing of a community of capable graduate students and entry-level scientists. Through their egalitarian structure, with no invited speakers and all talks of equal length, the Conferences provide mechanisms for young people to meet each other and all participants in a relaxed yet scientifically rigorous setting; these mechanisms include topical tutorials, themed evening workshops, and access to the broad representation of participants from academia, national laboratories, and industry. The Conferences have a tradition of a very high level of student participation (typically 30-40% of attendees), and will cultivate this through supporting students' local and travel expenses. An emphasis is placed on engendering diversity through support of women and minority scientists. These conferences bring together the world?s leading practitioners in these critical fields and result in high-level publications, effective applications codes, and the establishment of longterm collaborative research partnerships."
"1016531","Multiscale Simulations of Heterogeneous Particulate Flows","DMS","COMPUTATIONAL MATHEMATICS","08/15/2010","05/03/2012","Yuliya Gorb","TX","University of Houston","Continuing Grant","Leland Jameson","07/31/2014","$297,586.00","","gorb@math.uh.edu","4300 MARTIN LUTHER KING BLVD","HOUSTON","TX","772043067","7137435773","MPS","1271","9263","$0.00","The proposed research is on development and simulation of a multiscale <br/>model for heterogeneous particulate flows, in which the motion of a very <br/>large number of small solid particles is coupled with a Newtonian <br/>incompressible fluid. The problem derives from particle transport, <br/>sedimentation, fluidization and separation processes that are common in <br/>many applications. Currently, there are two major approaches to simulate <br/>such flows: one of them is based on averaged equations, the other one - on <br/>direct numerical simulations. The first approach requires homogeneity in <br/>the flow which is often violated in applications, while the second one is <br/>currently limited to a relatively small number (compared to applications) <br/>of particles. However, practical applications involve millions and <br/>billions of particles whose small size leads the problem of interest to <br/>span two length scales: fine scale - the scale of particles, and coarse <br/>scale - the scale of the application. In developing the proposed approach <br/>the variational multiscale framework is employed, in which the problem is <br/>split into two problems corresponding to the coarse and fine scales. It is <br/>assumed that in each coarse grid the particle distribution can be of three <br/>different regimes depending on their concentrations: dilute, moderate and <br/>dense. The main goal of the proposed study is to design a multiscale <br/>method that can handle heterogeneous flows in all three regimes in a <br/>unified way. The key idea of the proposed approach is, after separating <br/>the two scales, to use properly chosen subgrid models adaptively to <br/>represent micro-scale flow and particle dynamics on a coarse grid. In the <br/>dilute limit, a modified viscosity is used to represent averaged effects. <br/>In the dense limit, the discrete network approximation method to <br/>approximate the subgrid effects is utilized. Network models allow avoiding <br/>detailed fine-scale simulations in the dense regimes and provide <br/>substantial CPU savings. In the intermediate regime, fine-scale features <br/>within a target coarse-grid block are resolved. The issues to be focused <br/>on are (1) coarse coupling, (2) boundary conditions for local problems, <br/>(3) approximation of subgrid effects, (4) effective solution strategies.<br/><br/>The proposed project provides tools to simulate heterogeneous particulate flows of small rigid particles in an incompressible fluid which have been <br/>of great interest for the last decade and are commonly encountered in many <br/>applications and fundamental fluid mechanics. The complexity of this <br/>problem due to the presence of two different length scales is enormous and <br/>only very recently the development of numerical techniques for direct <br/>numerical simulations and computing power allowed for some attempts to <br/>numerically resolving flows containing a relatively large number of <br/>particles. However, existing direct numerical simulations methods have <br/>been developed for flows where the maximal number of particles to be <br/>handled does not exceed a couple dozens of thousands while for practical <br/>applications much larger amount is of primary importance. This dictates a <br/>need in developing a state-of-the-art predictive multiscale model for <br/>heterogeneous particulate flows which allows one to obtain a detailed and <br/>accurate representation of the flow, and which is the main focus of the <br/>proposed research."
"1016111","Multi-scale geometry of Lagrangian and vortex-surface fields in turbulence","DMS","COMPUTATIONAL MATHEMATICS","09/15/2010","06/14/2012","Dale Pullin","CA","California Institute of Technology","Continuing Grant","Leland Jameson","08/31/2014","$250,000.00","","dpullin@caltech.edu","1200 E CALIFORNIA BLVD","PASADENA","CA","911250001","6263956219","MPS","1271","9263","$0.00","The investigator and his colleagues apply a curvelet-based, multi-scale geometric (CBMSG) methodology  to the identification, characterization and classification of scale-dependent geometry  within three-dimensional, evolving Lagrangian-scalar  and vortex- surface scalar fields in several differing turbulent flows. The CBMSG methodology first decomposes the given  field into scale- dependent component fields. Structures from each field are then extracted by iso-surfacing  and the geometry of each structure is characterized by a finite set of geometrical parameters obtained as functions of moments of the joint probability distributions of the surface shape-index and curvedness. This allows pictorial depiction of the set of structures at each scale as a cloud of points in a visualization space. The density of points within this space provides information on the statistical geometry of scale-dependent structures embedded within the original  field. An important component of the research is the development of methodologies for numerically simulating the time-wise evolution of Lagrangian scalar fields as they are convected, deformed and stretched  by turbulent velocity fields. This is achieved using a novel particle backward-tracking method that constructs directly the time-backward or reverse Lagrangian map.  Specifically, the  research  includes study of the geometry of high-resolution, Lagrangian-scalar-field evolution for homogeneous turbulence, the statistical geometry of both Eulerian and Lagrangian fields for turbulent channel  flows and the development of a methodology for tracking vortex-surface fields for inviscid and viscous fluid flow.<br/><br/>The shapes or geometry of objects in nature often plays a crucial role in their behavior.  The form of a bird or insect wing, the detailed shape of a biological cell or of a complex molecule or the organization of a tree into a large trunk, smaller branches and leaves are all related to their special function. This geometry can be changing and not static; for example the ``eddies'' comprising water or other fluid motion have long been recognized to have repeatable shapes as can  seen in  cloud formation, in breaking  sea waves and  in the billowing and folding shapes of a rocket exhaust or an oil leak from the sea floor. Typically, this complex natural geometry cannot be easily perceived in terms of a single simple  shape but must be understood as an amalgam of interconnected but different forms.  Trees and clouds are good examples.  The aim of this research is to develop quantitative, statistical methods for characterizing the complex three-dimensional geometry of the eddies that comprise turbulent fluid flow.   The methods and techniques<br/>used come from modern computational applied mathematics. The immediate practical application is that the results will inform the development of advanced computational methods for the  numerical prediction of turbulent fluid flows in a wide range of industrial and environmental settings, including  pollutant and climate modeling. While the present focus is  on the geometry of  eddies that comprise  fluid-dynamic turbulence, the methods developed have more general applicability, in principle to any of the above illustrative examples. This research is expected to lead to impact in other areas of science and engineering where the visualization and reduction of complex ``organic'' geometry embedded within huge data bases  remains a challenging problem."
"1015002","A New Finite  Element Formulation of the Level Set Method for Free Boundary Problems","DMS","COMPUTATIONAL MATHEMATICS","08/15/2010","06/10/2011","Dmitri Kuzmin","TX","University of Houston","Standard Grant","Junping Wang","07/31/2014","$157,039.00","Dmitri Kuzmin","kuzmin@math.uh.edu","4300 MARTIN LUTHER KING BLVD","HOUSTON","TX","772043067","7137435773","MPS","1271","6863, 9263","$0.00","Many problems in mathematical biology and medical research are characterized by the presence of moving interfaces that may have a complex shape and undergo topological changes. The goal of this project is the development of an adaptive variational level set method for numerical simulation of such problems. A major challenge is the need to maintain the signed distance   property of the convected level set function and guarantee mass conservation for incompressible flows. In existing level set methods, these constraints are commonly enforced at a postprocessing step when an irrecoverable damage has already been done. In the proposed finite element formulation, numerical solutions are constrained using Lagrange multipliers in the variational   formulation for the Galerkin finite element method. This eliminates the need for postprocessing and the associated numerical errors. Algebraic flux correction is performed to satisfy the discrete maximum principle and secure nonlinear stability of the constrained problem. The result is a high-resolution finite element scheme that preserves all important properties of the exact solution. A further gain of accuracy is achieved with a new mesh adaptation strategy that combines local mesh refinement/coarsening with Arbitrary Lagrangian Eulerian (ALE) displacement of nodes.<br/><br/>This interdisciplinary research will help scientists and medical doctors to gain a better understanding of fluid flows that take place in human body. Computer simulations are feasible for almost every part of the cardiovascular system, and multiple experiments can be performed without causing any hazard to the patient. However, the usefulness of information obtained in this way depends on the accuracy of the employed numerical methods. It is easy to develop a code that produces beautiful colorful pictures but it is difficult to guarantee that the results are quantitatively correct, especially for the class of free boundary problems considered in this project. It is not unusual that numerical solutions exhibit spurious oscillations, or a spontaneous loss of mass is observed. To make matters worse, other departures from physical reality may remain unnoticed and lead to wrong decisions regarding the appropriate medical treatment. The proposed methodology is designed to rule out such situations. The revised level set method is backed by mathematical theory and has a number of unique features which make it possible to capture the deformation and motion of evolving interfaces with high precision. This research paves the way to reliable simulation of drug delivery, tumor growth, and other biological processes."
"1035227","Twentieth International Conference on Domain Decomposition Methods","DMS","COMPUTATIONAL MATHEMATICS","09/01/2010","08/30/2010","Randolph Bank","CA","University of California-San Diego","Standard Grant","Junping Wang","08/31/2011","$25,000.00","Michael Holst","rbank@ucsd.edu","9500 GILMAN DRIVE","LA JOLLA","CA","920930021","8585344896","MPS","1271","7556, 9263","$0.00","This NSF award will provide partial financial support for the Twentieth <br/>International Conference on Domain Decomposition Methods, to be held at <br/>the San Diego Supercomputer Center on the campus of the University of <br/>California at San Diego, in February 2011.  Domain decomposition, in some <br/>form, is by far the most common paradigm for large-scale simulation on <br/>massively parallel distributed, hierarchical memory computers.  This <br/>paradigm permeates almost all arenas of simulation, from such practical <br/>concerns as numerical climate modeling, modeling of complex biological <br/>molecules and biological processes, the design and testing of automobiles, <br/>aircraft and other structures, and the modeling of complex porous media <br/>flows, to more abstract scientific endeavors such as modeling black holes <br/>and searching for the origins of the universe.  However, many users of <br/>domain decomposition do not avail themselves of the most sophisticated <br/>and efficient methods known.  This has become more pronounced as the size <br/>of the large-scale scientific simulation community has grown with the <br/>availability of hardware in the past few years, particularly inside <br/>scientific communities without traditionally strong ties to the <br/>computational mathematics or computer science communities.<br/><br/>The goal of this conference is to promote advances in domain decomposition <br/>methods by encouraging interdisciplinary technical interchange throughout <br/>the international computational science and engineering communities, and by <br/>taking advantage of conference siting, to attract to this important area <br/>many new U.S. scientists.  It is strongly aligned with NSF's, and more <br/>generally, our national priorities to promote and advance fundamental <br/>interdisciplinary research in Computational Science and Engineering.<br/>NSF funding will make possible financial support for graduate students, <br/>post-docs, and other young researchers who otherwise might not be able to <br/>attend.  The funding will also allow for increasing participation of women, <br/>African Americans, and Hispanic Americans from across the nation as well as <br/>from the diverse Southern California scientific community."
"1016001","Development of Discontinuous Galerkin Methods for Kinetic Transport Models and Control Problems with State Constraints","DMS","COMPUTATIONAL MATHEMATICS","08/15/2010","08/12/2010","Yingda Cheng","TX","University of Texas at Austin","Standard Grant","Junping Wang","06/30/2012","$101,591.00","","ycheng@math.msu.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271","6863, 9263","$0.00","The objective of this project is to develop and analyze novel discontinuous Galerkin (DG) <br/>methods for solving partial differential equations arising from various application areas. The DG <br/>method is a class of finite element methods using completely discontinuous piecewise polynomial <br/>space for the numerical solution and the test functions. Those robust, compact, locally <br/>conservative methods can treat arbitrarily unstructured meshes and are ideal for hp-adaptive <br/>strategies. The good properties of the scheme call for further research in areas that are <br/>traditionally not solved by DG methods. In this grant proposal, the PI plans to conduct research <br/>in the following directions: (1) a positivity-preserving DG method for solving the kinetic <br/>equations, including the Boltzmann equations and Vlasov equations, (2) application of the <br/>proposed method to solar cell/semiconductor device simulations and plasma physics, (3) a novel <br/>DG solver for the Hamilton-Jacobi equations and its applications in control problems with state <br/>constraints.    <br/> <br/>The proposed activity lies between algorithm development, analysis and applications.  <br/>Developing robust, high-order accurate, cost-efficient  numerical algorithms for kinetic models <br/>and control problem is very challenging, not only because of the high dimensionality of such <br/>models, but also because of the fact that a deep understanding of the underlying physics is <br/>required. The eventual goal is to produce solvers that are  computationally efficient and suit the <br/>need for applications. The PI's work arises from the computational demand of real world <br/>applications. Many ideas developed in this proposal will have straightforward applications and <br/>impacts in semiconductor device simulations, high-efficiency fuel cell modeling, control problems <br/>and plasma physics. The PI actively interacts  with students and faculty members in mathematics, <br/>physics, electrical engineering and chemistry departments.  In addition, the PI will integrate the <br/>project with the training of  graduate students in order to communicate in a broader context."
"1016383","RUI: Multi-scale modeling of interfacial flows of magnetic fluids with macro-chain aggregates","DMS","COMPUTATIONAL MATHEMATICS","09/15/2010","07/31/2012","Philip Yecko","NJ","Montclair State University","Continuing Grant","Leland Jameson","08/31/2014","$226,779.00","A. David Trubatch","yecko@cooper.edu","1 NORMAL AVE","MONTCLAIR","NJ","070431624","9736556923","MPS","1271","9229, 9263","$0.00","Magnetic fluids (or ferrofluids) are suspensions of magnetic nanoparticles whose properties and flows are affected by applied magnetic fields, making them useful in industrial and biomedical applications. Potential future applications, such as targeted drug delivery and micro fluidic pumping, involve both active interfaces and motion on small scales, upon which the magnetic particle distribution may become nonuniform. In particular, under moderate fields, nanoparticles aggregate into macroscopic chains which, in turn, affect the fluid flow.  These chains have been previously observed by the investigators using high resolution X-ray phase-contrast images obtained at Argonne national lab.  Further progress in modeling and simulation of ferrofluids on small scales demands new approaches.  To speed the pace of development and design of ferrofluidic devices and to facilitate the exploration of new ferrofluid applications, a robust and exible simulation method is required.  This project will develop, validate and apply such a tool, in the form of a multi-scale code for the numerical simulation of interfacial flows of magnetic fluids. These simulation codes will integrate a mesoscale model of field-induced macroscopic magnetic-particle chains and a realistic nonlinear magnetization for the bulk ferrofluid with a state-of-the-art interfacial Navier-Stokes code.  The Navier-Stokes computation will include a high-order curvature algorithm that accurately computes surface tension at interfaces.  Viscous stress due to field induced macro-chains will be derived from a dissipative particle dynamics type model.  The proposal includes carefully planned projects that will involve and support students from Montclair State's diverse population in leading-edge research.<br/><br/>The investigators will develop a computer simulation of magnetic liquid, also known as ferrofluid, a unique ""smart"" material that is easily manipulated using ordinary magnets.  While widely used as a liquid seal in computer disk drives, this easily controlled fluid has far greater potential, including applications in biomedicine (drug delivery, eye surgery and as MRI contrast agents) and in small scale devices which manipulate tiny fluid volumes, as used in biotechnology and pharmaceuticals tests.  Progress has been stalled by two obstacles.  First, experiments are limited because the fluid is very opaque, appearing as a shiny black liquid.  Second, the nano-scale particles which give the fluid its magnetic character also lead to internal structures, such as particle chains, which make its mathematical description complex.  This project overcomes the first challenge by using state-of-the-art computer simulations instead of experiments, while it overcomes the second challenge by building simple mechanical models of internal structure based on high resolution x-ray experiments, performed at Argonne national lab.  The investigators will involve students in key roles in the development of this computer simulation tool that can be used to explore, design and test these and other new applications of magnetic fluids."
"1016618","Energy parameters and novel algorithms for an extended nearest neighbor energy model of RNA","DMS","COMPUTATIONAL MATHEMATICS","09/15/2010","09/13/2010","Peter Clote","MA","Boston College","Standard Grant","Junping Wang","08/31/2013","$399,998.00","","clote@bc.edu","140 COMMONWEALTH AVE","CHESTNUT HILL","MA","024673800","6175528000","MPS","1271","9263","$0.00","Thermodynamics-based ab initio RNA secondary structure algorithms are used to detect microRNAs, targets of microRNAs, non-coding RNA genes, temperature-dependent riboregulators, selenoproteins, ribosomal frameshift locations, RNA-protein binding sites, etc. The importance and ubiquity of applications of RNA thermodynamics-based algorithms cannot be overemphasized; indeed, such applications include RNA design for novel cancer therapies and for synthetic biology. Free energy parameters of the nearest neighbor (NN) model, also called the Turner model, form the foundation for essentially all current thermodynamics-based RNA algorithms. Dynamic programming minimum free energy structure computation using Zuker?s algorithm yields an accuracy in base pair prediction of around 70%. In this grant, we intend to improve base pair prediction accuracy by mining databases of experimentally measured entropy and enthalpy values for various kinds of loops, fitting novel nearest neighbor parameters by applying Brown?s algorithm to compute the joint probability distribution from inferred marginals, and by implementing extensions of the<br/>Zuker algorithm to compute minimum free energy structure and partition function for the extended nearest neighbor model. We will then validate the extended nearest neighbor energy model and our algorithms by benchmarking predictions with the Rfam database and with secondary structures inferred from X-ray structures by using RNAview. <br/>        <br/>RNA is now understood to be a biomolecule of fundamental importance to molecular biology, having potential clinical applications in cancer diagnosis, etc. In addition to its role in gene regulation (micro RNAs and riboswitches), noncoding RNA can direct which regions of the genome are transcribed (placement of epigenetic markers) and which variants of a protein will be produced in the cell of a particular organ (alternative splice variants). In medicine, the pattern of dysregulated micro RNAs forms a biomarker for certain types of cancer. Regulation by RNA depends on its structure, in fact, primarily its secondary structure, defined as the (planar) collection of hydrogen bonds formed between different RNA nucleotides of a given sequence. The prediction of RNA secondary structure, given only its nucleotide sequence, is roughly 70% accurate. By improving this accuracy, it will be possible to better predict the messenger RNA targets of micro RNAs, and more generally to better understand gene regulation by RNA. The goal of this grant proposal to improve prediction accuracy by developing a better energy model, called the extended nearest neighbor energy model, in which the formation of hydrogen bonds between two given nucleotides depends on whether additional hydrogen bonds can form as well between neighbors of the nucleotides. We will develop energy parameters for the extended nearest neighbor model by data mining existent UV absorption experimental data, using statistical fitting algorithms, and we will develop computer programs to predict RNA secondary structure using this new energy model. Prediction accuracy of our new approach will be benchmarked on databases of RNA secondary structure."
"0955604","CAREER:  Computational Dynamics and Topology","DMS","COMPUTATIONAL MATHEMATICS, ANALYSIS PROGRAM","07/01/2010","04/07/2010","Sarah Day","VA","College of William and Mary","Standard Grant","Rosemary Renaut","06/30/2016","$472,000.00","","sday@math.wm.edu","1314 S MOUNT VERNON AVE","WILLIAMSBURG","VA","231852817","7572213965","MPS","1271, 1281","0000, 1045, 1187, 9263, OTHR","$0.00","This project combines dynamical systems theory and computational topology in constructing and utilizing rigorous numerical techniques for the study of dynamics in model systems.  The primary focus is on constructing, extending and optimizing rigorous numerical techniques and investigating additional settings where computational topology may be used effectively to measure dynamical systems.  When possible, the computational results are verified rigorously, typically through the incorporation of error bounds and the use of topological tools.  The proposed projects include extending existing techniques for computer-assisted studies and proofs for discrete time dynamical systems and forcing theorems for braided stationary solutions.  Two more sets of projects are proposed in areas where the desired rigorous results are still out of reach, although some initial progress has been made.  These include measuring parameter sets for systems in a specified family which exhibit chaotic behavior, and the study of spatial and spatio-temporal pattern formation and evolution using computational homology.  There are many open research projects in these areas (both shorter and longer term) including the study of some very interesting and fundamental modeling questions concerning appropriate spatial and other scales in models.  This grant will fund a teacher-researcher postdoctoral position, undergraduate research projects, and support teaching and research group activities.<br/><br/><br/>Dynamical systems models are being used throughout society.  Some examples include weather models used for hurricane prediction and population models used to study environmental effects on population size and persistence.  Currently, many researchers study dynamical systems like these using high powered computer simulations and statistical techniques.  On the other end of the spectrum, mathematicians have been able to decipher highly complicated dynamics in more abstract mathematical models.  The work described in this proposal aims to serve as a bridge between these two approaches.  More specifically, the investigator and her collaborators focus on the development of computational techniques that use sophisticated mathematical tools and yield mathematically rigorous results.  The mathematical tools come from the fields of algebraic topology, analysis, numerical analysis, and dynamical systems theory and may be used to decipher some of the phenomena of interest in the studied systems.  Prior progress in studying complicated dynamics in models from population ecology and heat convection motivates these continued studies.  In addition to continuing work with existing collaborators, the investigator will mentor a postdoctoral teacher-researcher and advise undergraduate research projects in these areas."
"0968060","FRG: Collaborative Research: Atlas of Lie Groups and Representations: Unitary Representations","DMS","COMPUTATIONAL MATHEMATICS","07/01/2010","04/22/2010","Peter Trapa","UT","University of Utah","Standard Grant","Bruce P. Palka","06/30/2013","$164,457.00","","ptrapa@math.utah.edu","201 PRESIDENTS CIR","SALT LAKE CITY","UT","841129049","8015816903","MPS","1271","1616","$0.00","This project has two primary goals.  The first is to solve the problem of the unitary dual: to describe the irreducible unitary representations of real reductive Lie groups. The primary tool is an algorithm to compute the unitary dual of any given group, which we are implementing inside the ""atlas"" software. We plan to use this information to prove results about the unitary dual, beginning with the unitarity of Arthur's unipotent representations. The second primary goal is to make information about representation theory of real groups accessible to non-specialists, via the software, a web site, public workshops, and other means. The atlas software is freely available on the atlas web site, and will continue to be maintained there indefinitely.<br/><br/>The idea of using symmetry to study problems in mathematics and science dates back to Fourier's work on heat nearly two hundred years ago. In the hands of Hermann Weyl, Eugene Wigner, and Andre Weil, symmetry has come to play a central role in quantum mechanics and in number theory. Lie groups, named after the Norwegian mathematician Sophus Lie, are the mathematical objects underlying symmetry.  Representation theory studies all of the ways a given symmetry, or Lie group, can manifest itself. The problem of understanding all ""unitary"" representations (in which the symmetry operations preserve lengths) is one of the most important unsolved problems in the subject, and has potential applications in many areas; for example, it is an abstract version of the question, ""what quantum mechanical systems can admit a certain kind of symmetry?"""
"1016173","Numerical Methods and Algorithms for  Fully Nonlinear Second Order Evolution Equations with Applications","DMS","COMPUTATIONAL MATHEMATICS","08/15/2010","06/21/2012","Xiaobing Feng","TN","University of Tennessee Knoxville","Continuing Grant","Junping Wang","07/31/2014","$225,000.00","","xfeng@utk.edu","201 ANDY HOLT TOWER","KNOXVILLE","TN","379960001","8659743466","MPS","1271","6863, 9150, 9263","$0.00","Fully nonlinear second order partial differential equations (PDEs) are referred to <br/>    a class of nonlinear second order PDEs which are nonlinear in (at least one) second <br/>    order partial derivatives of unknown functions. Such a class of PDEs arise from many <br/>    scientific and engineering fields including astrophysics, differential geometry, geostrophic  <br/>    fluid dynamics, image processing, kinetic theory, materials science, mass transportation,  <br/>    meteorology, and optimal control. They constitute the most difficult class of PDEs to <br/>    analyze analytically and to approximate numerically. Building on the PI's recent success on  <br/>    developing convergent and efficient numerical methods and algorithms for fully nonlinear  <br/>    second order (time-independent) elliptic PDEs, the proposed research project intends to  <br/>    carry out a comprehensive and systematic study of numerical methods and algorithms <br/>    for fully nonlinear second order (time-dependent) evolution PDEs. The objectives of the  <br/>    proposed research include (i) to develop the vanishing moment method and the moment solution  <br/>    theory for fully nonlinear second order evolution PDEs, (ii) to develop fully discrete  <br/>    Galerkin type numerical methods (e.g. finite element methods, mixed finite element methods,  <br/>    spectral and discontinuous Galerkin methods) for fully nonlinear second order evolution PDEs  <br/>    based on the vanishing moment methodology, (iii) to apply and/or to adapt the developed numerical <br/>    methods to a number of emerging application problems which are governed by fully nonlinear second <br/>    order PDEs, (iv) to develop computer codes for implementing the proposed numerical methods. <br/>  <br/>    As numerical approximations of fully nonlinear second order evolution PDEs is an untouched  <br/>    sub-area within the numerical PDEs and those PDEs arise from many important applications in <br/>    astrophysics, differential geometry, geostrophic fluid dynamics, image processing, kinetic theory, <br/>    materials science, mass transportation, meteorology, and optimal control, the completion of the  <br/>    proposed research project is expected to have a profound impact on solving this class of PDEs and <br/>    on providing the much needed capability and enabling tools for solving a range of important <br/>application  <br/>    problems which are governed by fully nonlinear second order PDEs. As a by-product, the moment <br/>    solution theory is expected to give some insights to our understanding of the viscosity solution  <br/>    theory, and might be very likely to provide a logical and natural generalization and extension <br/>    for the viscosity solution theory which is not natural and neither practical from the computational  <br/>    point of view. The educational component of this project is to engage and train graduate students in  <br/>    developing necessary applied and computational mathematics knowledge and skills so that they can <br/>   pursue a successful career in science and engineering in the future."
"1000622","Conference on Numerical Linear Algebra: Perturbation, Performance, and Portability","DMS","COMPUTATIONAL MATHEMATICS, NUM, SYMBOL, & ALGEBRA COMPUT, PARAL/DISTRIBUTED ALGORITHMS","01/15/2010","02/03/2010","Robert van de Geijn","TX","University of Texas at Austin","Standard Grant","Junping Wang","12/31/2010","$24,000.00","","rvdg@cs.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271, 7933, 7934","0000, 7556, 9263, OTHR","$0.00","While the subject of numerical linear algebra dates back to before the first computations were performed by computers, it continues to be a vibrant topic of research.  It is central to practical fields like optimization, data mining, signal and image processing, and control, to name a small subset. Recent advances in computer architecture, including the emergence of hardware accellerators like GPGPUs and the Cell Broadband Accellerator, have forced a fresh look at perturbation (e.g., because such processors often do not support IEEE standard arithmetic and/or mix precisions), performance (how to unleash the promised performance), and portability (programmability) issues.  This conference will bring together leading experts in the field to examine recent and possible future advances related to these issues.<br/><br/>A two day event will be held in the Advanced Computing Engineering and Sciences (ACES) building on the UT-Austin campus, July 19-20, 2010.  The meeting will examine past and present contributions as well as future opportunities in the field of computational linear algebra, a key subject within mathematics and computer science that supports computational science.  The conference includes invited talks by established authorities as well as rising stars in the field.  An opportunity for more junior researchers (graduate and postdoctoral students) to showcase their research is included in form of a poster session.  A panel discussion will examine the state of the field and future opportunities.  The participation by individuals who do not have other federal support, and by students, postdocs, women, minorities, and persons with disabilities will be encouraged."
"1016577","Multiscale Algorithms for Wave Propagation","DMS","COMPUTATIONAL MATHEMATICS","08/01/2010","07/06/2010","Bjorn Engquist","TX","University of Texas at Austin","Standard Grant","Junping Wang","07/31/2013","$274,098.00","Lexing Ying","engquist@math.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271","9263","$0.00","Most scientific processes and their related mathematical models have important features in a wide range of time and length scales. Some typical examples related to the computation of waves are propagation and scattering of high frequency waves and interaction of the wave field with complex media.  Discretizing these problems directly at the finest scale and solving the resulting systems with standard numerical algorithms inevitably leads to an enormous computational problem with unacceptable long computation times and large memory requirements. Building on our previous experience in multiscale algorithms, we plan to design, implement, and analyze novel algorithms for problems in high frequency wave propagation and related fields. Such problems are challenging since many well-known techniques, such as multigrid and standard fast multipole methods have limited efficiency. We will focus on the following three topics: (1) high frequency acoustic and electromagnetic scattering, (2) Gaussian beam methods for high frequency wave and Schrodinger equations, and (3) homogenization of complex media with multiple reiterated scales.<br/><br/>The overarching theme of the research presented in this proposal is to exploit the geometric structures and asymptotic features of a variety of multiscale problems. The proposed research will have direct impact in several application fields. These algorithms will help us to solve large scale complicated scattering problems on the scales of thousands of wavelengths as in antenna design for wireless communication. We will also better understand wave propagation in composite materials with applications in exploration seismology. On the education side, the development of modern numerical algorithms and softwares requires researchers to understand different aspects of computational mathematics. We plan to use this grant to support two graduate students. <br/>This will not only help training a new generation of researchers who master algorithmic design, mathematical analysis, and software development, but also promote the awareness and interests in computational mathematics among undergraduates and underrepresented groups. We will work with researchers from industrial and government laboratories to disseminate ideas and deliver operational softwares for challenging applications."
"1009005","Collaborative Research: Randomized Algorithms in Linear Algebra and Numerical Evaluations on Massive Datasets","DMS","COMPUTATIONAL MATHEMATICS","10/01/2010","09/21/2010","Michael Saunders","CA","Stanford University","Standard Grant","Leland Jameson","09/30/2013","$228,963.00","","saunders@stanford.edu","450 JANE STANFORD WAY","STANFORD","CA","943052004","6507232300","MPS","1271","7721, 7752, 9263","$0.00","Data matrices have structural properties that present challenges and opportunities for both the Numerical Linear Algebra (NLA) community and the Theory of Algorithms (ToA) community. Matrix factorizations, such as the eigendecomposition, the rank-revealing QR factorization, and the Singular Value Decomposition, have been widely used for information retrieval. Historically, matrix factorizations have been of central interest in NLA since one can use them to express a problem in such a way that it can be solved more easily. ToA, on the other hand, has recently addressed the computation of such decompositions from a sampling perspective. The two approaches are complementary. However, thus far, the two communities have not worked closely together to integrate them. More often than not, each community is only cursorily aware of developments in the other community. Defining significant research directions that both communities can work on, and applying the resulting linear algebraic algorithms to data analysis problems (among others) will lead to important breakthroughs. The main objective for this proposal is to bridge the existing gap and bring together NLA and ToA researchers to promote cross-fertilization of ideas that could have immediate and long-term impact on data analysis. Towards that end, the PIs will work on set of prototypical research problems that can significantly benefit from ideas and research in both NLA and ToA. These problems range from approximating the singular values and vectors of a matrix by element-wise sampling to random-projection-based algorithms for least-squares problems and the design of randomized algorithms for the widely used non-negative matrix factorization.<br/><br/>This proposal seeks to explore the complementary perspectives that the Numerical Linear Algebra and the Theory of Algorithms (ToA) communities bring to linear algebra and matrix computations. This is a timely quest, motivated by technological developments over the last two decades that permit the automatic generation of large datasets. Such datasets are often modeled as matrices. The proposed work will serve as a demonstration project on the fruitfulness of collaboration between the NLA and the ToA communities on problems that are of common interest. It is expected that the proposed research will demonstrate commonality in the two approaches, as well as highlight the advantages of the dual perspective. Through outreach activities, the PIs hope to motivate even more researchers to undertake similar investigations on related topics. The proposed algorithms will be numerically evaluated on a suite of matrices from application domains that the PIs have been working on over the past few years, in order to understand better their properties and to demonstrate their potential in dealing with the modern, massive datasets. More specifically, the PIs will test the proposed strategies on population genetics data in order to infer ancestry of individuals, as well as gene expression data in order to investigate hypotheses that correlate genes and diseases. As such, we expect that the developed algorithms will impact the areas of linear algebra, randomized algorithms, information retrieval and data mining, as well as bioinformatics. Finally, in order to disseminate the proposed research, the PIs intend to organize workshops (following the example of the Workshops on Algorithms for Modern Massive Datasets in 2006, 2008, and 2010; the PIs were co-organizers of these workshops) and working group meetings, and will disseminate their research via blogs and articles intended for broader audiences."
"0968809","FRG: Collaborative Research: Modeling, Computation, and Analysis of Optical Responses of Nano Structures","DMS","COMPUTATIONAL MATHEMATICS","06/01/2010","05/05/2010","Shanhui Fan","CA","Stanford University","Standard Grant","Junping Wang","05/31/2013","$360,000.00","","shanhui@stanford.edu","450 JANE STANFORD WAY","STANFORD","CA","943052004","6507232300","MPS","1271","1616, 9263","$0.00","The interdisciplinary FRG team will develop mathematical techniques and computational methods for the light-matter interactions for nanoscale structures motivated by recent scientic and industrial applications. Critical issues on multi-physics modeling, multi-scale simulations as well as mathematical analysis of the coupled Maxwell and Schrodinger equations will be investigated. Our proposed mathematical modeling techniques and computational methods will address key scientific challenges in applied mathematics including multi-physics modeling, multi-scale computation, density functional theory, efficient numerical solution of Maxwell's equations, and well-posedness of the associated new nonlinear PDE models. Advanced tools in computational electromagnetics for  simulations and optimizations of nanophotonic structures will be developed, with a specific focus on those tools that enable multi-physics and multi-scale computations. The initial efforts will be directed towards developing  tools that enable efficient simulations of dynamically modulated photonic  structures, where there is a critical need to overcome the numerical challenges resulting from the large time-scale separations  between the electronic and the optical processes. The development here will contribute directly to increasing speed and reducing energy consumption in optical information processing applications. Partners in this FRG will collaborate to enable the applications of multi-physics simulations towards impacts in practical technologies such as sensing or energy conversion. <br/><br/>The capabilities for controlling light are of paramount importances for many aspects of modern society, and have applications in critical areas such as energy, sensing and information technology. The use of nanophotonic structures, where individual structure is at the nanoscale, is at the very forefront in our quest to control light. Nano-optics is a fundamental and vigorously growing technology with diverse applications including fast optical switches, plasmonic materials, photonic nanocircuits, optical microscopy, Ramam spectroscopy, and optical metamaterials. The recent enabling technologies of high-performance computing facilities and modern lithographic techniques have led to a substantial surge of applications of subwavelength and nano structures, establishing nano-optics as one of the most rapidly advancing areas of current research in optical science. A grand challenge encountered when optical fields meet nano structures is a fundamental mismatch in scales, which gives rise to phenomena not encountered in conventional optics and presents a challenge in interacting with such structures. The future development of nano-optics will clearly benefit from the availability of an efficient computational modeling tool and mathematical analysis techniques. The computational tools developed in this program will allow us to better understand and design these structures, potentially leading to faster information processing devices that consume less power, sensors with higher sensitivity, and solar cells with better conversion efficiency."
"1016214","Collaborative Research: Predicting the Release Kinetics of Matrix Tablets","DMS","COMPUTATIONAL MATHEMATICS","08/15/2010","08/05/2010","Peter Hinow","WI","University of Wisconsin-Milwaukee","Standard Grant","Junping Wang","07/31/2014","$125,782.00","","hinow@uwm.edu","3203 N DOWNER AVE","MILWAUKEE","WI","532113153","4142294853","MPS","1271","9263","$0.00","This work will extend two mathematical models for the dissolution and release process occurring in sustained release matrix tablets. The first of these models uses random walks on the weighted contact graph of a random dense packing of spheres of multiple diameters. The second model consists of a system of partial differential equations of reaction-diffusion type for the solved and unsolved excipient and drug, respectively.  We will develop new computational tools, borrowing from theories of random walks on graphs, probability density estimation, and numerical partial differential equations. The theoretical models will be implemented in fast, robust code, and model parameters will be calibrated to actual data in close collaboration with researchers in the  pharmaceutical sciences.<br/><br/>The team of investigators will develop mathematical and computational methods to predict the release kinetics of sustained release matrix tablets. These tablets are used to deliver an active drug and to gradually release it over an extended period of time. Sustained release tablets offer considerable advantages over immediate release tablets, namely maintaining more constant drug levels in the patient's body while minimizing the number of tablets that need to be taken each day. In previous  work, jointly with collaborators in New Zealand (initiated by NSF grant DMS-0737537), we have proposed mathematical models for the dissolution  and release process, predicting qualitatively excellent release curves for different compositions of the powder mixture. This research will streamline the design process of new and better pharmaceutical delivery devices and will introduce computational methods into a new field of science.  All programs will be written in open source software and will be freely available online to interested researchers."
"1016579","Modeling, Algorithms and Computation of Electromagnetic Wave Interacting with Dispersive Interface","DMS","COMPUTATIONAL MATHEMATICS","08/15/2010","08/05/2010","Shan Zhao","AL","University of Alabama Tuscaloosa","Standard Grant","Leland Jameson","07/31/2014","$150,000.00","","szhao@ua.edu","301 ROSE ADMIN BLDG","TUSCALOOSA","AL","354870001","2053485152","MPS","1271","7237, 9150, 9263","$0.00","The goal of the proposed project is to develop novel mathematical and simulation tools for studying electromagnetic wave interacting with arbitrarily curved dispersive interface. Great challenges exist in developing efficient and reliable numerical methods for such interactions. Physically, jumps in wave solution and its derivatives across the dispersive interface are time dependent. Numerically, the existing algorithms suffer a serious accuracy reduction due to their incapability to handle such time variant jumps. Computationally, this interface error will be significantly amplified when coupling with the staircasing approximation in treating curved interface. Due to these challenges, an extremely expensive mesh resolution of about 100 grid points per wavelength was commonly practiced in the metamaterial simulations. In this project, the investigator will rigorously analyze the time dependence and cross coupling of electromagnetic field components at the dispersive interface. Novel formulations will be derived for commonly used dispersive material and metamaterial models to convert time dependent jump conditions into time independent ones and to minimize the cross coupling. Building on these mathematical modeling, a second order accurate interface algorithm will be developed to deal with arbitrarily curved dispersive interface, by using only a simple Cartesian grid. This higher order of accuracy will promise a higher numerical resolution, so that the computational burden of the existing simulations can be significantly relieved. <br/><br/><br/>Dispersive media are ubiquitous in nature, such as in biological tissues, rocks, soils, and plasma. The numerical simulation of dispersive media is crucial to a wide range of electromagnetic and optical applications, such as microwave imaging for early detection of breast cancer, double negative metamaterial based subwavelength imaging system, and cloaking devices. The proposed mathematical modeling, algorithm development, and numerical computations will address key scientific challenges in an interdisciplinary filed lying at the interface of computational mathematics, physics, and electric engineering. The planned research activities will bring new advances to computational mathematics and lead to reliable simulation tools for the characterization, analysis, and design of various practical engineering devices and systems. These tools in turn may offer a better means for analyzing or calibrating some basic physical laws, such as the one governing the resolution limit of the sub-diffraction imaging system. In addition, this project will provide an interdisciplinary research training environment which could inspire and promote more students to purse careers in science and engineering."
"1016504","Simulation of Liquid Crystal Elastomers","DMS","COMPUTATIONAL MATHEMATICS","07/15/2010","07/06/2010","Wei Zhu","AL","University of Alabama Tuscaloosa","Standard Grant","Junping Wang","06/30/2014","$97,380.00","","wzhu7@bama.ua.edu","301 ROSE ADMIN BLDG","TUSCALOOSA","AL","354870001","2053485152","MPS","1271","9150, 9263","$0.00","Liquid crystal elastomers (LCEs) are rubbers that are comprised of weakly cross-linked liquid crystal polymers with orientationally ordered side-chain and main-chain mesogenic rods. The remarkable property of LCEs is the coupling between orientation order and mechanical deformation, which makes these rubbers very sensitive to external stimuli, such as illumination and other applied fields, leading to large and fast shape deformations. A great deal of the experimental and theoretical results on LCEs has been obtained during the last decade. However, a full characterization of LCEs still remains elusive, especially for the dynamic responses of LCEs. Recently, the investigator and his collaborators proposed a non-local continuum model to understand the dynamics of nematic LCEs. The simulation of the model demonstrated that the proposed model can successfully capture shape changing phenomena and some other features of LCEs that were observed from real experiments. The model thus provides a solid basis for further exploration of the dynamics of LCEs. However, due to the intrinsic complexity of the physical processes underlying the dramatic responses of LCEs, the numerical treatment of the model is very challenging. In this project, the investigator focuses on developing efficient and reliable numerical methods for solving the derived equations originating from the proposed model on nematic LCEs. The success of this project will provide an important tool to enhance the understanding of LCEs. Further, the deep understanding of the dynamic responses of LCEs is crucial to their technological applications including sensors, actuators, deformable adaptive optical elements, micro-fluidic pumps, etc.<br/><br/>Liquid crystal elastomers (LCEs) are soft complex materials. The salient feature of LCEs is that relatively small external effects, such as changes in temperature or onset of illumination, can result in large and fast shape deformations. Due to this remarkable property, LCEs have the potential for real technological applications including sensors, actuators, deformable adaptive optical elements, micro-fluidic pumps, etc. To fully exploit these materials, the investigator and his collaborators have already proposed a mathematical model that can successfully capture many dynamic features of LCEs, such as shape changing phenomena. However, due to the intrinsic complexity of the physical processes underlying the dramatic responses of LCEs, both theoretical study and simulation of the proposed model are very challenging. In this project, the investigator seeks to develop efficient and reliable numerical methods for the simulation. The success of the research will provide a powerful tool to improve the understanding of LCEs, and the deep understanding is essential to the real technological applications of these materials. Moreover, the methods developed in the research will be useful for the modeling of other related complex soft matter systems, and will therefore have a lasting value in the computational materials science community."
"1003889","Workshop on Fluid Motion Driven by Immersed Structures: Analysis, Computation, and Applications","DMS","COMPUTATIONAL MATHEMATICS","08/01/2010","07/19/2010","Anita Layton","NC","Duke University","Standard Grant","Junping Wang","07/31/2011","$41,550.00","","alayton@math.duke.edu","2200 W MAIN ST","DURHAM","NC","277054640","9196843030","MPS","1271","7556, 9263","$0.00","This project will provide travel support for graduate students and junior faculty to attend the Workshop on Fluid Motion Driven by Immersed Structures, to be held in August of 2010 at the Fields Institute. The meeting will be organized around three main themes: formulation and analysis of the underlying governing equations; algorithmic and computational issues related to increasing accuracy and efficiency through use of adaptivity, novel time-stepping schemes and parallelism; applications to problems in the biological, physical and engineering sciences. The principal goal of this workshop is to advance the field of fluid-structure interactions on various fronts, in part, via the gathering of a number of highly-respected applied mathematicians and engineers, who have agreed to present keynote lectures. In addition, the workshop will include two tutorials targeted to graduate students and junior mathematicians, with the goal of providing training opportunities to young scientists. By providing travel support, the workshop will facilitate the exposure of graduate and undergraduate students to state-of-the-art current research.<br/><br/>The workshop will bring together pioneers in both applied mathematics and engineering, who work on advanced computational techniques for simulating the interactions between fluid and an immersed structure. There is tremendous interest in the development and application of such techniques, in large part, because of the multitude of applications in biology and medicine. For example, these techniques have been used to simulate fluid flows around heart valves, so to shed insights into the design of prosthetic mitral heart valves. Also, recognizing that a commitment to nurturing young scientists is essential to the continued growth and success of a field, the workshop will attract junior participants (graduate students and junior faculty) by providing travel support and by making sure that keynote lectures are accessible."
"1016188","Models and Adaptive Methods for Compressible Multi-Material Reactive Flow","DMS","COMPUTATIONAL MATHEMATICS, OPPORTUNITIES FOR RESEARCH CMG","09/15/2010","09/18/2010","Donald Schwendeman","NY","Rensselaer Polytechnic Institute","Standard Grant","Junping Wang","08/31/2014","$296,326.00","Ashwani Kapila","schwed@rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","MPS","1271, 7215","7232, 9263","$0.00","Applications in a variety of scientific fields require accurate computation of physical phenomena that are driven by mechanisms operating at very fine scales.  Such problems often involve mixtures involving several distinct phases and/or constituents.  A successful approach requires two ingredients: multi-phase and/or multi-physics mathematical models that are valid at the larger scale of observation but contain within them all the necessary information from the finer scales, and a computational strategy that is robust and generates accurate numerical solutions.  One such problem is the initiation and propagation of detonation waves in high-energy solid explosives, a problem that is of major interest to those engaged in the stewardship of the nation's nuclear arsenal and is the main focus of the proposed research.<br/><br/>The proposed work is a contribution to the modeling and computation of high-speed, multi-material flow.  The project is focused on detonations in confined, high-energy granular explosives, and the aim is to accurately predict the response of the explosive/confiner system to an igniting stimulus.  The problem encompasses many scales; the molecular at which energy-liberating reactions occur, the meso at which physical processes determine the sites of ignition and the modes of combustion, and the macro at which the explosive does work to push or deform.  It is proposed that the entire assembly be modeled as a hybrid multi-phase multi-fluid mixture.  Problems at both the meso and the macro scales will be examined computationally; the former to uncover and quantify processes leading to discrete sites of ignition and the latter to explain possible mechanisms of detonation failure. The mathematical models will be nonlinear systems of hyperbolic partial differential equations with source terms, and a central goal of the research will be the development of numerical methods that provide an accurate description of material interfaces over long times."
"1016591","Transcending POD:  Model Reduction for Complex Fluid Flows","DMS","COMPUTATIONAL MATHEMATICS","09/15/2010","09/18/2010","John Roop","NC","North Carolina Agricultural & Technical State University","Standard Grant","Leland Jameson","08/31/2014","$83,389.00","","jproop@ncat.edu","1601 E MARKET ST","GREENSBORO","NC","274110002","3363347995","MPS","1271","9263","$0.00","The investigators will study improved computational algorithms for<br/>model reduction of complex fluid flows.  This research will have two<br/>main thrusts, new closure models and a parametric modeling framework.<br/>The investigators will investigate closure for models that are based on <br/>the proper orthogonal decomposition.  This component of the research <br/>will leverage current developments in large eddy simulation along with <br/>two-level algorithms for efficient computational implementation.  The<br/>fact that the closure models follow from both mathematical and physical <br/>arguments will allow for a methodology that generalizes to physical <br/>settings other than fluid flow.  A new globalization methodology that<br/>combines more accurate local models with an interpolation framework<br/>to evaluate the models in parameter space will also be studied.  The <br/>local model improvements are provided using flow sensitivity analysis <br/>and basis functions are constructed using a multidimensional Hermite <br/>interpolation method.   The investigators will emphasize problems in <br/>geophysical fluid dynamics as well as flows with free convection.<br/><br/>This research will expand the applicability of computationally<br/>efficient simulations to a wider class of fluid flows.  The availability<br/>of dramatically faster simulations is important to many engineering <br/>applications including optimization and control of fluid flows, data<br/>assimilation and uncertainty quantification.  Therefore, the research <br/>conducted in this project has direct application to a wide range of<br/>problems that include data assimilation in climate and weather modeling <br/>as well as simulation, optimization, and control of energy efficient buildings."
"1013845","Discrete and continuous nonlocal material models and their coupling","DMS","COMPUTATIONAL MATHEMATICS","09/15/2010","09/11/2010","Max Gunzburger","FL","Florida State University","Standard Grant","Junping Wang","08/31/2013","$330,000.00","","gunzburg@fsu.edu","874 TRADITIONS WAY","TALLAHASSEE","FL","323060001","8506445260","MPS","1271","9263","$0.00","The rational design of materials, the development of accurate and efficient material simulation, design, and control algorithms, and the determination of the response of materials to environments and loads occurring in practice all require an understanding of mechanics at disparate spatial and temporal scales. For this reason, there has been very considerable interest in the development of multiscale material models. A common approach for this purpose is to couple atomistic and continuum models, the first used to accurately resolve defects at small scales, the second to efficiently treat regions lacking defects. For example, many have tried to couple nonlocal molecular dynamics (MD) with local classical continuum elasticity (CE) models with limited success because, for all but the smallest samples, there remains a gap between the scales for which MD is tractable and CE is valid and also because one has to overcome problems arising from the coupling a nonlocal model (MD) to a local one (CE). The project addresses these difficulties by replacing MD with a newly developed variant (QC-QR) of the quasicontinuum (QC) method and CE by the nonlocal peridynamics (PD) continuum model. The QC-QR method approximates the well-known QC method by replacing the sums that determine the force on each active particle in the QC method by shorter sums defined using a ?quadrature? rule. The PD method does not involve spatial derivatives so that it can accurately account for defects at relatively small scales. The gains in efficiency effected by the QC-QR method relative to MD and QC and the gains in the range of validity effected by PD relative to CE, added to the fact that both QC-QR and PD are nonlocal models, means that a coupled QC-QR/PD model has the potential of overcoming the difficulties encountered for coupled MD/CE models that were alluded to above. In fact, QC-QR and PD are themselves multiscale material models, so that one significant aspect of the project is to explore the limits of their use as multiscale mono-models for materials. The project also considers the multiscale composite QC-QR/PD model whose efficacy is determined through computational and analytical studies. Likewise, the use of the QC-QR/PD coupled model as a bridge between MD and CE is considered.<br/>The rational design of new materials and their use in applications require an understanding of mechanics at disparate spatial and temporal scales ranging from that of atoms to that of the size of aircraft and bridges. For this reason, there has been very considerable interest in the development of multiscale material models that are valid over all that range of scales. Previous attempts at coupling models that are valid over limited scales so as to produce a composite model that is valid at all scales have not met with complete success because of several reasons, including the fact that a gap exists between the range of validity of some models and the range of tractability of others. Our goal is to produce a model for the mechanics of materials that is valid and tractable over a wider range of scales than can be handled by models in current use. We have participated in the development of new models, one that extends the range of validity of models that can operate at the large-end of the scales and one that improves the efficiency of models that operate at the atomistic scale. We make further studies of these models to determine more precisely their range of validity and tractability. We then study, through mathematical and computational means, how best to couple the two models and to quantify the resulting improvements over existing approaches. Finally, we test the new composite model by applying it to the solution of a series of test problems."
"1016381","Computational Design of Microfluidic Structures","DMS","COMPUTATIONAL MATHEMATICS","08/15/2010","07/10/2012","Mark Sussman","FL","Florida State University","Continuing Grant","Leland Jameson","07/31/2014","$300,327.00","Michael Roper","sussman@math.fsu.edu","874 TRADITIONS WAY","TALLAHASSEE","FL","323060001","8506445260","MPS","1271","9263","$0.00","This research project will develop new numerical techniques for the optimization/design and simulation of multi-phase/multi-fluid flow in microfluidic devices. Novel techniques will be developed for modeling the effect of surface tension and surfactants which will significantly reduce the simulation time in comparison to state-of-the-art methods. Novel, non-intrusive/derivative-free optimization techniques shall be developed for controlling the creation of droplets and minimizing droplet re-coalescence.<br/><br/>""Lab on a chip"" devices hold great promise for advancing research in proteomics and diagnostics and drug discovery.  One of the most frequently used microfluidic operations is the separation of aqueous reagents into droplets.  For example, these droplets can be stored in a droplet trap array and then released/processed at a later time.  Another operation of microfluidic devices is the creation of emulsions.  A better understanding of how surfactants and microfluidic device geometries affect droplet rupture and re-coalescence is fundamental in understanding the emulsification process.  Besides being an enabling technology for the design of microfluidic lab-on-a-chip devices, numerical methods that aid in the design process associated with multi-phase flow and/or surfactants have applications in ship hull design, ink-jet devices, design of off-shore structures, design of beach erosion prevention devices, and the design and application of dispersants in order to break up oil emulsions (oil slicks) at air/water interfaces."
"1016190","Numerical methods for heterogeneity and nonlocality","DMS","COMPUTATIONAL MATHEMATICS","08/15/2010","08/04/2010","Burak Aksoylu","LA","Louisiana State University","Standard Grant","Junping Wang","07/31/2014","$180,000.00","","baksoylu@tamusa.edu","202 HIMES HALL","BATON ROUGE","LA","708030001","2255782760","MPS","1271","6863, 9150, 9263","$0.00","The PI proposes two main research thrusts. The first is to develop scalable <br/>solvers, in particular, iterative substructuring methods, for integral <br/>equation based nonlocal (NL) problems such as peridynamics (PD).  As a <br/>component in the first thrust, heterogeneity is incorporated to study <br/>composite materials which is of utmost importance to numerous applications in <br/>material science and structural mechanics.  Within the first thrust, <br/>robustness of the solvers with respect to heterogeneity and multiscale finite <br/>element discretizations are the subsequent directions to pursue.  The second <br/>research thrust concentrates on preconditioning for partial differential <br/>equation (PDE) based (local) problems with rough coefficients.  The robustness <br/>aspect strongly connects the first research thrust to the second.  Since the <br/>impact of nonlocality on solvers has never been studied before, the first <br/>research thrust is unique, transformative, and has great potential to create a <br/>solver subfield: nonlocal domain decomposition methods (DDM).<br/>Solver research has the potential to reveal multiscale implications associated <br/>to NL modeling.  The PI proved fundamental results indicating that the weak <br/>formulation of PD gives rise to conditioning bounds that are independent of <br/>the mesh size, meaning that the length scale is carried by the horizon instead <br/>of the mesh size.  The study of composite materials requires solvers that are <br/>robust with respect to heterogeneity as well as discretizations supporting <br/>multiscale features and nonlinearities.  For robustness, the PI will <br/>capitalize on his existing preconditioning technology for (local) PDE based <br/>problems.  The second research thrust calls for a qualitative understanding of <br/>the PDE operators and their dependence on the coefficients because such <br/>understanding is essential for designing preconditioners.  This process draws <br/>heavily upon effective utilization of theoretical tools such as methods in <br/>operator theory.<br/>The resulting control of the behaviour of the operators should allow the <br/>detection of the main features that provide a basis for the construction of <br/>robust preconditioners.  After discretization, singular perturbation analysis <br/>(SPA) is used to detect and exploit algebraic features such as low-rank <br/>perturbations and decoupling of solution parts to construct computationally <br/>more feasible preconditioners.<br/>With the insights provided by operator theory and SPA, one acquires control of <br/>the effectiveness and computational feasibility simultaneously.<br/><br/>Scalable and robust solver technologies will create a great impact on modeling <br/>and simulation capabilities in material science and structural mechanics, the <br/>two vital fields that would maintain the nation's leadership in the aerospace <br/>industry.  There is imminent need for effective numerical methods in these <br/>fields as composite materials have become industry standard.  For instance, <br/>Airbus and Boeing heavily use light weight composite materials in modern <br/>aircrafts.  NL models, especially PD, have become increasingly useful for <br/>multiscale material modeling as well.  The effectiveness of PD has been <br/>established in sophisticated nanoscience applications such as fracture and <br/>failure of composites, nanofiber networks, and polycrystal fracture.  In <br/>addition, the prediction of crack paths has been successfully modeled by PD. <br/>Furthermore, NL modeling has been used in abundant applications which include <br/>fracture of solids, stress fields at dislocation cores and cracks tips, <br/>microscale heat transfer, and fluid flow in microscale channels.  There are <br/>other fields important to national interest where NL models are critically <br/>needed for the effective modeling and simulation of complex phenomena.  <br/>Examples include evolution equations for species population densities, image <br/>processing, porous media flow, and turbulence."
"1016224","Computational Methods for Structured and Singular Matrix Polynomials","DMS","COMPUTATIONAL MATHEMATICS","07/01/2010","06/30/2010","D. Steven Mackey","MI","Western Michigan University","Standard Grant","Junping Wang","06/30/2014","$300,000.00","Niloufer Mackey","steve.mackey@wmich.edu","1903 W MICHIGAN AVE","KALAMAZOO","MI","490085200","2693878298","MPS","1271","9263","$0.00","Matrix polynomials frequently arise in the engineering and applied sciences,especially in structural dynamics, vibrational analysis, control systems, and differential-algebraic equations (DAEs), to give a few examples. Principal among the associated problems are the computation of the eigenstructure of regular matrix polynomials, and in the case of  singular polynomials, the computation of minimal indices and minimal bases. In recent work, the investigators and their colleagues identified rich spaces of linearizations which led to the construction of new structured linearizations,condensed forms, and accurate structure-preserving algorithms. By using new techniques, they have also made progress on singular polynomials, showing that linearizations provide a pathway to the reliable computation of minimal indices and bases. This proposal singles out several important tasks for investigation concerning linearizations, quadratifications and minimal indices and bases. The goal is to develop new algorithms for these computations, and increase theoretical understanding so as to aid in the formulation of effective algorithms.<br/><br/>The problems studied in this proposal are ubiquitous in a wide range of important problems in engineering and applied sciences. Numerical methods for their solution are critical in structural mechanics, molecular dynamics, vibrational analysis, the simulation of electrical circuits, elastic deformation of anisotropic materials, and optical waveguide design, to give a few examples. <br/>The trend towards extreme designs, such as high speed trains, optoelectronic devices, micro-electromechanical systems, and ``superjumbo'' jets such as the Airbus 380, presents a challenge for the computation of the resonant frequencies of these structures. These extreme designs often lead to computationally sensitive problems, while the physics of the underlying problem leads to structure that numerical methods should exploit in order to obtain physically meaningful results. The aim of this project is to increase our theoretical understanding of mathematical transformations that preserve these structures and thereby advance the development of computationally effective algorithms. Consequently, this work will have direct benefit to scientists and engineers across a wide range of disciplines."
"1134731","Collaborative Research: Efficient algorithms for free boundary flows of complex fluids","DMS","COMPUTATIONAL MATHEMATICS","09/01/2010","06/07/2011","Giovanna Guidoboni","IN","Indiana University","Standard Grant","Junping Wang","07/31/2012","$65,295.00","","giovanna.guidoboni@maine.edu","107 S INDIANA AVE","BLOOMINGTON","IN","474057000","3172783473","MPS","1271","0000, 9263, OTHR","$0.00","In engineered and biological systems, flows often involve complexity because of the shape of the flow domain which can be unknown, and because the fluid can consist of or contain macromolecules and nanoparticles which impart unusual behavior.  This research aims at developing novel numerical algorithms for computing flows with such complexity. Because of their robustness and reliability, fully-coupled (monolithic/implicit) schemes are commonly used to simulate flows with free boundaries; however, these schemes may become impractical, especially in three-dimensional geometries and when the fluid has complex behavior, e.g., viscoelasticity. On the other hand, partitioned schemes have simpler implementation and potential lower computational cost, yet have shown severe stability issues when applied to highly nonlinear free boundary flows.  This research will develop novel partitioned algorithms for free boundary flows of complex fluids which will combine good stability properties with low computational costs and ease of implementation.<br/><br/>The novel algorithms developed in the project will be used to study and understand complex flows arising in biology, medicine, and engineering. Major applications include blood flow in human arteries, the optimization of coating processes, and the flow of emulsions which naturally occur in oil extraction. Multidisciplinary training will be incorporated in the research by joint advising of two PhD students in Applied Mathematics and Chemical Engineering.  The outcomes of the proposed research will impact cyberinfrastructures through scientific computing, as well as other areas of complex fluid mechanics where computing plays a central and essential role.<br/>"
"1016578","Discrete Simulation of Fluid Dynamics","DMS","COMPUTATIONAL MATHEMATICS","08/15/2010","08/03/2010","Alexander Wagner","ND","North Dakota State University Fargo","Standard Grant","Leland Jameson","08/31/2011","$22,500.00","","alexander.wagner@ndsu.edu","1310 BOLLEY DR","FARGO","ND","581055750","7012318045","MPS","1271","7556, 9150, 9263","$0.00","The conference on discrete simulation of fluid dynamics (dsfd.org) is the premier forum to discuss novel numerical methods for fluid flow including lattice gas automata (LGA), the lattice Boltzmann equation (LBE), discrete velocity methods (DVM), dissipative particle dynamics (DPD), smoothed-particle hydrodynamics (SPH), direct simulation Monte Carlo (DSMC), stochastic rotation dynamics (SRD), molecular dynamics (MD), and hybrid methods. The 19. meeting is held July 5-9, 2010 in Rome. Because of the significant cost of airfare underfunded researchers need additional support to attend meeting. The NSF funds provide partial support for 18 junior faculty members, postdocs and students from the US to present their research at this meeting. A local committee at North Dakota State University selected the travel support based on need, whether the applicant belongs to an underrepresented group, and the scientific soundness of the proposed research presentation.<br/><br/>Advances in materials, nanotechnology, information technology and biotechnology increasingly rely on novel numerical algorithms. So the training of students and postdocs who are developing the next generation of these methods is of paramount importance. This grant provides the most promising young researchers with the opportunity to learn about the newest developments from their peers, to exchange ideas with researchers who share similar interests, and the opportunity to present their own research results at a specialized conference in the field of novel numerical algorithms for the simulation of fluid dynamics."
"1016310","Innovative methods for the dynamics of immersed structures in complex fluids","DMS","COMPUTATIONAL MATHEMATICS","08/15/2010","06/04/2012","Hector Ceniceros","CA","University of California-Santa Barbara","Continuing Grant","Leland Jameson","07/31/2014","$401,162.00","","hdc@math.ucsb.edu","3227 CHEADLE HALL","SANTA BARBARA","CA","931060001","8058934188","MPS","1271","9263","$0.00","The investigator and collaborators propose to develop a new class of Immersed Boundary-based methods to investigate the interaction of a large number of immersed structures in 2D and 3D with a complex (non-Newtonian) fluid. These innovative methods will have the computational efficiency demanded  by some outstanding, formidable problems of flow-structure interaction in complex fluids and will establish new paradigms in the modeling and simulation of these type of systems.  To achieve this, the investigator and the project's participants  will introduce fundamentally innovative approaches for the fast computation of the influence of the structure on the flow, for the rapid  solution of robust, implicit discretizations, and for model building and computation in the presence of a complex fluid in important applications.  While the new approaches will be designed with concrete problems in mind (collective sperm motility in a complex fluid and peristaltic pumping),  their applicability will be broad.<br/><br/>A myriad of technologically and scientifically important problems can be described as the interaction of a flow and immersed structures that could be elastic or rigid and could come in a broad range of shapes and length scales, from nano to macro. The swimming of micro-organisms like cellular and flagellar locomotion, sperm motility,  insect flight, aerodynamic design,  cardiac fluid dynamics, and processing of polymeric materials are just a few important examples.  There is now a recognized, pressing need to investigate these dynamics in more realistic fluid environments which take into account the frequent viscoelastic character of the underlying complex flow.  The project focuses on the development of fluid models and efficient computational tools to investigate this important class of problems.  Research and education will be vigorously integrated in a multi-disciplinary environment with a sustained effort to promote and broaden the participation of underrepresented groups, with the active participation of undergraduates, with innovative pedagogic initiatives and modes of collaboration, and with ties with the industrial sector."
"1104333","Algorithms and Numerical Analysis for Nested Approximations of Stochastic Particle Dynamics","DMS","COMPUTATIONAL MATHEMATICS, COFFES","10/01/2010","11/29/2011","Petr Plechac","DE","University of Delaware","Standard Grant","Junping Wang","12/31/2012","$160,509.00","","plechac@math.udel.edu","220 HULLIHEN HALL","NEWARK","DE","197160099","3028312136","MPS","1271, 7552","0000, 9150, 9263, OTHR","$0.00","The ever-increasing computational power has instigated rapid development of computational techniques for simulating large stochastic interacting particle systems.  Growing computing capabilities have helped to obtain unprecedented insight into numerous problems ranging from physical phenomena in materials, chemical reactions, and biological processes to image processing.  However, as is common in the initial development of simulation methodologies the rapid emergence of new computational techniques far outstrips theoretical understanding of the algorithms.  From the computational point of view, balancing the competing aims of numerical accuracy and computational efficiency still remains one of the central problems in simulations of large multi-scale systems. <br/>     The proposed research outlines a framework for the numerical analysis and implementation of simulation algorithms based on coarse-graining of the microscopic system.  In the proposed work we view coarse-graining as numerical approximation of coarse observables which would have to be estimated from computationally expensive microscopic simulations.  The goal of the proposed work is to develop numerical tools for assessing the quality of the approximation and to use error indicators in order to implement reliable simulation algorithms.  Understanding approximations and their limitations is particularly important in the context of stochastic simulations, since even a convergent simulation may not provide any reliable insight into simulated phenomena (e.g., phase transitions, critical phenomena).  Furthermore, the computational complexity can be substantially decreased if a trade-off between accuracy and efficiency is properly adjusted.  In simulations of systems with a large number of interacting entities we often end up estimating average values of certain observables that depend on randomly distributed microscopic configurations of the system.  In the proposed approach we apply hierarchical microscopic-macroscopic computational paradigms and explore their potential for improving efficiency, reliability, and algorithmic complexity of methods used for sampling probability measures on high-dimensional spaces.  We aim at developing tools suitable also for approximating transient behavior which may not be properly captured, on experimentally relevant time-scales, by sampling the equilibrium distribution.  The proposed framework will derive nested approximations of the underlying multi-scale system with optimal interactions between different scales.  This scale decomposition strategy will be applied to the development of parallel algorithms for simulating stochastic systems composed of a large number of degrees of freedom.<br/>     The proposed work is in the intersection of numerical analysis, stochastic processes, and statistical mechanics.  The potential impact of the proposed mathematical topics encompasses a wide range of applications in physics, chemistry, materials science, and other fields where large multi-scale simulations are used.  Therefore, one of the objectives is to implement flexible tools that can be tailored to specific problems and existing packages within a short learning curve."
"1016204","The Analysis and Design of Gradient Methods for Large-Scale Nonlinear Optimization and Applications","DMS","COMPUTATIONAL MATHEMATICS","08/15/2010","08/03/2010","Hongchao Zhang","LA","Louisiana State University","Standard Grant","Junping Wang","07/31/2014","$141,602.00","","hozhang@math.lsu.edu","202 HIMES HALL","BATON ROUGE","LA","708030001","2255782760","MPS","1271","9150, 9263","$0.00","This project will develop efficient gradient-based innovative algorithms and theory for the solution of large-scale nonlinear optimization problems, including those with and without constraints imposed. The research will include the asymptotic convergence studies of Barizilai-Borwein type gradient methods, active set techniques and efficient preconditioners for bound constrained optimization, subspace affine-scaling methods for problems with continuous knapsack constraints, and active set methods for general nonlinear optimization with linear equality constrained phase. All the techniques developed for the optimization, as well as the sparse matrix technology for preconditioners and projectors will be incorporated into the active set algorithm for general large-scale nonlinear optimization. High quality software based on this research will be developed.<br/><br/><br/>Although the focus is nonlinear optimization, the methods and algorithms developed in the project will have broad impact in the many areas of computational science that require the solution of such large-scale nonlinear optimization problems. Specific applications of this project include Positron Emission Tomography (PET) which arises in medical imaging, (2) a design problem in  topology optimization where two materials are mixed so as to optimize their electrical properties, (3) Support Vector Machines (SVM) which are used in separation and classification problems in pattern recognition and data mining, (4) graph partitioning which arises in parallelization of algorithms and in fill reducing orderings for sparse matrix factorization, and (5) protein folding where the structure of a protein is reconstructed from inter-atomic distances derived from nuclear magnetic resonance spectroscopy. To maximize the impact,the software developed in this project will be made widely available. The supported graduate student will receive training on interdisciplinary applications of mathematics."
"1016450","Computational Algorithms for Model Reduction of Complex Flows","DMS","COMPUTATIONAL MATHEMATICS","09/15/2010","09/18/2010","Jeffrey Borggaard","VA","Virginia Polytechnic Institute and State University","Standard Grant","Leland Jameson","08/31/2013","$300,000.00","Traian Iliescu","jborggaard@vt.edu","300 TURNER ST NW","BLACKSBURG","VA","240603359","5402315281","MPS","1271","9263","$0.00","The investigators will study improved computational algorithms for<br/>model reduction of complex fluid flows.  This research will have two<br/>main thrusts, new closure models and a parametric modeling framework.<br/>The investigators will investigate closure for models that are based on <br/>the proper orthogonal decomposition.  This component of the research <br/>will leverage current developments in large eddy simulation along with <br/>two-level algorithms for efficient computational implementation.  The<br/>fact that the closure models follow from both mathematical and physical <br/>arguments will allow for a methodology that generalizes to physical <br/>settings other than fluid flow.  A new globalization methodology that<br/>combines more accurate local models with an interpolation framework<br/>to evaluate the models in parameter space will also be studied.  The <br/>local model improvements are provided using flow sensitivity analysis <br/>and basis functions are constructed using a multidimensional Hermite <br/>interpolation method.   The investigators will emphasize problems in <br/>geophysical fluid dynamics as well as flows with free convection.<br/><br/>This research will expand the applicability of computationally<br/>efficient simulations to a wider class of fluid flows.  The availability<br/>of dramatically faster simulations is important to many engineering <br/>applications including optimization and control of fluid flows, data<br/>assimilation and uncertainty quantification.  Therefore, the research <br/>conducted in this project has direct application to a wide range of<br/>problems that include data assimilation in climate and weather modeling <br/>as well as simulation, optimization, and control of energy efficient buildings."
"1016467","An Algorithm Suite for Computational Nonlinear Analysis of Power Systems","DMS","COMPUTATIONAL MATHEMATICS, DYNAMICAL SYSTEMS","09/15/2010","08/01/2012","Harry Dankowicz","IL","University of Illinois at Urbana-Champaign","Continuing Grant","Junping Wang","08/31/2014","$477,878.00","Ian Hiskens, Matthew West","danko@illinois.edu","506 S WRIGHT ST","URBANA","IL","618013620","2173332187","MPS","1271, 7478","7722, 7752, 9263","$0.00","An Algorithm Suite for Computational Nonlinear Analysis of Power Systems<br/>This effort targets the original development of CNAPS, an innovative suite of numerical algorithms for continuation analysis of multi-segment trajectories in large-scale, nonlinear dynamical systems with multiple slow and fast timescales, coupled components, and with triggers, resets and switches. Continuation methods have proven very successful for analyzing system behavior of low-dimensional systems. In CNAPS, we aim to dramatically scale continuation methods to complex networked systems with hybrid system trajectories and tens of thousands of states, by developing new multiscale, multisegment, trajectory-discretization algorithms based on asynchronous collocation methods; developing new mesh adaptation algorithms suitable for the asynchronous collocation methods, which accommodate segment-specific discretization error bounds; and constructing domain decomposition methods particular to the network topology and the asynchronous collocation formulation, which enable efficient parallel execution.<br/>The core application of CNAPS considered in this multidisciplinary effort is modern power systems that include renewable sources of generation, specifically wind power, and newer forms of load, characterized by multiple coexisting time scales and trigger-induced switching behavior. Analysis of large-disturbance dynamic phenomena in such systems currently relies almost exclusively on forward simulation. While such tools may reveal complex behavior, they offer little help in the design process required to address unacceptable behavior, especially emerging phenomena associated with the increased use of power electronic converters. The development of CNAPS enables intelligent and efficient exploration of transient and steady-state responses of complex power systems, aimed at quantifying design and uncertainty margins for stable, faultless operation."
"1016405","Hybrid Algorithms for Wave Propagation","DMS","COMPUTATIONAL MATHEMATICS","09/15/2010","09/08/2010","Yassine Boubendir","NJ","New Jersey Institute of Technology","Standard Grant","Junping Wang","08/31/2014","$121,514.00","","boubendi@njit.edu","323 DR MARTIN LUTHER KING JR BLV","NEWARK","NJ","071021824","9735965275","MPS","1271","9263","$0.00","This project is focused on the development of innovative and efficient algorithms dedicated to solving problems of acoustic and electromagnetic wave propagation. The strategy consists of using domain decomposition to design advanced numerical techniques for obtaining high computational efficiency, and improved convergence and accuracy properties. The proposed approach also allows for suitable utilization of parallel computing. The investigator is concerned with two classes of problems. The first consists of using domain decomposition methods to suitably combine,  (1) finite element methods with boundary element methods, and (2) finite element methods with asymptotic techniques.  In the second class, the investigator proposes to couple domain decomposition methods with a specific integral equation method for problems concerning multiple scatterers in the high frequency regime. The resulting algorithm bypasses the need to resolve at the wavelength scale while retaining error-controllability. A new Krylov-subspace method that significantly improves convergence of the iterative procedure will be investigated. This approach will decrease the computational time required to obtain a given accuracy. A careful mathematical analysis will be conducted to help achieve these goals.<br/><br/><br/>The main focus of this proposal is the development of innovative and efficient algorithms dedicated to problems of acoustic and electromagnetic wave propagation. The strategy consists of careful mathematical analysis and design of high efficiency algorithms. The work is highly interdisciplinary and has impact on advanced technological applications including problems arising in areas such as  telecommunications, aircraft design, and oceanography. For example, the response of large, geometrically complex structures to incoming electromagnetic radiation is a topic of great interest to the aerospace industry, which seeks to improve stealth capabilities of airborne vehicles. Engineers regularly employ computational tools to predict the radar signature of aircraft, which helps to minimize design costs. Clearly, such efforts will be greatly aided by the development of computationally efficient and rigorous numerical methods. Some aspects of this project will be supported by an active collaboration with engineers."
"1016313","Immersd Finite Element Methods for Interface Problems","DMS","COMPUTATIONAL MATHEMATICS","09/01/2010","08/05/2010","Tao Lin","VA","Virginia Polytechnic Institute and State University","Standard Grant","Junping Wang","08/31/2015","$210,000.00","Slimane Adjerid","tlin@math.vt.edu","300 TURNER ST NW","BLACKSBURG","VA","240603359","5402315281","MPS","1271","6863, 9263","$0.00","Most of the published research results about immersed finite element<br/>(IFE) methods deal with 2nd order elliptic interface problems. This project <br/>plans to extend the research on developing and analyzing IFE methods for <br/>interface problems to more sophisticated partial differential equations such <br/>as the Stokes system and the linear elasticity system which are of great <br/>importance in many applications of engineering and sciences. The proposed <br/>research consists of three key modules which complement each other. The first <br/>part is to develop new IFE functions and integrate them into modern finite <br/>element techniques for solving Stokes and linear elasticity interface problems. <br/>The intent is to find suitable IFE functions locally in interface elements <br/>that can handle interface jump conditions required by the interface problems <br/>and other conditions such as the inf-sup stability condition required by the <br/>finite element formulations to be used. The proposed research will result in <br/>efficient and robust IFE methods with an emphasis on DG formulations that <br/>simplify local h-, p-, and hp- refinements on Cartesian meshes. The second <br/>module is the theoretical analysis of IFEs, starting from their interpolation <br/>approximation capabilities and deriving error bounds for IFE solutions. The <br/>challenges are that the traditional analysis techniques have a limited use <br/>here. For example, using equivalent quotient norm in the scaling argument <br/>leads to an estimate for IFE interpolation useless for further deriving <br/>estimate of IFE solution unless it can be shown that the constants in the <br/>error bounds are independent of the interface. Also, 2D and 3D IFE methods are <br/>essentially non-confirming methods whose error estimations are often more <br/>complicated. The third module is about the applications of IFE methods. In <br/>addition to improving the IFE solver for the particle-in-cell simulator, this <br/>project will investigate the applications of IFE methods to be developed to <br/>multi-fluid Stokes flow problems and the multi-material shape/topology <br/>optimization problems involving the linear elasticity.<br/><br/>The IFE methods to be developed in this project can provide new and efficient <br/>simulation tools that can use structured/Cartesian meshes to solve challenging <br/>interface problems involving multi-scale and multi-physics with nontrivial <br/>interfaces in many areas of engineering and science, including flow problems, <br/>electromagnetic problems, shape/topology optimization problems, to name just a <br/>few. This research project will proceed in harmony with the development of IFE <br/>software packages to verify and support the theory, and address complex and <br/>realistic problems from a variety of disciplines. This strategy will enable <br/>theoretical innovation to become practice much more quickly than traditionally <br/>possible. The proposed research projects will have a great potential to impact <br/>on numerical simulations in the design/research of ion-propulsion engines for <br/>interplanetary deep space travel, optimal packaging of electronic devices, <br/>efficient and better image reconstruction in computer tomography, non-<br/>destructive/non-invasive detection of suspicious materials in security check, <br/>design of optimal shapes for lighter and stronger structures, and many other <br/>application areas of great federal interests."
"1045151","Oil spill transport modeling in shelf, estuary, and intracoastal regions","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","09/01/2010","08/26/2010","Ethan Kubatko","OH","Ohio State University","Standard Grant","Junping Wang","08/31/2012","$137,663.00","","kubatko.3@osu.edu","1960 KENNY RD","COLUMBUS","OH","432101016","6146888735","MPS","1253, 1271","5987, 7914, 9263","$0.00","The main goal of this research is to further develop, apply, and analyze a <br/>computational tool that can be used to examine the transport tendencies along <br/>the U.S. East Coast including Florida, Georgia, and both Carolinas as they <br/>relate to the Deepwater Horizon oil spill. The central piece of this <br/>computational tool will be the Advanced Circulation (ADCIRC) hydrodynamic <br/>model. ADCIRC is a finite element model for solving time?dependent, free <br/>surface circulation and transport problems in two? and three?dimensions. <br/>Existing finite element meshes of the region will be further developed to <br/>provide an unprecedented level of resolution and physical detail, including <br/>detailed coverage of coastal rivers and lagoons, tidal creeks, the Atlantic <br/>Intracoastal Waterway, and tidally flooded marshes. The ability to accurately <br/>simulate the tidal dynamics of this region, as well as hurricane storm surge, <br/>will be coupled with recent and ongoing development of the transport <br/>capabilities of the ADCIRC model using discontinuous Galerkin methods. The <br/>integration and further development of these three key components, i.e., the <br/>high-resolution finite element meshes, the ability to accurately simulate <br/>tidal and storm surge dynamics, and robust, mass-conserving transport <br/>algorithms, will provide a powerful computational tool that will be used to <br/>simulate the transport tendencies of the Deepwater Horizon oil spill along the <br/>U.S. East Coast.<br/><br/>The Deepwater Horizon oil spill began on April 20, 2010 as a result of an oil <br/>well blowout that caused an explosion on the Deepwater Horizon offshore <br/>drilling platform located forty miles southeast off the Louisiana coast. A <br/>major and immediate concern related to the Deepwater Horizon oil spill is the <br/>possibility of the oil slick reaching the Loop Current ? a warm ocean current <br/>that enters the Gulf of Mexico flowing northward through the Yucatan Strait <br/>and that exits flowing east through the Florida Straits continuing northward <br/>along the east coast of Florida as the Gulf Stream. Oil entering the Loop <br/>Current would eventually be transported far afield to the Atlantic Ocean where <br/>the presence of large-scale eddies that separate from the western edge of the <br/>Gulf Stream have the potential to carry oil toward the U.S. East Coast. There <br/>is additional concern regarding the transport of oil that may occur during the <br/>upcoming Atlantic Hurricane Season, which has been forecasted by NOAA to be an <br/>?active to extremely active? hurricane season. The transport of oil towards <br/>the U.S. East Coast ? by means of reaching the Loop Current or from the onset <br/>of a hurricane ? would obviously have a major detrimental impact on the <br/>coastal environment, severely damaging their beaches and coastal wetlands, <br/>which serve as critical habitats to the fish and wildlife. The primary <br/>objective of this proposal is to provide a computational tool that will be <br/>used to help analyze and assess possible damage from the Deepwater Horizon oil <br/>spill along the U.S. East Coast including Florida, Georgia, and both Carolinas.<br/>Specifically, the fate and transport of oil spill remnants (e.g., tar<br/>balls) entrained in Gulf Stream eddies and feeding the U.S. East Coast will be <br/>modeled along the shelf and into the Atlantic Intracoastal Waterway and <br/>estuarine systems. Using available data sources, simulations will be performed <br/>to ultimately identify areas especially susceptible to receiving transported <br/>oil and likely areas of deposition.  The model and results will also be <br/>transferable to other regions of the Gulf of Mexico."
"1016325","Scalable Methods for Approximating and Optimizing Robust Stability Functions","DMS","COMPUTATIONAL MATHEMATICS, CI REUSE","08/15/2010","08/05/2010","Michael Overton","NY","New York University","Standard Grant","Junping Wang","07/31/2014","$650,000.00","","overton@cs.nyu.edu","70 WASHINGTON SQ S","NEW YORK","NY","100121019","2129982121","MPS","1271, 6892","6863, 9263","$0.00","Robust stability functions (RSFs) have broad importance in many fields in science and engineering.  In the case of linear dynamical systems, described by ordinary differential or difference equations with no feedback control, RSFs are real-valued functions of system coefficient matrices. The most important examples are the pseudospectral abscissa and radius functions and the distance to instability.  The principal investigator is developing and analyzing new efficient iterative methods to approximate RSFs much more quickly than is currently possible.  In many applications the coefficient matrices depend on parameters which may be varied in order to optimize robust system stability. Because RSFs are not convex and are typically not differentiable at optimizers, it is essential to use nonsmooth, nonconvex optimization (NNO) methods that take this into account. The efficiency of the new methods will open the way to computing and optimizing RSFs for much larger systems than was previously possible, including discretized systems of partial differential equations. In practice most dynamical systems include feedback control. Then the RSFs of interest become more complex and an important generalization is the H-infinity norm. The PI is involved in the development of software that can be widely used in the engineering community. This award was selected for partial funding by a  program which promotes the reuse of Cyberinfrastructure (CI) elements through the Office of Cyberinfrastructure at the National Science Foundation.<br/><br/>The goal of the project is to bring new optimization tools to a wide community of scientists and engineers, for use in many different kinds of applications.  The investigator's open-source software is already in use in a variety of applications, including the design of aircraft controllers, a proton exchange membrane fuel cell system, power systems controllers and the design of winding systems for elastic web materials. All of these systems require controllers to work effectively: a complex system such as an airplane or a power plant requires automatic controllers to function safely and effectively, in addition to skilled operators who know how to use such systems.  However, these  computations are currently limited to small or moderate-sized systems, which cannot model real physical systems very accurately. New scalable methods will allow the design of controllers for much larger systems than was previously possible, including control of discretized systems of partial differential equations, which have applications throughout the natural sciences and engineering.  This award was selected for partial funding by a  program which promotes the reuse of Cyberinfrastructure (CI) elements through the Office of Cyberinfrastructure at the National Science Foundation."
"1016177","Multilevel methods in PDE constrained optimization","DMS","COMPUTATIONAL MATHEMATICS","07/01/2010","07/01/2010","Andrei Draganescu","MD","University of Maryland Baltimore County","Standard Grant","Junping Wang","06/30/2014","$149,986.00","","adraganescu@gmail.com","1000 HILLTOP CIR","BALTIMORE","MD","212500001","4104553140","MPS","1271","9263","$0.00","The objective of this project is to develop efficient multilevel<br/>algorithms for large-scale optimization problems constrained by partial<br/>differential equations (PDEs) with additional inequality constraints (ICs)<br/>on the controls and states.  The computational revolution of the last two<br/>decades has fostered not only high-resolution numerical computations based<br/>on PDE models, but also a shift from model based simulation to model based<br/>design. The latter translates into the question of solving optimization<br/>problems in order to identify initial and/or boundary values, material<br/>properties, sources, and other parameters for which the PDE models behave<br/>in a desired way. However, in general, by increasing resolution not only<br/>do optimization problems get larger, but they also become more difficult<br/>to solve, thus rendering an ever widening gap between the resolution of<br/>PDEs and that of associated parameter identification problems that can be<br/>solved using state of the art resources; in order to take full advantage<br/>of these resources, highly efficient algorithms are critical. While such<br/>efficient algorithms have been developed over the past few years, they are<br/>mostly restricted to problems without ICs. The addition of ICs on the<br/>controls and/or states normally increases the difficulty of the problem<br/>due to the presence of Lagrange multipliers that have lower regularity<br/>than the solution. Recent years have witnessed a sensible progress in the<br/>optimization algorithms that target such problems, however, it is expected<br/>that significant efficiency can further be gained by improvements in the<br/>linear algebra technology needed during the optimization process.  In this<br/>project the PI specifically aims to develop optimal order multilevel<br/>preconditioners for the linear systems arising in the interior point<br/>method and semismooth Newton method solution processes of optimization<br/>problems constrained by linear and semilinear elliptic or parabolic PDEs<br/>with ICs on the controls and/or states.  For the more difficult problem of<br/>state ICs, both Lavrentiev and Moreau-Yosida regularizations will be<br/>considered. The long term goal is to develop efficient multilevel<br/>algorithms for large-scale control problems for fluid flows (Stokes, and<br/>Navier-Stokes systems).<br/><br/>The results of this project are expected to enable end users of the software<br/> - engineers, applied scientists - to solve<br/>high-resolution, relevant optimization problems at a cost that is<br/>comparable (a small multiple of) to that of performing a single<br/>simulation. Long-term targeted applications include data assimilation for<br/>weather prediction and air contamination modeling.  Fast data assimilation<br/>for high resolution models would enable, for example, gaining in a timely<br/>manner a better quantitative understanding of the current state of the<br/>atmosphere around a hurricane, thus potentially improving the current<br/>predictive capabilities.  From an educational perspective, the successful<br/>project will help the PI's efforts in promoting this field of research at<br/>University of Maryland Baltimore County (UMBC), and it will allow graduate and undergraduate UMBC students to gain<br/>experience in a research area of strategic interest, which is likely to<br/>increase their opportunities of finding a good position in a research<br/>university or laboratory."
"1016038","Numerical Computation of Geodesics in the Framework of Metamorphosis","DMS","COMPUTATIONAL MATHEMATICS","07/15/2010","07/07/2010","Laurent Younes","MD","Johns Hopkins University","Standard Grant","Junping Wang","06/30/2013","$275,000.00","","laurent.younes@jhu.edu","3400 N CHARLES ST","BALTIMORE","MD","212182608","4439971898","MPS","1271","7721, 7722, 7752, 9263","$0.00","The proposed research focuses on metamorphosis for shape analysis, which relies on a shape transformation<br/>model within which shape variation is coupled with other transformations of the data, permitting<br/>topological changes, or partial advection of attributes attached to the deformed objects. This results<br/>in a versatile framework in which many different models can be devised, based on any mathematical<br/>structure that can both be advected by diffeomorphisms and embedded in a Hilbert or<br/>Riemannian space. This construction equips the space of deformable objects of interest with a new<br/>Riemannian metric, allowing for the comparison of these objects, and for the use of tools associated<br/>to data analysis in Riemannian manifolds, like the representation of data sets in exponential<br/>charts. The research will involve models of metamorphosis in which the deformable structures are represented<br/>by images, densities, or measures, in two or three dimensions. One of the main issues in<br/>this context is the computation of geodesics, either as a variational problem (shortest path between<br/>two points in the manifold) or as an initial value problem (solving the Euler-Lagrange equation for<br/>the evolution of geodesics). The numerical analysis of both problems is challenging, especially<br/>when one adds the requirement for the two solutions to be numerically consistent, in the sense that<br/>discrete solutions of the first problem coincide with discrete solutions of the second one, which is<br/>important for applications. This research will address these issues, by developing variational<br/>integrators for the initial value problems, and shooting methods for the boundary value<br/>problems, in contexts that will involve solutions that combine smooth and singular components.<br/>The PI and collaborators will also deploy and extend of a comprehensive software<br/>that provides a collection of algorithms associated to diffeomorphic matching.<br/><br/><br/><br/><br/>The goal of shape analysis is to understand and represent variations of shapes in data sets of<br/>deformable objects (like collections of landmarks, images, curves or surfaces). This issue is important,<br/>in particular, for the characterization of anatomical variations in medical images, and of<br/>their relation with pathologies. One of the main areas of applications in this context is known as<br/>Computational Anatomy, and methods from mathematical shape analysis have already been used for <br/>several successful applications. Examples of developments in this domain include collaborations of the PI with<br/>researchers at the Kennedy Krieger Institute in Baltimore, or at the Institute for Computational Medicine at <br/>Johns Hopkins University, on the analysis of brain disease and of cardiac failure. <br/>The theory and tools that will be developed in this research will enable the analysis of situations that cannot be <br/>handled by previous methods, which work under the assumption that anatomical variation can be essentially described<br/>by smooth changes of shape. The proposed approach, called metamorphosis, will be able to address cases<br/>for which these assumptions are not satisfied, and make possible, for example, the analysis of images<br/>that include dramatic changes between subjects. This includes the analysis of datasets measuring the evolution<br/>of tumors, or describing brain recovery after a major stroke. The research will contribute to the emergence of new solutions<br/>in such contexts, and make the related software available to the scientific community."
"1004223","Graduate Student Support for the 2010 Gene Golub Summer School in Italy","DMS","COMPUTATIONAL MATHEMATICS","03/01/2010","02/22/2010","Daniel Szyld","PA","Temple University","Standard Grant","Junping Wang","02/28/2011","$20,000.00","Ilse C.F. Ipsen","szyld@temple.edu","1801 N BROAD ST","PHILADELPHIA","PA","191226003","2157077547","MPS","1271","0000, 7556, 9263, OTHR","$0.00","This grant will support the participation of US-based Ph.D. students at the first Gene Golub SIAM Summer School (G2S3), which is also the Second International Summer School on Numerical Linear Algebra (ISSNLA).<br/>The G2S3 2010 will take place in Fasano, Italy, during the two weeks of June 7-18, 2010.<br/>The ISSNLA is organized by the SIAM Activity Group on Linear Algebra. The local organization is in the hands of researchers from the Universities of Bari and Bologna. The purpose of the ISSNLA is to acquaint doctoral students with recent developments and novel applications in a subfield of Applied Mathematics called ""Numerical Linear Algebra"". By design, the summer school is forward-looking: the courses cover topics<br/>that are too recent to have been included in textbooks or doctoral courses; these topics include nonlinear eigenvalue problem, and tensor analysis and computations.<br/><br/>The target audience of the International Summer School on Numerical Linear Algebra are doctoral students in any field that requires results and methods from Numerical Linear Algebra.  The courses will be self contained, and taught at a level that is accessible to a wide audience. They will be of interest to graduate students in science and engineering. The lecturers are leading experts who are also well known for their expository skills.  They were chosen by an Advisory Committee composed by leading international scientists.<br/>NSF support for US-based participants will have a positive impact on the continued strong competitiveness of the US in this crucial discipline, with its connections to virtually every area of scientific computing."
"1008983","Collaborative Research: Randomized Algorithms in Linear Algebra and    Numerical Evaluations on Massive Datasets","DMS","COMPUTATIONAL MATHEMATICS","10/01/2010","05/29/2013","Petros Drineas","NY","Rensselaer Polytechnic Institute","Standard Grant","Leland Jameson","07/31/2015","$220,413.00","","pdrineas@purdue.edu","110 8TH ST","Troy","NY","121803522","5182766000","MPS","1271","9263","$0.00","Data matrices have structural properties that present challenges and opportunities for both the Numerical Linear Algebra (NLA) community and the Theory of Algorithms (ToA) community. Matrix factorizations, such as the eigendecomposition, the rank-revealing QR factorization, and the Singular Value Decomposition, have been widely used for information retrieval. Historically, matrix factorizations have been of central interest in NLA since one can use them to express a problem in such a way that it can be solved more easily. ToA, on the other hand, has recently addressed the computation of such decompositions from a sampling perspective. The two approaches are complementary. However, thus far, the two communities have not worked closely together to integrate them. More often than not, each community is only cursorily aware of developments in the other community. Defining significant research directions that both communities can work on, and applying the resulting linear algebraic algorithms to data analysis problems (among others) will lead to important breakthroughs. The main objective for this proposal is to bridge the existing gap and bring together NLA and ToA researchers to promote cross-fertilization of ideas that could have immediate and long-term impact on data analysis. Towards that end, the PIs will work on set of prototypical research problems that can significantly benefit from ideas and research in both NLA and ToA. These problems range from approximating the singular values and vectors of a matrix by element-wise sampling to random-projection-based algorithms for least-squares problems and the design of randomized algorithms for the widely used non-negative matrix factorization.<br/><br/>This proposal seeks to explore the complementary perspectives that the Numerical Linear Algebra and the Theory of Algorithms (ToA) communities bring to linear algebra and matrix computations. This is a timely quest, motivated by technological developments over the last two decades that permit the automatic generation of large datasets. Such datasets are often modeled as matrices. The proposed work will serve as a demonstration project on the fruitfulness of collaboration between the NLA and the ToA communities on problems that are of common interest. It is expected that the proposed research will demonstrate commonality in the two approaches, as well as highlight the advantages of the dual perspective. Through outreach activities, the PIs hope to motivate even more researchers to undertake similar investigations on related topics. The proposed algorithms will be numerically evaluated on a suite of matrices from application domains that the PIs have been working on over the past few years, in order to understand better their properties and to demonstrate their potential in dealing with the modern, massive datasets. More specifically, the PIs will test the proposed strategies on population genetics data in order to infer ancestry of individuals, as well as gene expression data in order to investigate hypotheses that correlate genes and diseases. As such, we expect that the developed algorithms will impact the areas of linear algebra, randomized algorithms, information retrieval and data mining, as well as bioinformatics. Finally, in order to disseminate the proposed research, the PIs intend to organize workshops (following the example of the Workshops on Algorithms for Modern Massive Datasets in 2006, 2008, and 2010; the PIs were co-organizers of these workshops) and working group meetings, and will disseminate their research via blogs and articles intended for broader audiences."
"1014817","Novel mixed and DG methods","DMS","COMPUTATIONAL MATHEMATICS","08/15/2010","08/04/2010","Jay Gopalakrishnan","FL","University of Florida","Standard Grant","Junping Wang","05/31/2012","$188,005.00","","gjay@pdx.edu","1523 UNION RD RM 207","GAINESVILLE","FL","326111941","3523923516","MPS","1271","6863, 9263","$0.00","Ever increasing demands on computational solution techniques necessitate development of new and improved methods.  Two classes of methods, increasingly being used in simulation of physical and engineering systems, are finite element methods of the mixed type and the discontinuous Galerkin (DG) type.  Building sound mathematical foundations for these methods increases their reliability, reveals avenues to improve them, and helps discover radically new methods.  In this spirit, five lines of research are proposed on the following topics: (i) mixed methods (ii) discontinuous Petrov-Galerkin (DPG) schemes(iii) hybridizable discontinuous Galerkin (HDG) methods (iv) simulation of photonic membranes, and (v) complex axisymmetric simulations. The first deals with new stress elements and their implications in mixed methods for elasticity with weakly imposed stress symmetry. The second pursues a new DPG paradigm in the design of schemes where optimal test spaces are automatically computed. The third, concerns DG methods that mimic mixed methods, yet having the added advantage of flexible stabilization, and continues a line of research previously supported by the foundation. Both source problems and eigenproblems are considered.  The remaining two lines of research, considers applications in need of new mathematical developments, e.g., (iv) needs good nonlinear eigensolvers and (v) needs sound treatment of singularities.<br/><br/>Methods for computer simulation are an indispensable tool in modern scientific research.  The proposed research brings fresh mathematical ingredients that spawn novel simulation methods. These mathematical techniques have the advantage of being broadly applicable. Accordingly, several disparate application areas can be targeted, including solid mechanics, transport phenomena, fluid flow, wave propagation, triggered lightning, and nanophotonic membranes. To detail a few examples, application of the new methods to fluid flow, through industrial and academic collaborations, can potentially benefit the aircraft industry.  Reliable simulation methods can inexpensively guide experimentation of next generation nanophotonic devices.  Finally, human resource development is integrated into the activities through training and participation of graduate students in the research."
"1016092","Numerical Methods for Transmission Eigenvalues","DMS","COMPUTATIONAL MATHEMATICS","08/15/2010","08/04/2010","Jiguang Sun","DE","Delaware State University","Standard Grant","Junping Wang","07/31/2013","$119,169.00","","jiguangs@mtu.edu","1200 N. Dupont Highway","Dover","DE","199012277","3028576001","MPS","1271","6863, 9150, 9263","$0.00","The transmission eigenvalue problem has attracted many researchers in the <br/>scattering and inverse scattering communities recently. Although simply <br/>stated, the problem is not covered by any standard theory of partial <br/>differential equations. Numerical treatment of transmission eigenvalues is <br/>very limited to date. Effective numerical methods will enhance the <br/>understanding of the problem and provide tools for mathematicians and <br/>engineers to compute transmission eigenvalues. This proposal aims at robust <br/>numerical methods for transmission eigenvalues for the Helmholtz equation and <br/>the Maxwell's equations. In particular, the following research topics will be <br/>carried out. 1) Iterative methods for the Helmholtz equation. Based on a <br/>fourth order reformulation, an associated generalized eigenvalue problem will <br/>be solved by the finite element method. Then iterative methods will be applied <br/>to search roots of a related algebraic function which turn out to be the <br/>transmission eigenvalues. 2) Continuous finite element method for the <br/>Maxwell's equations. The transmission eigenvalue problem of the Maxwell's equations will be written in a suitable weak form first. Then the curl conforming edge elements will be used to compute the transmission eigenvalues. 3) Iterative methods for the anisotropic Maxwell's equations. This approach is again based on a forth order reformulation of the transmission eigenvalue  problem of the anisotropic Maxwell's equations. An associated generalized Maxwell's eigenvalue problem will be used to set up an algebraic equation whose roots are the transmission eigenvalues. Then iterative methods can be applied to search the roots of the algebraic equation. It is an extension of the iterative methods for the Helmholtz equation. However, the case for the Maxwell's equations is much more difficult and require additional technical treatment.<br/><br/>The proposed research will be a pioneer numerical study on transmission <br/>eigenvalues for the Helmholtz equation and the Maxwell's equations. The <br/>results are important for the development of mathematical theory for <br/>transmission eigenvalues and can be used to compare various estimates in <br/>inverse scattering theory.  The proposed research will provide mathematicians <br/>and engineers reliable tools to compute transmission eigenvalues. It will lead <br/>to new methods for studying the inverse scattering problems such as inverse <br/>electromagnetic scattering problem for anisotropic media. Since transmission <br/>eigenvalues can be used to estimate material properties of the scattering <br/>object, the proposed research has potential usage in non-destructive testing, <br/>geophysical applications, medical imaging, etc. For example, it is possible to <br/>detect the presence of cavities in the dielectric from the location of the <br/>transmission eigenvalues. The numerical results will be disseminated to <br/>mathematician for analytical study of transmission eigenvalues and engineers <br/>for detection and reconstruction of unknown objects. In addition, successful accomplishment of the proposed project will enhance the research capacity of the university and provide graduate students valuable research opportunities."
"1016047","Efficient Methods for Random Field Approximation with Application to Nonlinear Schrodinger Equation","DMS","COMPUTATIONAL MATHEMATICS","08/15/2010","08/05/2010","Qian-Yong Chen","MA","University of Massachusetts Amherst","Standard Grant","Junping Wang","07/31/2015","$116,704.00","","qchen@math.umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","MPS","1271","6863, 9263","$0.00","This project studies the formation and evolution of the soliton waves in the 1D and 2D nonlinear Schrodinger equation (NLSE) with a random potential (also called the  Gross-Pitaevskii equation), which governs the evolution of the mean-field wave function in Bose-Einstein condensate (BEC). The main focus is to investigate the impact of three parameters: the strength and the correlation length of the disorder, and the norm of the solution (i.e., the number of atoms in the condensate). But first, the random field approximation will be investigated within a more general context in the sense that the methodology can be applied in any applications involving uncertainties,  not limited to the random potential approximation of the NLSE. In practical problems, the variables with uncertainty are often described as a second-order stochastic process (or random field/function), i.e., its second-order moment is finite. The marginal distribution and covariance function are typically the available information. One prominent way of discretizing a second order random field is through the Karhunen-Loeve (KL) series expansion. The approximation with truncated KL expansion is optimal in terms of mean square error, and the errors for the first two moments are fixed for any specific truncated KL expansion. But there are still many issues needed to be addressed. In particular, the proposed research will focus on the following topics. 1.) More efficient computation of the KL expansion by introducing two adaptive meshes, when the analytical formulas are unavailable (true for most cases). 2.) Minimize the error of the marginal distribution by determining the distribution of the random variables in the KL expansion through the minimization of higher order moments. 3. Compare the efficiency of the KL expansion and the 'direct sampling' technique paired with correlation control technique, when the correlation length is short.<br/><br/>Either due to the randomness in nature or the insufficiency of knowledge, uncertainty is nearly observed in all the disciplines to some degree. Petroleum reservoir a few miles under the earth's surface,  traffic flow on state highways, measurement of gas flow in turbine, and the stock and futures market are several such examples. To gain a better understanding of the intrinsic dynamics, such uncertainty should be modeled and analyzed. The proposed research will enable faster and more efficient calculations of the involved uncertainties, provide unprecedented predictive capabilities. It will bring profound impact across all the scientific and engineering disciplines that involve uncertainty."
"1016595","Algorithms and Numerical Analysis for Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","09/15/2010","05/03/2012","Alfred Schatz","NY","Cornell University","Continuing Grant","Rosemary Renaut","08/31/2013","$244,407.00","","schatz@math.cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","MPS","1271","9263","$0.00","It is a well established fact that in solving many of the complex problems that arise in industry and science, it is cost-effective to first model the problem mathematically and then run simulations under various design conditions.  This is to determine whether a design criteria is achieved.  If the design does not meet specifications it is usually easier to change the mathematical model and test it again rather than build a new machine.  An example of this is that an entire commercial airplane has been designed using this procedure.  Very often the solution of the problem is the solution of an elliptic parabolic and hyperbolic partial differential equations, and thus it is important to devise accurate methods of solution that are efficient as possible.  This proposal seeks to examine various fundamental aspects of the finite element method.  This is a method for solving partial differential equations, which has shown itself to be very flexible. The proposed research can be separated into three parts.  In it we shall restrict ourselves to the study of elliptic equations.<br/><br/>(1) L-infinity estimates on polygonal domains allowing highly refined grids.  This type of estimate of the accuracy of the finite element method would be very useful in analyzing many problems.  Consider poissons equation on a plain polygomal domain.  This problem is often used as a typical problem where the solution may be singular at points.  For a convex polygon the derivatives are bounded and we have proved that the error in the derivates as the best proximation property in W1/infinity.  Estimates of this kind in L/infinity are more difficult to obtain and we have succeeded in obtaining almost optimal results on nonconvex domains.  These are under the conditions that the mesh is only locally quasi uniform.  Results of this type are very useful in analyzing self-adaptive finite element codes.<br/><br/>(2) A posteriori error estimates.  This study will address the general question of a posteriori of error estimators, which predict errors with precision on a single element.  To get a firm theory is often necessary to isolate model problems, which contain basic difficulty found in more involved problems.  As an example, the study will investigate the general problem in the context of problems on nonconvex polygomal domains.  As in number 1, there are corner singularities, which tax estimators.  Special attention will be paid to situations in which known estimators do not work.<br/><br/>(3) Discrete finite element potential theory.  This part of the proposal deals with trying to find analogs of potential theory for finite elements that could be useful in solving nonlinear problems.  A great deal of effort has recently gone into solving second order nonlinear elliptic problems.  The numerical schemes that are known depend to a great extent on the knowledge of discrete versions of maximum principles and Harnack inequalities.  Some of these do not seem to hold strictly for finite elements.  We will search for versions of these theorems, which are valid to finite elements and useful to obtain approximate solutions of non linear equations.<br/><br/>The intellectual merit of the proposed project is that it addresses fundamental and basic questions in computational science.  The broader impact of the proposed activity will be better understanding of existing algorithms, leading to improved methods."
"1016460","Collaborative Research: A Study of the Transition of Knot Space from Confinement to Relaxation","DMS","COMPUTATIONAL MATHEMATICS","09/15/2010","09/13/2010","Yuanan Diao","NC","University of North Carolina at Charlotte","Standard Grant","Junping Wang","08/31/2014","$73,847.00","","ydiao@uncc.edu","9201 University City Boulevard","CHARLOTTE","NC","282230001","7046871888","MPS","1271","9263","$0.00","Circular molecules confined to a small volume are often modeled by random polygons confined in a sphere and extracted (that is relaxed) circular molecules are modeled by relaxed random polygons without confinement. The PIs propose to explore the geometric changes that occur during the transition of the polygonal knotspace from confinement to relaxation and to establish correlations between these geometric changes and the topological complexity of the polygons. The results of this research project will provide benchmark data on the relationships between certain knot complexity measures and some geometric measures, where all quantities are measured as averages over families of random polygons before and after they are relaxed. The results can guide the evaluation of experimental data such as the data available in the case of the bacteriophage P4 virus. To reach the goal of the proposed research, several critical objectives must be achieved: a) The development of a fast, reliable, and unbiased algorithm to generate large sets of long equilateral random polygons within a confining volume; b) The development of relaxation schemes for equilateral random polygons and their corresponding algorithms; c) Quantification of the effect of topology on geometric changes of random polygons when transitioning from confinement to relaxation and d) Identification of  inferences about topological properties of the random polygons using the average geometric properties of the polygons before and after relaxation. The proposed research will provide a systematic study between the relationships between various geometric measures and topological properties of knots in the average sense when the knots under consideration undergo a transition change from volume confinement to relaxation. The proposed research will reveal potentially important and interesting relationships among these quantities and the role of confinement in these relationships. <br/>It is well known that macromolecular self-assembly processes are key players in the complex network of interactions that take place in every organism. One of these self-assembly processes is the packing of the genetic material in the capsids of viruses. Little is know about the details of the packing processes, because in a confined small volume DNA is usually condensed and folds in ways that are difficult to quantify experimentally. DNA molecules that are forcefully removed from bacteriophage P4 capsids often form complicated knots that are a result of the packing process. Thus, the extracted DNA carries important information about how the DNA is packed inside the capsids. The question of how to decipher such information is a main motivation of the proposed research. Circular molecules confined to a small volume are often modeled by random polygons confined in a sphere. On the other hand, extracted circular molecules are usually modeled by relaxed random polygons without confinement. The proposed research will explore the geometric changes that occur during the transition of the polygonal knot space from confinement to relaxation and to establish correlations between these geometric changes and the topological complexity of the polygons. The results will provide some essential benchmark data on the relationships between certain knot complexity measures and some geometric measures, which are important in order for us to fully understand the mechanism of DNA packing in a tight space. The PIs their students (ranging from exceptionally talented high-school students, to undergraduates, graduates, and Ph. D. students) will develop mathematical tools and computational models that will be made freely available to the scientific community and/or interested educators. The results of the work can be used in areas such as biology and physics to check the validity of models of highly condensed DNA or tightly packed polymers."
"1016267","Collaborative Research: Efficient surface-based numerical methods for 3D interfacial flow with surface tension","DMS","COMPUTATIONAL MATHEMATICS","10/01/2010","08/03/2012","David Ambrose","PA","Drexel University","Continuing Grant","Leland Jameson","09/30/2015","$269,989.00","","ambrose@math.drexel.edu","3141 CHESTNUT ST","PHILADELPHIA","PA","191042816","2158956342","MPS","1271","9263","$0.00","The investigators develop and apply efficient boundary integral methods for the motion of interfaces in 3D flow.  The methods address a significant difficulty in the numerical computation of fluid interfaces with surface tension or elastic forces in 3D flow. Such forces introduce high order (i.e., high derivative) terms into the evolution equations, which lead to severe stability constraints or `stiffness' for explicit time-integration methods.  Furthermore, the high order terms appear in nonlinear and nonlocal operators, making the efficient application of stable implicit methods difficult.<br/>The investigators' method relies on using the first and second fundamental coefficients of the surface as dynamical variables, and employs a special parameterization of the interface combined with an  analysis of the governing equations at small scales. This enables the efficient application of implicit time-integration methods for 3D flow. The investigators implement the method in canonical interface problems for inviscid fluids, including the Kelvin-Helmholtz, Rayleigh-Taylor, and water wave problems, and study the dynamics of inextensible elastic sheets in inviscid flow and vesicles in 3D viscous flow. Most importantly, they develop a version of the numerical method which uses domain decomposition or overlapping coordinate patches to describe the interface. This has the added benefit of providing a framework for the implementation of  spectrally accurate and spatially adaptive methods.<br/><br/>Moving boundary problems occur in many diverse areas in, for example, fluid dynamics, materials science, and biology.  Specific examples include traveling ocean waves, growing cancer tumors,  beating hearts and moving cells and organisms. The investigators develop accurate and efficient `boundary integral'<br/>numerical methods for the simulation of moving boundaries in applications.<br/>Boundary integral methods are among the most accurate numerical methods for the simulation of moving interfaces, but are often inefficient when the interface is acted on by surface tension or elastic forces.  The development of  fast and accurate boundary integral methods for 3D interfacial flow with surface tension or elastic forces will be of great benefit in understanding existing applications and developing technology further."
"1016406","Collaborative Research: Efficient surface-based numerical methods for 3D interfacial flow with surface tension","DMS","COMPUTATIONAL MATHEMATICS","10/01/2010","08/03/2012","Michael Siegel","NJ","New Jersey Institute of Technology","Continuing Grant","Leland Jameson","09/30/2014","$282,832.00","","misieg@njit.edu","University Heights","Newark","NJ","071021982","9735965275","MPS","1271","9263","$0.00","The investigators develop and apply efficient boundary integral methods for the motion of interfaces in 3D flow.  The methods address a significant difficulty in the numerical computation of fluid interfaces with surface tension or elastic forces in 3D flow. Such forces introduce high order (i.e., high derivative) terms into the evolution equations, which lead to severe stability constraints or `stiffness' for explicit time-integration methods.  Furthermore, the high order terms appear in nonlinear and nonlocal operators, making the efficient application of stable implicit methods difficult.<br/>The investigators' method relies on using the first and second fundamental coefficients of the surface as dynamical variables, and employs a special parameterization of the interface combined with an  analysis of the governing equations at small scales. This enables the efficient application of implicit time-integration methods for 3D flow. The investigators implement the method in canonical interface problems for inviscid fluids, including the Kelvin-Helmholtz, Rayleigh-Taylor, and water wave problems, and study the dynamics of inextensible elastic sheets in inviscid flow and vesicles in 3D viscous flow. Most importantly, they develop a version of the numerical method which uses domain decomposition or overlapping coordinate patches to describe the interface. This has the added benefit of providing a framework for the implementation of  spectrally accurate and spatially adaptive methods.<br/><br/>Moving boundary problems occur in many diverse areas in, for example, fluid dynamics, materials science, and biology.  Specific examples include traveling ocean waves, growing cancer tumors,  beating hearts and moving cells and organisms. The investigators develop accurate and efficient `boundary integral'<br/>numerical methods for the simulation of moving boundaries in applications.<br/>Boundary integral methods are among the most accurate numerical methods for the simulation of moving interfaces, but are often inefficient when the interface is acted on by surface tension or elastic forces.  The development of  fast and accurate boundary integral methods for 3D interfacial flow with surface tension or elastic forces will be of great benefit in understanding existing applications and developing technology further."
"1016202","Space-time DG-FEMs for Fluid and Kinetic Plasma Models","DMS","COMPUTATIONAL MATHEMATICS","08/15/2010","09/14/2012","James Rossmanith","WI","University of Wisconsin-Madison","Continuing Grant","Leland Jameson","07/31/2013","$139,394.00","","rossmani@iastate.edu","21 North Park Street","MADISON","WI","537151218","6082623822","MPS","1271","9263","$0.00","The investigator, along with his students and collaborators, will develop efficient high-order time-stepping methods that will be used in conjunction with discontinuous Galerkin spatial discretizations. In particular, adaptive space-time methods will be developed that will allow for either (1) explicit local time-stepping that allows for different time-steps in different flow regimes, or, (2) implicit time-stepping, which is sometimes required in certain applications. A key feature that will be integrated into these numerical schemes is error control in the form of adaptive mesh refinement. Several error estimators will be investigated, as well as several shock-capturing strategies. The resulting numerical schemes will be applied to a variety of model equations that arise in plasma physics, including ideal magnetohydrodynamics, two-fluid Euler-Maxwell, and kinetic Vlasov equations. Specific application problems that are of interest include the dynamics of solar coronal loops, the formation and propagation of astrophysical jets, and the simulation of collisionless magnetic reconnection.<br/><br/>Plasma is the fourth state of matter (after solid, liquid, and gas), which can be characterized as an ionized gas (i.e., a gas that is able to conduct electricity). Plasma appears in a wide range of applications including astrophysics and space physics, as well as in laboratory settings such as in magnetically confined fusion. Modeling and understanding the basic phenomenon in plasma have long been topics in scientific computing, yet many problems remain far too numerically intensive for modern parallel computers. The main difficulty is that plasmas span a wide range of spatial and temporal scales. The scope of this research is to develop accurate and efficient computational methods that can better solve various equations that model plasma behavior. A key aspect of this research is the development of adaptive numerical methods that are able to dynamically estimate and control the errors that are produced during the course of a computation."
"1016514","Arbitrarily Wide Angle Wave Equations: New Constructs for Subsurface Imaging, Unbounded Domain Analysis and Multiscale Modeling of Solids","DMS","COMPUTATIONAL MATHEMATICS","09/15/2010","09/02/2010","Murthy Guddati","NC","North Carolina State University","Standard Grant","Junping Wang","08/31/2015","$243,968.00","","mnguddat@eos.ncsu.edu","2601 Wolf Village Way","Raleigh","NC","276957514","9195152444","MPS","1271","9263","$0.00","One-way wave equations are mathematical constructs that allow the propagation of waves in a specified direction, while suppressing the propagation in the opposite direction, i.e. they have a 180-degree range of propagation angles as opposed to the 360-degree range of full wave equations. Due to this special property, they are being used in various application areas including wave-based imaging algorithms (seismic imaging and nondestructive testing), ocean acoustics (modeling of long-range propagation), wave propagation modeling in unbounded domains, and multi-scale modeling of solids (phonon-absorbing boundary conditions for coupling molecular dynamics with continuum models). While the existing one-way wave equations are well developed for simple acoustic media, they are not as robust and efficient for more complicated, elastic, media. To cater to this need, the PI and his coworkers have recently developed a new series of one-way wave equations called the Arbitrarily Wide-angle Wave Equations (AWWEs). Unlike the existing one-way wave equations which are derived only for acoustics and special cases of elasticity, AWWEs can be derived for complicated media where the full wave equation has second-order derivatives in space (this includes wave propagation in general anisotropic, viscous and porous elastic media). Furthermore, AWWEs have simple form and are easy to implement. They are highly efficient and have the flexibility to treat various types of propagating and evanescent waves. The current limitation is that a straightforward design of AWWE leads to instabilities for complicated media (this is similar to many existing one-way wave equations). Stability of an AWWE is application-dependent and the proposed effort is aimed at devising stable AWWEs that can be used for various application areas including, (a) imaging in heterogeneous and anisotropic elastic media, (b) analysis of wave propagation in unbounded elastic domains that are heterogeneous and/or anisotropic, and (c) phonon-absorbing boundary conditions for molecular dynamics. Stabilization procedures will be developed by building on existing wellposedness and stability theory for linear hyperbolic systems in the contexts of absorbing boundary conditions, perfectly matched layers, and ocean acoustics. The resulting stabilized AWWE would be implemented and tested in various settings to ensure their robustness.<br/>The proposed work is aimed at developing new mathematical constructs that transmit waves in a specified direction while suppressing them in the other direction. Due to the ubiquitous nature of wave phenomenon in physics, successful completion of the proposed project would facilitate the solution of several important problems related to: (a) seismic inversion - locating hidden oil reservoirs; (b) seismology - modeling of wave scattering and focusing in complex geological basins; (c) soil-structure interaction - simulation of complex response of structures embedded in unbounded soil during earthquakes; (d) nanomechanics - understanding the failure of materials at nanometer level; (e) nondestructive evaluation - characterizing hidden cracks for strength assessment; (f) military applications - detection and characterization of buried mines.  The proposed work also has applications in many other areas such as modeling optical circuits, synthetic aperture sonar and medical imaging. Finally, the project includes a graduate education component (thus contributing to the human resources development for computational mathematics), and the development of instructional modules for wave propagation and multiscale modeling (thus contributing to broader education in mechanics)."
"1016420","Collaborative Research: A Study of the Transition of Knot Space from Confinement to Relaxation","DMS","COMPUTATIONAL MATHEMATICS","09/15/2010","09/13/2010","Claus Ernst","KY","Western Kentucky University Research Foundation","Standard Grant","Junping Wang","08/31/2014","$106,152.00","Uta Ziegler","claus.ernst@wku.edu","Western Kentucky University","Bowling Green","KY","421011016","2707454652","MPS","1271","9150, 9263","$0.00","Circular molecules confined to a small volume are often modeled by random polygons confined in a sphere and extracted (that is relaxed) circular molecules are modeled by relaxed random polygons without confinement. The PIs propose to explore the geometric changes that occur during the transition of the polygonal knotspace from confinement to relaxation and to establish correlations between these geometric changes and the topological complexity of the polygons. The results of this research project will provide benchmark data on the relationships between certain knot complexity measures and some geometric measures, where all quantities are measured as averages over families of random polygons before and after they are relaxed. The results can guide the evaluation of experimental data such as the data available in the case of the bacteriophage P4 virus. To reach the goal of the proposed research, several critical objectives must be achieved: a) The development of a fast, reliable, and unbiased algorithm to generate large sets of long equilateral random polygons within a confining volume; b) The development of relaxation schemes for equilateral random polygons and their corresponding algorithms; c) Quantification of the effect of topology on geometric changes of random polygons when transitioning from confinement to relaxation and d) Identification of  inferences about topological properties of the random polygons using the average geometric properties of the polygons before and after relaxation. The proposed research will provide a systematic study between the relationships between various geometric measures and topological properties of knots in the average sense when the knots under consideration undergo a transition change from volume confinement to relaxation. The proposed research will reveal potentially important and interesting relationships among these quantities and the role of confinement in these relationships. <br/>It is well known that macromolecular self-assembly processes are key players in the complex network of interactions that take place in every organism. One of these self-assembly processes is the packing of the genetic material in the capsids of viruses. Little is know about the details of the packing processes, because in a confined small volume DNA is usually condensed and folds in ways that are difficult to quantify experimentally. DNA molecules that are forcefully removed from bacteriophage P4 capsids often form complicated knots that are a result of the packing process. Thus, the extracted DNA carries important information about how the DNA is packed inside the capsids. The question of how to decipher such information is a main motivation of the proposed research. Circular molecules confined to a small volume are often modeled by random polygons confined in a sphere. On the other hand, extracted circular molecules are usually modeled by relaxed random polygons without confinement. The proposed research will explore the geometric changes that occur during the transition of the polygonal knot space from confinement to relaxation and to establish correlations between these geometric changes and the topological complexity of the polygons. The results will provide some essential benchmark data on the relationships between certain knot complexity measures and some geometric measures, which are important in order for us to fully understand the mechanism of DNA packing in a tight space. The PIs their students (ranging from exceptionally talented high-school students, to undergraduates, graduates, and Ph. D. students) will develop mathematical tools and computational models that will be made freely available to the scientific community and/or interested educators. The results of the work can be used in areas such as biology and physics to check the validity of models of highly condensed DNA or tightly packed polymers."
"1016291","Nonlinear Optimization Algorithms for Large-Scale and Nonsmooth Applications","DMS","COMPUTATIONAL MATHEMATICS","07/01/2010","06/21/2010","Frank Curtis","PA","Lehigh University","Standard Grant","Junping Wang","12/31/2013","$110,001.00","","fec309@lehigh.edu","Alumni Building 27","Bethlehem","PA","180153005","6107583021","MPS","1271","9263","$0.00","The investigator, his colleagues, and his students study the development, analysis, and implementation of algorithms for large-scale PDE-constrained and nonsmooth optimization.  The novelty of the work in both of these frameworks is that in each case the investigator and his group are finding powerful ways in which the most advanced methods for nonlinear programming can be enhanced and broadened to remain effective for application areas in which they have previously been inefficient or inapplicable.  In the context of large-scale PDE-constrained problems, such as those in optimal design, parameter estimation, and image registration, this is being achieved by removing the need for the factorization of matrices and allowing for inexactness in the solution of large-scale linear systems, while still guaranteeing convergence to a solution point.  In the context of nonsmooth applications, such as those in compressed sensing and robust stability and control, this is being achieved by enhancing leading algorithmic frameworks through a process of gradient sampling, allowing for a loosening of the assumption that the problem functions are differentiable everywhere.  These works in these fields tie together algorithms and computational techniques from diverse areas, and both numerical methods and convergence theory are being provided.<br/><br/>The broader impact of this project is that it advances pencil-and-paper engineering ideas to the point where they can be implemented in high-performance computing software and are able to solve challenging problems in the design and analysis of complex systems.  For example, there is a high demand for optimization tools such as these in healthcare, particularly in the area of cancer treatment and therapy.  By providing doctors and medical technicians with novel computational tools, they will be able to optimally administer hyperthermia treatment in a manner that takes into account the inner complexities of the human body, such as blood flow.  They will also be able to effectively and adaptively design plans for radiation therapy that minimize damage to healthy -- and often critical -- tissue near the target area(s).  Amazingly enough, these same computational tools can also be employed in medical image registration, aiding medical professionals in the detection of irregularities over time and between different (e.g., PET, CT, MRI) scans.  The goal in all of these areas is to provide the user with sophisticated software that can answer, in real-time, difficult questions such as ""What is the optimal way of administering this radiation?"" and ""Is there anything in this image that has changed or is cause for alarm?"""
"1053675","Local Scales and Multi-Scale Representations of Images","DMS","COMPUTATIONAL MATHEMATICS","05/25/2010","12/07/2011","Triet Le","PA","University of Pennsylvania","Standard Grant","Leland Jameson","06/30/2013","$57,608.00","","trietle@math.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","MPS","1271","0000, 9263, OTHR","$0.00","The investigator and his colleagues study the problem of extracting features of images and their properties via scales and local scales using the classical theory of function spaces and partial differential equations. They use the knowledge of scales and local scales in images to obtain an efficient method for image decompositions and multiscale representations, which are image dependent. Finally, they extend the theory of scales and local scales to higher dimensional data (graphs and manifolds), and to find efficient computational methods and algorithms to solve these problems.<br/><br/>Reducing a complex data to simpler representations that can be more easily analyzed is an important task in mathematics and information science. The study of scales and local scales provides a tool for doing this task. In particular, it provides a tool for organizing and clustering the internal multiscale structures of the data.<br/>Applications include medical imaging, hyperspectral imaging, satellite imaging, material science, terrain data analysis, and dimension reduction in higher dimensional data.<br/>"
"1005441","Numerical Methods for Wave Propagations in Inhomogeneous Media","DMS","COMPUTATIONAL MATHEMATICS","09/15/2010","09/15/2010","Wei Cai","NC","University of North Carolina at Charlotte","Standard Grant","Junping Wang","08/31/2014","$200,000.00","","cai@smu.edu","9201 University City Boulevard","CHARLOTTE","NC","282230001","7046871888","MPS","1271","9263","$0.00","In this proposal, the PI will develop numerical methods and their mathematical analysis, ultimately their implementations in studying wave phenomena in nano-electronics, coupled arrays of quantum dots, and phase shift masks in lithography. Propagation of classical electromagnetic and quantum waves plays a key role in these physical and engineering systems. In order to gain a quantitative understanding of the wave phenomena in those systems, accurate and efficient numerical simulations are needed with appropriately designed numerical algorithms.  The targeted applications motivate our research with the following three proposed numerical methods: [1] An adaptive conservative cell average spectral method for Wigner equations in electron transport of nano-electronics; [2] A fast integral solver for quantum wave scattering in 3-D quantum dots in layered media [3] A parallel spectral element method based on eigen-oscillations for complex Helmholtz equations. The potential technology impact of this research is to understand the physics involved and provide design guidelines for nano-electronics such as nano-MOSFETs, phase shift masks, and quantum dots.  <br/><br/>The numerical methods developed in this research will be used for the engineering design of quantum devices with significant impact on maintaining US technology preeminence in the development of new VLSI microchips, and  next generation X-ray  lithography in microchip manufacturing. Also, graduate students trained in this project will provide skilled workforce in the competitive high technology job market as well as potential academic researchers."
"1016125","Collaborative Research: Theory and Algorithms for Beta Random Matrices: The Random Matrix Method of ""Ghosts"" and ""Shadows""","DMS","COMPUTATIONAL MATHEMATICS","09/01/2010","08/05/2010","Alan Edelman","MA","Massachusetts Institute of Technology","Standard Grant","Junping Wang","08/31/2014","$280,104.00","","EDELMAN@MATH.MIT.EDU","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","MPS","1271","9263","$0.00","The main goal of the work described in this proposal is to introduce and perform a thorough theoretical and numerical analysis of the class of beta random matrix ensembles. The investigators will generalize and extend to any postive beta the classical real, complex, and quaternion random matrix ensembles which correspond to the cases  1, 2, 4, respectively. Already many results in infinite random matrix theory and a few results in finite random matrix theory suggest that the use of beta as a continuous  parameter is reasonable. The key new concept in this proposal is the notion of a beta-random variable, an object which, for all practical purposes behaves as a beta-dimensional algebra over the reals. To develop the theory the PIs use the notions of ""ghosts"" and ""shadows"". A ""ghost"" is a beta-dimensional random variable and a ""shadow"" is a derived real or complex quantity that can be sampled. Along with the derivation of theoretical results, a major goal of this project is to provide algorithms for computation with these random matrix ensembles.<br/><br/>A vast number of practical application ranging from bioinformatics, and genomics (population classification) to wireless communications (network capacity optimization) and military applications (automatic target classification) rely on the methods of multivariate statistics and in turn on random matrix theory. The proposed research will provide new algorithmic and theoretical tools for these applications as well as enable new applications and research directions in these fields."
"1016283","A Posteriori Analysis of Multirate Numerical Methods","DMS","COMPUTATIONAL MATHEMATICS","09/01/2010","08/26/2010","Victor Ginting","WY","University of Wyoming","Standard Grant","Junping Wang","08/31/2014","$188,159.00","","vginting@uwyo.edu","1000 E. University Avenue","Laramie","WY","820712000","3077665320","MPS","1271","6863, 9150, 9263","$0.00","This research project is concerned with a posteriori analysis of a class of multirate numerical methods whose natural application appears in multiscale differential systems. A common trait in the multirate numerical methods is the decomposition of the original governing equations into collection of subsystems with different scales. Each subsystem can use a different discretization parameter pertaining to its characteristic scale. This is in contrast to using a single discretization parameter dictated by the dominating scale in the original governing equations if standard fully coupling numerical procedure is to be used. The multirate numerical methods, however, introduces a set of errors which directly affect the accuracy and stability of the approximate solutions in both obvious and subtle ways that are difficult to quantify accurately. These issues are addressed by conducting a posteriori analysis of the multirate numerical methods based on variational adjoint techniques. These techniques are desired because of their suitability for error prediction in the specified quantities of interest expressed in terms of functional of the approximate solutions. Being able to focus directly on application-based quantities of interest has strong consequences for computational efficiency in error estimation and adaptive error control. The goal is to formulate accurate estimation techniques that have the capability to distinguish and quantify the error components, such as the multirate discretization, incomplete iteration in the nonlinear solution, and numerical errors in the solution of each subsystem This can then be used to gain better insights of the effects of the errors on issues such as accuracy, stability, and adaptivity of the methods.<br/><br/>Multirate numerical methods are widely used in many applications. The main indicator of the successful completion of this project will be a better understanding of these methods and a capability to quantify their errors. This will have a broad impact on areas of engineering and science such as power system technology, nuclear engineering, petroleum production, and biology. Applications of multirate numerical methods arising in several of these areas are used as benchmark problems for developing the error estimation techniques. The project design allows for addressing fundamental issues in employing multirate numerical methods, such as accuracy and stability, adaptivity, and efficiency. This in turn will significantly contribute to developing efficient and accurate multirate numerical methods. Activities within this project are expected to strengthen ongoing collaborations, especially with investigators in the Rocky Mountain region. The project involves training of a graduate student in the area of a posteriori analysis and their application to multirate numerical methods."
"1016284","Closing the Gap Between Matrix and Tensor Computation","DMS","COMPUTATIONAL MATHEMATICS, Information Technology Researc, Special Projects - CCF, MSPA-INTERDISCIPLINARY","08/15/2010","08/04/2010","Charles Van Loan","NY","Cornell University","Standard Grant","Junping Wang","07/31/2013","$250,506.00","","cv@cs.cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","MPS","1271, 1640, 2878, 7454","9263","$0.00","A strong case can be made that tensor computation is the ``next big thing'' in numerical analysis. High-dimensional modeling is becoming commonplace and it requires the manipulation and analysis of huge multidimensional arrays. The investigator and his colleagues will enrich the interplay between matrix computations and tensor computations by pursuing four basic directions of research. They will<br/>(1) develop  tensor approximation techniques based on matrices that have low Kronecker product rank, (2) implement a pair of basic tensor algebra subprograms, one that showcases a new contraction-level generalization of Strassen multiplication and one that demonstrates how to compute effectively  contractions between tensors that have symmetry, (3) analyze the data sparse representation of huge vectors through tensor networks, and (4) develop a unifying framework for SVD-like tensor decompositions through an embedding idea that involves symmetric tensors.<br/>  <br/><br/>A table of data is 2-dimensional and many matrix computation techniques exist for extracting information from the numbers that appear in the rows and columns. A tensor can be thought of as a table whose entries are other tables. For example, a table having 10 rows and 8 columns has 80 ``cells''. If each of those cells is itself a 5-by-4 table, then the entire data set can be thought of as a 10-by-8-by-5-by-4 tensor. Data sets of this variety are increasingly prominent in engineering and the sciences because it is the natural way to structure the information associated with a model that depends upon many factors.<br/>The research plan is to help build an infrastructure for the scientific community that makes tensor-based  computation as natural and easy as matrix-based computation. The successful problem-solving and problem-analysis tools provided by the matrix computation field will  be broadened and generalized. The outreach agenda includes the production of educational materials that will help ensure the development of a tensor-savvy scientific community. <br/>These materials include an online, ten-lecture short course on tensor computation, participation in a Visiting Lecturer program that targets 4-year colleges, and the addition of a tensor computation chapter in the upcoming fourth edition of  the highly-cited textbook on matrix computations by Golub and Van Loan."
"1016136","Collaborative Research: Predicting the Release Kinetics of Matrix Tablets","DMS","COMPUTATIONAL MATHEMATICS","08/15/2010","04/25/2014","Ami Radunskaya","CA","Pomona College","Standard Grant","Junping Wang","09/30/2014","$124,472.00","","aradunskaya@pomona.edu","Alexander Hall","Claremont","CA","917114434","9096218328","MPS","1271","9263","$0.00","This work will extend two mathematical models for the dissolution and release process occurring in sustained release matrix tablets. The first of these models uses random walks on the weighted contact graph of a random dense packing of spheres of multiple diameters. The second model consists of a system of partial differential equations of reaction-diffusion type for the solved and unsolved excipient and drug, respectively.  We will develop new computational tools, borrowing from theories of random walks on graphs, probability density estimation, and numerical partial differential equations. The theoretical models will be implemented in fast, robust code, and model parameters will be calibrated to actual data in close collaboration with researchers in the  pharmaceutical sciences.<br/><br/>The team of investigators will develop mathematical and computational methods to predict the release kinetics of sustained release matrix tablets. These tablets are used to deliver an active drug and to gradually release it over an extended period of time. Sustained release tablets offer considerable advantages over immediate release tablets, namely maintaining more constant drug levels in the patient's body while minimizing the number of tablets that need to be taken each day. In previous  work, jointly with collaborators in New Zealand (initiated by NSF grant DMS-0737537), we have proposed mathematical models for the dissolution  and release process, predicting qualitatively excellent release curves for different compositions of the powder mixture. This research will streamline the design process of new and better pharmaceutical delivery devices and will introduce computational methods into a new field of science.  All programs will be written in open source software and will be freely available online to interested researchers."
"1001839","The 2010 Barrett Lectures: Discrete Differential Geometry and Applications","DMS","COMPUTATIONAL MATHEMATICS, ANALYSIS PROGRAM","04/15/2010","04/09/2010","Kenneth Stephenson","TN","University of Tennessee Knoxville","Standard Grant","Junping Wang","03/31/2011","$20,125.00","","KENS@MATH.UTK.EDU","1331 CIR PARK DR","Knoxville","TN","379163801","8659743466","MPS","1271, 1281","7556, 9150, 9263","$0.00","The proposal seeks funds to support a five day conference representing the 2010 Barrett Memorial Lectures. The Lectures, which are well known and highly regarded, have been organized annually on a variety of topics and with a distinguished list of speakers and participants. The 2010 Barrett Lectures are entitled ""Discrete Differential Geometry and Applications"". This will be a five-day conference organized by Professor Kenneth Stephenson (Tennessee), and Professor Alexander Bobenko (Technical University, Berlin). The conference continues a sequence which started in Germany and has been instrumental in founding Discrete Differential Geometry) as a coherent topic. Three distinguished researchers, Rick Kenyon, Igor Pak, and Peter Schroeder, will be involved in organizing the five days, each devoted to a different aspect of DDG through hour talks and sessions for shorter talks. One evening there will be a contributed poster session, and one evening a contributed software demonstration session. <br/><br/>The conference is intended to introduce Discrete Differential Geometry and its unique mixture of theory, computation, and application more broadly in the US. Young researchers and graduate students are particularly important parts of the audience, and every effort will be made to attract a diverse and interdisciplinary audience, including women and minorities."
"1048840","RAPID: Modeling and experiments of oil-particulate mixtures of relevance to the Gulf of Mexico oil spill","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","09/01/2010","07/16/2010","Andrea Bertozzi","CA","University of California-Los Angeles","Standard Grant","Junping Wang","08/31/2012","$140,618.00","","bertozzi@math.ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","MPS","1253, 1271","5987, 7914, 9263","$0.00","The Gulf of Mexico Oil Spill is perhaps the most significant environmental disaster in US history with a significant portion of the US coastline affected by the approaching crude.  Cleanup of beaches is important for both environmental reasons and for the tourist trade.  This research program addresses fundamental questions of the dynamics of oil and sand of direct relevance to the cleanup problem.  The work builds on recent studies of the Principal Investigator on mathematical models for oil-sand mixtures on slopes, including work on critical inclination angles for separation of oil-sand mixtures and modeling of shear-induced migration in oil/particulate films.  The current research effort addresses such basic questions as whether there is a critical angle of incline for beach sand dunes that result in oil collecting in the dune vs. flowing to the bottom of the dune. The study of periodic patterns of shearing due to waves is also important for this research project.<br/><br/>The dynamics of particulates (e.g. sand) in oil is a complex process involving hindered settling dynamics and dynamics of the fluid such as shear.  Recently the research group of the PI has found the dominant physics for particle-oil film mixtures on an incline and can explain quantitatively the bifurcation that occurs between regimes of particle settling downstream of the flow and clear fluid separating out from the flow.  The equilibrium theory compares shear-induced migration due to the bulk flow properties with hindered settling due to gravity, and matches well with laboratory experiments.  The current research program develops dynamic theories for particle-sand mixtures on inclines of particular relevance to the current crude oil spill.   In addition to basic time-dependent flow problems the study considers oil-water mixtures and periodic time dependent shear such as what might result from wave motion and tidal forces on beaches."
"1014666","Automated Structure Generation, Error Correction, and Semi-Definite Programming Techniques for Structured Quadratic Inverse Eigenvale Problems: Theory, Algorithms and Applications","DMS","COMPUTATIONAL MATHEMATICS, DYNAMICAL SYSTEMS","09/01/2010","07/01/2010","Moody Chu","NC","North Carolina State University","Standard Grant","Junping Wang","08/31/2014","$194,999.00","","chu@math.ncsu.edu","2601 Wolf Village Way","Raleigh","NC","276957514","9195152444","MPS","1271, 7478","9263","$0.00","Mathematical modeling has become an indispensable task in almost every discipline of sciences. However, since most of the information gathering devices or methods have only finite bandwidth, one cannot avoid the fact that the models employed often are not exact.  Techniques of inverse problems that validate, determine, or estimate the parameters of the system according to its observed or expected behavior, therefore, are critically important. One of the most frequently used models in important applications including applied mechanics, electrical oscillation, vibro-acoustics, fluid mechanics, signal processing, and finite element discretization of PDEs is the notion of quadratic pencils. The inverse problem of ""constrained quadratic model reconstruction from eigeninformation"" is essential for the understanding and management of complex systems, yet the fundamental understanding of either its theory or computation is still in a quite primitive state. This proposal intends to develop theoretic understanding and to implement the concept into new numerical algorithms that are effective in aspects of robustness, speed and accuracy. The ultimate goal of this project is to establish a mechanism (followed by a software package) that can automatically, systematically and universally reduce the inexactness and uncertainty within the model while maintaining feasibility conditions required by the system.<br/>This research will take on three specific challenges for solving quadratic inverse eigenvalue problems with innovative but promising approaches among which are the automated structure generation, consistency correction, and semi-definite programming techniques. This project is expected to find important applications ranging from new development of numerical algorithms to theoretic solution of difficult problems. The resulting technology would significantly advance knowledge in the emerging field of model updating and related problems which, in turn, would have substantial impact on broad areas in scientific and engineering fields.<br/><br/><br/><br/>In mathematical modeling, techniques of inverse problems that validate, determine, or estimate the parameters of the system according to its observed or expected behavior are critically important. This research concentrates on the inverse model reconstruction problems with their pertinence to physical and engineering applications. These problems have been strongly motivated  by scientific and industrial applications, including structural mechanics such as vibration control and stability analysis of bridges, buildings and highways, vibro-acoustics such as predictive coding of sound, biomedical signal and image processing, time series forecasting, information technology, and others. Thus this project will impact a wide variety of industries utilizing these applications, including aerospace, automobile, manufacturing and biomedical engineering. The greatest challenge facing these industries is to manufacture increasingly improved products with limited engineering and computing resources. A great deal of money and effort has been spent in these industries to satisfactorily perform the model updating task.<br/>However, the lack of proper theory and computational tools often force these industries to solve their problems in an ad hoc fashion. An improved analytical model that can be used with confidence for future designs is an essential tool in achieving this objective. The proposed research has not only strong mathematical foundation but also significant mathematical modeling and experimental aspects using industrial data which should be instantly welcome by the industries. Students working on this project will receive a valuable inter-disciplinary training blending mathematics and scientific computing with various areas of engineering and applied sciences.<br/>Such expertise is rare to find, but there is an increasing demand both in academia and industries."
"1016182","Numerical Approximations of Non-Newtonian Fluid Flows with Applications","DMS","COMPUTATIONAL MATHEMATICS","09/15/2010","09/15/2010","Hyesuk Lee","SC","Clemson University","Standard Grant","Leland Jameson","08/31/2014","$209,922.00","","hklee@clemson.edu","230 Kappa Street","CLEMSON","SC","296340001","8646562424","MPS","1271","9150, 9263","$0.00","This research is focused on numerical approximation of non-Newtonian fluid flows in physical applications. Such fluid flows are abundant in our everyday lives, from the flow of blood in our bodies to the production of polymeric material such as plastics. There are two prototypal problems considered in the project: (i) optimal control for defective boundary conditions, and (ii) non-Newtonian flow within an elastic medium. Blood flow is one of most important examples related to such situations as a non-Newtonian flow interacts with an elastic vessel wall, where only flow rate or mean pressure is specified on each inflow and outflow boundary. The model problems in this research involve either coupled domains representing multi-physics behavior or coupled state-adjoint systems. This increases the numerical complexity as both stress and velocity must be resolved in the domains, and the strong interaction between the governing equations requires  solution algorithms that achieve optimal convergence rates while splitting the operators. <br/>Additionally, because of the large number of unknowns to be approximated, there is a need to develop efficient solvers for these problems. The proposed research addresses issues on decoupling schemes, and their stability and convergence. The primary contribution of the research is the development  of robust numerical schemes  for non-Newtonian flows in coupled systems, and analytical and numerical study of  optimal control for non-Newtonian flows.<br/><br/><br/>There have been extensive studies on multidisciplinary problems involving Newtonian flows, but to date mathematical and numerical investigations of non-Newtonian flows are still far behind.  Because of the many important biological and engineering processes involving non-Newtonian fluid flow, there is a great demand for mathematical support in these applications.  The proposed research broadens the mathematical basis for the numerical simulation of non-Newtonian fluid flow problems in physical settings. Also the research benefits biomedical and polymer industries by providing improved algorithms for the numerical simulation of important processes."
"1016060","Meshfree particle methods for analysis of elastic plates and shells","DMS","COMPUTATIONAL MATHEMATICS","10/01/2010","09/20/2010","Hae-Soo Oh","NC","University of North Carolina at Charlotte","Standard Grant","Junping Wang","09/30/2013","$118,165.00","","hso@uncc.edu","9201 University City Boulevard","CHARLOTTE","NC","282230001","7046871888","MPS","1271","9263","$0.00","A large number of structural components in engineering  can be classified as <br/>plates. Typical examples  of civil engineering structures are floor and <br/>foundation slabs, lock-gates, thin retaining walls, bridge decks, and slab <br/>bridges. Plates are also indispensable in ship building, automobile, and <br/>aerospace industries. The  stress resultants of a thin plate can be calculated <br/>through the 3-dimensional elasticity equations. However, under certain <br/>hypotheses, the 3-dimensional elasticity equations for a  plate  are reduced  <br/>to the 2-dimensional equations. The Kirchhoff plate model  is well suited for  <br/>thin  plates. However,  the governing equation for the displacement of  this <br/>plate model is the fourth order differential equation. The conventional finite <br/>element method is difficult to apply  because  of the complexity of  <br/>constructing smooth finite elements. Furthermore, moderately thick plates have <br/>other difficulties such as  boundary layer problems and shear  locking <br/>problems. <br/> <br/>Meshless methods (in which smooth flexible approximation functions are used <br/>and complicated mesh generation is not necessary)  have several advantages <br/>over the conventional finite element method.  However,  these  methods have <br/>several major limitations including  the inefficiency in handling essential  <br/>boundary conditions, large matrix condition numbers, and complexity in <br/>constructing partitions of unity.  Most recently, the PI invented  one of the <br/>most  flexible  closed form partition of unity, called the Generalized Product <br/>Partition of Unity.  The PI proposes to introduce  Meshfree particle methods  <br/>by using the Generalized Product Partition of Unity,  together with new local <br/>approximation functions that can handle geometric boundary conditions as well  <br/>as force boundary conditions  arising in various plate models. Furthermore, <br/>the PI proposes to apply  Meshfree particle  methods  to obtain highly <br/>accurate  stress analysis of plates and shells for design and maintenance of <br/>related engineering structures. <br/> <br/>The Intellectual Merit: The proposed research will greatly improve the stress <br/>analysis of plates, shells,  and laminated composite plates so that design and <br/>maintenance  of automobiles, airplanes, ships, and all other engineering <br/>structures related to plates and shells  may be more effective and safer.  <br/>Moreover, without any difficulty, the proposed method is able to surgically <br/>make the approximation space  enriched with any type of singular function.  <br/>The proposed method is flexible and effective in dealing with singularities <br/>and  it can be used for accurate prediction of crack propagation. <br/> <br/>The Broader Impacts: Results from the proposed research can be used to design <br/>fuel efficient automobiles, safer airplanes, ships  and new materials more <br/>resistant to failure. The proposed research   can also be applied to improve <br/>maintenance of aging airliners, bridges, ships, buildings, and numerous other <br/>applications where structural integrity should be closely monitored. <br/>Ultimately,  the  proposed research  will  have  direct impacts on the public <br/>safety and the environment by increasing efficiency and safety of  common <br/>modes of transportation and structures used everyday."
"1016183","New statistical approaches to inverse problems in biomedicine","DMS","COMPUTATIONAL MATHEMATICS, COFFES","07/01/2010","07/01/2010","Erkki Somersalo","OH","Case Western Reserve University","Standard Grant","Junping Wang","06/30/2013","$309,971.00","","ejs49@case.edu","Nord Hall, Suite 615","CLEVELAND","OH","441064901","2163684510","MPS","1271, 7552","9263","$0.00","The aim of the project is to develop new computational tools for solving inverse problems arising in biomedical applications. The computational framework is based on the Bayesian statistical paradigm, in which the inverse problem is reformulated as a statistical inference problem, and information complementing the scarce and noisy data is imported in the form of prior probability distribution. The methodological emphasis of this project is the development of structural, hierarchical and dynamic prior models. Structural prior models make it possible to combine different imaging modalities, an approach often referred to as data assimilation. The closely related hierarchical models, on the other hand, allow uncertainties in the prior model itself, letting the data guide the prior. In particular, the approach facilitates the implementation of prior information that is qualitative in nature, important examples being sparsity or locality of the solution. Dynamic prior models are essential in time dependent problems, and they often involve structural elements. Another central question addressed in this project is the development of efficient computational strategies to explore the posterior probability distributions. In particular, sequential methods based on the use of fast reduced forward models will be explored. The visualization of uncertainties drawn from a Monte Carlo sample in imaging applications will also be addressed. The resulting algorithms will be applied to biomedical inverse problems, including Electrical Impedance Tomography (EIT), MagnetoEncephaloGraphy (MEG), Positron Emission Tomography (PET) and ElectroNeuroGraphy (ENG), using data provided by an already established network of collaborators.<br/><br/>The current trend in biomedical research is to develop new imaging modalities, clinical procedures and technologies that are minimally invasive. Instead of using ionizing radiation that may constitute a health risk, methods that use weak electric currents or the electromagnetic fields of the body itself are preferable. Electric current/voltage measurements can be used to identify potential malignant tumors in breast tissue; localization of the onset loci of epileptic seizures, an essential procedure before brain surgery to gain control of refractive epilepsy, can be done by measuring the weak magnetic fields due to the brain activity. Similarly, in designing technologies that help patients with spinal cord trauma to regain control of their muscles, or patients with an amputated limb to control a prosthetic arm, new methods of recording non-invasively the nerve signals are developed. A common feature of these methods is that the signals that they rely on are weak, cluttered by noise, and hard to identify. In addition, the computational models are incomplete, since several details describing the setting are unknown. The investigator, together with his colleagues, develops computational methods to overcome the aforementioned difficulties. The methodology relies on probabilistic modeling of the signal and uncertainties within the model. The incomplete data is augmented by complementary information, and a particular emphasis is on the question, how to translate qualitative information about the unknowns into a quantitative form so that it can be entered in the computational model."
"1015370","Fast Multigrid Solvers for Transport with Forward-Peaked Scattering","DMS","COMPUTATIONAL MATHEMATICS","09/01/2010","08/16/2010","Scott MacLachlan","MA","Tufts University","Standard Grant","Junping Wang","08/31/2014","$279,537.00","Christoph Borgers","scott.maclachlan@tufts.edu","136 Harrison Ave","Boston","MA","021111817","6176273696","MPS","1271","9263","$0.00","The primary goal of this proposal is to develop fast, efficient, and robust multigrid-based solvers for the solution of the linear Boltzmann-transport equation in the regime of highly forward-peaked scattering.  Recently, the project team have developed an angular multigrid algorithm for a model problem that captures the essential features of the Boltzmann-transport equation for scattering in a two-dimensional ""Flatland"" model.  The research goals of this project are, thus, to extend this approach to an efficient and effective method for true three-dimensional scattering, in realistic media, with accurate discretizations.  Among the challenges of extending the already developed technique to three dimensions are improving the discretization to allow discontinuous coefficients, and local grid refinement needed in regions of interest.  Additionally, the project team will investigate theoretical analysis of the convergence of these algorithms, in both two and three spatial dimensions, providing critical insight into the design of these algorithms for realistic scattering kernels.<br/><br/>Accurate and efficient models of forward-peaked scattering are of significant interest in both biomedical and nuclear engineering applications.  This regime describes the scattering of electron beams, used in radiation therapy for the treatment of certain cancerous tumors, as well as the transport of charged particles in reactor physics and astrophysics.  While there is a long history of interest in efficient and accurate algorithms for modeling charged-particle transport, the problem still poses formidable challenges.  The approach considered here offers a new direction for research in this area.  The proposed work leads directly to simulation tools for biomedical and nuclear engineers and scientists.  The active roles of the PI and co-PI in the computational science and mathematical biology communities ensure timely and widespread dissemination of the resulting algorithms.  Furthermore, the project directly involves a doctoral student, who is actively mentored by the PI and co-PI, contributing to the training of an early career scientist in an important field of research."
"1016712","Fast Evaluation and Fast Transforms of Band-Limited Functions","DMS","COMPUTATIONAL MATHEMATICS","08/15/2010","08/03/2010","Hong Xiao","CA","University of California-Davis","Standard Grant","Leland Jameson","07/31/2014","$274,955.00","","hxiao@ucdavis.edu","OR/Sponsored Programs","Davis","CA","956186134","5307547700","MPS","1271","9263","$0.00","Whenever physical signals are measured or generated, the results tend to be band-limited (i.e. to have compactly supported Fourier transforms), or, in more generic terminology, signals tend to only contain information from a limited number of frequencies.  Indeed, measurements of electromagnetic and acoustic data are band-limited due to the oscillatory character of the processes that have generated the quantities being measured.  When the signals being measured come from heat propagation or diffusion processes, they are (practically speaking) band-limited, since the underlying physical processes operate as low-pass filters, i.e.  high frequency components are attenuated or completely removed.  The importance of band-limited functions has been recognized for hundreds of years; classical Fourier analysis can be viewed as an apparatus for dealing with such functions.  When band-limited functions are defined on the whole line (or on the circle), classical tools are very satisfactory.  However, in most practical cases, we are confronted with band-limited functions defined on finite intervals or regions (or, more generally, on compact regions in Rn).   It was determined more than 40 years ago that a special class of functions, the Prolate Spheroidal Wave Functions, are the optimal tool for dealing with band-limited functions. But their realistic use has been limited by the need to develop efficient and accurate algorithms for their evaluation. The product of this research project will be efficient and accurate algorithms for evaluating and transforming PSWFs. <br/><br/>Classical Fourier analysis is an indispensable tool in many scientific and engineering disciplines: mathematics, physics, signal processing, image processing, acoustic scattering, electromagnetics, etc, and works well for handling band-limited functions (those that have limited frequency content) that are defined on the whole line (or on the circle).  Technologies based on the research proposed in this project, however, will remedy the inadequacy of the classical Fourier analysis in dealing with practical situations which frequently call for modeling with band-limited functions that are defined on the interval.  At the same time, the proposed method maintains some of the benefits of Fourier analysis: fast evaluation, fast transformation, and high accuracy. The proposed research will be applied to practical problems not amenable to existing techniques including problems in wireless communications, radar and sonar signal design, and image texture analysis.  In addition, the investigator plans to implement education and outreach programs for mentoring undergraduate and graduate students, and for public dissemination of research results and software.  Specific goals<br/>include: (1) developing inter-related courses on mathematical programming, on numerical methods in integration and interpolation, and on fast algorithms and band-limited functions, ranging from freshman to graduate level; (2) mentoring undergraduate students in related research projects; (3) bringing current research to scientific and engineering communities, via organizing workshops and by contributing publicly available production grade software libraries."
"1016554","Hybrid Adaptive Numerical Methods and Computational Software for Biological Fluid-Structure Interaction","DMS","COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY","09/01/2010","06/27/2013","Boyce Griffith","NY","New York University Medical Center","Continuing Grant","Junping Wang","10/31/2014","$299,993.00","","boyceg@email.unc.edu","One Park Avenue, 6th FL","New York","NY","100165800","2122638822","MPS","1271, 7334","9263","$0.00","Building upon his earlier work in developing parallel and adaptive immersed boundary (IB) methods for simulating fluid-structure interaction (FSI), in this project, the investigator aims to construct a new hybrid FSI methodology which incorporates features of both the IB method and the immersed interface (II) method.  The IB method is a broadly-useful approach to FSI which has been applied to diverse problems in biological fluid dynamics.  Although the IB method has been demonstrated to be a useful approach to such problems, it is generally only first-order accurate, and fine spatial grids are therefore required to obtain resolved numerical simulations.  The II method is an IB-like approach to FSI which yields second-order accuracy for certain problems, but which is currently limited to thin elastic interfaces which are closed (i.e., which do not have free edges).  The hybrid FSI methodology of this project will incorporate features of both the IB and II methods to obtain high-order accuracy for both ""thick"" and ""thin"" elastic bodies, including thin elastic interfaces with free edges.  We believe that the basic version of the methodology will be the first IB-like method to achieve full second-order accuracy for thick elastic bodies such as the muscular walls of the heart, and that the extended version of the methodology will be the first II-like method to treat interfaces with free edges, such as the thin leaflets of the cardiac valves.  These new methods will be used to simulate cardiovascular flows, especially the fluid dynamics of the aortic heart valve.<br/><br/>Problems in which a fluid flow interacts with an elastic structure, such as the writhing and coiling of DNA or, as addressed within this project, blood flow in the heart and vessels, are ubiquitous in engineering, biology, and medicine.  The immersed boundary (IB) method is a broadly-useful approach to such problems which was introduced to enable the computer simulation of the fluid dynamics of the heart and its valves.  Indeed, cardiovascular applications have motivated much work to develop mathematical and computational methods for FSI, and the large and growing number of patients suffering from cardiovascular diseases (80 million people in the United States, approximately 30% of the population), such as coronary heart disease (16.8 million people) or heart failure (5.7 million people), make such applications increasingly important.  This project aims to develop an improved version of the IB method which will improve the accuracy of the methodology, possibly leading to significantly more realistic simulations of cardiovascular dynamics.  Because the IB approach is widely useful, and because the software implementing the methods of this project will be freely distributed, the potential impact of this work is quite broad, possibly affecting studies which aim to address basic scientific questions (e.g., the fluid-structure interactions which result in the beating of cilia within the oviduct or respiratory tract) to studies which aim to improve the design of medical therapies and devices (e.g., prosthetic cardiac valves or treatments for heart failure)."
"1016232","Collaborative Research: A posteriori error analysis and adaptivity for discontinuous interface problems","DMS","COMPUTATIONAL MATHEMATICS","10/01/2010","07/20/2011","Haiying Wang","MI","Michigan Technological University","Standard Grant","Rosemary Renaut","09/30/2013","$0.00","","haiyingw@mtu.edu","1400 Townsend Drive","Houghton","MI","499311295","9064871885","MPS","1271","9263","$0.00","There are many practical physical situations that can be modeled by partial differential equations in which some of the coefficients in the problem, e.g. those describing material properties, are discontinuous across an interface. Such problems arise in a very broad range of scientific and engineering disciplines, including computational biology, ground water flow and reservoir simulation, environmental remediation studies, crystal growth, wave propagation, sedimentation phenomena, and the preparation of nuclear fuel rods. Such problems cause notorious difficulties for classic numerical methods as a direct result of the lack of smoothness. At the same time, numerical methods for efficiently solving interface problems using a fixed Cartesian grid have attracted considerable attention because they offer a number of computational advantages and a number of approaches have been pursued. Unfortunately, regular-shape discretizations are generally problematic because the interface ?cuts? through the cells without respecting the regular geometry of the discretization, which has a strongly negative impact on the accuracy of the resulting approximations. Consequently, it is critically important to provide computational error estimates that quantify the accuracy of a computed quantity of interest in terms of various sources of discretization and modeling error. <br/><br/>This project will develop variational finite element frameworks for several discrete interface methods that identify both a discretization and a modeling component to the model and use the variational framework to derive accurate a posteriori error estimates for specified quantities of interest. Both stationary and evolutionary problems in two and three space dimensions will be considered. The development of efficient adaptive discretization methods for both stationary and evolution problems will be addressed. The methodology and analytic tools to be developed in this proposal will provide a powerful tool for the systematic treatment of problems in which interfaces have complex geometry and the material properties vary considerably on a scale smaller than the overall scale of the discretization. The project will yield a systematic approach to deriving computable and accurate error estimates for quantities of interest and further, provide detailed information about the relative contributions to the error arising from discretization and modeling."
"1016086","Collaborative Research: Theory and Algorithms for Beta Random Matrices: The Random Matrix Method of ""Ghosts"" and ""Shadows""","DMS","COMPUTATIONAL MATHEMATICS","09/01/2010","08/05/2010","Plamen Koev","CA","San Jose State University Foundation","Standard Grant","Junping Wang","08/31/2014","$181,503.00","","koev@math.sjsu.edu","210 North Fourth Street","San Jose","CA","951125569","4089241400","MPS","1271","9263","$0.00","The main goal of the work described in this proposal is to introduce and perform a thorough theoretical and numerical analysis of the class of beta random matrix ensembles. The investigators will generalize and extend to any postive beta the classical real, complex, and quaternion random matrix ensembles which correspond to the cases  1, 2, 4, respectively. Already many results in infinite random matrix theory and a few results in finite random matrix theory suggest that the use of beta as a continuous  parameter is reasonable. The key new concept in this proposal is the notion of a beta-random variable, an object which, for all practical purposes behaves as a beta-dimensional algebra over the reals. To develop the theory the PIs use the notions of ""ghosts"" and ""shadows"". A ""ghost"" is a beta-dimensional random variable and a ""shadow"" is a derived real or complex quantity that can be sampled. Along with the derivation of theoretical results, a major goal of this project is to provide algorithms for computation with these random matrix ensembles.<br/><br/><br/>A vast number of practical application ranging from bioinformatics, and genomics (population classification) to wireless communications (network capacity optimization) and military applications (automatic target classification) rely on the methods of multivariate statistics and in turn on random matrix theory. The proposed research will provide new algorithmic and theoretical tools for these applications as well as enable new applications and research directions in these fields."
"0967386","FRG: Collaborative Research: Atlas of Lie Groups and Representations: Unitary Representations","DMS","COMPUTATIONAL MATHEMATICS, ANALYSIS PROGRAM","07/01/2010","04/22/2010","Dan Barbasch","NY","Cornell University","Standard Grant","Bruce P. Palka","06/30/2013","$102,181.00","","barbasch@math.cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","MPS","1271, 1281","1616","$0.00","This project has two primary goals.  The first is to solve the problem of the unitary dual: to describe the irreducible unitary representations of real reductive Lie groups. The primary tool is an algorithm to compute the unitary dual of any given group, which we are implementing inside the ""atlas"" software. We plan to use this information to prove results about the unitary dual, beginning with the unitarity of Arthur's unipotent representations. The second primary goal is to make information about representation theory of real groups accessible to non-specialists, via the software, a web site, public workshops, and other means. The atlas software is freely available on the atlas web site, and will continue to be maintained there indefinitely.<br/><br/>The idea of using symmetry to study problems in mathematics and science dates back to Fourier's work on heat nearly two hundred years ago. In the hands of Hermann Weyl, Eugene Wigner, and Andre Weil, symmetry has come to play a central role in quantum mechanics and in number theory. Lie groups, named after the Norwegian mathematician Sophus Lie, are the mathematical objects underlying symmetry.  Representation theory studies all of the ways a given symmetry, or Lie group, can manifest itself. The problem of understanding all ""unitary"" representations (in which the symmetry operations preserve lengths) is one of the most important unsolved problems in the subject, and has potential applications in many areas; for example, it is an abstract version of the question, ""what quantum mechanical systems can admit a certain kind of symmetry?"""
