"AwardNumber","Title","NSFOrganization","Program(s)","StartDate","LastAmendmentDate","PrincipalInvestigator","State","Organization","AwardInstrument","ProgramManager","EndDate","AwardedAmountToDate","Co-PIName(s)","PIEmailAddress","OrganizationStreet","OrganizationCity","OrganizationState","OrganizationZip","OrganizationPhone","NSFDirectorate","ProgramElementCode(s)","ProgramReferenceCode(s)","ARRAAmount","Abstract"
"9803154","Moving Frames & Computer Vision","DMS","GEOMETRIC ANALYSIS, APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/01/1998","06/23/1998","Peter Olver","MN","University of Minnesota-Twin Cities","Standard Grant","Deborah Lockhart","06/30/2002","$115,000.00","","olver@umn.edu","200 OAK ST SE","MINNEAPOLIS","MN","554552009","6126245599","MPS","1265, 1266, 1271","9216, 9263, HPCC","$0.00","This project  is devoted to innovative applications of the geometry of<br/>moving frames  and the mathematical theory of differential invariants to<br/>problems arising in computer vision, with emphasis on medical imaging. <br/>Since symmetry forms a basic component of the human visual system, it should be<br/>naturally incorporated into mathematical methods for image processing and object<br/>recognition. The image processing applications to be considered will include<br/>denoising and smoothing, segmentation and edge detection, as well as object<br/>recognition, including symmetry detection and partial occlusions. Practical<br/>implementations will be based on the signature curve paradigm, that is based on the construction of suitable differential invariants for the symmetry group under consideration.  Metrics that distinguish signature curves of different objects will be compared, with the goal being to recognize and extract objects from both two and three-dimensional images.  Practical implementations of the image processing systems will rely on a new method of constructing symmetry-preserving numerical approximations to differential invariants that is to be developed as a part of this project.  The applications will be based on a new, practical theory of moving frames, that can be applied  to general group actions, both finite and infinite-dimensional.  Part of the project will be devoted to the further development of this general theory. Various additional applications, to problems arising in physics, geometry, invariant theory, and the calculus of variations, will also be investigated.<br/><br/>"
"9873326","KDI: Multiscale Physics-Based Simulation of Fluid Flow for  Energy and Environmental Applications","DMS","COMPUTATIONAL MATHEMATICS, PMP-Particul&MultiphaseProcess, ESD-Eng & Systems Design, Hydrologic Sciences, ADVANCED COMP RESEARCH PROGRAM, KDI OPPORTUNITY FUND","10/01/1998","09/11/1998","Mary Wheeler","TX","University of Texas at Austin","Standard Grant","Michael Steuerwalt","09/30/2002","$1,700,000.00","Todd Arbogast, Chandrajit Bajaj, Clinton Dawson, Steven Bryant","mfw@ices.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271, 1415, 1464, 1579, 4080, 8876","0000, 1337, 1339, 9216, 9263, HPCC, OTHR","$0.00","Wheeler<br/>9873326<br/><br/>Fluid flows at and below the earth's surface are the cause and cure for problems of water and soil pollution, while petroleum and natural gas production depends on flows in the subsurface.  In these problems, the length scales of practical interest range from tens of meters to kilometers.  However, the behavior at these scales depends critically on physics occurring at much smaller length scales.  A wide disparity in time scales also exists in these problems.  Moreover, different physical processes occur simultaneously in different parts of the domain.  In this project, the investigators and their university, government and industrial collaborators develop much-needed scientific understanding of small-scale phenomena from theory and experiment, and also develop new computational tools and strategies for incorporating this understanding at the practical scale, for handling multiple types of physics across subdomains, for remote collaboration, and for visualizing and manipulating the results.  The project focuses on better understanding of small-scale phenomena (e.g., multiphase interfacial area, hysteresis, dispersion, and discrete fractures in porous media), interdomain coupling by means of multiblock or multiphysics methodologies (e.g., coupling of surface water and groundwater environments), the development of accurate and efficient algorithms and prototype simulators, and methods for viewing results interactively and with collaborators off site.  The algorithms and simulators developed include novel mortar type spaces for coupling domains, and sophisticated, adaptive, finite element, finite volume and time-stepping methods for modeling nonlinear advective, diffusive and reactive processes.  The algorithms are implemented on parallel computing platforms.  Interactive steering and visualization are coupled closely to the simulators.  Important work related to this project are laboratory experiments and field data for critical evaluation of the simulators, demonstration of prototypical simulators on petroleum engineering production models and environmental subsurface and surface flow applications, and educational and professional outreach and training through workshops, video and web-based technologies.<br/><br/>This project concerns computer simulation and prediction of the movement and interaction of fluids in surface waters and subsurface groundwater and petroleum reservoirs.  The focus is on fundamental multiscale and multiphysics applications (i.e., physical processes occurring together at different length and time scales and different physical processes occurring in different parts of the spatial domain).  The motivation behind this work is the need to better understand and quantify the effect of small-scale processes on larger, field-scale processes, and to understand how different physical processes occurring in close proximity affect each other.  The investigators study these problems through the development of appropriate mathematical models, numerical algorithms, computational science and visualization tools, and laboratory experiments.  This work is carried out in collaboration with other university researchers and government and industrial partners.  Educational outreach and training of future scientists and engineers is an important part of this effort.  The applications of interest include petroleum and natural gas production, groundwater contamination and remediation, surface water circulation and pollution, and the interaction between surface and groundwater environments.  These applications have significant environmental and economic impact.<br/>"
"9804846","Solving Sparse Polynomial Systems by Polyhedral Homotopies","DMS","COMPUTATIONAL MATHEMATICS","07/15/1998","06/26/1998","Tien-Yien Li","MI","Michigan State University","Standard Grant","Jong-Shi Pang","06/30/2001","$85,000.00","Jan Verschelde","li@math.msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1271","9216, 9263, HPCC","$0.00","9804846  Li    Sparse polynomial systems occur frequently in a wide variety of  applications in sciences and engineering where the knowledge of all their   isolated solutions is essential. Practical evidence has shown  that homotopy continuation algorithms are efficient, reliable and  accurate in finding all the isolated zeros of polynomial systems.  Moreover, the method is inherently parallel and is therefore a natural  candidate for distributed processing architectures.    The proposed research is to be directed along several avenues in  solving polynomial systems by the newly emerged polyhedral homotopies. The  essence of the project is to develop efficient computational algorithms,  which involves a theoretical study of the method, investigation of the stability and efficiency of the algorithm, and benchmark testing for a wide range of problems. The ultimate goal of the project is to produce a high-quality software package that can be used to solve large-scale real world applications on a wide variety of advanced architectures."
"9870178","Multivariate Splines:  Theory, Computation and Applications","DMS","COMPUTATIONAL MATHEMATICS","08/01/1998","07/17/1998","Ming-Jun Lai","GA","University of Georgia Research Foundation Inc","Standard Grant","Jong-Shi Pang","07/31/2001","$70,334.00","","mjlai@uga.edu","310 E CAMPUS RD RM 409","ATHENS","GA","306021589","7065425939","MPS","1271","9216, 9263, HPCC","$0.00","9870178  Lai    This project concerns investigation of multivariate spline functions.  Bivariate and trivariate splines of smoothness r and degree d, will be studied more carefully to enhance their computational efficiency which is essential for applications in computer aided geometric design (CAGD) and numerical solutions of partial differential equations (PDE).     The PI will identify the best spline spaces for these applications in the   bivariate setting, comparing the dimension of all spline spaces of a fixed   smoothness, the number of triangles of  their underlying triangulations and   their approximation power.  The PI will implement these best spline spaces   when r=1 and r=2 for typical applications in CAGD and numerical solution   of PDE's, e.g., scattered data fitting, filling polygonal holes,  numerical   solutions of linear and nonlinear biharmonic equations. The PI will study   the construction of compactly supported orthonormal wavelets under H1 norm    using bivariate splines so that the numerical solution of the standard   elliptic equations can be solved without inverting the linear systems.   Furthermore, the PI will also study the trivariate spline spaces and identify   the best one for the application in numerical solutions of 3D  partial differential equations, in particular 3D Navier-Stokes equations.  Once the best spline space for r=1 is identified, the PI will implement  it for numerical solution of PDE's in the trivariate setting.   When computing with these splines, multi-level and domain decomposition   methods will be employed to improve the performance of the computation."
"9805590","Negative Norm Least-Squares Finite Element Methods for Electromagnetics","DMS","COMPUTATIONAL MATHEMATICS","07/01/1998","06/20/2002","Xuejun Zhang","TX","Texas A&M Research Foundation","Standard Grant","Michael Steuerwalt","06/30/2003","$65,000.00","","","400 HARVEY MITCHELL PKWY S STE 3","COLLEGE STATION","TX","778454375","9798626777","MPS","1271","9148, 9216, 9263, HPCC, MANU","$0.00","9805590<br/>Zhang<br/><br/><br/>The objectives of this project are the design and analysis of robust and accurate finite element methods for problems arising from mechanics and electromagnetics and the construction of iterative algorithms for solving the resulting algebraic systems.  The research will focus on the investigation of negative norm least-squares finite element methods for div-curl systems and the Maxwell equations.  These equations are representatives of a class of first order systems arising from fluid and electromagnetics.  Applications of the proposed work occur in, for example, the design of accelerator and beam control magnets, fusion devices, and electrical motor design.<br/><br/>Finite element methods based on negative norm least-squares principles provide a natural approach to the numerical solution of those problems.  The negative norm least-square methods have a number of attractive features.  Like mixed finite element methods, variables of most interest can be approximated directly instead of a posteriori.  However, least-squares methods are not subject to the inf-sup stability condition and hence the finite element spaces are selected based solely on approximation properties and computational cost.  The convergence of negative norm least-squares methods requires only a moderate amount of smoothness on the solution.  Moreover, the corresponding algebraic system is symmetric and positive definite and hence can be solved effectively by, e.g., the preconditioned conjugate gradient method.  The proposed methods will exploit both the mathematical structure of model problems and the computational features of negative norm least-squares principles.<br/>"
"9870399","Numerical Solution of Differential Equations in Mechanics","DMS","Gravity Theory, COMPUTATIONAL MATHEMATICS","07/15/1998","06/17/1998","Douglas Arnold","PA","Pennsylvania State Univ University Park","Standard Grant","Thomas W. Fogwell","01/31/2002","$200,000.00","","arnold@umn.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1244, 1271","9216, 9263, HPCC","$0.00","9870399 <br/>Arnold<br/><br/>The investigator will devise, improve, and analyze methods for the numerical simulation of complex physical phenomena modeled by partial differential equations.  Three major areas of application will be studied, each requiring special methods: computational relativity, certain important classes of differential equations arising from incompressible fluid flow and from electromagnetism, and linearly elastic plates.<br/><br/>In the area of computational relativity, the work is motivated by the search for gravitational radiation using the LIGO detector, presently under construction.  LIGO is the prime example of a new generation of gravitational wave detectors, and is being designed to detect gravity waves (which have hitherto escaped detection due to their small amplitude).  If the detected wave can be analyzed to determine the nature of the massive but distant astronomical event which gave birth to it (e.g., the spiraling coalescence of a pair of black holes), then LIGO will become mankind's first window on the universe that can ""see"" beyond the electromagnetic spectrum (light and radio signals).  The proposed project is to devise efficient algorithms to enable such analyses to be performed on high performance computers.  These algorithms are based on Einstein's equations underlying general relativity.  The investigator will both extend and apply already completed computer codes for the constraint equations, purely spatial partial differential equations arising from the Einstein equations, and will also study the problem of numerically solving the Einstein evolution equations.  This is highly interdisciplinary work, involving extensive collaboration between the investigator, a mathematician, and his group, and physicists and astronomers.<br/><br/>The second area of study concerns the developments of multigrid algorithms and supporting theory for solving certain sorts of differential equations which have hitherto resisted such approaches.  Multigrid algorithms, which exploit a decomposition of the desired solution into components on many different scales, are among the most efficient algorithms invented for solving many sorts of differential equations.  However for an important class of problems arising from incompressible continua and another group of problems arising from Maxwell's equations of electromagnetism, new multigrid approaches are required.<br/><br/>Finally the investigator will collaborate on a monograph on the theory of elastic plates, including modeling, analysis, and numerical simulation.  There has been extensive progress in these areas over the past decade, and the book will serve as both a reference for workers in the field and in the active field of elastic shell modeling, and as an introduction for researchers new to the area.<br/>"
"9800673","Partial Funding for the Fifth International Conference on Integral Methods in Science and Engineering (IMSE98)","DMS","COMPUTATIONAL MATHEMATICS, CONTROL, NETWORKS, & COMP INTE","10/01/1998","07/14/2000","Barbara Bertram","MI","Michigan Technological University","Standard Grant","Jong-Shi Pang","12/31/2000","$10,240.00","Amitabh Narain, Allan Struthers, Madhukar Vable, David Sikarskie","bertram@mtu.edu","1400 TOWNSEND DR","HOUGHTON","MI","499311200","9064871885","MPS","1271, 1518","0000, 9263, OTHR","$0.00","9800673<br/>Bertram<br/><br/>This project supports graduate student and junior researcher participation in the Fifth International Conference on Integral Methods in Science and Engineering (IMSE98) which will be held August 10-13, 1998 at Michigan Technological University, Houghton, Michigan.  <br/><br/>The invited speakers:<br/><br/>Gregory Beylkin (University of Colorado, Boulder, Colorado), Archie G. Gibson (University of New Mexico, Albuquerque, New Mexico), Glenn R. Ierley (Scripps Institute, San Diego, California), Sangtae Kim (University of Wisconsin, Madison, Wisconsin), M. Zuhair Nashed (University of Delaware, Newark, Delaware), Jean Claude Nedelec (Centre de Mathematiques Appliquees, Palaiseau, France), Brian Sleeman (University of Leeds, Leeds, United Kingdom),<br/><br/>Will discuss numerous rapidly evolving areas of Integral Methodology.  Since such techniques embrace a wide variety of scientific disciplines, conference participants will have many opportunities to broaden established research programs, as well as  obtain an introduction to a wide range of fields employing  integral methodologies.  Since this is truly an interdisciplinary meeting,  there will be many opportunities for technology transfer of state of the art integral methods to and between the different applied sciences and engineering.   In addition, this conference will provide the opportunity for young scientists to meet, listen to, converse with, and learn from more seasoned researchers.<br/><br/>"
"9707040","Linear and Nonlinear Multigrid Methods on Cache Based       Parallel and Serial Computers with Applications","DMS","COMPUTATIONAL MATHEMATICS, ADVANCED COMP RESEARCH PROGRAM","06/01/1998","05/19/1998","Craig Douglas","KY","University of Kentucky Research Foundation","Standard Grant","Michael Steuerwalt","05/31/2002","$120,000.00","","craig.c.douglas@gmail.com","500 S LIMESTONE","LEXINGTON","KY","405260001","8592579420","MPS","1271, 4080","9216, 9263, HPCC","$0.00","Douglas  9707040       The investigator begins a study of multigrid methods for  computers whose performance is highly dependent on the cache  utilization.  The project includes both algorithm development and  realizations in code.  For structured problems in two dimensions,  effective new algorithms can be devised.  For general,  unstructured problems in either two or three dimensions, this is  much harder and requires a completely different approach.  Two  approaches are planned.  One is based on localizing graph  connections of a sparse matrix associated with the grid based  problem.  A second is based on a software tool that re-orders the  computation at run time to use the cache efficiently.  In  addition, the investigator develops new nonlinear multigrid  algorithms that can robustly solve real applications.  A new  methodology is developed to coarsen adaptively refined grids for  problems in which current algorithms fail to converge.       Real world simulations of complex science and engineering  problems like climate, ocean, petroleum reservoir, and pollutant  tracking modeling require enormous amounts of computer time.  Computers today have separate memory modules that run at vastly  different speeds.  Normally, programs run at the speed of the  slowest memory in a computer.  The investigator examines how to  use the faster memory modules instead of the slowest memory for  the solvers needed to run complex problems much faster."
"9816951","Impulse Models for Fluid Motion with Flexible Boundaries","DMS","COMPUTATIONAL MATHEMATICS","09/15/1998","08/09/1999","Ricardo Cortez","LA","Tulane University","Standard Grant","Michael Steuerwalt","08/31/2002","$88,550.00","","rcortez@tulane.edu","6823 SAINT CHARLES AVE","NEW ORLEANS","LA","701185665","5048654000","MPS","1271","0000, 9263, OTHR","$0.00","Cortez<br/>9816951<br/><br/>The investigator develops new numerical methods for the solution of problems involving the interaction of flexible boundaries and the incompressible fluids in which they are immersed.  Typical applications of such problems are found in biology and physiology.  The approaches pursued include Lagrangian and Eulerian methods based on impulse variables, which combine elements from other numerical techniques such as vortex and projection methods.  A hybrid particle method is developed for high Reynolds number flows.  In this case the accumulated effect of immersed boundary forces is accounted for through the evolution of impulse variables.  The viscous effects are modeled using a deterministic method for the diffusion of vorticity using vortex monopoles.  Finite-difference grid-based methods are also developed for the solution of the these problems in moderate Reynolds number flows.  Making use of the Lagrangian representation of the flexible boundaries, the investigator and his collaborators use ideas from the Lagrangian impulse method to describe the evolution of the immersed boundaries within the framework of the grid solution.  The researchers highlight improvements to existing numerical methods for this type of problems.<br/><br/>The numerical solution of fluid flow problems with thin flexible moving boundaries is motivated partly by the wide range of potential applications in biology and physiology.  For example, the membranes of the inner ear, the walls of the heart or lungs, muscle tissue, swimming jellyfish and eels can be modeled as thin membranes embedded in a fluid.  These examples are part of everyday life and yet many of their technical aspects are not fully understood.  The development and availability of reliable numerical simulations that could help our understanding of such commonly occurring natural phenomena is of great importance.  Numerical methods can be used to conduct improved computer simulations of new heart valve designs; computer simulations of collapsible tubes with a fluid inside, such as arteries weakened by disease, can be studied; efficiency in swimming motions of a single organism as well as the apparently synchronized patterns of groups of animals can be analyzed; new propulsion mechanisms can be devised.  Undulatory motion, for example, is present in organisms of a wide range of sizes because it is the preferred swimming mode of spermatozoa as well as eels and snakes.  The mathematical solution of such problems lies at the crossroads of natural sciences, mathematical modeling and scientific computing.<br/>"
"9806389","Pseudo-Boolean Functions: Representations and Optimization","DMS","COMPUTATIONAL MATHEMATICS","09/01/1998","08/20/1998","Peter Hammer","NJ","Rutgers University New Brunswick","Standard Grant","John C. Strikwerda","08/31/2001","$175,000.00","Endre Boros","hammer@rutcor.rutgers.edu","3 RUTGERS PLZ","NEW BRUNSWICK","NJ","089018559","8489320150","MPS","1271","0000, 9263, OTHR","$0.00","9806389<br/>Peter L. Hammer<br/><br/>Numerous problems in area as diverse as VLSI design, game theory, artificial intelligence, neural networks, operations research, statistics, reliability, and finance can be modeled by using set functions, i.e., mappings of the subsets of a finite set into the reals.  It was noticed in the mid-60's by the PI that set functions can be viewed as ""pseudo-Boolean"" functions, i.e., real valued functions with 0-1 variables, and can be represented as multilinear polynomials.  It was noticed along the years that beside their polynomial representation, pseudo-Boolean functions admit also other algebraic representations, e.g., as additive posiforms, as logical posiforms, etc.  It also turns out that various types of applications may lead naturally to various types of representations.  Also, it can be seen that the solution of some of the most important problems concerning pseudo-Boolean problems (finding a global optimum, finding a local optimum, approximating the optimum, finding a good approximation of the functions, finding a good majorant or minorant of the function) depends heavily on the particular representation used.  In this proposal the investigators will deal mostly with the optimization of pseudo-Boolean functions with a heavy emphasis on their representation.  They will consider separately various problems of optimization, majorization, approximation, etc., for pseudo-Boolean functions given in polynomial form, in additive posiform, as well as in disjunctive posiform representation.  Beside investigations concerning the algebraic problems of presentation, the investigators will lay heavy emphasis on the computational aspects of the problem, and plan to elaborate specialized algorithms for exact and heuristic optimization problems of pseudo- Boolean functions in various forms, on local optimization, and on the detection of efficient methods for particular classes of problems.<br/><br/>In numerous real-life situations, optimization problems have to be solved involving decisions and selections between various alternatives.  When, for example, locations have to be found for cellular ground stations, emergency facilities, warehouses, etc., the usual mathematical optimization procedures cannot be applied blindly, since they may recommend the location of say half a unit in one place and the other half in another.  Therefore, new mathematical techniques are needed to make sure that the solutions can only involve locating either an entire unit in one place or no part of it in that place.  Similar problems occur when selections are made between projects to be undertaken, people or equipment to be assigned to various tasks, or much more complex situations where a large company (e.g. an airline) has to assign its equipment (e.g. aircrafts) to its various activities (e.g. flights).  In such situations, the mathematical formulation of the problem requires the use of variables which can only take the values of 0 or 1.  In spite of its apparent simplicity, this requirement can cause major mathematical and computational difficulties.  This project deals to a large extent with the problem of finding various mathematical models describing situations like the above ones and developing optimization techniques for handling them.  A substantial amount of computational experimentation is part of the project and will complement the mathematical developments.<br/>"
"9805495","Interior Point Methods for Nonconvex Nonlinear Programming","DMS","COMPUTATIONAL MATHEMATICS","08/01/1998","07/15/1998","David Shanno","NJ","Rutgers University New Brunswick","Standard Grant","John C. Strikwerda","07/31/2001","$94,500.00","","shanno@rutcor.rutgers.edu","3 RUTGERS PLZ","NEW BRUNSWICK","NJ","089018559","8489320150","MPS","1271","0000, 9263, OTHR","$0.00","  DMS-9805495    David F. Shanno  Interior Point Methods for Nonconvex Nonlinear Programming      Abstract:      The research is concerned with studying logarithmic barrier methods for  nonconvex nonlinear programming. The problem studied is the problem of  minimizing a nonlinear objective function subject to nonlinear inequality  constraints. Topics to be studied include merit functions, trust regions,  and matrix modification methods for nonconvex problems. A topic of extensive  study will be higher order methods for solving the nonlinear system of  equations arising from the first order conditions for the problem, with  particular emphasis on extending Mehrotra's predictor-corrector method to  nonconvex problems. The general nonlinear programming problem, which has  equality contraints, bounds and ranges as well as inequality constraints   will be adapted so as to be solvable with the algorithms developed. Careful  study will be made of the problem of determining infeasiblility and   unboundedness for nonconvex nonlinear programs. Special algorithms will be  developed for problems where second derivatives are not available. All   developed algorithms will be coded and extensively tested.         Nonlinear programming problems arise in a wide variety of applications  drawn from a broad spectrum of engineering and science problems, statistics  problems, economics problems, and logistics problems to name a few of the   many areas where such problems are common. For example, drawing inference from  data bases is a statistics problem that often requires the minimization  of a nonlinear likelihood function subject to parametric constraints. This  problem becomes particularly difficult when the dtabase is very large. The  proposed research will develop methods for these nonlinear problems that are  akin to the interior point methods that have proved so efficient for very  large scale linear problems. These methods are also highly applicable to  solving nonlinear partial differential equations with n onlinear boundary  conditions, which are used in everything from aircraft design to design  of structures such as bridges to estimating the reserves in an underground  groundwater or oil reserve, as a few examples of the myriad applications. Part  of the project will be to collect as broad a problem set of real applications  as possible to adapt the algorithms to be efficient for these problems, and  to demonstrate the use of the algoritms across the widest possible spectrum  of applications. In all cases, the the algorithms will be designed to   solve very large problems efficiently, as these methods are proving extremely  efficient for large problems on high performance computers."
"9803442","Numerical Methods for Conservation Laws","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, ADVANCED COMP RESEARCH PROGRAM","07/01/1998","06/11/1998","Randall LeVeque","WA","University of Washington","Standard Grant","Deborah Lockhart","12/31/2001","$244,455.00","","rjl@uw.edu","4333 BROOKLYN AVE NE","SEATTLE","WA","981950001","2065434043","MPS","1266, 1271, 4080","9216, 9263, HPCC","$0.00","Hyperbolic systems of conservation laws arise in many problems where the<br/>conservation of physical quantities such a mass, momentum, and energy are<br/>modeled. These equations must typically be solved by approximate numerical<br/>methods.  Discontinuities in the data and/or solution (e.g. shock waves)<br/>cause difficulties in developing accurate and stable methods. <br/><br/>This proposal concerns the development of high-resolution methods and their<br/>implementation as software that can be widely used in solving problems<br/>that arise in many different fields.  The P.I. has been actively<br/>involved in developing the CLAWPACK and AMRCLAW software for<br/>multi-dimensional hyperbolic systems.  This software is freely<br/>available and allows students and researchers studying a wide range of<br/>phenomena to use the technology of high-resolution methods and adaptive<br/>mesh refinement.  This software will be further developed and used to<br/>explore a number of particular applications in science and<br/>engineering.  One application concerns computing acoustic or elastic<br/>waves in heterogeneous media.  Such problems often arise in geophysics<br/>and materials science, for example.  Another application is to<br/>numerical relativity, where there is interest in simulating<br/>gravitational waves that may soon be detectable by astronomers.<br/>This can be accomplished by using a hyperbolic formulation of the Einstein<br/>equations.<br/><br/><br/>"
"9806358","Least-Squares Finite Element Methods and Optimization-Based Domain Decomposition Methods for Partial Differential       Equations","DMS","COMPUTATIONAL MATHEMATICS, CENTRAL & EASTERN EUROPE PROGR","07/15/1998","05/21/1999","Max Gunzburger","IA","Iowa State University","Standard Grant","Thomas W. Fogwell","06/30/2002","$102,634.00","","gunzburg@fsu.edu","1350 BEARDSHEAR HALL","AMES","IA","500112103","5152945225","MPS","1271, 5979","0000, 5973, 9216, 9263, HPCC, OTHR","$0.00","9806358  Gunzburger      In the last few years, the engineering and mathematical communities have shown  increasing interest in least-squares finite element methods for solving a  variety of problems in fluids, electromagnetics, elasticity, and other  applications. The great promise of least-squares methods arises from the fact that, when compared to other discretization schemes, they lead to discrete problems that are much easier to solve on a computer. In the past the PI has studied numerous facets of least-squares finite element methods. These include: the use of mesh-dependent weights in least-squares functionals in order to achieve optimally accuracy, the solution of practical implementation issues that needed to be addressed in order to make these methods practical and competitive, and the application of these methods to problems with discontinuous coefficients that arise, e.g., from inhomogeneous media properties. The PI plans to apply least-squares finite element methodologies to optimization and control problems and to develop, analyze, and implement domain decomposition algorithms in the least-squares setting.    Domain decomposition methods have attracted even more attention due to their  usefulness in a parallel processing environment. The PI has developed novel  non-overlapping domain decomposition methods based on optimization or optimal  control ideas that posses numerous desirable features, the most important  perhaps being that they are easily extended to nonlinear problems. The PI plans to introduce preconditioners to speed-up the performance of the methods, to look at different functionals and optimization parameters on which to base the decomposition into subdomains so that again more efficient algorithms are obtained, to apply and analyze algorithms to the solution of optimization problems for partial differential equations, to develop  algorithms for time-dependent problems, and to implement  algorithms on parallel computers consisting of clusters of Pentium processors."
"9803226","3D Scanning: Acquiring and Modeling Surface Properties","DMS","STATISTICS, COMPUTATIONAL MATHEMATICS, ADVANCED COMP RESEARCH PROGRAM","08/15/1998","06/08/2000","Werner Stuetzle","WA","University of Washington","Continuing Grant","John Stufken","07/31/2002","$406,473.00","Thomas Duchamp, Brian Curless","wxs@stat.washington.edu","4333 BROOKLYN AVE NE","SEATTLE","WA","981950001","2065434043","MPS","1269, 1271, 4080","0000, 9146, 9216, 9263, HPCC, MANU, OTHR","$0.00","-----------------------------------------------------------------------  Proposal Number: DMS 9803226  PI:              Werner Stuetzle, Brian Curless, Tom Duchamp  Institution:     University of Washington  Project:         3D Scanning: Acquiring and Modeling Surface Properties    Abstract:    3D scanning is the inverse of computer aided manufacturing: given a   physical object, such as a clay model of a car, a sculpture, a chair,   or a house, create an electronic representation capturing its shape  and appearance.  3D scanning is similar in principle to a number of  other important technologies (like digital audio, digital photography,  document scanning, and digital video) that quickly, accurately, and  cheaply record useful aspects of physical reality.  These technologies  have had an enormous impact, primarily because electronic  representations can be used in ways the original physical objects  cannot. For example, they can be stored in, searched for, and  retrieved from databases, transmitted electronically over long  distances, manipulated and edited in software, and used as templates  for making electronic or physical copies.  Research in 3D scanning  promises to have a similar impact on a number of areas, including  the Federal Strategic Areas of high performance communication, civil  infrastructure, and manufacturing, as well as virtual museums,  entertainment, and product marketing.    This research group and others have made significant progress in  capturing, modeling, and displaying geometric shape.  The task of   acquiring and computing surface properties such as appearance,   however, has received far less attention.  The research effort in this   project focuses on three aspects of the problem: (i) texturing, bump   mapping and selective refinement of multiresolution meshes, (ii)   capturing, modeling and displaying radiance (color as a function of   position and direction), and (iii) generally estimating functions over   surfaces."
"9805621","Efficient Numerical Methods for Unsteady Viscous            Incompressible Flows","DMS","COMPUTATIONAL MATHEMATICS","07/15/1998","07/16/1998","Jian-Guo Liu","MD","University of Maryland, College Park","Standard Grant","John C. Strikwerda","06/30/2001","$96,000.00","","jliu@phy.duke.edu","3112 LEE BLDG 7809 REGENTS DR","College Park","MD","207420001","3014056269","MPS","1271","0000, 9215, 9263, HPCC, OTHR","$0.00","DMS-9805621       EFFICIENT NUMERICAL METHODS FOR VISCOUS INCOMPRESSIBLE FLOWS                             Jian-Guo Liu                            Project Summary      This project will focus on continuing the development of efficient,  accurate, high order finite difference and finite element methods for  the unsteady viscous incompressible Navier-Stokes equations (NSE),  with emphasis on finding efficient time stepping procedures and new  formulations of the equations better suited to numerical computation.  Some practical aspects of the methods, including extensions to flows  in general 2D and 3D domains, and applications to more challenging  physical problems, will be investigated.  In the vorticity  formulation, a new time-stepping procedure is used for high Reynolds  number flows.  For such flows the convection and viscous terms are  treated explicitly. The stream function, and hence the velocity, is  then evaluated from the vorticity via the kinematic equation.  The key  to the efficiency of the new time-stepping procedure is that the value  of the vorticity on the boundary is obtained explicitly from the steam  function without any iteration.  This eliminates some traditional  difficulties associated with the vorticity formulation.  More akin to  the primitive variable formulation, the investigator is using a new  formulation of the NSE in the impulse density variable which differs  from the velocity by a gauge transformation. The gauge freedom enables  one to assign simple and specific boundary conditions for both the  impulse and gauge fields, thus eliminating some traditional  difficulties such as the pressure boundary condition.      This new class of efficient numerical methods has already been used  to study such real world problems as the investigation of the  mechanism of drag reduction on airfoils at high velocities, as well as  the development of severe storms in tropical latitudes.  These  methods provide an important tool that allow scientists and engineers  to study related  fluid problems in manufacturing and industry that  were previous unsolvable with currently available numerical  techniques.  They represent a significant step forward in the  efficient computation of solutions to such problems, and are naturally  suited for implementation on high performance massively parallel  computer architectures."
"9805748","Computational Error Estimation and Adaptive Error Control   for Numerical Solutions of Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","07/15/1998","08/04/2000","Donald Estep","GA","Georgia Tech Research Corporation","Standard Grant","Jong-Shi Pang","06/30/2001","$73,780.00","","donald.estep@colostate.edu","926 DALNEY ST NW","ATLANTA","GA","30332","4048944819","MPS","1271","0000, 9216, 9263, HPCC, OTHR","$0.00","9805748  Estep    Systems of quasi-linear reaction-diffusion-convection differential   equations have widespread importance in  modeling physical phenomena in   such diverse fields as biology, chemistry, metallurgy, and combustion.   Some examples are shear flow in fluids with temperature dependent   viscosity; Hodgkin-Huxley type models of nerve bundles; and models of   the spread of disease in populations.  Because such problems are   typically highly nonlinear and exhibit complex behavior, numerical   solutions of the differential equations have become the main tool for   investigation of their properties.  However, these same qualities give   rise to some fundamental scientific questions: How can reliable and   accurate estimates of the accuracy of information computed from   numerical solutions be obtained and how can a desired range of accuracy   be achieved?  The project will address these question on three levels: theoretical analysis; implementation in code;   and application to practical problems.      The proposed approach is based on developing an a posteriori theory of error   estimation in which the error is estimated in terms of quantities   depending on the numerical solution that can be computed or   approximated. The theory will then be used to develop methods of   computational error estimation and adaptive error control. The PI will also analyze the reliability and accuracy of the  computational error estimates and, because stability has a direct impact on the accuracy of numerical solutions, the preservation of stability properties of the differential equation under discretization. Practical goals of this project include; a  publicly-accessible code for solving general reaction-diffusion problems using computational error estimation and adaptive error control, applications to the practical models like   those mentioned above,  and an educational component in the form of a   textbook on the finite element method for the basic nonlinear models of   science."
"9806408","Experimental Low-Dimensional Geometry and Topology","DMS","COMPUTATIONAL MATHEMATICS","09/15/1998","08/12/1998","Jonathan Poritz","DC","Georgetown University","Standard Grant","Junping Wang","08/31/2001","$89,950.00","","jonathan.poritz@gmail.com","MAIN CAMPUS","WASHINGTON","DC","200570001","2026250100","MPS","1271","0000, 9229, 9263, OTHR","$0.00","Poritz<br/>9806408<br/><br/>The principal investigator employs computer visualization tools to aid in the study of a number of questions in low-dimensional differential and algebraic geometry and topology.  In particular, these questions have to do with fundamental domains for discrete groups of isometries of various three-dimensional geometries, moduli spaces of polygons in each of the three-dimensional space forms, and direct constructions of families of compactifications of semisimple Lie groups of low dimension.  Interactive software has been developed to explore fundamental domains on the sphere at infinity for cyclic groups of isometries of three-dimensional hyperbolic space and this is extended to the interior of hyperbolic space, other groups and other geometries.  Moduli spaces of polygons are investigated to determine aspects of their own geometry and because of their relationship to moduli spaces of vector bundles over punctured Riemann surfaces and some symplectic and geometric-invariant theory quotients.  Images have also been made of moduli spaces of certain algebraic compactifications of the group of isometries of the hyperbolic disk and further images are generated of moduli spaces of other algebraic compactifications as well as of the compactifications themselves.  An important component of this project is the direct involvement of undergraduate students:  while the mathematics is of various levels of abstraction, the computer tasks are accessible to serious students and provide them with an unusual opportunity for hands-on involvement in current mathematical research.<br/><br/>The fantastic interactive three-dimensional graphics that can be seen in many of today's commercial computer games are the result of the phenomenal advances that have occurred in recent years in the sophistication of computer software and the speed and power of computer hardware.  But in a larger sense they can be attributed to the increase of engineering knowledge based on hard science and, ultimately, on deep mathematical understanding.  It is thus somewhat surprising that these computational and graphics tools have been used very little in pure mathematical research.  The principal investigator uses interactive computer visualization to perform mathematical experiments in a variety of different fields that all have some component relating to two-, three- or four-dimensional geometry; as this is pure mathematics, experimental evidence must then be justified in a purely abstract setting.  An important part of this project is the direct involvement of undergraduate students: here again it is possible to take advantage of the very high level computer abilities that many undergraduates now possess to create the software that drives the mathematical explorations, while at the same time giving these undergraduates the extremely rare opportunity to have immediate experience of current mathematical research.<br/><br/>"
"9714380","Statistical Methods in Computational Modeling and Virtual   Experiments","DMS","STATISTICS, COMPUTATIONAL MATHEMATICS, THEORY OF COMPUTING","06/01/1998","09/28/1999","John Tucker","DC","National Academy of Sciences","Standard Grant","Joseph M. Rosenblatt","11/30/2000","$22,000.00","","JTucker@NAS.edu","2101 CONSTITUTION AVE NW","WASHINGTON","DC","204180007","2023342254","MPS","1269, 1271, 2860","0000, 9216, 9263, HPCC, OTHR","$0.00","PI: John Tucker  Proposal Number: DMS 9714380  Project: Statistical Methods in Computational Modeling and            Virtual Experiments    Abstract:    The Committee on Applied and Theoretical Statistics (CATS)  will convene a multidisciplinary study panel on statistical  methods in computational modeling and virtual experiments.  The panel will recommend sound methods for identifying and   quantifying uncertainties that arise in simulation experiments.  The panel will develop recommendations for improved and, where  necessary, new statistical methods and data analysis techniques  for use in simulation modeling and virtual experiments.  It will  also recommend appropriate statistical methods to assist  practitioners in their use of experimental data when validating  simulation models or assessing model fit and predictive   performance. These recommendations will address modeling and  simulation limitations associated with ever increasingly complex  systems. The panel's report will provide examples to illustrate  the complexity of evaluating model combinations that arise from  varying assumptions, parameters, and initial conditions within   the models, will point out possible approaches for addressing  those complexities from existing experimental design techniques,  and will highlight areas needing further research. Experts may   be consulted from the communities concerned with computer  simulation, discrete events systems, and dynamic systems  modeling, and any other scientists, researchers, or engineers  with significant technology or methodology to contribute.    A National Research Council panel of experts will examine the   state-of-the-art for statistical methods used in computer  simulation and modeling, and computational experimentation. This  is needed because of an ever-growing dependence upon these kinds  of simulations and ""virtual"" experiments in designing and  evaluating such complicated devices and systems as semiconductors,  automobiles, aircraft, spacecraft, or in very complex  application  areas such as transportation networks, government intelligence, and  battlefield scenarios. The study will address how modeling and  simulation tools can be developed with the robustness and  reliability to handle the demands of emerging intelligence,  domestic, and military technology. It will also look at limitations  on modeling and simulation with respect to these increasingly   complex systems."
"9807491","A Posteriori Error Estimates for Discontinuous Finite Element Methods Applied to Problems in Geosciences and Medicine","DMS","COMPUTATIONAL MATHEMATICS, Hydrologic Sciences, Engineering of Biomed Systems","10/01/1998","08/13/2000","Bernardo Cockburn","MN","University of Minnesota-Twin Cities","Continuing Grant","Michael Steuerwalt","09/30/2001","$180,225.00","","cockburn@math.umn.edu","200 OAK ST SE","MINNEAPOLIS","MN","554552009","6126245599","MPS","1271, 1579, 5345","1339, 9183, 9198, 9216, 9263, BIOT, EGCH, HPCC","$0.00","Cockburn<br/>      The investigator and his colleague Bernardo Cockburn, in a collaborative project, develop adaptive numerical methods for problems with moving interfaces and long-time dynamics.  These problems incorporate multiple temporal and spatial scales.  Finite element methods have long been used for solving partial differential equations.  Recently, methods using discontinuous approximating spaces have become popular, especially for nonsteady convection-diffusion problems.  Two such methods are the local discontinuous Galerkin method (LDG) and the Godunov-mixed method (GMM), developed by the investigators and their collaborators.  These methods have the advantage that they are based on local conservation and approximate shocks and sharp gradients with no spurious oscillations, which is important in many convection-diffusion applications.  They also lend themselves to parallel computation.  Both methods have been implemented computationally, and a priori error estimates have been derived; however, no adaptive strategies based on these methods have been developed.  It has long been recognized that adapting the finite element mesh and time-step during a simulation is desirable for obtaining an accurate solution.  In order to successfully adapt the mesh to guarantee that the actual error is below a given tolerance, it is essential to develop a posteriori error estimates that measure the actual error as a funtion of the mesh, time step and the computed solution.  While a substantial literature exists for such estimates for steady problems and conforming finite element spaces, little research has been done for nonsteady problems and discontinuous methods. In this project, the investigators and their colleagues develop a posteriori estimates for the LDG and GMM methods for convection-diffusion equations, with emphasis on three important applications: shallow water flow, chemically reactive transport in porous media and surface water, and the modeling of brain tumor cell growth and treatment.  The basis for these estimates is the so-called approximate adjoint equation methodology; however, other ad-hoc methods which may potentially be more efficient are also investigated.  These estimates are novel for the applications as well as the numerical methods.<br/><br/>      The applications of interest are important to industry, government laboratories and departments, and state agencies. Modeling of flow patterns in shallow water systems (e.g. bays and estuaries) is important for understanding, for instance, the environmental impacts of oil spills and the economic impacts of dredging, and can also be useful in tracking storm surges during hurricanes and other extreme weather events.  Modeling of transport of chemical species in groundwater and surface water is important for understanding waste disposal and pollution remediation.  The modeling of brain tumors can be useful in predicting tumor growth and examining potential treatments. These applications, though varied, share common mathematical characteristics and can utilize similar numerical simulation methodologies.  Lacking for these applications and methodologies are sound, mathematically based tools for controlling and adapting the simulations to meet specific accuracy criteria of interest to the user; that is, criteria which can be used to determine whether a numerical simulation actually reflects physical reality.  The goals of this project are to develop such criteria for making the simulations efficient, accurate and physically realistic, and to train future researchers in the underlying mathematics, computational science and multidisciplinary aspects of the applications.  <br/>"
"9729251","An International Conference on Turbulence: Challenges for   the 21st Century","DMS","COMPUTATIONAL MATHEMATICS","04/15/1998","04/03/1998","Katepalli Sreenivasan","CT","Yale University","Standard Grant","John C. Strikwerda","09/30/1998","$14,000.00","","katepalli.sreenivasan@nyu.edu","105 WALL ST","NEW HAVEN","CT","065118917","2037854689","MPS","1271","0000, 9263, OTHR","$0.00","Sreenivasan  DMS9729251    ""Turbulence: Challenges for the 21st Century""  An International Conference        Wind gusts and roaring fires, tornadoes and hurricanes, flows around    ships and aircraft, flow through pipelines, pumps, turbomachinery, as    well as arteries, are some examples of turbulent motion of fluids.    Our ability to describe and predict turbulent phenomena strongly    impacts such diverse fields as environmental pollution, weather    prediction, commercial chemical processes, aircraft and ship design,    ocean dynamics, and astrophysics. Turbulence is thus a subject of    great importance and demands serious attention. Yet, it is one of the    poorly understood subjects, despite about hundred years of serious    research.    Why is this so? It is trite but true to say that it is a very    difficult subject. The difficulties stem from the fundamentally    complex dynamical characteristics of turbulence including, for    example, strong nonlinearity, the simultaneous presence of a large    number of interacting degrees of freedom across a wide range of    spatial scales, marked departure from statistical equilibrium, and so    forth. More than $10^{18}$ degrees of freedom can be excited in    turbulent flows typical of atmospheric phenomena. This makes full    computer simulation of such flows impractical. Experimental studies    have also suffered because of approximations such as Taylor's    hypothesis and the use of one-dimensional surrogates for    three-dimensional quantities.    A confluence of important advances has occurred in the last decade:    new experimental tools have emerged, and enabled direct measurement    of spatio-temporal fields of turbulence, and new parameter ranges are    being explored in experiments by harnessing air at high pressures or    unconventional fluids such as helium. Direct numerical simulation has    become a powerful tool for the study of turbulence. Recent    improvements in computer memory and speed, especially the    availability of we ll-integrated massively parallel machines, have    made computer simulation a useful complement to laboratory    experiments. In addition, greater insights into the behavior of    nonlinear partial differential equations are being acquired rapidly.    Together, these advances have had a qualitative impact on the    understanding of turbulence dynamics, and on the development of    working models in engineering practice. Particular progress has been    achieved in the case of passive admixtures (such as dye, water vapor,    pollutants which are mixed by turbulence, but do not feed back to the    turbulent motion itself). For example, theoretical predictions have    been made for anomalous scaling in a class of passive admixtures.    These predictions are in turn supported by direct numerical    simulation.    To assess these recent advances and define, where possible, new    directions for the field, a conference is being organized at Los    Alamos between the 25th and 28th of May 1998. The conference is being    supported by the National Science Foundation and the Los Alamos    National Laboratory. The specific goal of the conference is to    provide an opportunity for scientists world-wide to communicate    recent critical advances in fundamental studies and engineering    applications of fluid turbulence, and to foster further development    of this broad field of nonlinear science."
"9816592","Ninth Copper Mountain Conference On Multigrid Methods","DMS","COMPUTATIONAL MATHEMATICS","10/01/1998","09/18/1998","Steve McCormick","AZ","Front Range Scientific Computations, Inc.","Standard Grant","Michael Steuerwalt","09/30/2002","$40,000.00","Thomas Manteuffel","stevem@colorado.edu","8865 E CALLE BUENA VIS","SCOTTSDALE","AZ","852558364","3035541232","MPS","1271","0000, 9218, 9263, HPCC, OTHR","$0.00","McCormick<br/>9816592<br/><br/>The investigator and his colleagues organize a series of annual Copper Mountain Conferences.  The subject of these meetings alternates between multigrid methods in odd-numbered years and iterative methods in even-numbered years.  The Copper Mountain Conferences provide a forum for the exchange of ideas in these two closely related fields.  The program for a conference in this series consists of tutorials, invited lectures, and contributed papers, as well as time for scientific interaction among the participants.  Topics of emphasis for the conferences include advanced architectures, algebraic-type methods, and nonsymmetric linear systems.  This grant provides support for students to participate in the conferences.<br/><br/>The mathematical description of real-world problems leads inevitably to equations to solve.  Many times the equations are nonlinear ones, arising because the underlying problem is nonlinear.  Often, however, the original problem is linear and the mathematical equations are too.  Such problems arise in all areas of science and technology, and are of special interest in biology, materials, environmental studies, and manufacturing.  Progress in these areas requires solution of more comprehensive modeling equations --- such models are usually more nonlinear than simpler models ---, or more accurate solution of existing models --- increasing the size of the numerical problem to be solved.  Many problems lead to equations that are not symmetric; computational methods for such problems offer special difficulties.  Numerical methods for solving a differential equation usually begin by imposing a grid on the region where the equation holds.  From the differential equation, algebraic equations are then developed; their solution represents the solution of the differential equation.  The accuracy of the approximate solution commonly is measured by the fineness of the grid.  Multigrid methods are numerical methods for solving partial differential equations that systematically exploit the relationship between approximate solutions on different grids to arrive at a solution whose accuracy is consistent with the finest grid but for considerably less work.  The methods are often dramatically more efficient than others.  The conferences address advances in iterative methods and in multigrid methods to deal with larger numerical systems, nonsymmetric and nonlinear systems, and the use of multiprocessor computers.  The methods are of great practical import in engineering, manufacturing, materials, physics, and fluid dynamics.  This project supports student participants at the Copper Mountain conferences on multigrid methods and on iterative methods.  The students present a talk on their research in the regular sessions of the conference.  The primary objective here is to encourage student participation in these rapidly evolving areas, and to provide an excellent opportunity for these students to demonstrate their new results, to learn more about the field from its experts, and to become a more integral part of the discipline.  Supporting student participation is critical for developing the next generation of scientists and engineers.<br/><br/>"
"9874015","OPAAL:  Optimized Meshless Algorithms for Seamless Integration of CAD, Simulation and Design","DMS","OFFICE OF MULTIDISCIPLINARY AC, INFRASTRUCTURE PROGRAM, COMPUTATIONAL MATHEMATICS, , , ","10/01/1998","02/28/2002","Weimin Han","IA","University of Iowa","Continuing Grant","Lloyd E. Douglas","09/30/2002","$1,600,169.00","Jiun-Shyan Chen, David Stewart, Kyung Choi, Suely Oliveira","weimin-han@uiowa.edu","105 JESSUP HALL","IOWA CITY","IA","522421316","3193352123","MPS","1253, 1260, 1271, X091, X573, Y614","0000, 9263, OTHR","$0.00","A major bottleneck in integration of finite element or finite difference-based Computer Aided Engineering (CAE) tools with industrial Computer Aided Design (CAD) and Computer Aided Manufacturing (CAM) tools is the generation of well-shaped meshes that are consistent with complex CAD models and which provide computational accuracy and efficiency of numerical solutions, particularly for nonlinear simulation and design of manufacturing processes. A meshless-based numerical method is planned to provide seamless integration through CAD geometry, simulation, and shape design optimization. The method can be directly linked to CAD geometries since the shape/interpolation functions in the meshless method are formulated independent of the background integration zone. The meshless method will provide a higher rate of convergence and alleviate many numerical difficulties with respect to mesh distortion and moving continuities encountered in conventional finite element methods. A meshless formulation for linear and nonlinear problems involving elastic and inelastic materials and contact conditions will be developed. Efficient computable error estimates will be derived for the meshless formulation. Nodal integration methods will be formulated to enhance efficiency, and adaptive meshless methods will be developed for controlling accuracy and efficiency in large deformation problems. Development and implementation of the meshless methods will be accomplished using scalable and portable high-performance algorithms optimized for use in parallel processor computer environments. New, fast graph partitioning techniques and hierarchical methods for subdividing the domain will be used to gain maximum benefits in computational speed and efficiency from parallel processor computers. A meshless shape design sensitivity analysis method that exploits the CAD-linked geometries will be developed for rapid, robust design.<br/><br/>The objective of the planned research is to achieve technology solutions that promote seamless  and substantive interaction between diverse design and engineering analysis disciplines throughout the production process, from concept development to manufacturing. The technology developed under this effort will remove major impediments to comprehensive collaboration between product designers and engineers by maintaining a high degree of coherence between CAD, CAE and CAM modeling and simulation, as well as by significantly enhancing the speed and relevance of design information which designers and engineers exchange during all stages of the product development process. Achieving the meshless-based integration of CAD, engineering simulation, and design will have substantial positive impact with respect to cost reduction, mature design development, and reduced time-to-market by enabling more extensive use of accurate and reliable simulation-based engineering and design methods in lieu of costly and time-consuming prototype design, test, and evaluation. The application of the meshless technology is also designed to take maximum advantage of high-performance computer capabilities that are in widespread use in industry.<br/> <br/>The research program to be carried out under this effort will expedite validation of meshless methods and technology transfer to industry. A partnership with Ford Motor Company has been established under which Ford's Research Laboratory will commit to an open exchange of data and expertise, as well as personnel resources for testing and validating meshless methods and their implementation on high performance computer platforms. Planned internship programs, graduate and undergraduate student participation, academic seminars, creation of new academic courses, reports and publications, and an international workshop will provide a range of options for practical and effective dissemination of the results and technical accomplishments of this effort.<br/><br/>Funding for this activity will be provided by the Division of Mathematical Sciences, the MPS Office of Multidisciplinary Activities, and by DARPA.<br/>"
"9805518","Computational Modeling of Platelet Aggregation and Coagulation and Development of Software for Biofluid Dynamics Problems","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, Engineering of Biomed Systems","09/15/1998","09/05/2002","Aaron Fogelson","UT","University of Utah","Standard Grant","Michael Steuerwalt","08/31/2003","$363,685.00","","fogelson@math.utah.edu","201 PRESIDENTS CIR","SALT LAKE CITY","UT","841129049","8015816903","MPS","1266, 1271, 5345","0000, 1339, 9183, 9216, 9263, BIOT, HPCC, OTHR","$0.00","Fogelson<br/>9805518<br/>     The investigator undertakes modeling and computational<br/>simulation of platelet aggregation and coagulation.  These are<br/>the components of normal blood clotting and of the<br/>life-threatening blood clots associated with vascular disease and<br/>with the use of cardiovascular prostheses.  The investigator and<br/>coworkers continue to explore and refine their models of platelet<br/>aggregation in small and large diameter vessels; continue<br/>development of models of coagulation including the effects of<br/>flow, transport, and surface reactions; and integrate the<br/>platelet aggregation and coagulation models to form a more<br/>comprehensive model of the hemostatic and thrombotic processes.<br/>These models use coupled systems of nonlinear partial and<br/>ordinary differential equations to describe interactions between<br/>the blood's fluid dynamics, the transport of platelets and<br/>chemicals in the blood plasma, the mechanics and chemistry of<br/>developing aggregates, and the solution-phase and surface-bound<br/>biochemistry of the coagulation process.  The models present<br/>substantial computational challenges that require development and<br/>use of state-of-the-art numerical methods for their solution.<br/>These include immersed boundary methods for fluid-material<br/>interactions, high-resolution finite-difference methods combined<br/>with Fourier-collocation spectral methods, immersed-interface<br/>methods for handling transport in regions of complex geometry,<br/>and parallel computation.  This work involves extensive<br/>comparisons between computational results and laboratory<br/>experiments and is aided by collaboration with leading experts on<br/>flow and thrombosis.  The proposal is also concerned with<br/>developing state-of-the-art parallel computational methods for<br/>simulating biofluid dynamic flows like those involved in<br/>aggregation and coagulation, and with including these<br/>computational tools in a powerful and easy-to-use problem solving<br/>environment that facilitates solving a wide range of complex<br/>biofluid dynamic problems.<br/>     Thrombosis, which is the formation of blood clots within<br/>vessels of the circulatory system, is the proximal cause of most<br/>heart attacks and of other severe cardiovascular problems such as<br/>ischemia and angina.  It is also a major problem associated with<br/>the use of blood-contacting prostheses such as mechanical heart<br/>valves.  The process by which these blood clots form is very<br/>complex and involves many dynamic, sometimes competing, sometimes<br/>mutually-reinforcing, biophysical and biochemical processes.  A<br/>major part of this project involves developing powerful<br/>mathematical and computational tools for studying this complex<br/>process, and using these tools to probe the factors that effect<br/>the location, extent, and speed of formation of thrombi.<br/>Computational modeling complements traditional experimental<br/>approaches and provides a way to simulate complex dynamic events,<br/>like the dynamic interactions among fluid, blood cells, clotting<br/>factors, and blood vessel or prosthesis surface that lead to<br/>thrombosis, that are beyond the reach of current laboratory<br/>techniques.  Such simulations can give new insights into the<br/>basic mechanisms that control this important biological process,<br/>and can ultimately help in the more rational design of<br/>therapeutic interventions and prosthetic devices.  Many other<br/>challenging biological and biomedical flow problems have features<br/>in common with that of simulating thrombosis, and so the<br/>state-of-the-art parallel computational methods developed for<br/>this project potentially have wide-spread application to problems<br/>important to basic science, health care, and biotechnology.  To<br/>help realize this potential the investigators develop and<br/>disseminate an easy-to-use software package that facilitates<br/>using these computational methods to set up and carry out<br/>simulations of important biofluid dynamics problems.<br/><br/>"
"9801395","Algorithmic Number Theory Symposium III","DMS","ALGEBRA,NUMBER THEORY,AND COM, COMPUTATIONAL MATHEMATICS","05/01/1998","04/21/1998","Joe Buhler","OR","Reed College","Standard Grant","Robert Perlis","04/30/1999","$15,000.00","","jpb@reed.edu","3203 SE WOODSTOCK BLVD","PORTLAND","OR","972028138","5037711112","MPS","1264, 1271","0000, 9263, OTHR","$0.00","          9801395  Buhler    This award supports a five-day international conference on algorithmic number theory to be held at Reed College in June 1998. This is the third conference in the Algorithmic Number Theory Symposia (ANTS) series. The ANTS conferences were organized to encourage not only the usual kind of number-crunching associated with number theory, but also some of the newer aspects, including algebraic number theory and geometry, applications to other fields such as cryptography, and theoretical investigations of computational complexity. Twenty years ago many of these ideas would have seemed very foreign to number theorists, but their increasing importance has led to a widely perceived need for a conference devoted entirely to algorithmic concerns, both practical and theoretical.       This conference falls into the general mathematical field of number theory.  Number theory has its historical roots in the study of the whole numbers,  addressing such questions as those dealing with the divisibility of one  whole number by another. It is among the oldest branches of mathematics and  was pursued for many centuries for purely aesthetic reasons. However, within  the last half century it has become an indispensable tool in diverse  applications in areas such as data transmission and processing, cryptography, and  communication systems."
"9805494","Modeling and Computational Studies of Cell and Tissue       Movement","DMS","PLANT FUNGAL & MICROB DEV MECH, APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/15/1998","06/28/1999","Hans Othmer","UT","University of Utah","Continuing Grant","Michael Steuerwalt","08/31/2000","$400,000.00","Dean Bottino, Eirikur Palsson","othmer@math.umn.edu","201 PRESIDENTS CIR","SALT LAKE CITY","UT","841129049","8015816903","MPS","1118, 1266, 1271","0000, 9263, OTHR","$0.00","Othmer  9805494       The principal investigator and his colleagues formulate and  analyze mathematical models for the motion of individual,  non-interacting cells and for the collective motion of cellular  aggregates in which cells interact strongly.  They use the  cellular slime mold Dictyostelium discoideum as the model system  because it exemplifies both the free-ranging movement of  individual cells and the collective motion of aggregates, and  because it is widely used as a model experimental system for the  study of cell movement.  There is a large body of experimental  data on this system, and several labs have agreed to share their  new data as it becomes available.  Three complementary  subprojects are pursued in parallel.  The first is to investigate  an individual cell-based model that incorporates internal  structure and active force generation and allows the  investigators to evaluate various theoretical proposals for  individual cell movement.  The second involves the formulation of  a higher-level, cell-based model used for analyzing the  collective motion of many cells, and the third employs a  continuum approach in which the cellular system is modeled as a  viscoelastic fluid with contributions to the stress tensor from  both the intracellular stress and the viscoelastic interactions  between cells.  Current information on the movement is used in  the formulation of the models, and the ongoing interaction with  experimental groups provides feedback on the validity of the  models and enables the investigators to suggest experiments to  test the models.  However, what is learned on cell and tissue  movement not only is applicable to Dictyostelium discoideum, but  also can be used in several other contexts, including embryonic  development, wound healing, and the immune system.       Cell and tissue movement plays a vital role throughout the  lifespan of many organisms.  Bacteria and other single-cell  organisms find food and avoid repellents by swimming in favorable  directions,  and cells such as macrophages in the human immune  system must detect sites of infection and move toward them in  order to ingest bacteria and cellular debris.  At the tissue  level, the coordinated movement of aggregates of cells plays a  critical part in such diverse processes as early embryonic  development and wound healing.  Thus it is important to develop a  better understanding of cell movement and its control, both in  the low-density regime where cells move individually, and at  tissue-level densities where cells interact strongly and move  collectively.  Mathematical modeling can play an important role in  understanding these processes by testing hypotheses that are  difficult to test experimentally with current technology.  A  better understanding of how cells and tissues move will lead, for  example, to a better understanding of the formation and control  of bacterial biofilms, which are deleterious in contexts such as  medical transplants, but valuable in contexts such as pollution  control and drug production."
"9805491","A Posteriori Error Estimates for Discontinuous Finite Element Methods Applied to Problems in Geosciences and Medicine","DMS","COMPUTATIONAL MATHEMATICS, Hydrologic Sciences, Engineering of Biomed Systems","10/01/1998","06/21/1999","Clinton Dawson","TX","University of Texas at Austin","Continuing Grant","Michael Steuerwalt","09/30/2002","$155,900.00","","clint@ices.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271, 1579, 5345","1339, 9183, 9198, 9216, 9263, BIOT, EGCH, HPCC","$0.00","Dawson<br/><br/>     The investigator and his colleague Bernardo Cockburn, in a collaborative project, develop adaptive numerical methods for problems with moving interfaces and long-time dynamics.  These problems incorporate multiple temporal and spatial scales.  Finite element methods have long been used for solving partial differential equations.  Recently, methods using discontinuous approximating spaces have become popular, especially for nonsteady convection-diffusion problems.  Two such methods are the local discontinuous Galerkin method (LDG) and the Godunov-mixed method (GMM), developed by the investigators and their collaborators.  These methods have the advantage that they are based on local conservation and approximate shocks and sharp gradients with no spurious oscillations, which is important in many convection-diffusion applications.  They also lend themselves to parallel computation.  Both methods have been implemented computationally, and a priori error estimates have been derived; however, no adaptive strategies based on these methods have been developed.  It has long been recognized that adapting the finite element mesh and time-step during a simulation is desirable for obtaining an accurate solution.  In order to successfully adapt the mesh to guarantee that the actual error is below a given tolerance, it is essential to develop a posteriori error estimates that measure the actual error as a funtion of the mesh, time step and the computed solution.  While a substantial literature exists for such estimates for steady problems and conforming finite element spaces, little research has been done for nonsteady problems and discontinuous methods. In this project, the investigators and their colleagues develop a posteriori estimates for the LDG and GMM methods for convection-diffusion equations, with emphasis on three important applications: shallow water flow, chemically reactive transport in porous media and surface water, and the modeling of brain tumor cell growth and treatment.  The basis for these estimates is the so-called approximate adjoint equation methodology; however, other ad-hoc methods which may potentially be more efficient are also investigated.  These estimates are novel for the applications as well as the numerical methods.<br/>   <br/>     The applications of interest are important to industry, government laboratories and departments, and state agencies. Modeling of flow patterns in shallow water systems (e.g. bays and estuaries) is important for understanding, for instance, the environmental impacts of oil spills and the economic impacts of dredging, and can also be useful in tracking storm surges during hurricanes and other extreme weather events.  Modeling of transport of chemical species in groundwater and surface water is important for understanding waste disposal and pollution remediation.  The modeling of brain tumors can be useful in predicting tumor growth and examining potential treatments. These applications, though varied, share common mathematical characteristics and can utilize similar numerical simulation methodologies.  Lacking for these applications and methodologies are sound, mathematically based tools for controlling and adapting the simulations to meet specific accuracy criteria of interest to the user; that is, criteria which can be used to determine whether a numerical simulation actually reflects physical reality.  The goals of this project are to develop such criteria for making the simulations efficient, accurate and physically realistic, and to train future researchers in the underlying mathematics, computational science and multidisciplinary aspects of the applications. <br/>"
"9802367","Reliability of Computational Analysis","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, NUMERIC, SYMBOLIC & GEO COMPUT","08/01/1998","05/04/2000","Ivo Babuska","TX","University of Texas at Austin","Continuing Grant","Deborah Lockhart","07/31/2002","$225,000.00","","babuska@ices.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1266, 1271, 2865","9216, 9263, HPCC","$0.00","9802367  Babuska    The project will address the following topics:  1) A posteriori error estimation in the finite element method.  It will focus   on the error estimation of the values of engineering interest as error in the   solution, the gradients (stresses) in the entire domain as well as   subdomains, the values of the functionals, etc.  The upper and lower a-  posteriori bounds will be addressed.  The effectivity and robustness of   these estimates will be theoretically and computationally investigated.    The linear elliptic equations and problems occurring in engineering   practice will be focussed on and also the nonlinear and parabolic ones will   be investigated.  The results will also be applied in the adaptive procedure.   2) The generalized finite element method.  A flexible form of FEM   allowing one to use special shape functions will be designed and   theoretically analyzed.  The classical h- and p- version is a special case.    The method will be implemented in two dimensions and possibly later,   three dimensions as well.  This method can typically be applied for   solving problems of heterogeneous material, solutions with boundary   layers and oscillatory character. 3) The problem of composites.  This is a   multi-scale problem with particular focus on composite fibrous materials.    The main interest will be on a fiber scale.  The study will be both   deterministic and stochastic. The stochastic formulation is essential   because the position of the fiber scale statistical character.  The work will   be performed in collaboration with the Aeronautics Institute of Sweden. 4)   The p-version of FEM.  This work will be focused on resolving various   aspects of the p-version in 3 dimensions although first the methodology   will be used on the two-dimensional setting.  The theory will utilize new   functional spaces which are needed for addressing the problems occurring   in engineering.  The work is a continuation of the results of results   obtained in the past.    The planned  research addresses problems with a high level of importance   in the engineering computations.  It will focus on the reliable and accurate   a-posteriori error estimations and adaptive procedures in the Finite   Element Method, which are essential for confidence in the computed data.    In this way, various accidents could be avoided.  Although the finite   element method is a major tool in engineering computations, various   important problems are practically unsolvable by the standard approach.    Hence a new generalized flexible finite element method will be designed   with the goal to increase the effectivity of the method when solving   unusually difficult problems. The problem of the composite material with   the focus on the fiber scale is one of these types of problems when   millions of fibers are present with only statistical character in regard to   knowledge of their position.  Here new approaches which are very tight to   the experimental studies are needed and will be addressed."
"9805492","Coupling Internal and External Mechanics of Swimming Organisms: A Computational Approach","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/15/1998","08/13/2002","Lisa Fauci","LA","Tulane University","Standard Grant","Michael Steuerwalt","08/31/2003","$188,000.00","","fauci@tulane.edu","6823 SAINT CHARLES AVE","NEW ORLEANS","LA","701185665","5048654000","MPS","1266, 1271","9183, 9263, BIOT","$0.00","Fauci<br/>9805492<br/>     This project concerns the fluid dynamics of aquatic animal<br/>locomotion, a field that encompasses the study of flagellar<br/>motility as well as invertebrate swimming.  The investigator and<br/>her colleages explore the coupling of the internal<br/>force-generating mechanisms of the organisms with an external<br/>viscous, incompressible fluid.  A unified computational approach<br/>can be adapted to model the internal axoneme mechanics of a<br/>beating cilium, the force-generating internal flagella of<br/>spirochetes, as well as the coupling of active and passive tissue<br/>properties to the swimming mechanics of a leech.  In addition to<br/>modeling the dynamics of a single organism, the collective<br/>hydrodynamic interactions of groups of organisms and their<br/>environment can be examined.  The investigator has developed a<br/>mathematical model designed to study the coupled mechanical<br/>system comprised of the fluid and the immersed organism.  The<br/>numerical method used is the immersed boundary method.  The full<br/>incompressible Navier-Stokes equations are solved in a domain of<br/>fluid within which neutrally-buoyant organisms undergoing<br/>time-dependent movements are immersed.  The salient feature of<br/>this method is that the suspended organism is replaced by<br/>suitable contributions to a force density term in the fluid<br/>dynamics equations.<br/>     This interdisciplinary project employs modern methods in<br/>scientific computing to study important biological processes.  The<br/>understanding of bacterial motility and aggregation is of vital<br/>importance in bioremediation, the process by which bacteria are<br/>used to degrade toxic chemicals.  In addition, the study of the<br/>internal mechanisms of cilia, flagella and spirochetes has<br/>applications in medicine and biotechnology.  The computational<br/>algorithms developed in this project will be useful in studying<br/>other biofluiddynamic problems as well as contributing to<br/>expertise in high performance computing.<br/><br/>"
"9805483","A Mathematical Framework for Tensor Image Processing","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, Engineering of Biomed Systems","09/15/1998","07/18/2001","Akram Aldroubi","TN","Vanderbilt University","Standard Grant","Michael Steuerwalt","05/31/2002","$124,875.00","","akram.aldroubi@vanderbilt.edu","110 21ST AVE S","NASHVILLE","TN","372032416","6153222631","MPS","1266, 1271, 5345","0000, 9251, 9263, OTHR","$0.00","Aldroubi<br/>9805483<br/><br/>The investigator develops a mathematical framework for representing discrete tensor images that is suited to post-processing applications, such as pattern recognition, registration and geometric transformations.  In particular, he constructs atomic Wiener amalgam tensor spaces that consist of continuous tensor fields, and establishes conditions on the generating tensors that guarantee that the discrete tensor field spaces obtained by any regular sampling of the continuous spaces are atomic and are isomorphic to the continuous spaces.  Using the connection between the approximation problems in atomic spaces and the filtering paradigm in signal and image processing, he develops and implements fast filtering algorithms for various fundamental processing operators, such as noise reduction, rotation, translation, and general affine transformations.  Because tensor image data possess spatial information about the fiber structure and geometry of materials, tissues, or organs, he also uses results from differential geometry to extract different architectural features of ordered media.  Part of the project is devoted to testing the accuracy, precision and speed of these algorithms.  For this purpose, he generates synthetic data sets and also uses real data acquired from in vivo clinical diffusion tensor MRI studies, and other imaging modalities, to evaluate the performance of these algorithms.<br/><br/>This project is motivated primarily by the need to process and analyze clinical data obtained from diffusion tensor MRI, a new noninvasive imaging modality that allows physicians to visualize nerve and muscle fiber tracts in the body.  However, the mathematics developed here is applicable to processing and analyzing data acquired from a much larger number of imaging devices and modalities used in diverse application areas including medicine, material sciences, oceanography, meteorology, fluid mechanics, satellite reconnaissance, and astronomy.  Many new scanning systems measure several quantities at each point or position within an image rather than a single quantity.  These lists of numbers may represent important physical quantities, such as velocities or displacements, or the amount of light absorbed, reflected, or emitted at different wavelengths at a particular location.  The theory being developed here provides a rational means to represent, process, analyze and compress this data -- a problem which no theory currently treats.  In addition, this work is intended to ameliorate many problems inherent in the measurement of these new types of data sets.  In particular, imaging data are usually corrupted by noise, are discrete rather than continuous, and are spatially averaged.  Finally, because these new imaging modalities can generate vast amounts of data, the algorithms that the investigator implements for representing, processing, analyzing, and compressing the data must be fast and efficient, as well."
"9803323","Shock Wave Theory","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","08/01/1998","09/24/2002","Tai-Ping Liu","CA","Stanford University","Continuing Grant","Deborah Lockhart","07/31/2003","$226,000.00","","liu@math.stanford.edu","450 JANE STANFORD WAY","STANFORD","CA","943052004","6507232300","MPS","1266, 1271","0000, 9263, OTHR","$0.00","DMS-9803323    Tai-Ping Liu         We propose to study two fundamental questions for general   systems of hyperbolic conservation laws: The first is the well-posedness   problem. This is done with Tong Yang. For this, we already constructed a   nonlinear functional for the two conservation laws and are in the process  of doing so for the general systems. The second problem is to study   multi-dimensional gas flows. Lien and the author have succeeded in showing   that three-dimensional self-similar gas flow past a cone is nonlinearly   stable. We are generalizing the new approach of superpositioning local   self-similar flows to other problems. We expect this approach to yield   new qualitative information on nonlinear stability and instability of   multi-dimensional gas flows. Our second project is to study the viscous   conservation laws. With Zeng, we are in the process of studying the   stability of nonlinear waves for hyperbolic-parabolic systems such as the   compressible Navier-Stokes equations. Other problems in combustion and   MHD, and numerical analysis of shock calculations are being considered.   Of particular interest is the role of dissipative parameters on the   structure and stability of nonlinear waves. The pointwise approach the   author introduced is effective for these purposes.        The author plans to study basic questions concerning the invisicd   and viscous solutions for gas dynamics and mechanics.  One of the   fundamental questions concerns the validity of the Euler equations for   the gas dynamics. The equations were derived by Euler in the eighteenth   century. Only until recently the author and his collaborator are able to   show that the equations are mathematically valid in that small errors in   the data yield small errors in the solutions. This is of obvious   importance in the applications because there is always small error either  in the experimental data or numerical computations. Other problems of interest   to the author include the sensitive role of di ssipation parameters. In   combustion, magneto-hydrodynamics, nonlinear elasticity and other   continuum physics, dissipative mechanisms, such as viscosity, heat   conductivity, and species diffusions are important. The geometric   properties and stability of the nonlinear waves may depend sensitively   on these parameters. The author has recently introduced a pointwise approach,   which is effective in studying the nonlinear interactions of waves. The   role of dissipation parameters are being studied using the basic   conservation laws in physics."
"9732876","Mathematical Sciences: Internal Layers in Fluid Flow and    Solid Deformation","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","08/01/1998","09/01/1999","James Glimm","NY","SUNY at Stony Brook","Continuing Grant","Michael Steuerwalt","07/31/2001","$180,000.00","Bradley Plohr, David Saltz","glimm@ams.sunysb.edu","W5510 FRANKS MELVILLE MEMORIAL L","STONY BROOK","NY","117940001","6316329949","MPS","1266, 1271","0000, 9263, OTHR","$0.00","DMS 9732876    James Glimm     Abstract    Mixing layers, internal layers, and fronts are the primary features of many  important fluid flow and solid deformation problems.  The proposers have  established striking progress in these areas, and propose here to develop  systematically an effective theoretical and computational methodology for their  study.  The central intellectual challenge in the study of layers and fronts  involves the complex interactions of physical processes with disparate length  scales.  The length scales of key microscopic processes within a layer are  typically orders of magnitude smaller than those of the ambient fluid in which  the layer is embedded, yet they may have a profound effect on the macroscopic  structure of the fluid flow.  For this reason, direct numerical simulation  requires special algorithms to resolve the important layer microstructure  accurately with reasonable computational resources.  The theoretical challenge  is two-fold, as the problem requires scale-up techniques to understand the  effects of the microscopic processes at the macroscopic level, and then methods  to express the nonlinear coupling of distinct physical processes operating on  comparable length scales.  While the study of layers and fronts is at least a  two-scale problem, the interest here is in practical applications, which  usually involve multiple length scales within a layer.  This project will  provide (a) the theoretical and algorithmic basis for a new class of production  codes for the simulation of complex fluid flow and solid deformation; (b) the  theoretical basis for understanding turbulent multiphase flow and fluid mixing;  (c) validation of turbulence and mixing models, through exploration of  parameter regimes in highly resolved simulations that are in step with physical  experiment; and (d) a new mathematical theory for the interaction of nonlinear  hyperbolic waves, including an understanding of phenomena which can in some  cases prevent or overcome the poor perform ance of simulation codes.    When the surface of contact between two distinct materials is unstable, small  random disturbances on the surface will develop into interpenetrating  structures, such as fingers, jets, droplets, and bubbles.  These structures are  complex and chaotic, and together they comprise a ""mixing layer.""  Mixing  layers are of fundamental importance in natural phenomena such as supernova  explosions, and in technological applications such as inertial confinement  fusion (ICF), where they are known to be a major limiting factor in the  performance of ICF capsules.  Typically a mixing layer is embedded in a  large-scale fluid or solid flow, and in this case the precise resolution of a  mixing layer by computer simulation is impractical (if not impossible) if the  computer code is to be used to make quantitative predictions on a regular  basis.  For this reason, a scientific theory is required to capture the  unresolvable microstructure of mixing layers in a macroscopic framework which  is amenable to computer simulation.  The goal of this project is to develop  such a theory and to demonstrate its validity by comparison with computer  simulation and physical experiment.  This work will require new ideas, as  described in this proposal, and will contribute to the fundamental knowledge  base of science, of significance to a broad range of scientific phenomena."
"9731956","Finite Difference Equations for Transport Effects in Kinetic Theory","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","08/01/1998","08/04/1998","Jack Schaeffer","PA","Carnegie-Mellon University","Standard Grant","Junping Wang","07/31/2002","$73,588.00","","js5m@andrew.cmu.edu","5000 FORBES AVE","PITTSBURGH","PA","152133815","4122688746","MPS","1266, 1271","0000, OTHR","$0.00","9731956  Schaeffer      This award supports research on systems of nonlinear partial  differential equations which model plasma behavior.  In particular a  kinetic model of plasma in which the density of ions in phase space  satisfies the Landau-Fokker-Planck equation is considered.  A major  focus is to develop finite difference schemes which correctly track the  transport effects.  In the case where collisions are neglected, particle  methods are widely used, but the computation of the collision operator  may be carried out more easily on a regular grid.  Hence the interest in  a finite difference method.  The goals here are to study both the  results of implementing such methods and analysis of convergence (as  feasible).  The starting point for this work is the context in which  solutions have spherical symmetry.  An additional problem of interest is  the Vlasov-Einstein system in which the relativistic motion of matter is  coupled to the Einstein field equations."
"9873442","KDI: New Algorithms, Architectures and Science for Data Mining of Massive Astrophysics Sky Surveys","DMS","COMPUTATIONAL MATHEMATICS, NUMERIC, SYMBOLIC & GEO COMPUT, KDI OPPORTUNITY FUND","10/15/1998","09/14/1998","Andrew Moore","PA","Carnegie-Mellon University","Standard Grant","Michael Steuerwalt","09/30/2001","$1,600,000.00","Christos Faloutsos, Peter Spirtes, Larry Wasserman, Robert Nichol","awm@cs.cmu.edu","5000 FORBES AVE","PITTSBURGH","PA","152133815","4122688746","MPS","1271, 2865, 8876","0000, 1337, 1339, 9218, 9263, HPCC, OTHR","$0.00","Moore<br/>9873442<br/>     There many massive databases in industry and science, and<br/>this is particularly true for Astrophysics.  There are many kinds<br/>of questions that physicists and other users wish to ask the<br/>databases in real time, e.g., 'find outliers'; 'find clusters';<br/>'find patterns'; 'classify the data records into N predetermined<br/>classes.'  Wide-ranging statistics and machine learning<br/>algorithms similarly need to query databases, sometimes millions<br/>of times for a single inference.  With millions or billions of<br/>records (such as the new generation of astrophysics sky surveys)<br/>this can be intractable using current algorithms.  This project<br/>aims to make repeated statistical querying of huge datasets<br/>computationally feasible by transforming massive databases into<br/>condensed representations that permit the rapid answering of such<br/>questions.  To achieve these goals, the investigator and his<br/>colleagues explore ways in which tools from statistics (such as<br/>Bayesian networks), databases (such as kd-trees/R-trees), and<br/>Artificial Intelligence (such as AD-trees and rule-finders) can<br/>help, how they scale up, and how they can be combined.<br/>     The investigators intend to help automate the process of<br/>scientific discovery for astrophysical data sources in which<br/>there is too much information for any unaided human to have a<br/>chance of spotting patterns, regularities, or anomalies.<br/>Government and industry in the U.S. have invested heavily in<br/>ingenious new ways to gather information in all branches of<br/>science and industry, from cell biology to the flows of capital<br/>in international commerce.  Scientists and analysts who have<br/>worked so hard to gather magnitudes more data than they had ten<br/>years ago are now faced with an equally daunting task: exploiting<br/>it fully.  It is ironic that in fields such as astrophysics there<br/>is now so much data that no human has enough time to even see a<br/>tiny fraction of it.  The job of discovering new relationships,<br/>anomalies, and even causation, must now be at least partly turned<br/>over to computers.  The investigators comprise a team of<br/>statisticians, computer scientists, and astronomers who have each<br/>already made progress in this direction.  This team develops new<br/>algorithms to squeeze as much information as possible from<br/>trillion-byte astrophysics databases such as the Sloane Sky<br/>Survey.  They also make sure that the resulting technology is<br/>deployed elsewhere in science and industry.<br/><br/>"
"9870384"," Application of Distributed Adaptive Mesh Refinement        Techniques to Problems Involving Diffusion","DMS","COMPUTATIONAL MATHEMATICS","09/15/1998","08/25/1998","William Allard","NC","Duke University","Standard Grant","Michael Steuerwalt","08/31/2001","$150,000.00","John Trangenstein","wka@math.duke.edu","2200 W MAIN ST","DURHAM","NC","277054640","9196843030","MPS","1271","0000, 9183, 9189, 9263, BIOT, EGCH, OTHR","$0.00","A number of physical problems involve localized phenomena<br/>that move in time, such as fluid fronts, interfaces and shocks.<br/>Often, these phenomena are not captured well by finite difference<br/>methods on uniform grids.  The investigators work on three<br/>classes of such problems: flow in porous media, particularly<br/>chemically enhanced aquifer remediation; thin film flow with<br/>fluid fronts due to vanishing diffusive fluxes; and excitable<br/>media, particularly the modeling of the propagation of electrical<br/>impulses in the heart.  All three of these problems involve<br/>diffusion; the diffusion can be nonlinear, subdiffusive or<br/>superdiffusive.  The investigators develop efficient multilevel<br/>iterative methods and adaptive mesh refinement tools to solve<br/>these problems on parallel processor machines.<br/>     The power of computers has dramatically increased  since<br/>they were introduced a half century ago, and this improvement in<br/>performance continues at a breathtaking pace.  Nonetheless,<br/>although the public is generally unaware of this, the<br/>computational resources required to simulate many phenomena, like<br/>the weather, greatly exceed those currently available.  One way<br/>to obtain a lot of computer power is to arrange for many<br/>computers to work simultaneously on a problem.  However, it is a<br/>daunting task to program these computers so that they will<br/>correctly produce the desired simulation in a timely fashion.  In<br/>this work, the investigators develop effective methods to use<br/>many computers working together to simulate the flow of<br/>contaminants in the ground, the behavior of thin films, and the<br/>electrophysiology of the heart.  Groundwater contamination is a<br/>significant environmental problem.   Thin film problems arise in<br/>lubrication and in manufacturing processes.  A fundamental<br/>understanding of the electrical and muscular behavior of the<br/>heart is important and could lead to better control of the<br/>mechanisms of arrhythmia.<br/><br/>"
"9870091","Analysis of Fluid Motion","DMS","COMPUTATIONAL MATHEMATICS","07/15/1998","09/01/1999","J. Thomas Beale","NC","Duke University","Continuing Grant","Michael Steuerwalt","12/31/2001","$150,000.00","","beale@math.duke.edu","2200 W MAIN ST","DURHAM","NC","277054640","9196843030","MPS","1271","0000, 9263, OTHR","$0.00","DMS-9870091  J. Thomas Beale    Abstract     The purpose of the proposed work is to analyze the errors in  numerical methods for the time-dependent motion of water waves,  to design improved methods, and to verify the reliability of the  proposed methods with error estimates, convergence proofs, and  computational tests.  The methods of interest are called boundary  integral methods.  They have been widely used in ocean engineering  as well as in applied mathematics.  The motion of the water surface  is tracked by markers representing material particles which are moved  according to a velocity field computed from quantities on the surface.    The velocity is expressed in terms of singular integrals, since the  governing equations are formulated through potential theory.  The  evolution has the character of nonlinear, nonlocal wave motion on  the boundary.  Numerical instabilities have long been observed in  such methods, but analysis of the two-dimensional case has shown  that they can be ruled out by proper design.  The first goal of the  proposed research is to develop stable, convergent numerical methods  for the simulation of exact, time-dependent, three-dimensional water  wave motion which is periodic in the horizontal directions.  Thus the  full nonlinear motion will be dealt with, but interactions with solid  objects will be neglected.  The method of calculation of the singular  integrals is a primary issue, one which may have relevance to other  problems.  A second goal is to deal with the errors from edges where  a solid object meets the water surface.    Practical predictions of the motion of fluids and solids  are often made by numerical solution of the equations  which express the basic physical laws of the motion.  Methods of the type studied here have been used in  ocean engineering in order to predict the motion of  large water waves, the interaction of water waves with  ships or stationary objects, and the force exerted by  a wave on a wall or object.  Calculations of these probl ems  and others have encountered numerical instabilities; that is,  because of the numerical approximation, small scales may  grow in a way unrelated to the physical problem.  Mathematical analysis can be used to understand such  errors and to design improved methods.  Previous  work for two-dimensional waves (those not varying in  the third direction) has identified the sources of errors  for this special case.  The purpose of the present  work is to carry out such analysis in more  difficult and realistic cases where the sources of  errors are likely to be more serious.  It is hoped that  improvements in the numerical methods could contribute  to reliable predictions of water wave motion."
"9803305","Fundamental and Applied Problems in Granular Flow","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/15/1998","06/14/2000","David Schaeffer","NC","Duke University","Continuing Grant","Deborah Lockhart","08/31/2002","$540,000.00","William Allard, Robert Behringer","dgs@math.duke.edu","2200 W MAIN ST","DURHAM","NC","277054640","9196843030","MPS","1266, 1271","0000, 9263, OTHR","$0.00","Fundamental and Applied Problems in Granular Flow  David Schaeffer/ Michael Shearer    This project focuses on three aspects of the flow of granular  materials: an investigation of fluctuations, flows and stresses in  industrial silos, and liquefaction of soils.  The various issues will  be addressed using an interdisciplinary approach involving analysis,  computation and experiment.  The latter two parts will also involve  input from industrial and geotechnical experts.  Details of each  subproject follow.  Subproject 1, fluctuations in sheared granular  materials: Recent work has shown that fluctuations of forces and to  some extent velocities can be very large for moderate scale systems.  The experimental part of this project will provide additional  quantitative characterizations of these fluctuations for modest scale  slowly sheared systems.  In addition, new experiments will be  constructed of a Couette type that will probe force fluctuations on  larger length and time scales.  These experiments will be integrated  into ongoing work to model force fluctuations by lattice type models,  and computations using novel hybrid molecular dynamics  and finite  element codes. Subproject 2, flow in industrial silos: In collaboration  with engineers at the firm Jenike and Johanson, Inc. the co-PI's of this  project will analyze flows in a spatial region that corresponds to the  shape of a typical hopper.  This analysis will be based both on Coulomb  materials and on  critical state soil mechanics (CSSM).  Some of the aspects  under study will  include an investigation  of the relationship between  CSSM and  Coulomb  models, shock and rarefaction wave solutions, boundary  value problems for  hopper flow, and stability of such solutions.  An  important application  is the design of flow corrective devices.  Subproject 3, liquefaction of soils: This phenomenon corresponds to the  abrupt  loss of load-bearing capacity of a loose, water-saturated soil,  possibly leading to a massive landslide. Real world s oil  failure/liquefaction will be investigated in collaboration with  G. Gudehus and his associates.    This project will combine experiments, mathematical analysis, computer  simulation and industrial/geotechnical expertise to better understand  the flow of granular materials.  The area of study is of considerable  importance to technical processes involving all types of granular  materials, including but by no means limited to chemical process  industries, and to the handling of coal, ores, food grains, and  pharmaceuticals.  Many aspects of the above processes are not fully  understood, leading in some cases to enormous financial losses. Also  under consideration are geotechnical issues such as the stability of  embankments,  as well as the stability of soils under earthquake conditions.  The project will involve the application of existing theories for granular  materials to such fundamental  problems as flows in hoppers and stability  of soils in landfills.  New models will be developed in order to take into  account some important aspects  of granular flows such as fluctuations of  forces. Recent experiments in this lab have shown that fluctuations,  which are not accounted for in existing models,  can be very strong and  may well be necessary to provide safe and reliable design criteria for  industrial devices involving granular flows. The models will be tightly  linked to the experimental data, on the one hand, and, on the other hand,  will be the basis of computer solutions for relevant technical problems."
"9807172","Parallel Algorithms for Incomplete Factorization            Preconditions","DMS","COMPUTATIONAL MATHEMATICS","08/01/1998","07/15/1998","Alex Pothen","VA","Old Dominion University Research Foundation","Standard Grant","Jong-Shi Pang","07/31/2001","$69,009.00","","apothen@purdue.edu","4111 MONARCH WAY","NORFOLK","VA","235082561","7576834293","MPS","1271","9216, 9263, HPCC","$0.00","9807172  Pothen    Preconditioning is a technique for improving the convergence of  iterative methods for solving  large, sparse systems of linear equations. The most robust preconditioners available to date are based on computing incomplete factors of the coefficient matrix, i.e., factors  that include only a small subset of the nonzero elements created during  the factorization. New algorithms for computing incomplete factor preconditioners for unsymmetric and symmetric matrices on serial and parallel  computers will be designed and implemented in this project. These algorithms have two phases: in the first symbolic factorization phase,  the positions in which the incomplete factors have nonzeros are identified, and data structures for the incomplete factors  are set up. In the second numerical factorization phase, these  data structures are used to compute the numerical values of the preconditioners in time proportional to the number of arithmetic  operations. Without the first symbolic factorization phase, the second phase   cannot be implemented  efficiently. The new symbolic factorization algorithms rely on a structure theory developed for identifying the positions in which the incomplete factors have  nonzero elements. The nonzero  elements in the incomplete factors are identified from the path structure  of  a graph model of the problem. Two graph reduction techniques, transitive reduction and symmetric reduction, are used to reduce the data needed to predict the fill, and thereby to  obtain fast symbolic factorization algorithms. The new algorithms can be proven to require less time  than the currently used algorithm, and preliminary implementations show that they  are faster by an order of magnitude or more  in problems with high fill.       Methods for solving large, sparse, linear systems of equations are workhorses for  solving partial differential equations from scientific and engineering models. Hence these fields will benefit from the algorithms and software developed in this pro ject. These  preconditioners will be used to solve specifically the Helmholtz problem in acoustics and Maxwell's equations in computational electromagnetics. The software developed from this project will be integrated with the PETSc (Portable, Extensible Toolkit for Scientific Computing) package  from Argonne National Laboratories for wide dissemination."
"9805983","Algorithms for Solving Linear Recurrence Equations","DMS","COMPUTATIONAL MATHEMATICS","06/15/1998","06/19/1998","Mark van Hoeij","FL","Florida State University","Standard Grant","Jong-Shi Pang","05/31/2001","$41,802.00","","hoeij@math.fsu.edu","874 TRADITIONS WAY","TALLAHASSEE","FL","323060001","8506445260","MPS","1271","0000, 9263, OTHR","$0.00","9805983<br/>van Hoeij<br/><br/>Difference equations (i.e. recurrence equations) have a number of properties in common with differential equations.  The PI recently introduced the notion of finite singularities of difference equations.  With this notion, more methods for differential equations can now be applied to difference equations, and this leads to new algorithms.  In particular, the PI intends to implement a new efficient algorithm for computing hypergeometric solutions of recurrence equations.  These algorithms have several applications, such as finding and proving formulas, or solving certain linear differential equations.<br/><br/>"
"9805547","Computational Methods for the Simulation of Chemical Vapor  Deposition on Rough Surfaces","DMS","COMPUTATIONAL MATHEMATICS","08/01/1998","07/17/1998","Matthias Gobbert","MD","University of Maryland Baltimore County","Standard Grant","John C. Strikwerda","07/31/2001","$68,000.00","","gobbert@umbc.edu","1000 HILLTOP CIR","BALTIMORE","MD","212500001","4104553140","MPS","1271","0000, 9263, OTHR","$0.00","DMS 9805547    Matthias K. Gobbert    Computational Methods for the Simulation of Chemical Vapor Deposition  on Rough Surfaces    Abstract:    In chemical vapor deposition (CVD) processes a mixture of reacting  gases is applied to the surface of a semiconductor wafer in the  reaction chamber of a chemical reactor. A thin film of material is  formed on the surface via surface reactions with the surface material.  The wafer surface contains small trenches and holes, collectively  referred to as features, for interconnect lines, transistor gates,  etc., thus making the surface rough. Currently, reactor scale models  (RSM) based on the Navier-Stokes equations capture the flow of the  reacting gases throughout the entire reactor chamber with a typical  dimension of 10 centimeters, and feature scale models (FSM) based on  kinetic equations predict the film growth profile inside a single  feature with a typical dimension of 1 micrometer. Due to the extreme  difference of length scales, an integrated process model spanning all  length scales of interest is best obtained by introducing a mesoscopic  scale model (MSM) with typical dimension on the order of 1 millimeter.  This project will develop the mathematical model and computational  methods for the appropriate kinetic equations in the low pressure  regime on this scale.    This project is part of an effort at modeling the manufacturing  processes of computer chips. Computers are already and will continue to  be one of the most important tools of our economy and technology. There  is a trend towards more specialized computer chips to be produced in  smaller numbers, for instance for specific applications in space  exploration or defense systems.  But prototype runs necessary to test  the manufacturing processes use expensive chemicals and produce  hazardous exhaust gases, which need to be treated before releasing them  to the environment.  For these reasons, interest in simulating the  manufacturing processes on all scales from individual device to fa ctory  floor has been increasing. This project will contribute to the  development of appropriate models as well as better numerical  techniques for the process of chemical vapor deposition, one of the  crucial production steps for computer chips. In this process, a thin  layer of material is deposited to form either the electrical lines or  the electronic devices that make up the computer chip in the final  product."
"9870317","Interior-point Methods for Large-scale Nonlinear Programming","DMS","COMPUTATIONAL MATHEMATICS","08/15/1998","08/13/1998","Robert Vanderbei","NJ","Princeton University","Standard Grant","Michael Steuerwalt","11/30/2001","$162,000.00","","rvdb@princeton.edu","1 NASSAU HALL","PRINCETON","NJ","085442001","6092583090","MPS","1271","0000, 9263, OTHR","$0.00","9870317<br/>Robert Vanderbei<br/><br/>The objective of this research project is to extend interior-point methods so that they can be applied to smooth nonlinear optimization problems.  In particular, an existing linear/quadratic solver will be enhanced so as to become an easy-to-use and efficient system for the solution of these problems.  If a problem is convex, the system will find a globally optimal solution.  If it is nonconvex, then the system will find a locally optimal solution in a neighborhood of a given initial solution.  The algorithmic issues to be addressed include: (a) which merit function to use, (b) when and by how much to perturb indefinite Hessians, (c) how to adapt the predictor-corrector variant, (d) how and when to sparsify Hessians, (e) how much to push initial values away from bounds, (f) how to detect and handle problems in which the constraints don't satisfy a constraint qualification condition, and (g) how to ensure that the infeasible interior-point method doesn't evaluate any function outside its domain.  As part of this research, a database of real-world nonlinear optimization models will be assembled.  This database will be freely available via the internet.  Finally, techniques will be sought that will enable one to use the interior-point-based nonlinear-programming system to solve semidefinite programming problems.<br/><br/>Nonlinear optimization plays a fundamental role in all branches of applied science and engineering.  Whether it is maximizing the speed at which flutter destroys a wing, minimizing the use of nonrenewable resources in hydrothermal power generation, designing a structure that can bear a specified load with minimal amount of material, or minimizing side-lobe signal strength in the output of an antenna array while preserving main-lobe characteristics, there is one commonly shared theme: optimization.  Interior-point methods provide a new approach to the solution of these problems, which promises to enable one to solve them more reliably and much more efficiently than before. This research project will focus on resolving the issues involved in producing an efficient and robust interior-point algorithm for nonlinear optimization.<br/><br/>"
"9805582","From Microscopic to Macroscopic:  A Multiscale Numerical    Approach","DMS","COMPUTATIONAL MATHEMATICS","09/15/1998","09/11/1998","Shlomo Ta'asan","PA","Carnegie-Mellon University","Standard Grant","Michael Steuerwalt","08/31/2001","$255,000.00","","shlomo@andrew.cmu.edu","5000 FORBES AVE","PITTSBURGH","PA","152133815","4122688746","MPS","1271","0000, 1339, 9263, OTHR","$0.00","Ta'asan<br/>9805582<br/>     The investigator and his colleagues develop multiscale<br/>numerical techniques for dealing with phenomena on a wide range<br/>of scales.  The main aspect of the research is the numerical<br/>construction of macroscopic equations in the form of partial<br/>differential equations from microscopic models such as molecular<br/>dynamics models.  The numerical techniques focus on fluids<br/>modeling starting from molecular models.  Special emphasize is<br/>given to models involving mixtures of several types of<br/>atoms/molecules that may be governed by different interactions.<br/>Such molecular models give rise to complicated physical phenomena<br/>including multiphase flows.  A sequence of models is constructed<br/>numerically in an hierarchical manner starting from molecular<br/>dynamics.  Each level in this hierarchy represent a larger scale<br/>dynamics (in time or space or both) of the previous level, and is<br/>constructed using statistical tools (regression analysis) applied<br/>to the data resulting from a simulation of the previous level.<br/>The finest level of modeling is given by Hamiltonian dynamics and<br/>is deterministic.  Stochastic particle dynamics models are<br/>constructed from the finest level model, and represent the<br/>physical phenomenon on time scale of the order of the relaxation<br/>time.  Further coarsening (averaging) in space-time results in<br/>deterministic density evolution models, which can be identified<br/>as finite difference approximations to some partial differential<br/>equation that is the macroscopic limit.<br/>     Numerical techniques have been used extensively for several<br/>decades to obtain approximate solutions of partial differential<br/>equations in different fields, and have improved significantly<br/>scientific insights and engineering tasks.  The derivation of<br/>those equations, which describe physical phenomena in different<br/>areas, was done by analytical techniques whose use is limited to<br/>relatively simple cases.  The treatment of more complex models<br/>cannot, in general, be done analytically and it calls for another<br/>approach.  This is the subject of this work: the use of numerical<br/>techniques for 'deriving' macroscopic dynamics equations from<br/>more basic principles given at microscopic levels.  This task is<br/>carried out by large scale simulation of the detailed microscopic<br/>models and appropriate statistics.  The problems treated in this<br/>work are limited to multiphase fluid flows, which are crucial in<br/>many areas of applications, including medical inhalation devices,<br/>auto and aerospace industries (engines), computer industries<br/>(printers), and more.  The techniques developed here, however, are<br/>quite general and apply to other areas in chemistry, physics and<br/>economics, from fundamental questions to real world applications.<br/><br/>"
"9806702","Collaborative Research on Numerical Methods for Image       Processing","DMS","COMPUTATIONAL MATHEMATICS","07/01/1998","06/18/1998","Daniela Calvetti","OH","Case Western Reserve University","Standard Grant","Jong-Shi Pang","06/30/2001","$72,216.00","","dxc57@case.edu","10900 EUCLID AVE","CLEVELAND","OH","441061712","2163684510","MPS","1271","9216, 9263, HPCC","$0.00","9806702  Calvetti    The numerical solution of image processing problems gives rise to very large  nonsymmetric linear systems whose solutions are extremely sensitive to   perturbations in the data. To avoid or at least contain the disastrous effects   of such instability regularization is required. Regularization yields slightly   modified problems which are less sensitive to inaccuracies in the data.    The aim of the research by the investigator and her colleague is to   develop effective and efficient regularization methods for the solution of  large nonsymmetric linear systems that arise in image processing applications,   as well as to develop new algorithms for image compression.      The new numerical methods will be tested on medical imaging data and will be   applied to interventional magnetic resonance imaging in collaboration the   department for Biomedical Engineering at Case Western Reserve University."
"9714811","Joint NCSU-Boeing Academic-Industrial Research Project","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","06/01/1998","04/01/2002","Carl Meyer","NC","North Carolina State University","Standard Grant","Lloyd E. Douglas","05/31/2003","$293,988.00","Carl Kelley, Stephen Campbell, Ilse C.F. Ipsen, John Betts, Daniel Pierce","meyer@ncsu.edu","2601 WOLF VILLAGE WAY","RALEIGH","NC","27607","9195152444","MPS","1253, 1271","0000, 1504, 9263, OTHR","$0.00","The purpose of this project is to build a collaborative  structure involving personnel from Boeing's Mathematical and  Engineering Analysis Division (John Betts and Daniel Pierce) and  NCSU's Applied Mathematics program (Carl Meyer, Stephen Campbell,  Ilse Ipsen, Carl Kelley and four graduate students) to  investigate problems of mutual interest which arise in  the design and development of modern aircraft.    Modern manufacturing techniques attempt to utilize sophisticated  automatic assembly machines to reliably construct a product while  reducing production cost and time.  The problem of modeling  the  motion of complex dynamical systems such as robot arms,  multi-axis milling machines and automated assembly tools is a  central issue in the effort toward manufacturing modernization.   Complex differential-algebraic equations (DAE's) are often at the  heart of these problems, and the goal is to use these DAE's to  simulate system performance, thereby avoiding ad hoc process  design approaches and circumventing the need to build physical  mockups.  Notwithstanding recent advances, computer simulations  in these areas are not always performed using the DAE's because  state-of-the-art solution technology for DAE's is not robust and  reliable enough for everyday use.  Instead, engineers convert the  problems to initial value differential equation problems and  treat algebraic constraints using heuristics.  As a result of  this ad hoc process, each problem requires special treatment  which not only translates into increased costs, but extends  product-to-market times.  The net result is a degradation in both  industrial and national competitive advantages.    This joint academic-industrial research project focuses on some  immediate problems requiring advanced and robust DAE solvers.  Specific applications include Boeing's current tool planning  project which is aimed at optimizing the path of a trim tool in  the production of airplane parts, the solution of an inverse  problem that uses measured d ata to determine actual air  pressures, and the trajectory planning problem required for  Boeing's high speed civil transport project. Common to each  application are DAE models which require advances in DAE solution  technology before more sophisticated production engineering  computing tools can be developed.    The joint research effort will be facilitated through regular  short visits by members of each team to the other team's site,  and it will be further strengthened by installing NCSU graduate  students in Boeing's Mathematics and Engineering Analysis  division.    Boeing will allocate a substantial amount of salary support from  their research budget to allow members of their team to engage in  this collaborative effort.  Boeing will provide facility support  in the way of office space, computing hardware and software,  library resources, etc., while NCSU team members visit Bellevue.   NCSU will reciprocate when Boeing personnel visit Raleigh.    Boeing will provide funds to help support NCSU graduate students  working on the project commensurate with their level of  involvement.  These funds will provide salary and living expenses  for students while at Boeing.  While at NCSU, the graduate  students would be supported by traditional research  assistantships through this grant.    It is anticipated that the regular visits the PIs make to the  other team's site would be short (on the order of two to three  weeks per visit), but flexibility for longer visits exists.  The  NCSU students would stay at Boeing for longer periods so as to  become fully integrated in the applications and research.   Students could be at Boeing from anywhere between a few weeks to  several months, depending on project needs and individual  circumstances.    Boeing will also grant a license for use of their nonlinear  optimization software for the use of the team of principal  investigators at North Carolina State University.      It is currently estimated that developing a complete solution to  the optimization  of the path of tool trim problem could result in  a substantial cost reduction of all Boeing machined tools and  parts.  It would also allow Boeing to achieve its targeted  manufacturing rates while stabilizing employment oscillations and  improve the quality of its manufactured parts.  the savings are  expected to be substantial by the year 2000 when it is hoped that  a sizable percentage of the machining tools at Boeing will be  using these methods.  In the years to follow, the cost savings  are expected to be truly dramatic.  Moreover, this is a  fundamental industrial need, used in manufacturing everything  from components of your car's continuous velocity joint, the mold  for your computer's cabinet, to the booster rockets on the Space  Shuttle.  The advances made on the machine path problem would  have a very wide ranging impact.        This GOALI project is jointly supported by the MPS Office of  Multidisciplinary Activities (OMA) and the Division of  Mathematical Sciences (DMS)."
"9803362","Hyperbolic 3-Manifold Theory","DMS","TOPOLOGY, COMPUTATIONAL MATHEMATICS","08/15/1998","06/29/2000","Colin Adams","MA","Williams College","Continuing Grant","Benjamin M. Mann","07/31/2002","$138,600.00","","Colin.Adams@williams.edu","880 MAIN ST","WILLIAMSTOWN","MA","012672600","4135974352","MPS","1267, 1271","0000, 9178, 9229, 9263, OTHR, SMET","$0.00","  9803362  Adams       Hyperbolic 3-manifold theory has had a tremendous impact on the field  of low-dimensional topology.  Outstanding conjectures have fallen, one after  the other, with the application of hyperbolic techniques.  There has been a  shift in the entire approach to low-dimensional topology, as researchers now  use rigid geometric arguments to prove topological theorems.  The two  principal investigators intend to continue their research, both individually  and jointly, on the theory and computation of hyperbolic 3-manifolds.  Through a set of projects, many relying heavily on their ability to compute  explicit examples on a computer, the researchers plan to further the  understanding of the connections between hyperbolic 3-manifolds, the  invariants that come out of hyperbolic 3-manifold theory, and the  traditional topological invariants in 3-manifold theory.  They will also  consider applications of 3-manifold theory to cosmological models of the  spatial universe, working in conjunction with cosmologists.  Undergraduates  will be involved in original research projects related to this research.       A 2-dimensional surface may have positive curvature like a sphere, zero  curvature like a flat Euclidean plane, or negative curvature like a saddle.  Almost all surfaces can be given negative curvature, meaning that locally,  they behave like the hyperbolic plane discovered by Lobachevsky, Gauss, and  Bolyai in the last century.  An analogous understanding of finite  3-dimensional spaces eluded researchers for decades, but in the mid-1970's  W. P. Thurston conjectured that 3-manifolds, the analog of 2-dimensional  surfaces one dimension up, can be cut into pieces, each of which has one of  eight geometries.  He proved the conjecture for vast quantities of  3-manifolds.  By far the most commonly occurring geometry for 3-manifolds is  hyperbolic geometry.  The resulting ""hyperbolic structures"" are rich and  have been used to solve a great many topological and geometrical questions.  T he present project continues this work both theoretically and  computationally.  The theoretical advances make the computations possible,  and the explicitly computed examples guide the further development of the  theory.  In the past year the project has found a new and very exciting  application.  The spatial universe within which we live is an example of a  3-manifold.  Data from NASA's Microwave Anisotropy Probe (MAP) may, in the  year 2001, reveal the spatial universe to be finite in extent.  If so,  algorithms from the present project will be used to determine the exact  shape of the universe.  The investigators are currently extending their  software to tolerate the high levels of noise that will be present in the  MAP data, and to handle the spherical and Euclidean cases as well as the  hyperbolic one.  Preliminary data suggests the real universe is hyperbolic,  but the other possibilities cannot yet be ruled out.  ***"
"9803467","Topology of Nonisolated Singularities and the Geometry      of Functions","DMS","TOPOLOGY, COMPUTATIONAL MATHEMATICS","08/15/1998","05/23/2000","James Damon","NC","University of North Carolina at Chapel Hill","Standard Grant","Benjamin M. Mann","07/31/2001","$84,339.00","","jndamon@math.unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275995023","9199663411","MPS","1267, 1271","0000, 9263, OTHR","$0.00","9803467  Damon       Professor Damon's research will apply infinitesimal methods from  singularity theory (originally introduced by Mather) to investigate  the topological structure of a general class of highly nonisolated  singularities arising as nonlinear sections of varieties.  This class  includes discriminants of mappings, bifurcation sets, nonlinear  arrangements of hypersurfaces, etc.  He will use analogues of Morse  singularities for sections of varieties to derive general algebraic  formulae for certain fundamental topological invariants.  He will also  apply these ideas involving sections of varieties to understand the  geometry of functions using the notion of ""relative critical sets,""  which extend the notion of ridges and ""cores"" used in computer  imaging.  He will combine these geometric techniques with other  singularity-theoretic methods developed for determining generic  properties of solutions to partial differential equations.  Together  they will be applied to ""pixel intensity functions"" representing  medical images.  In conjunction with Gaussian blurring or nonlinear  blurring techniques, they will associate certain geometric structures  that can be used for addressing various questions in medical imaging.       The first part of Professor Damon's research project will concern  qualitative properties of spaces defined as the set of solutions of  specific types of systems of nonlinear equations.  The specific form  of the equations will allow the investigator to use methods from the  field of mathematics called singularity theory.  Specifically, this  allows the analysis of the set of solutions by perturbing the  equations and reducing to the analysis of certain basic cases.  The  total contributions from the basic cases can be determined  algebraically, yielding a qualitative understanding of the structure  of the set of solutions.  Second, such systems of equations will be  specifically applied to analyze medical images.  They allow one to  associate to a medical image a g eometric structure, which captures  essential features of the image.  The geometric structure is defined  using systems of equations of the above type, and it even allows one   first to remove ""noise"" from the image by applying appropriate filters.  The basic properties of the geometric structure obtained from the  first part will allow it to be used to address several questions in  medical imaging.  ***"
"9807666","The Role of Bacterial Chemotaxis in the Biodegradation of   Naphthalene in Porous Media","DMS","COMPUTATIONAL MATHEMATICS, ENVIRO GEOCHEM AND BIOGEOCHEM","09/01/1998","08/24/1998","Michael Aitken","NC","University of North Carolina at Chapel Hill","Standard Grant","Michael Steuerwalt","08/31/2000","$215,000.00","Cass Miller","mike_aitken@unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275995023","9199663411","MPS","1271, 1584","1043, 1584, 9198, 9263, EGCH","$0.00","Aitken  9807666       There is considerable interest in methods of remediating  contaminated soil and ground water by in situ processes,  particularly if remediation can be accomplished through natural  processes such as biodegradation by indigenous microorganisms.  To properly evaluate and develop in situ bioremediation methods,  it is important to understand the dominant physical, chemical and  biological processes.  Biological processes are perhaps the least  understood of these.  The investigator and his colleagues focus  on the potential role of bacterial chemotaxis in the  biodegradation of common soil pollutants in porous media.  They  study the biodegradation of naphthalene, a common soil pollutant,  by Pseudomonas putida G7 in a model porous medium consisting of  uniform glass beads.  The effect of chemotaxis is evaluated by  comparing the rates of mineralization of naphthalene by the  chemotactic wild-type strain and by an immotile or  non-chemotactic mutant strain with the same inherent kinetics of  naphthalene degradation as the wild-type.  A mathematical model  is constructed that incorporates the most significant chemical  and biological phenomena in the experimental system.  The model  is used to quantify the chemotactic and random motility  coefficients of the organism as a function of the size of the  glass beads, and to evaluate the relative influences of random  motility and chemotactic motility in naphthalene biodegradation.       Chemical contamination of soil and ground water is an  enormous problem in the U.S.  The cost of cleaning up  contaminated sites can be reduced dramatically if the  contaminated materials do not have to be excavated or pumped to  the surface for treatment or disposal; consequently there is  great interest in taking advantage of processes referred to as  ""natural attenuation.""  Many bacteria found in the subsurface are  known to be able to degrade a variety of chemicals, but the  behavior of bacteria in soil is relatively poorly understood.  A  commo n property of many bacteria is chemotaxis, an ability to  move in response to the presence of a chemical.  However, the  potential role of chemotaxis in the biodegradation of pollutants  in soil has not been explored before.  It is likely, for example,  that bacteria able to swim towards the sources of chemical  contamination are able to degrade the contaminants faster than  those bacteria unable to do so.  The investigators in this project  conduct experiments with a simulated soil environment and  mathematical modeling techniques to evaluate the potential role  of chemotaxis in the biodegradation of a pollutant found at many  contaminated sites.  An improved understanding of the role of  chemotaxis will permit better characterization of the feasibility  of natural attenuation processes, and may permit the development  of strategies to accelerate the in situ treatment of contaminated  sites that take advantage of bacterial chemotaxis."
"9732742","Deformation Methods for Grid Adaptation","DMS","COMPUTATIONAL MATHEMATICS","08/01/1998","09/01/1999","Guojun Liao","TX","University of Texas at Arlington","Continuing Grant","Michael Steuerwalt","07/31/2002","$186,000.00","Dale Anderson","liao@uta.edu","701 S. NEDDERMAN DR","ARLINGTON","TX","760199800","8172722105","MPS","1271","0000, 9215, 9263, HPCC, OTHR","$0.00","DMS-9732742<br/>Guojun Liao<br/><br/>A key factor to the success of numerical simulation of scientific and engineering problems is that of grid generation of the physical domains.  The objective of the project is to develop an adaptive grid generation method that can be used with various numerical schemes such as finite element, finite difference, etc.  Our method is based on sophisticated mathematics and its numerical implementation is straightforward.  It is the deformation method which redistributes the grid points according to the physical variables that are being simulated.  A monitor function is calculated which is small where the error is large.  The deformation method then moves each grid point according to the monitor function so that the new grid will be concentrated where the need for better resolution exists to reduce the error. Model problems from fluid dynamics and other important applications will be simulated on such moving grids.  We will demonstrate that the method is capable of generating grids that are adapted to the fine features of the physical variables such as shock waves, moving fronts, and boundary layers, etc.<br/><br/>This project is aimed to greatly enhance our ability to simulate large scale computational problems that are crucial to the national strategic interests.  The advance of computing technology allows us to simulate some real world problem without conducting costly experiments.  But the needs for accurate and efficient simulation far exceed the most powerful computers of today.  A lot of simplification and upgrading have to be made to stay within the limit of today's computing capacity.  Fixed grids are wasteful in computing resource.  Our research will lead to software that can automatically put more points to the regions where and when the physical variables change rapidly without adding new points.  This would be very useful for high performance computing and the numerical simulation of material science, environment problems, manufacturing process and other fields that require a grid.  By working in the project, mathematics and engineering students will gain first hand experience on the application of mathematics to the solution of engineering problem.  Advanced degrees will be granted to graduate students who make significant contributions to the project after their completion of course work.<br/>"
"9814331","Linear Algebra:  Theory, Applications, and Computation","DMS","COMPUTATIONAL MATHEMATICS","08/01/1998","07/14/1998","James Nagy","NC","Wake Forest University","Standard Grant","Jong-Shi Pang","07/31/1999","$9,660.00","Todd Torgersen","jnagy@emory.edu","1834 WAKE FOREST RD","WINSTON SALEM","NC","271096000","3367585888","MPS","1271","0000, 9263, OTHR","$0.00","9814331  Nagy    This award will partially support attendance, especially for graduate  students and new investigators, at the conference ""Linear Algebra:  Theory, Applications, and Computations,"" to be held at Wake Forest  University, Winston-Salem, North Carolina, January 8--9, 1999.   The conference intends to recognize Robert Plemmons' outstanding   contributions to core, applied, and computational Linear Algebra on   the occasion of his sixtieth birthday.     The major themes of this conference will be: matrix analysis and  nonnegative matrix theory; large, sparse least squares problems and  parallel algorithms; applications of linear algebra in signal and  image processing.  The primary purpose of the meeting is to bring  together scientists researching in these diverse, yet related areas,  to explore greater commonality.  There will be four invited long  presentations, and twenty-five invited short presentations.  In order  to facilitate interaction between researchers with varying interests,  there will be no parallel sessions.  Contributed papers will be  solicited for informal poster presentations, and new investigators  will be especially encouraged to participate.  The conference will be  held in an intimate setting to encourage interaction between  researchers, and between senior scientists and new investigators.  Research results presented at the meeting will be published in a  special issue of the journal Linear Algebra and its Applications."
"9805584","Computational Topology for Dynamics","DMS","COMPUTATIONAL MATHEMATICS","07/15/1998","08/30/2001","Konstantin Mischaikow","GA","Georgia Tech Research Corporation","Standard Grant","Michael Steuerwalt","06/30/2003","$101,836.00","","mischaik@math.rutgers.edu","926 DALNEY ST NW","ATLANTA","GA","30332","4048944819","MPS","1271","0000, 9232, 9263, OTHR","$0.00","9805584<br/>Mischaikow<br/><br/>The PI proposes to develop techniques, algorithms, and computer code through which the Conley index will become an effective computational tool.  There are a wide variety of problems motivating this development.  The primary issue is that of being able to compute invariant sets for nonlinear dynamical systems arising from differential equations or physical experiments.  Since in general invariant sets can undergo dramatic bifurcations under small perturbations, numerical errors, parameter drift, and noise tend to make direct approximations of invariant sets numerically unstable.<br/><br/>Being an algebraic topological quantity, the Conley index is extremely stable with respect to perturbations.  At the same time it is fine enough to provide useful information  (e.g. symbolic dynamics) about the structure of the invariant set.  Computing the Conley index involves two steps: (1) approximating the dynamics, and (2) computing algebraic topological quantities.  Both of these issues are being addressed in this project. Specific applications include joint work with experimentalists to analyze and control chaotic systems, and the rigorous numerical analysis of low dimensional attractors of high dimensional ordinary differential equations and partial differential equations.<br/>"
"9870274","Numerical Continuation for Nonlinear Problems with Symmetry Structures","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","08/01/1998","07/29/1998","Kurt Georg","CO","Colorado State University","Standard Grant","Deborah Lockhart","07/31/2002","$130,000.00","Eugene Allgower","georg@math.colostate.edu","601 S Howes St","Fort Collins","CO","805232002","9704916355","MPS","1266, 1271","0000, 9215, HPCC, OTHR","$0.00","DMS 9870274<br/><br/>Abstract<br/><br/>Numerical Continuation for Nonlinear Problems with Symmetry Structures<br/><br/>Kurt Georg and Eugene L. Allgower <br/><br/>This investigation deals with the study and development of numerical<br/>continuation methods which intrinsically exploit symmetries. The<br/>integration of techniques for exploiting symmetry in the solution of<br/>linear systems, which have recently been developed by the<br/>investigators, into a numerical continuation method will provide a<br/>practical and efficient tool for detecting symmetry pattern breaking<br/>bifurcations while tracing a branch, and for following bifurcating<br/>branches for secondary and multiple bifurcations. The continuation<br/>methods which will be studied and developed will concentrate upon the<br/>handling of large systems of equations such as those stemming from<br/>discretizations of systems of partial differential equations and<br/>integral  equations.  Several techniques for numerically handling<br/>bifurcations will be investigated. These include the normal form<br/>equations of center manifold theory and the Lyapunov-Schmidt <br/>reduction. By applying symmetry reduction methods developed by the<br/>investigators, block diagonalizations are obtained which greatly<br/>facilitate the bifurcation analysis. Among the applications to be<br/>treated will be: nonlinear elliptic equations such as those which<br/>model the buckling of shells with symmetries, equations for spherical<br/>convection which model planetary atmospheres, Ginzburg-Landau<br/>equations modelling the dynamics of travelling waves, and nonlinear<br/>boundary integral equations which are discretized via boundary element<br/>methods. Integral equations of the latter kind arise in a natural way<br/>from exterior boundary value problems. It is anticipated that the<br/>programs which will be developed will be disseminated via anonymous<br/>ftp in the same manner as the investigator's programs for numerical<br/>continuation and symmetry reduction methods have been done.<br/><br/>Numerical continuation for large structured systems, which will be<br/>studied in this investigation, has a broad  field of important<br/>applications. In particular, numerical continuation can be used to<br/>computationally simulate how the variation of inherent control<br/>parameters causes qualitative changes in a physical system. Such<br/>parameters may represent loading, speed, temperature, viscosity,<br/>aspect ratio, etc. The determination and analysis of critical values<br/>of control parameters is  of great significance to the scientist and<br/>engineer, because at these values decisive phenomena occur: stability<br/>can be lost, structures can break or  go into resonance, ingnition<br/>takes place, atmospheric flow patterns change, etc. Mathematically,<br/>critical values of control parameters in physical models are<br/>characterized by bifurcation points. Numerical continuation methods<br/>can be used to detect and calculate bifurcation points. The<br/>investigation  will concentrate on phenomena taking place in regimes<br/>which have geometric symmetry structures. The consideration of such<br/>structures enhances the scientific understanding, but can also be<br/>exploited for more precise and efficient calculations. The computer<br/>visualization programs which will be developed will assist researchers<br/>and students to simulate, study, and gain insights into the pattern<br/>changes of physical phenomena under the variation of parameters.<br/>"
"9803604","Inverse Diffraction Problems in Optics","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/15/1998","07/16/1998","Gang Bao","FL","University of Florida","Standard Grant","Deborah Lockhart","09/13/1999","$79,200.00","","bao@math.msu.edu","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","MPS","1266, 1271","9146, 9263, MANU","$0.00","9803604  Bao    This project will support research on the mathematical issues and   computational methods for solving the following classes of direct and   inverse problems motivated by industrial applications:  inverse problems   in diffractive optics, modeling of structure enhanced nonlinear optical   effects, and optimal design problems in nonlinear optics. The main topics   of the proposed work include:  Uniqueness, stability, and regularity   properties for inverse problems in optics. Numerical computation of   inverse and optimal design problems in diffractive optics. Modeling of   nonlinear second harmonic generation in periodic structures. Structure   enhanced nonlinear optical effects. Well-posedness of a partial differential   equation model in nonlinear optics. Interface least-squares finite element   methods for solving the model problem. Computational methods for   design and optimization in nonlinear optics.    These problems arise naturally in modeling and design of micro diffractive   optics. Micro diffractive optics is a fundamental, emerging technology in   which optical devices are micromachined with very small structural   features. Exploiting diffraction effects, diffractive structures perform   functions unattainable with conventional optics.  Examples of current and   potential application areas include corrective lenses, electronic displays,   microsensors, lasers, optical storage systems, optical communication   components, and integrated opto-electronic semiconductor devices. The   practical applications and scientific developments have driven the need for   rigorous mathematical models, mathematical analysis, and numerical   algorithms to accurately describe the diffraction of complicated diffractive   structures, to compute electromagnetic vector fields and thus to predict the   performance of a given diffractive structure in linear and nonlinear optical   media, as well as to carry out optimal design of new structures. The   research has significant potential for evo lving new science and providing   industry with guidance to design and fabricate new optical devices."
"9732602","Targeted Proof Machines in Combinatorics","DMS","ALGEBRA,NUMBER THEORY,AND COM, COMPUTATIONAL MATHEMATICS, NUMERIC, SYMBOLIC & GEO COMPUT","07/01/1998","04/20/2000","Doron Zeilberger","PA","Temple University","Continuing Grant","B. Brent Gordon","06/30/2001","$180,000.00","","zeilberg@math.rutgers.edu","1801 N. Broad Street","Philadelphia","PA","191226003","2157077547","MPS","1264, 1271, 2865","0000, 9216, 9263, HPCC, OTHR","$0.00","          Zeilberger  9732602      Zeilberger plans to develop algorithms for automatic discovery and proof of results in combinatorics and related areas. In particular, he plans to mechanize Dodgson's method evaluating hypergeometric determinants, to use techniques from computational linguistics to empirically discover  and then rigorously prove `grammars' of combinatorial families,  and to develop a computational Ansatz for multi-variate rational generating functions. He also proposes to investigate combinatorial analogs of techniques from computational chemistry and to try to prove Haiman's Diagonal Harmonics conjecure.      This research is in the general area of Combinatorics. One of the goals of Combinatorics is to find efficient methods of studying how discrete collections  of objects can be arranged. The behavior of discrete systems is extremely  important to modern communications. For example, the design of large networks, such as those occurring in telephone systems, and the design of algorithms in  computer science deal with discrete sets of objects, and this makes use of  combinatorial research.   This research is also in the general area of Symbolic Computation, that attempts to teach computers to perform research that previously required extensive human resources. Progress in this area promises to have important ramifications to science and technology."
"9802388","RUI:  Geometric Tomography","DMS","GEOMETRIC ANALYSIS, APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/01/1998","06/17/1998","Richard Gardner","WA","Western Washington University","Standard Grant","Christopher Stark","03/31/2002","$115,491.00","","Richard.Gardner@wwu.edu","516 High Street","Bellingham","WA","982259038","3606502884","MPS","1265, 1266, 1271","9146, 9178, 9229, 9251, 9263, SMET","$0.00","Geometric tomography uses data concerning sections by planes and projections on planes of geometric objects to obtain information about these objects. The latter include general compact sets, but often they are convex bodies, polytopes, star-shaped bodies, or finite sets. One advantage of this setting is that it becomes more probable that inverse problems have a unique solution.  Generally, the a priori knowledge that the unknown object is of uniform density can be exploited to retrieve more information than would otherwise be possible. This can lead to algorithms that are more effective when few measurements are available, and less sensitive to measurement errors or noise. Within mathematics, geometric tomography has links to functional analysis, convex geometry, Minkowski geometry, and combinatorics. The project will focus on several topics in this area and continue the development of geometric tomography begun in two previous NSF proposals. New directions include reconstruction of objects from measurements of volumes of projections onto planes or concurrent sections by planes, stability questions related to sections, and the systematic development of discrete tomography (involving inverse problems concerning finite sets). Examples of proposed techniques are the use of recently discovered Fourier transform formulas and of special bodies defined by $p$th means of metric quantities. Also included is a program designed to stimulate undergraduate research.    CAT scanners are machines that save lives daily. They take X-rays in a number of different directions, and synthesize the information to create an image of a two-dimensional section of part of the body. The mathematics behind this process is called computerized tomography. It is very successful, but not perfect; the reconstructed image is only approximate, and to get a better picture with the same procedure one has to take more X-rays, causing greater expense and likelihood of side effects. In geometric tomography, only homogeneous objects ar e allowed-the density of the object is the same everywhere inside it. An example from medicine would be a bone or a kidney. One can use this information to find better reconstruction procedures. The scope of geometric tomography is actually much wider. Any measurement involving sections of a homogeneous object by lines or planes or its shadows on lines or planes can be considered. Because of this, it has many links to other areas, both in mathematics (there is a large overlap with convex geometry, the geometry of shapes without holes or dents) and outside. For example, a new technique in electron microscopy allows measurement of the number of atoms in a crystal lying on certain lines. The material scientist wants to reconstruct the crystal from this information. The object in this case-the crystal-is mathematically represented by a finite set of points.  This project continues the development of several aspects of the mathematics of geometric tomography."
"9802556","Workshop on Constructive Methods in Cellular                Automata Theory","DMS","PROBABILITY, COMPUTATIONAL MATHEMATICS, MATHEMATICAL PHYSICS, THEORY OF COMPUTING, EXPERIMENTAL SYSTEMS/CADRE","06/01/1998","05/20/1998","David Griffeath","WI","University of Wisconsin-Madison","Standard Grant","K Crank","05/31/1999","$12,000.00","","griffeat@math.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","MPS","1263, 1271, 1287, 2860, 4725","0000, 9263, OTHR","$0.00","9702556  Griffeath   This award provides funds to partially support a workshop on cellular automata   theory to be held at the Santa Fe Institute. The purpose of the workshop is to bring   together researchers from different disciplines to help foster the development of rigorous   results in cellular automata. The workshop will focus on three active areas of cellular   automata research: shape and interface theory, constructive analysis of Conway's Life, and   algorithmic complexity of elementary cellular automata."
"9805629","Elliptic Inverse Problems","DMS","COMPUTATIONAL MATHEMATICS","08/15/1998","07/17/1998","Ian Knowles","AL","University of Alabama at Birmingham","Standard Grant","John C. Strikwerda","07/31/2001","$65,731.00","","iknowles@uab.edu","1720 2nd Avenue South","Birmingham","AL","352940001","2059345266","MPS","1271","0000, 9263, OTHR","$0.00"," 9805629<br/> Knowles<br/><br/>This project centers on parameter identification inverse problems.  Typically, in such a problem one is given certain information about the solution of a partial differential equation  and one is hopeful of using this information to compute one or more of the coefficients in the equation.  Such problems are typically  mathematically ill-posed and, to make matters worse, in processing the data in many practical applications, one must contend not only with measurement error but sometimes also with the fact that the readings may only be taken at a rather sparse collection of measurement points. In this proposal we outline a continuation of work on a new and very promising approach to a broad class of parameter identification problems.  At the core of the method is the Dirichlet principle for elliptic boundary value problems, that the solution may be obtained by the minimization of a certain energy functional; that the same energy functional can also be used to compute coefficients in the elliptic equation, if an appropriate constrained minimization is employed, is the significant observation that drives much of the work in this proposal.  Extensive numerical experiments have shown that  the same numerical stability that is associated with the Dirichlet principle approach to finding solutions is also present (assuming the  appropriate stabilization is employed) in the constrained minimization; in particular the method appears to be quite robust in the presence of noise in the data.  The parameter identification problems amenable to this approach are, roughly speaking, those that involve elliptic equations that may besolved by means of a Dirichlet principle; as is well known this is a large class, having considerable practical significance.  In addition, many parameter identification inverse problems involving parabolic (diffusion) and hyperbolic (wave propagation) equations  may be restated to a form covered by this theory, and thus the eventual impact is expected to be even greater.<br/><br/>The first part of the project involves producing working algorithms to identify, from easily obtainable measurements, the various parameters needed to quantify flow in porous media.  This is a crucial step in the modeling of underground water systems and a necessary first step when one wishes for example to manage water resources efficiently, or to predict the effects on an aquifer caused by environmental factors such as flooding or industrial pollution.  The second part of the project is concerned with the problem of imaging inside the human body with electrical impedance tomography.  Here, one attempts, by means of low voltage electrical measurements taken at the surface of a subject, to form an image of the interior.  Such imaging has the advantage of being both non-invasive and non-destructive, and inexpensive; current disadvantages include poor image quality, and it is hoped that improvements can be accomplished by methods related to those used above.  Related practical applications of these ideas include non-destructive evaluations involving the  determination of gas pores, impurities, and cracks in cast metals; such problems are of interest in a variety of manufacturing situations, including the inspection of airplane parts, and also in the manufacture and testing of nuclear reactor containment vessels.<br/>"
"9870420","Numerical Modeling of Problems in Liquid Crystals","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/15/1998","07/16/1998","Eugene Gartland","OH","Kent State University","Standard Grant","Hans Engler","06/30/2001","$68,502.00","","gartland@math.kent.edu","OFFICE OF THE COMPTROLLER","KENT","OH","442420001","3306722070","MPS","1266, 1271","0000, 9263, OTHR","$0.00","This grant supports ongoing research in the area of   numerical modeling of basic and applied problems that arise  in the physics of liquid crystals.  The work is interdisciplinary   in nature, involving collaborations with physicists in the Liquid   Crystal Institute at Kent State University as well as with   computer scientists and applied and computational mathematicians   at Kent, Purdue University, and the Courant Institute.  The   emphases of the work will be in three project areas: (1) numerical   modeling of equilibrium orientational properties of confined   liquid crystal materials, (2) developing and utilizing modern CS  problem-solving environments (for rapid prototyping of such numerical   codes and packages), and (3) numerical modeling of the interaction   between a laser beam and the liquid-crystal medium through which it   is propagating (to investigate and validate modeling and asymptotic   analyses performed on such a system by a group at Courant).    Liquid Crystals are materials capable of existing in states   (call ""mesophases"") in between solids and liquids.  They enjoy   properties of both.  They are fluid; yet their molecules tend   to orient themselves in certain preferred ways (depending on   inter-molecular forces, geometry, conditions at boundaries,   external applied electric or magnetic fields, and the like).  They have significant commercial importance because of applications   in the display industry.  Modern liquid crystal devices (with   microscopic geometry and interfering neighboring effects) now   require considerable two- and three-dimensional numerical modeling   for analysis and design.  The proposed work will contribute  to the advancement of the general state of the art for this type   of scientific computing while numerically modeling specific   systems of current interest."
"9803397","Theory and Applications of Some Inverse Problems in PDE","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/01/1998","06/18/1998","Victor Isakov","KS","Wichita State University","Standard Grant","Deborah Lockhart","06/30/2001","$62,900.00","","victor.isakov@wichita.edu","1845 Fairmount","Wichita","KS","672600007","3169783285","MPS","1266, 1271","0000, 9146, MANU, OTHR","$0.00","The PI intends to continue his study of uniqueness and stability for certain <br/>important inverse problems. The contemporary methods of the theory of <br/>partial differential equations will be used. Those include Carleman type <br/>estimates, the Fourier integral operators, potential theory, and general <br/>functional analytic approach. An emphasis is on inverse problems with <br/>local/partial boundary measurements, on increasing stability by isolating <br/>ill-posedness in a simple linear transform, on recovery of non-linear <br/>equations, and on interaction between inverse problems and optimal <br/>control theory. Based on the theory the PI plans to develop efficient <br/>numerical algorithms for the following important applied inverse <br/>problems.<br/>      The applied focus of the project will be on <br/>-     the problem of electromagnetic detection of the active part of human <br/>brain<br/>-     identifying a source of acoustical noise located on the surface of an <br/>aircraft cabin from interior measurements<br/>-     finding constitutive laws for complicated non-linear physical systems, <br/>including underground flows in porous media and chemical reactions<br/>-     reconstruction of the volatility coefficient of options trading from <br/>current market data.<br/>The second problem is of immediate importance in designing less noisy <br/>cars and midsize aircraft. The fourth one is about prediction of the future <br/>state of the very important financial area influencing the life of <br/>contemporary society.<br/>"
"9805507","Chaos and Crystallographic Symmetry","DMS","COMPUTATIONAL MATHEMATICS","06/01/1998","04/30/1998","Clifford Reiter","PA","Lafayette College","Standard Grant","John C. Strikwerda","05/31/2001","$140,000.00","","reiterc@lafayette.edu","730 High Street","Easton","PA","180420000","6103305029","MPS","1271","9141, 9178, 9229, 9251, 9263, SMET","$0.00","Reiter  9805507    Chaos and Crystallographic Symmetry    Recent investigations have led to illustrations of attractors arising  from the iteration of functions that are measurably chaotic but  nonetheless have specified nontrivial symmetry.  This requires  determination of classes of functions with suitable equivariance  properties along with searches for parameters yielding nontrivial  behavior and visualization techniques suited to the attractor.  This  investigation is designed to advance that work to the crystallographic  space groups.  The classes of equivariant functions need to be  identified, nontrivial parameters located and the attractors  visualized.  It is expected that viewing parameters can be changed in  real time at low resolution and fixed images and animations routinely  created at high resolution.  This task is challenging and interesting  because of the mathematical complexity of the 230 crystallographic space  groups and the difficulties in rendering attractors in three dimensions  in a manner in which the symmetries are apparent.  It is expected that  this work will allow viewers to experience the features of these  symmetry groups in new ways.    The general focus of this project is to find and visualize certain  complex mathematical objects in three dimensions using a high  performance workstation; the particular objects are chaotic attractors  with crystallographic symmetry.  These mathematical objects have an  underlying chaotic structure while at the same time exhibiting a high  degree of symmetry.  The symmetries which will be considered are those  associated with crystals; these symmetries have been of great interest  to chemists for that reason.  Similar two dimensional objects have been  the subject of considerable recent study by mathematicians and this  project is designed to extend our understanding of objects of this type  to three dimensions.  A graphics workstation with massive memory will be  used to create high quality images of these complex objects.  Sin ce  these complex objects are the result of literally millions or billions  of data points, creating insightful, meaningful visual representations  of the data is essential to understanding them.  The high level  visualization techniques and the resulting insights into the three  dimensional symmetries of these objects should be of interest to  mathematicians and others, like chemists, who can benefit from  understanding these symmetry groups.  The project is designed to fully  involve several undergraduate students in the research and hence these  students will not only gain valuable experience with using this high  performance workstation but they should also be among the first to view  these symmetry groups in the new ways resulting from this research  project."
"9802259","The Numerical Analysis and Application of High Dimensional  Higher Index DAEs","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, PRODUCTION SYSTEMS, Manufacturing Machines & Equip","07/01/1998","07/06/1998","Stephen Campbell","NC","North Carolina State University","Standard Grant","Deborah Lockhart","06/30/2002","$200,000.00","","slc@math.ncsu.edu","2601 Wolf Village Way","Raleigh","NC","276957514","9195152444","MPS","1266, 1271, 1465, 1468","9148, 9216, 9263, HPCC, MANU","$0.00","9802259  Campbell    A differential algebraic equation  (DAE) is  a system of equations  relating various quantities with some of their derivatives.  However,  unlike with an ordinary differential equation (ODE), the equations do  not directly provide all the derivatives of the state variables.     A  nonnegative integer called the  index is one measure of how far a DAE  is from an ODE which is index zero.  The higher the index the greater the  difficulty in working with the system.   Many  physical problems are  most naturally initially modeled as a DAE particularly those that are  analyzed and simulated using computer generated mathematical models.  Because of the importance of DAEs in applications a variety of numerical  techniques have been developed in recent years to simulate and analyze  DAEs.  These techniques, while very useful, are limited to systems with  special structure and low index (no more than three and often limited to  one or two)    This project is to investigate the analysis, simulation, and application of  high dimensional, higher index DAEs of unknown and nonstandard structure.  Two applications, of considerable independent interest, will be considered  to serve as both application of, and guide for, the theoretical,  analytic,  and numerical work.  The first application is the optimization of the path  of a trim tool.  A trim tool is a machine used for cutting a part from a  piece of metal.  Improved performance of trim tools is of great importance  for manufacturing and industrial competitiveness.  The second application is  the simulation of densely packed high frequency circuits for which current  industrial simulation packages are inadequate.  The robust solution of these  types of problems requires additional fundamental theoretical results and  algorithms for high index high dimensional DAEs.  This project will develop  theory and computational algorithms for high index high dimensional  DAEs and apply them to the two applications.  For both of these  applications  the high fidelity models needed are mixed systems of partial  differential equations, DAEs, and  constraints.  Their  solution will  require  examining the interplay between type of  model, type of approximation process,  and resulting types of DAEs."
"9806413","Collaborative Research on Numerical Methods for Image       Processing","DMS","COMPUTATIONAL MATHEMATICS","07/01/1998","06/26/1998","Lothar Reichel","OH","Kent State University","Standard Grant","Thomas W. Fogwell","12/31/2001","$86,401.00","","reichel@math.kent.edu","OFFICE OF THE COMPTROLLER","KENT","OH","442420001","3306722070","MPS","1271","9216, 9263, HPCC","$0.00","9806413  Reichel    The numerical solution of image processing problems gives rise to very large  nonsymmetric linear systems whose solutions are extremely sensitive to   perturbations in the data. To avoid or at least contain the disastrous   effects of such instability, regularization is required. Regularization   yields slightly modified problems which are less sensitive to inaccuracies   in the data.    The aim of the research by the investigator and his colleague is to develop  effective and efficient regularization methods for the solution of large   nonsymmetric linear systems that arise in image processing applications,   as well as to develop new algorithms for image compression. The new   numerical methods will be tested on medical imaging data and will be   applied to interventional magnetic resonance imaging in collaboration with the   department for Biomedical Engineering at Case Western Reserve University."
"9803759","Adaptive Control Algorithms for Adaptive Optics Applications","DMS","COMPUTATIONAL MATHEMATICS","07/01/1998","06/26/1998","Moody Chu","NC","North Carolina State University","Standard Grant","Thomas W. Fogwell","05/31/2002","$63,885.00","","chu@math.ncsu.edu","2601 Wolf Village Way","Raleigh","NC","276957514","9195152444","MPS","1271","0000, 9263, OTHR","$0.00","Chu  9803759      This research concerns the design, analysis and performance  evaluation of adaptive control algorithms for adaptive  optics applications. This investigation could lead to  improved techniques for use in several areas of applications,   including ground-based astro-imaging processing, medicine,  communications, and laser technology. One specific area  is the deformable mirror control computation for adaptive-optics  systems to compensate for atmospheric turbulence. The challenges   in this application are that atmosphere changes rapidly and that   the statistics of the turbulence usually is unknown. The purpose   of this study is threefold: (1) to develop a mathematical theory   on how the turbulence statistics can be estimated using measured  data, (2) to design a fast algorithm that enables efficient   computation in real time, and (3) to integrate the theory and the   algorithm into real application facilities."
"9870323","Thurston-Nielsen Theory and Fluid Mixing","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/15/1998","07/16/1998","Philip Boyland","FL","University of Florida","Standard Grant","Deborah Lockhart","06/30/2002","$78,000.00","","boyland@math.ufl.edu","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","MPS","1266, 1271","0000, 9263, OTHR","$0.00","DMS-9870323<br/><br/>Thurston-Nielsen theory and Fluid Mixing<br/><br/>Philip Boyland<br/><br/>The Thurston-Nielsen theory provides a powerful collection of tools to<br/>analyze and understand two-dimensional dynamical systems.  The theory<br/>has potential for significant advances in the study of two-dimensional<br/>systems of physical interest.  Among the most interesting and important<br/>come from fluid mechanics.  Dr. Boyland will use Thurston-Nielsen<br/>theory in conjunction with other dynamical tools to obtain a deeper<br/>understanding of two-dimensional fluid mixing.  Various mathematical<br/>extensions of the Thurston-Nielsen theory will be obtained.  These<br/>extensions would enhance the applicability of the theory as well as<br/>being of intrinsic mathematical interest.  In addition, numerical and<br/>laboratory experiments are proposed with the goal of designing<br/>effective mixers and understanding many vortices as a model for<br/>two-dimensional turbulence.<br/><br/>The mixing of different species of materials is extremely common in<br/>natural systems and industrial applications.  The main scientific<br/>question is to understand how the mixing takes place, while in<br/>industrial applications the focus is usually on the development of<br/>schemes for effective mixing.  In many applications high viscosity,<br/>sensitivity of materials, the need to avoid foaming, and other<br/>constraints make turbulence mixing infeasible and undesirable.  Thus in<br/>most instances the design of useful mixing procedures requires close<br/>attention to efficiency.  The added mathematical understanding made<br/>possible by this project should help in this design process, providing<br/>novel ideas for efficient mixing procedures and helping to eliminate<br/>inefficient ones prior to expensive experimentation. In addition, this<br/>project will make a powerful body of pure mathematics more accessible<br/>for application to problems of physical and industrial importance.<br/>"
"9812786","Workshop on Uncertainty in Modeling and Simulation","DMS","COMPUTATIONAL MATHEMATICS","08/01/1998","07/30/1998","James Crowley","PA","Society For Industrial and Applied Math (SIAM)","Standard Grant","Michael Steuerwalt","07/31/1999","$18,380.00","","jcrowley@siam.org","3600 Market St.","Philadelphia","PA","191042688","2153829800","MPS","1271","0000, 9263, OTHR","$0.00","Crowley  9812786       The investigator and his colleagues organize a workshop on  uncertainty in modeling and simulation.  Its aim is to sketch out  broad scientific questions and promising avenues of research  related to uncertainty issues, to document the potential impact  of the issues, and to produce a report outlining key research  issues.  The report will be distributed in print and via the web.       Uncertainty issues arise throughout science and engineering.  The problems these fields tackle involve nonlinear phenomena and  complex systems that are not well understood; observations are  not error-free and are irregular in space and time (weather and  climate data typify these characteristics); and many natural and  engineering processes are inherently stochastic or chaotic.  The  mathematical and statistical models of such systems share the  same features of complexity, nonlinearity, and stochasticity.  Scientists, mathematicians, and engineers analyze and compute  with these models to understand and predict the underlying  systems.  Therefore the recognition and the management of  uncertainty are important issues in both analysis and computation  as well.  Hence the meeting involves engineers, mathematicians,  and scientists.  The interplay between these disciplines is  essential to form the required perspective of opportunities and  challenges that arise from dealing with uncertainty.  Identifying  key research issues is an important step in guiding research; the  results affect every area of science and engineering."
"9996254","Formation Process and 3-D Dynamics of Vortex Rings","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","12/17/1998","05/03/1999","Monika Nitsche","NM","University of New Mexico","Standard Grant","Deborah Lockhart","08/31/2000","$23,299.00","","nitsche@math.unm.edu","1700 Lomas Blvd. NE, Suite 2200","Albuquerque","NM","871310001","5052774186","MPS","1266, 1271","9216, HPCC","$0.00",""
"9804739","Participant Support for Newton Institute Program on         Biomolecular Function and Evolution in the Context          of the Genome Project","DMS","COMPUTATIONAL BIOLOGY ACTIVITI, Genetic Mechanisms, PHYLOGENETIC SYSTEMATICS, POPULATION DYNAMICS, PROBABILITY, STATISTICS, COMPUTATIONAL MATHEMATICS","06/15/1998","06/09/1998","Thomas Kurtz","WI","University of Wisconsin-Madison","Standard Grant","K Crank","05/31/1999","$43,500.00","","kurtz@math.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","MPS","1107, 1112, 1171, 1174, 1263, 1269, 1271","0000, 9263, OTHR","$0.00","9804739  Kurtz   The problems facing molecular biologists in understanding and analyzing the flood   of molecular genetic sequences and structures resulting from the Genome Projects raise a   range of challenging biomathematical research questions. The Newton Institute will host a   program on ""Biomolecular Function and Evolution in the Context of the Genome   Project."" This inter-disciplinary program, on the function, structure and evolution of   molecular sequences, will bring mathematicians and computer scientists working on   subjects such as probabilistic modeling, stochastic processes, geometry, statistical data   analysis, computational complexity, neural networks, genetic algorithms and expert   systems, together with molecular biologists working in medical and biological fields. This   award will support participation by US researchers. US participants will include graduate   students and postdoctoral and senior researchers."
"9804985","High Order Methods for Shock Calculations and Computational Electromagnetics","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, CONTROL, NETWORKS, & COMP INTE","09/01/1998","06/17/1998","Chi-Wang Shu","RI","Brown University","Standard Grant","Deborah Lockhart","08/31/2002","$210,000.00","","chi-wang_shu@brown.edu","BOX 1929","Providence","RI","029129002","4018632777","MPS","1266, 1271, 1518","9216, 9263, HPCC","$0.00","The objective of the proposed research is to study high order numerical<br/>methods for shock calculations and for computational electromagnetics.<br/>High order methods can resolve complicated physical problems with a<br/>relatively coarse mesh, hence reducing computational cost for such<br/>problems.  However, high order methods for shock calculations and for<br/>computational electromagnetics involve many theoretical and practical<br/>issues which must be investigated.  The proposed work involves the<br/>development, analysis, and applications of high order finite difference,<br/>finite element and spectral methods in the applications areas of<br/>computational fluid dynamics and computational electromagnetics.<br/>Two emphasized aspects of the proposed effort are complex geometries<br/>and efficient parallel implementations. In particular, the proposal contains the following components: high order methods for shock wave calculations, including finite difference ENO and WENO schemes, finite element discontinuous Galerkin methods, spectral methods, and high order methods in computational<br/>electromagnetics, including spectral methods, spectral multidomain<br/>methods, and absorbing layers. It is expected that the proposed effort will improve the state of art in high order methods for discontinuous problems and long time integrations, especially in complex geometry.<br/><br/><br/>"
"9803480","Generalized Nonlinear Schrodinger Equations and             Applications to Superfluid Turbulence","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","10/01/1998","10/17/2001","Paul Roberts","CA","University of California-Los Angeles","Continuing Grant","Deborah Lockhart","03/31/2002","$169,000.00","Natalia Berloff","roberts@math.ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","MPS","1266, 1271","0000, 9263, OTHR","$0.00","DMS 9803480    Paul Roberts, Natalia Berloff    GENERALIZED NONLINEAR SCHRODINGER EQUATIONS AND APPLICATIONS       TO SUPERFLUID TURBULENCE    The proposed research has three closely related objectives.  The first  is to develop and study new variants of the nonlinear Schroedinger  equation (NLS) that are more faithful to superfluid helium. In real  helium, even in the low temperature range, normal fluid is present  which is coupled to the superfluid and which, through its viscosity,  provides a high wavenumber energy sink. So the existing models need to  be modified to include the mutual friction with the normal fluid. To  evaluate the energy loss of interactions with the normal fluid one  needs the kinetic coefficients in the Landau two-fluid model.  Calculations of these coefficients are usually performed with a  simplistic dispersion relation, i.e., the relation between the  frequency of sound waves and their wavenumber. For example, the  dispersion relation is supposed anomalous and with no roton minimum. We  shall study models in which the interaction potential is nonlocal and  which imply the correct dispersion curve.  The second objective is to  analyze such dissipative NLS models from the point of view of dynamical  systems. We shall study and classify attractors, bifurcation sequences,  and routes to chaos. The third objective is to make use of the results  to elucidate superfluid turbulence in the low temperature regime where  the density of the normal fluid component is smaller than the density  of the superfluid component and where one may expect turbulence in the  superfluid largely to determine turbulence in the normal fluid.    Our investigations will provide targets for experimental work in the  low temperature range. Such experiments are currently in the planning  stage by the Donnelly group at the University of Oregon.  There may be  important implications well beyond the field of liquid helium research:  similar ideas may apply to the newly discovered, high temperature  super conductors, to systems of magnetic spins, to the melting  transition of crystals, and to some cryogenic engineering applications.  Superfluid Helium is used as a coolant in superconducting magnets and  infrared detectors, and superfluid turbulence affects the transfer of  heat in such devices. An understanding of superfluid turbulence may  make it possible to design more efficient methods of refrigeration for  superconducting devices.  Turbulence in ordinary fluids is one of the  most formidably difficult subjects in physics and engineering.  Superfluid turbulence is similar but in some respects simpler for  theoretical study, and it is believed that some of the models we shall  develop will throw light onto turbulent behaviors in ordinary fluids."
"9872890","KDI:  Towards Ideal Data Representations","DMS","COMPUTATIONAL MATHEMATICS, COLLABORATORIES, NUMERIC, SYMBOLIC & GEO COMPUT, KDI OPPORTUNITY FUND","10/01/1998","09/17/2002","Amos Ron","WI","University of Wisconsin-Madison","Standard Grant","Michael Steuerwalt","09/30/2003","$2,570,000.00","David Donoho, Peter Schroder, Ingrid Daubechies, Ronald DeVore","amos@cs.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","MPS","1271, 1921, 2865, 8876","0000, 1337, 1338, 5980, 9139, 9263, HPCC, OTHR","$0.00","9872890<br/>Ron<br/>     Advances in communication, sensing, and  computational power<br/>have led to an explosion of data.  The size and varied formats for<br/>these datasets challenge existing techniques for transmission,<br/>storage,   querying, display,  and numerical manipulation,  to<br/>the point where limits on their accessibility and portability may<br/>severely restrict their usefulness for human knowledge.  This<br/>often leads to the paradoxical situation where experiments or<br/>numerical computations produce rich, exquisitely detailed<br/>information, for which, at this point,  no adequate analysis<br/>tools exist.    In order to address this challenge, the<br/>investigator and his colleagues develop a new technology for data<br/>representation based on the two  basic principles of   multiscale<br/>decompositions and redundant representations.   Multiscale<br/>decompositions arrange data into strata reflecting their relative<br/>importance.  This allows for rapid access to good coarse<br/>resolution of the data while retaining the flexibility for<br/>increasingly fine representations.  Redundant representations<br/>allow for a multitude of data decompositions.  While this on the<br/>surface appears contrary to the need for efficiency, the<br/>redundancy gives the flexibility of choosing `best<br/>representations'   from a unified family of representers and<br/>thereby provides efficiency and robustness.  The proposed<br/>research is expected to deliver major results for: (i) accurate<br/>representation of image and acoustic data, (ii) parsimonious<br/>representation of high dimensional data, (iii) parsimonious<br/>representation of images and volumetric objects with<br/>singularities along curves and surfaces, (iv) acceleration of<br/>scientific/engineering computations.<br/>     The KDI initiative takes place at a time when intellectual<br/>and commercial life are beginning to feel the effects of a<br/>revolutionary combination: sensor ubiquity, computational<br/>ubiquity, and internet connectivity.  A clear priority in all<br/>fields of commercial, engineering, and scientific endeavor must<br/>be to identify and exploit the opportunities available in this<br/>new era.  The center of the effort  should be the intensive<br/>development of new schemes for representing digitally acquired<br/>data, and for rapidly manipulating those representations.  In<br/>fact, advances in this central area have tremendous<br/>repercussions, accelerating progress in every other area.  For<br/>astronomers straining to detect faint gravitational signals<br/>coming from the farthest reaches of the universe, or looking back<br/>in time to the earliest moments after creation, searching for<br/>temperature fluctuations that would give clues about the central<br/>theories of physics; for geophysicists looking for subtle<br/>deformations in the earth's inner structure for clues about our<br/>seismic future; for engineers developing new medical imaging<br/>devices;  even for Hollywood entrepreneurs wanting more realistic<br/>computer graphic simulations for mass entertainment -- data<br/>representation plays a key role.  To this end, this project<br/>assembles a team of experts to address issues of developing new<br/>data representations and new methods of analysis and<br/>manipulation.  The premise of this venture is that significant<br/>advances in data representation  require an interdisciplinary<br/>effort, meshing the skills and knowledge of theoreticians and<br/>practitioners from varied fields of research that involve large<br/>datasets.  Thus, the proposed research team consists of<br/>mathematicians, statisticians, computer scientists, and engineers<br/>with extensive skills and experience in  the development and use<br/>of representations for datasets.  A primary component of the<br/>project is the  set of application areas in image and signal<br/>processing, large scale computation, and computer graphics.  The<br/>project produces conceptual deliverables in the form of new<br/>methods for storing, compressing, denoising, and querying data.<br/>It also produces concrete deliverables in the form of algorithms<br/>and software for use in the scientific and commercial sector.  The<br/>project serves as a national center for data representation.<br/>Interaction between the project and other national and<br/>international centers treating datasets is cultivated.  The<br/>project also provides a national resource for theoretical<br/>advances, techniques of implementation, and software development.<br/><br/>"
"9805602","Computational and Mathematical Investigations in            Optimization","DMS","COMPUTATIONAL MATHEMATICS, NUMERIC, SYMBOLIC & GEO COMPUT, OPERATIONS RESEARCH","07/15/1998","07/27/2000","Michael Todd","NY","Cornell University","Continuing Grant","Junping Wang","06/30/2002","$359,992.00","Leslie Trotter, Yuying Li","mjt7@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","MPS","1271, 2865, 5514","0000, 9263, OTHR","$0.00","9805602<br/>Todd<br/><br/>The goal of this project is to continue a broad set of ongoing studies concerning optimization algorithms and the mathematical theory underlying them.  The project covers continuous and discrete optimization algorithms, both exact and approximate, their computational complexity, practical large-scale implementation, performance guarantees (in the case of approximate algorithms), and applications in such areas as crew-scheduling, image-processing, facility location, financial modeling, electrical power systems, and statistical learning theory.<br/><br/>The research to be conducted can be roughly grouped into three areas.  The first is interior-point methods, including the study of: semidefinite programming, algorithm design and analysis; infeasible-interior-point methods for both linear and convex programming, including detection of infeasibility; the complexity of target-following methods and of semidefinite programming; and methods for large-scale nonlinear problems arising in image-processing, financial modeling, and statistical learning theory.  The second area of research is combinatorial optimization, encompassing:  investigation of stable-set and crew-scheduling problems; the study of linear congruence relations and their use in branch-and-cut methods; analysis of inconsistent linear inequality systems, with applications in computer vision, data compression, and statistical discriminant analysis; and design of approximation algorithms for facility location problems.  The third is concerned with numerical linear algebra, and will study: methods to solve the linear systems that arise at each iteration of an interior-point semidefinite programming algorithm in a stable manner; and special methods for obtaining accurate solutions to ill-conditioned linear systems arising in electrical power systems.<br/><br/>This research will lead to improved algorithms to find exact or approximate solutions to large-scale optimization problems arising in industry, finance, the military, science, and engineering.  Emphasis is placed on the interplay between practice and theory.<br/><br/>"
"9729260","Third International Conference on Monte Carlo and           Quasi-Monte Carlo Methods in Scientific Computing to be     held June 22-26, 1998, in Claremont, California","DMS","STATISTICS, COMPUTATIONAL MATHEMATICS","04/15/1998","04/08/1998","Jerome Spanier","CA","Claremont Graduate University","Standard Grant","John C. Strikwerda","09/30/1999","$12,267.00","","jspanier@uci.edu","150 East Tenth Street","Claremont","CA","917115909","9096079296","MPS","1269, 1271","0000, 9263, OTHR","$0.00","Spanier  DMS 9729260      Monte Carlo & Quasi-Monte Carlo methods are very active and pervasively influential areas of applied mathematics in which highly sophisticated uses of mathematical modeling, simulation and probability theory are used to solve a wide variety of real-world problems not amenable to other solution methods. Conventional Monte Carlo methods provide tools for studying such problems on a computer, making use of probability theory and statistical error estimation. Quasi-Monte Carlo methods are essentially deterministic versions of Monte Carlo methods, based not on randomly chosen samples but carefully chosen deterministic nodal sets. Their analysis utilizes number theory, combinatorics, abstract algebra and even algebraic geometry. And in the past several years, exciting new hybrid methods, combining the best features of both stochastic and deterministic models, have been developed for application to many of the most difficult of today's problems.     The Third International Conference on Monte Carlo and Quasi-Monte Carlo Methods in Scientific Computing, to be held in Claremont, California June 22-26, 1998, will assess recent progress in Monte Carlo and Quasi-Monte Carlo theory and address the application of these methods to a range of problems challenging scientists, engineers and economists today, problems arising in nuclear physics and engineering, semiconductor and computer modeling, cryptanalysis, oil exploration, and financial engineering - to name just a few important applications."
"9803568","Computational Electromagnetic Methods in Nonlinear Optics   and Microwave Material Processing","DMS","COMPUTATIONAL MATHEMATICS","08/01/1998","10/05/2001","Cheryl Hile","NJ","New Jersey Institute of Technology","Standard Grant","Leland Jameson","07/31/2003","$90,000.00","","","University Heights","Newark","NJ","071021982","9735965275","MPS","1271","0000, 9263, OTHR","$0.00","DMS-9803568    Cheryl V. Hile    TECHNICAL DESCRIPTION  ---------------------  The research in this project focuses on the development of efficient  computational electromagnetic methods that will be utilized to gain a  fundamental understanding of (1) ultrashort pulse propagation in nonlinear  optical fibers and devices and (2) microwave material processing systems.  The  first project focuses on understanding the behavior of ultrashort pulse  propagation in nonlinear optics fibers and devices by (1) developing  computational solutions of Maxwell's equations and (2) determining the extent to  which asymptotic envelope approximations can be used to describe these pulses.  Specifically, we develop computational solutions of Maxwell's equations to  understand the behavior of one-dimensional pulse propagation near the zero  dispersion wavelength in dispersion-shifted optical fibers and to understand the  behavior of two-dimensional pulse propagation of ultrashort spatial solitons.  In parallel with this, we derive corresponding envelope equations and determine  the extent to which these more simplified equations can be used to model  ultrashort pulse propagation near the zero dispersion wavelength and  two-dimensional pulse propagation of ultrashort spatial solitons.  The second  project focuses on the development of efficient hybrid numerical methods to  model microwave material processing in single- and multi-mode cavity heating  systems.  We will begin by developing an efficient hybrid numerical method to  model the electromagnetic interaction of a low-loss ceramic in a high-Q  single-mode waveguide applicator.  Finally, we will extend these ideas to create  a hybrid numerical method for modeling high-Q multi-mode cavity heating systems.    NON-TECHNICAL DESCRIPTION  -------------------------  The research in this project focuses on the development of efficient  computational electromagnetic methods that will be utilized to gain a  fundamental understanding of (1) ultrashort pulse propagation in  nonlinear  optical fibers and devices and (2) microwave material processing systems.  Understanding these complex phenomena and processes is essential for the  development of new optical technologies and the industrial production of high  quality materials and products.  The first aspect of this project focuses on  understanding the behavior of ultrashort pulse propagation in nonlinear optics  fibers and devices by (1) developing computational solutions of Maxwell's  equations and (2) determining the extent to which asymptotic envelope  approximations can be used to describe these pulses.  The second aspect of this  project focuses on the development of efficient hybrid numerical methods to  model microwave material processing in single- and multi-mode cavity heating  systems.  These numerical methods will provide detailed knowledge of the  interaction between the waveguide applicator, the electromagnetics fields and  the ceramic in these microwave heating systems.  Detailed knowledge of this  interaction will lead to a more complete characterization of the heating process  and thereby help to prevent nonuniform heating and lead to future optimizations  of the heating process."
"9809815","An International Symposium on Discontinuous Galerkin        Methods:  Theory, Computation and Applications","DMS","COMPUTATIONAL MATHEMATICS","09/01/1998","10/26/1999","George Karniadakis","RI","Brown University","Standard Grant","Jong-Shi Pang","08/31/2000","$14,765.00","Chi-Wang Shu","George_Karniadakis@brown.edu","BOX 1929","Providence","RI","029129002","4018632777","MPS","1271","0000, 9263, OTHR","$0.00","9809815  Karniadakis    A new class of projection methods, the Discontinuous Galerkin Methods (DGM),  has been developed recently and has found its use very quickly in such diverse applications as aeroacoustics, semi-conductor device simulation, turbomachinery, turbulent flows, materials processing, MHD and plasma simulations, and image processing. While there has been a lot of interest from mathematicians, physicists and engineers in DGM, only scattered information is available and there has been no prior effort in organizing and publishing the existing volume of knowledge on this subject.    The authors of this proposal plan to organize the first international symposium on DGM with equal emphasis on the theory, numerical implementation, and applications. They plan to publish a book to serve as the first reference on this subject with both review articles and state-of-the-art contributions presented at the symposium. The Symposium will include both invited papers as well as other contributions in order to encourage wider participation especially from young scientists and under-represented minorities."
"9802309","Collaboration on Inverse Problems Using Holographic Image   Data; Using RAM Theory","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/01/1998","07/12/2000","Joyce McLaughlin","NY","Rensselaer Polytechnic Institute","Continuing grant","Henry Warchall","06/30/2002","$124,200.00","","mclauj@rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","MPS","1266, 1271","0000, 9178, 9183, 9251, 9263, BIOT, OTHR, SMET","$0.00","The principal investigator and her colleague Yulia Karpeshina will <br/>collaborate to solve inverse problems for holographic image data using <br/>Kolmogorov-Arnold-Moser (KAM) theory.  The goal is to use selected <br/>level sets of mode shapes of vibrating systems as data for the inverse <br/>problem. With these level sets as data, formulas will be established.  The <br/>formulas will then be used to determine physical properties of the system, <br/>such as density or stiffness.  The results will be based on perturbation <br/>results for the natural frequencies and the mode shapes.  The difficulty in <br/>establishing these results arises from the fact that a small divisor problem <br/>and a sequence of Eikonal equations must be solved simultaneously.  A <br/>consequence of the resultant mathematical structure will be that the <br/>perturbed quantities can be strongly different from the unperturbed <br/>quantities.  McLaughlin's graduate student will concentrate on developing <br/>formulas to use the data and on numerical implementation of those <br/>formulas.<br/><br/>The goal with this work is to consider membrane like materials, such as a <br/>thin slice of biological tissue.  Excite this membrane with an oscillating <br/>force and suppose the frequency of oscillation is a natural frequency, that <br/>is, a frequency where the membrane gives a large response. Illuminating <br/>the vibrating surface with two lasers we see a dark and light line pattern.  <br/>Each line is a level set of the vibrating surface.  Now assume that the <br/>membrane is nonhomogeneous; it could be more stiff or less stiff in some <br/>places.  [In the biological example, increased stiffness can indicate the <br/>presence of rapidly dividing cells.  In a mechanical example, decreased <br/>stiffness can indicate deterioration of the material.] The goal is to <br/>determine the stiffness variations without altering the membrane, that is, to <br/>find a nondestructive test for the stiffness variations.  Our data is the dark <br/>and light line pattern. The problem is difficult because the stiffness <br/>variations can have (but not always) a very large perturbative effect on the <br/>pattern.  The mathematics will establish when the perturbation is large, <br/>when it is not, and what formulas will yield the stiffness variations from <br/>this particular data set.<br/>"
"9803605","Computation of High-Gradient Phenomena in Solid Mechanics","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/01/1998","06/25/1998","Dawn Lott","NJ","New Jersey Institute of Technology","Standard Grant","Hans Engler","06/30/2001","$57,550.00","","dlott@desu.edu","University Heights","Newark","NJ","071021982","9735965275","MPS","1266, 1271","9161, 9263, AMPP","$0.00","The aim of this research is the development and implementation<br/>of effective numerical methods for the solution of partial differential <br/>equations which model the nonlinear mechanics of solids.  The principal <br/>investigator will use numerical methods to study quasilinear<br/>partial differential equations governing large motions of nonlinearly <br/>elastic, elastoplastic and viscoplastic materials.  <br/>The equations governing the motions of such materials are generally <br/>systems of hyperbolic conservation laws which are ideally suited for <br/>numerical study. In particular, the PI will utilize an efficient numerical <br/>scheme based on finite-difference approximations and inspired by numerical <br/>methods from gas dynamics in order to study antiplane and radial motions <br/>of elastoplastic materials, with the goal of characterizing the formation of shocks. <br/>Additional effort will be directed toward the study of the formation of <br/>shear bands in viscoplastic materials.  The principal investigator will <br/>study the effects of strain-gradient regularization on the development <br/>and propagation of shear bands in two-dimensional nonlinear viscoplasticity.  <br/>This will include studies of problems where the solutions exhibit <br/>narrow shear bands, across which rapid variations in strain occur.  <br/>The PI will develop adaptive pseudo-spectral methods to resolve spatial <br/>regions where rapid variations occur during plastic deformation.<br/><br/>The behavior of materials such as rubber, steel, or concrete can be<br/>described by complicated systems of partial differential equations which are<br/>in general difficult to analyze.  However, there are certain special <br/>situations in which these equations simplify to a point where they can be both<br/>analyzed theoretically and computed numerically.  Examples include <br/>the motion of a material block between a fixed and a moving plane and<br/>the compression of a solid ball of material.  As a focus of this project, <br/>the principal investigator will investigate the nature of shock formation <br/>and of permanent plastic deformation on the formation and propagation <br/>of shocks for these types of motions.  A second area of research is the <br/>formation of shear bands.  These are localized regions of intense shear <br/>that form when ductile solids undergo large deformations.  Shocks <br/>and shear bands correspond to possible regions in which material failure occurs,<br/>and their accurate determination is therefore very important.  The principal<br/>investigator will take advantage of the special form of the equations to<br/>apply high-performance numerical methods that have been developed for <br/>applications in gas dynamics. <br/><br/><br/> <br/>"
"9732709","Number Theory With Emphasis on Algorithms and Algebraic     Number Theory","DMS","ALGEBRA,NUMBER THEORY,AND COM, COMPUTATIONAL MATHEMATICS, NUMERIC, SYMBOLIC & GEO COMPUT","07/01/1998","07/20/1998","Hendrik Lenstra","CA","University of California-Berkeley","Standard Grant","Tomek Bartoszynski","06/30/2002","$243,242.00","","hwl@math.berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947101749","5106433891","MPS","1264, 1271, 2865","0000, 9216, 9263, HPCC, OTHR","$0.00","  ABSTRACT    Hendrik Lenstra  Berkeley  9732709     Professor Lenstra will study a collection of problems in algorithmetic number theory, algebraic number theory, and algebraic geometry. Topics to be studied include smooth numbers, Mersenne primes, Galois groups of local fields, Belyi functions, Lacunary polynomials, and polynomials over finite fields.     Number theory is one of the oldest branches of mathematics.  It is the study of the natural numbers, the basic numbers of counting.  From the very beginning of the area, there has been a gap between what was known to be possible for all numbers, and what could actually be done for a specific one.  For example, it is known that any natural number can be factored in only one way as the product of smaller unfactorable numbers.  Yet given a carefully chosen large number, it can be so difficult to factor into parts that scientists have developed secure codes based on factorization.  This project is devoted to improving the methods we have for actually computing some of the most important mathematical properties of particular numbers.  In the computer age, the potential applications for improved methods of computation go well beyond mathematics and science and into everyday life."
"9803599","Innovative Sparse Matrix Algorithms","DMS","COMPUTATIONAL MATHEMATICS","08/01/1998","04/20/2000","Timothy Davis","FL","University of Florida","Continuing grant","Michael Steuerwalt","07/31/2002","$192,729.00","William Hager","davis@tamu.edu","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","MPS","1271","0000, 9216, HPCC, OTHR","$0.00","9803599<br/>Davis<br/><br/>Solving computational problems in science and engineering often involves solving sparse linear systems of equations.  In this research, Davis and Hager focus on direct solution techniques, and the following avenues of research:  (1) numerical update and downdate methods, (2) ordering methods for reducing fill-in, including a powerful optimization approach, and (3) parallel unsymmetric factorization algorithms.<br/><br/>The problem of analyzing the effect of small changes in a system of equations arises in a wide range of applications, including optimization, finite-element problems, partial differential equations, and statistics, to name a few.  Sparse techniques will be developed to take into account both the sparsity pattern of the equations and the incremental nature of the system change.  Although long recognized as an important problem, the sparse case has not been fully developed.  In developing an algorithm that will be effective in a wide range of applications, some of the important features that will be addressed include multiple rank updates and downdates, matrix reordering and refactorization, the use of dense matrix kernels, and changes in matrix order.  When the coefficient matrix of a linear system has the special, but important, form of a matrix times its transpose, techniques for fill-reducing orderings will be developed that do not require the explicit formation of the matrix product.  This structure arises in QR factorization, in sparse partial pivoting methods, in interior point methods, in a dual active set approach for linear programming, and in outer-product sparse LU factorization methods.  In addition, a different pivoting strategy will be developed that uses optimization theory to solve a parameterized quadratic programming problem.  When the parameter is 1, this strategy yields the minimum degree scheme; setting the parameter to half the matrix dimension yields global nested dissection type strategies.  Hence, a continuum between local greedy and global strategies is obtained.  When the pivoting problem is recast in this way as an optimization problem, powerful optimization algorithms and analytical tools can be used to determine both optimal pivots (in a constrained sense) as well as approximate optima.  For large, sparse unsymmetric matrices, a parallel, distributed-memory, unsymmetric-pattern multifrontal factorization method will be developed.  The basic idea is to use graph partitioning techniques on the directed or bipartite graphs arising from the factorization of unsymmetric sparse matrices.  Factorization of the separated components of the graph will be guided by a coarse separator tree, and be based on dense matrix kernels.  Each node in the coarse separator tree will be factorized by a single processor.<br/>"
"9732734","Pattern Formation in Biology, Dynamics and Computer Graphics","DMS","COMPUTATIONAL MATHEMATICS","01/15/1998","01/10/1998","Mikhael Gromov","","Institut des Hautes Etudes Scientifques","Standard Grant","Michael Steuerwalt","12/31/1998","$40,000.00","","gromov@cims.nyu.edu","Le Bois-Marie,","Bures-sur-Yvette","","91440","0160926670","MPS","1271","0000, 9263, OTHR","$0.00","Gromov  9732734    The investigator organizes an international conference  at Institut des Hautes Etudes Scientifiques to study  pattern formation in biology, mathematics, and computer graphics.    Collaborations will lead to new tools for analyzing,  computing, and visualizing patterns.      Symmetry and structure arise often in nature,  and their presence is often betrayed by patterns.    Mathematicians, biologists, and computer scientists  approach these common problems from different perspectives.    One goal of the conference is to stimulate synergistic interchanges  about these problems  between these different disciplines.    The conference aims to foster a greater understanding of  patterns, their significance in biological areas, and  how they can be handled mathematically and computationally."
"9805827","Collocation Methods for Partial Differential Equations","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","08/01/1998","07/29/1998","Bernard Bialecki","CO","Colorado School of Mines","Standard Grant","Michael H. Steuerwalt","07/31/2002","$170,000.00","Graeme Fairweather","bbialeck@mines.edu","1500 Illinois","Golden","CO","804011887","3032733000","MPS","1266, 1271","0000, 9263, OTHR","$0.00","  From graeme@glenclova.Mines.EDU Sat Jun 27 16:02:38 1998  Date: Sun, 21 Jun 1998 09:02:48 -0600 (MDT)  From: Graeme Fairweather <graeme@glenclova.Mines.EDU>  To: ""John C. Strikwerda (MPS/DMS)"" <jstrikwe@nsf.gov>  Cc: bbialeck@mines.edu, gfairwea@mines.edu  Subject: Re: NSF Proposal       Dear Dr. Strikwerda:  DMS 9805827    Bernard Bialecki and Graeme Fairweather       The focus of this project is on the formulation, theoretical analysis   and efficient implementation of orthogonal spline collocation (OSC)  algorithms for various partial differential equations arising in problems  of practical interest. Research will continue on the iterative  solution of OSC equations arising in second and fourth order   elliptic boundary value problems. Promising new methods have been  formulated for rather general second order linear elliptic problems, and  in a study of the OSC solution of nonlinear elliptic problems   the use of these methods will be addressed. The investigation of iterative  methods and nonlinear problems is expected to play an important role in the  development of OSC for nonlinear biharmonic and Stokes problems.   Work will  continue on Schrodinger problems in two space variables, in  particular, problems arising in plate vibration problems and nonlinear   problems. Algorithms developed for biharmonic problems will be used in  certain time-stepping procedures in cases where alternating direction  implicit methods cannot be formulated. A study of collocation methods   for solving partial integro-differential equations, including  problems with nonlocal boundary conditions, will also be undertaken.   Throughout this project, rigorous theoretical analysis will be combined with the  design and numerical testing of algorithms.    Many problems in science and engineering are modelled by partial  differential equations which fall into several distinct categories with  quite different characteristics. In this project, several types of  equations are considered, for example, biharmonic problems  which arise in  fluid dynamics and plate bending and are of particular interest in the  aviation industry, and Schrodinger equations  which model problems in quantum mechanics, underwater acoustics, plasma  physics, vibration problems and seismology. Some problems, such as  biharmonic problems, are steady state, that is, independent of time,   and investigations of these often provide insight into the handling of  time-dependent problems, like Schrodinger equations. Basic  models are  usually linear and techniques developed for their solution guide the  treatment of more realistic - nonlinear - situations.  Time dependent  problems which take into account the history of a process, as in   viscoeleasticity, result in partial integro-differential equations.   Because of the complexity of the partial differential equation models,  one must resort to computational techniques for their solution.  In this project, numerical methods called orthogonal  spline collocation methods will be developed for several classes of linear  and nonlinear, steady state and time-dependent problems of the form just  described.  These methods have several advantages over existing  techniques, including the ease with which they can be implemented on high  performance multiprocessor computers and the accuracy of the  approximations produced. The successful completion of this project will  provide efficient algorithms built on a strong theoretical foundation for  the solution of problems of much practical importance."
"9805546","High Order Number Schemes for Multi-Dimensional Systems of Conservation Laws and Conservative Schemes for MultiphaseFluids","DMS","COMPUTATIONAL MATHEMATICS","07/01/1998","05/07/1998","Xu-Dong Liu","CA","University of California-Santa Barbara","Standard Grant","John C. Strikwerda","06/30/2001","$77,252.00","","xliu@math.ucsb.edu","Office of Research","Santa Barbara","CA","931062050","8058934188","MPS","1271","0000, 9215, 9263, HPCC, OTHR","$0.00","DMS-9805546 Xu-Dong Liu This project is concerned with several new numerical methods for solving multidimensional systems of conservation laws, including a new fully conservative scheme for multi-phase fluid calculations. The first contribution of this project is the extension of Friedrich's positivity principle from multi-dimensional symmetric linear systems to systems of conservation laws, which has become one of the guidelines for designing numerical methods. A family of positive schemes is constructed. Positive schemes are very robust, simple and of low cost. Many numerical experiments have shown that positive schemes are among the best 2nd order accurate high resolution methods. This is also the first work of this type which contains theoretical results for scheme design in multi-dimensional hyperbolic systems. The second contribution of this project is the new Convex Essential-Non-Oscillatory (CENO) schemes for multi-dimensional hyperbolic systems. The scheme can be implemented in component-wise fashion. Therefore its apparent advantages are: (1) No complete set of eigenvectors is needed and hence weakly hyperbolic systems can be solved. (2) Component-wise limiting is twice as fast as field-by-field limiting in each space dimension, which makes Convex ENO one of the fastest existing schemes. (3) The component-wise version of the scheme is simple to program. In addition, (4) the Convex ENO scheme is very robust. The third contribution of this project is the introduction of a fully conservative method for multi-phase flow problems. This new idea enables us to avoid the spurious oscillations near material interfaces common to all other conservative schemes. This is done through the addition of a general equation of state. The new scheme works essentially for mixture of any fluids such as gamma-law gas, water and JWL (explosive material). The new idea works in any space dimension and is scheme-independent, which means it should apply to a typical users' existi ng code. Preliminary numerical experiments show that this scheme is very promising. This project is aimed at solving real world problems and is intended to have a significant impact on semiconductor device modeling, underwater and solid explosives modeling, computational fluid dynamics, magneto-hydrodynamics, and many other applications, which are all a part of high-performance computing. The principal goals are: (1) to design and improve numerical methods for more efficiency, simplicity, and robustness; (2) to improve computer simulation of multi-phase fluids. The methods reported in this project are a step towards this goal."
"9731421","Groups, Algorithms and Geometries","DMS","ALGEBRA,NUMBER THEORY,AND COM, COMPUTATIONAL MATHEMATICS","04/15/1998","11/06/2001","William Kantor","OR","University of Oregon Eugene","Continuing grant","Andrew D. Pollington","03/31/2004","$332,280.00","","kantor@math.uoregon.edu","5219 UNIVERSITY OF OREGON","Eugene","OR","974035219","5413465131","MPS","1264, 1271","0000, OTHR, 9263","$0.00","KANTOR 9731421 The proposer will investigate fast recognition algorithms for black box exceptional groups of Lie type (research begun with K. Magaard), and finding the characteristic of a black box group of Lie type (research begun with A. Seress). These have applications to upgrading all known Monte Carlo nearly linear permutation group algorithms to Las Vegas algorithms, versions of which will then be programmed into the group theory system GAP. Other consequences will be very practical Sylow algorithms for permutation groups, which will also go into GAP. The field of group theory is the mathematical theory of symmetry and interacts with many other disciplines, for example physics and chemistry outside of mathematics, coding theory, number theory and geometry inside mathematics.The investigator's particular area is finite groups, computation and applications to geometry and coding."
"9803538","Turbulence Theory: Approximation of Higher Statistics","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","06/01/1998","05/28/1998","Robert Kraichnan","NH","Robert H Kraichnan Inc","Standard Grant","Henry A. Warchall","05/31/2001","$126,558.00","","","","Dublin","NH","03444","","MPS","1266, 1271","0000, OTHR, 9263","$0.00","Kraichnan<br/><br/>This proposal is for theoretical research on the higher statistics of <br/>Navier-Stokes turbulence. The principal tool to be used is called mapping <br/>approximation. It is a systematic mathematical procedure applied to the fluid <br/>equations of motion. Nonlinear transformations of fields with Gaussian <br/>statistics are exploited. In previous applications to several problems, <br/>notably to the advection of passive or chemically active scalar contaminant <br/>fields by turbulent flows and to Burgers' one-dimensional model of turbulence, <br/>it has yielded quantitatively accurate predictions of statistics that describe <br/>extreme intermittency of small scales. The proposed work involves further <br/>development of mapping approximation and its application to intermittency of <br/>vorticity in incompressible turbulent flows. Ultimate goals include the <br/>determination of scaling exponents for vorticity.<br/><br/><br/>Turbulence, the disordered motion of fluids, is an ubiquitous phenomenon in <br/>geophysics and industry. It has been an outstanding challenge to <br/>mathematicians and physicists for over a century. Examples where turbulence <br/>plays a crucial role are weather systems, airplane flight, the dispersal of <br/>atmospheric pollutants, and industrial chemical reactors. The complexity of <br/>turbulent motion is so extreme that fully detailed computer solutions of real <br/>turbulent flows are not possible; the demands on memory and speed are too <br/>extreme. In order to reduce computation to maneagable size, theoretical models <br/>of the statistics of the smaller scales of turbulent motion are essential. The <br/>research to be carried out under this proposal brings recently developed new <br/>tools to bear on the statistics of small scales. These tools have proved to be <br/>powerful in related problems. Improved models of the small scales of <br/>turbulence that can be used in computer simulations are an objective of this <br/>research."
