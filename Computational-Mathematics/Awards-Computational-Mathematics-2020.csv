"AwardNumber","Title","NSFOrganization","Program(s)","StartDate","LastAmendmentDate","PrincipalInvestigator","State","Organization","AwardInstrument","ProgramManager","EndDate","AwardedAmountToDate","Co-PIName(s)","PIEmailAddress","OrganizationStreet","OrganizationCity","OrganizationState","OrganizationZip","OrganizationPhone","NSFDirectorate","ProgramElementCode(s)","ProgramReferenceCode(s)","ARRAAmount","Abstract"
"2012291","Variable-Order Fractional Partial Differential Equations: Computation, Analysis, and Application","DMS","COMPUTATIONAL MATHEMATICS","09/01/2020","07/28/2020","Hong Wang","SC","University of South Carolina at Columbia","Standard Grant","Yuliya Gorb","08/31/2024","$200,000.00","","hwang@math.sc.edu","1600 HAMPTON ST # 414","COLUMBIA","SC","292083403","8037777093","MPS","1271","9150, 9263","$0.00","Mathematical modeling and simulation techniques have been widely used in science, engineering, and industry. In this project, we consider a class of models of complex phenomena which exhibit memory effects and long range interactions, with applications in design and manufacturing of visco-elastic materials, anomalous diffusive transport, hydrofracking in gas and oil recovery, bioclogging of porous materials, and the deformation of some materials such as in orthopedic implants and shape memory polymers. The focus is on fractional calculus and specifically on variable order fractional partial differential equations, in which the fractional order may be a function of space, time and even unknown solutions. The research activities will contribute to the analysis, simulation, modeling and application of fractional calculus, and provide advanced interdisciplinary training to students. The project includes training opportunities for graduate students. <br/><br/>Fractional partial differential equations (FPDEs), which are characterized by power-law decaying tails, have shown to accurately model complex phenomena of nonlocal nature. However, rigorous mathematical and numerical analysis of variable-order FPDEs is currently less known than that for integer-order PDEs. For instance, it is well known that linear elliptic and parabolic FPDEs imposed on smooth domains with smooth data exhibit weak initial or boundary singularity, which is in sharp contrast to their integer-order analogues. This makes it unrealistic to carry out error estimates of numerical approximations to FPDEs based on the (often untrue) smoothness assumptions of their true solutions. In this project the investigators develop accurate and stable numerical approximations to variable-order FPDEs and their fast solution algorithms, as well as prove their well-posedness and smoothing properties. The investigators will also prove optimal-order error estimates of numerical approximations to variable-order FPDEs without any artificial regularity assumption of their true solutions, but only under the regularity assumptions of their coefficients, variable orders and other related data.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012046","Collaborative: Novel Fast Microlocal, Domain-Decomposition Algorithms for High-Frequency Elastic Wave Modeling and Inversion in Variable Media","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","07/27/2020","Jianliang Qian","MI","Michigan State University","Standard Grant","Yuliya Gorb","07/31/2024","$215,000.00","","qian@math.msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1271","9263","$0.00","Wave propagation is an important phenomenon in many science and engineering disciplines. Computational wave propagation has become a fundamental, vigorously growing technology in diverse disciplines, ranging from radar, sonar, seismic imaging, medical imaging, submarine detection, stealth technology, remote sensing and electronics to microscopy and nanotechnology. These applications are important in particular for the petroleum industry, medical imaging, and material sciences. One of the most challenging problems in computational wave propagation is how to carry out large-scale high frequency wave propagation efficiently and accurately. The investigators in this project will develop novel, fast algorithms for high frequency elastic wave propagation and inversion. In particular, they will focus on novel techniques including microlocal-analysis and domain-decomposition based fast Huygens sweeping methods and fast multiscale Gaussian beam methods to tackle this long-standing challenge.  Graduate students will be involved and receive interdisciplinary training. <br/><br/>The project is motivated by science and engineering applications, and it will foster innovations in several theoretical and computational aspects. The goal is to develop efficient and accurate Hadamard-Babich expansion based fast Huygens sweeping methods and multiscale Gaussian wavepacket transform based fast multiscale Gaussian beams for elastic wave propagation in variable media in the high frequency regime and in the presence of caustics.   Several thrusts will be considered. First, the proposed new methods will address the challenges in large-scale high-frequency elastic wave modeling and inversion in the presence of caustics. Second, advances will be made in developing novel Hadamard-Babich expansion, domain decomposition, and butterfly-algorithm based fast Huygens sweeping methods for partial differential equation-based Eulerian geometrical optics and computational wave propagation. Both the Hadamard-Babich expansion and domain-decomposition based fast Huygens sweeping method and the fast multiscale Gaussian beam method are capable of producing uniform asymptotic solutions beyond caustics for wave propagation in the high-frequency regime. Third, the new methods will provide efficient tools not used before for many elastic wave-related applications in inhomogeneous media, such as seismic imaging and inversion, and medical imaging and inversion.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012562","Mathematical and Numerical Analysis of Asymptotically Compatible Discretization of Nonlocal Models","DMS","COMPUTATIONAL MATHEMATICS","07/01/2020","07/26/2022","Qiang Du","NY","Columbia University","Continuing Grant","Yuliya Gorb","08/31/2023","$300,000.00","","qd2125@columbia.edu","202 LOW LIBRARY 535 W 116 ST MC","NEW YORK","NY","10027","2128546851","MPS","1271","9263","$0.00","The study of nonlocal models has attracted much attention in many science and engineering disciplines such as materials science, mechanics, biology, and social science, and they are therefore of interest to applied and computational mathematics.  Nonlocal models differ from the more common local models because they account for the factors active on a range rather than only at a point at which they are considered.  The project is aimed at advancing the mathematical and numerical analysis of robust and effective numerical methods for those nonlocal models with a finite range of interactions.  The research will complement the ongoing development of effective simulation platforms for nonlocal modeling in various application domains. It will also contribute to the integrated interdisciplinary education and research training of students.<br/><br/>An important class of robust numerical schemes for nonlocal models is provided by asymptotically compatible (AC) discretization schemes. The latter are designed to assure the convergence of approximate solutions, as numerical resolution gets refined, to correct physical solutions for problems with changing or even diminishing ranges of nonlocal interactions. The project will include a comprehensive study of AC schemes for nonlocal problems with heterogeneously distributed ranges of nonlocal interactions and/or having boundary/interfaces. Further investigations of AC schemes will be carried out for problems involving coupled local/nonlocal models and nonlinear problems motivated by important applications. The focus on robust discretization methods like the AC schemes is particularly relevant to reliable and efficient simulations of nonlocal models with application to complex physical systems involving multiscale, singular, and anomalous behaviors.  An integrated analytical and computational approach will be used to develop both fundamental ideas and practical insight so that the research findings will not only enrich the mathematical theory of AC schemes but also offer guidance to their practical applications.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012699","Entropy-Consistent Moment-Closure Approximations of Kinetic Boltzmann Equations","DMS","COMPUTATIONAL MATHEMATICS","09/01/2020","05/26/2020","James Rossmanith","IA","Iowa State University","Standard Grant","Yuliya Gorb","08/31/2024","$289,997.00","","rossmani@iastate.edu","1350 BEARDSHEAR HALL","AMES","IA","500112103","5152945225","MPS","1271","9150, 9263","$0.00","This research is concerned with the development of mathematical models and corresponding state-of-the-art computational methods for simulating and predicting the dynamics of complex fluid systems, such as those arising from multiphase flows and plasma. The ability to predict the dynamics of these complex fluid systems is of vital importance in understanding a wide range of phenomena such as particulate flow in the atmosphere, fuel sprays in combustion engines, magnetically-confined fusion reactors, laser-plasma accelerators, space weather, and astrophysical events. The underlying physics of such systems are often well-represented by kinetic models that represent the state of the fluid in terms of probability density functions. The main challenge in accurately simulating these kinetic models is that solutions live in a high-dimensional phase space and contain information over wide-ranging spatial and temporal scales. The goal of this research is to develop reduced models that simultaneously capture the important physics and can be more readily solved on modern computer architectures. As part of this research effort, graduate and undergraduate students will be trained in mathematical modeling and computational mathematics. Students from groups that are underrepresented in applied and computational mathematics will be encouraged to participate in the research efforts.<br/> <br/>The primary objective of this research is to develop accurate and efficient computational methods for solving kinetic models of both polydisperse multiphase flows and plasma flows via entropy-consistent moment closures. The purpose of moment-closure techniques is to reduce high-dimensional kinetic models to more computationally tractable approximations. However, determining a suitable moment closure is a mathematical challenge; a general approach that combines desirable mathematical features remains elusive. This research will pursue two related approaches: (1) using quasi-exponential representations of the underlying kinetic distribution functions, and (2) using delta functions in conjunction with entropy maximization. Novel moment-inversion algorithms and high-order numerical schemes will be developed. The resulting codes will be implemented on massively parallel computers. These techniques will be applied to problems in polydisperse multiphase flows and plasma flows.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1945029","CAREER: Deep Learning Based Scientific Computing: Mathematical Theory and Algorithms","DMS","COMPUTATIONAL MATHEMATICS","07/01/2020","07/15/2022","Haizhao Yang","IN","Purdue University","Continuing Grant","Yuliya Gorb","10/31/2022","$279,972.00","","haizhaoyang@yahoo.com","2550 NORTHWESTERN AVE STE 1900","WEST LAFAYETTE","IN","479061332","7654941055","MPS","1271","079Z, 1045, 9263","$0.00","Deep learning has demonstrated remarkable, high fidelity performance on computer vision and natural language processing tasks that revolutionize manufacturing and social life. Recent applications of deep learning in scientific problems have also advanced scientific discovery via computational chemistry, materials science, medicine, immunology, climate sciences, etc. Understanding the mathematical principles of deep learning algorithms is crucial to validating and improving these algorithms, and will allow scientists and engineers to obtain more reliable predictions and perform a better risk assessment. The research goal is to develop a systematic deep learning analysis serving as the theoretical foundation of numerous scientific problems based on deep learning; cutting-edge algorithms for the efficient solutions of high-dimensional and highly nonlinear partial differential equations arising in various application domains will also be proposed with a theoretical guarantee. The proposed deep learning-based algorithms for high-dimensional and highly nonlinear problems will be expected to greatly advance the state-of-the-art simulations of complex physical systems arising in many fields in science and engineering. <br/><br/>The theoretical challenges of deep learning are largely due to the highly non-linear nature of deep neural networks (DNNs). As a function parametrization tool formulated as compositions of non-linear functions, DNNs are highly non-linear and require advanced mathematics to fully understand. Therefore, there is a critical need for new advances in mathematics for a better understanding of DNNs. The theoretical part of this project mainly focuses on the approximation and generalization capacity of DNNs. The central questions to be answered are whether DNN approximation conquers or lessens the curse of dimensionality, what is the optimal approximation rate of various function classes, and how to characterize the Rademacher complexity of various DNNs trained with state-of-the-art empirical regularization methods aiming at optimal generalization error bound. The computational part of this project concentrates on solving high dimensional and highly oscillatory partial differential equations. The specific approach of this project is to propose hybrid algorithms that combine the advantage of deep learning algorithms and traditional numerical techniques for more efficient computation and higher accuracy. The key idea is to treat deep learning solvers as a preconditioner of traditional numerical algorithms. The algorithms designed in the project will also be implemented in deep learning packages for numerical PDEs and made publicly available. Research outcomes of this project will be disseminated through conferences, publications (journal papers and textbooks), and new mathematical deep learning courses to a broad audience, especially for the next generation of computational scientists.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011519","Collaborative Research: Advancing Theoretical Understanding of Accelerated Nonlinear Solvers, with Applications to Fluids","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","05/21/2020","Sara Pollock","FL","University of Florida","Standard Grant","Yuliya Gorb","07/31/2024","$175,379.00","","s.pollock@ufl.edu","1523 UNION RD RM 207","GAINESVILLE","FL","326111941","3523923516","MPS","1271","9263","$0.00","Many mathematical models used to describe and predict behavior of physical, biological, chemical, and financial systems lead to systems of equations for which the problem coefficients depend on an unknown solution. These are known as nonlinear problems, and they are solved iteratively, by generating a sequence of successive approximations.  For many such problems, even state of-the-art solution methods can be slow, can fail, and may not be robust with respect to changes in the underlying problem data. This project aims to develop faster and more reliable iterative solution techniques using methods which recombine information from previous approximations to create a more accurate next approximation.  Theory will be developed to mathematically show how these methods improve current solution techniques, and the improved methods will be demonstrated on a wide range of systems that arise from important practical problems in optics and fluid mechanics. This project provides research training opportunities for graduate students.<br/><br/>The efficient solution of systems of nonlinear equations is essential to the high-fidelity simulation technology necessary for predictive physical modeling throughout engineering and the life sciences.  An extrapolation technique commonly referred to as Anderson acceleration (AA) has been known since 1965 to often improve the efficiency and robustness of iterative solvers for nonlinear problems. It has been successfully used in a surprisingly wide variety of applications, however theoretical understanding of its convergence properties remains largely open. Better theoretical understanding of mathematical algorithms is fundamentally important for both practical implementation and for the creation of the next generation of algorithms. The aim of this proposal is to improve theoretical understanding for AA, and to develop robust and efficient variants with improved convergence properties, both in general settings and for specific nonlinear PDEs. The main theoretical components are (1) the analysis of a variant using principal component analysis; (2) the design and analysis of robust adaptive damping and algorithmic depth strategies for noncontractive operators; (3) the analysis of the superlinear convergence of accelerated Newton iterations for degenerate problems.  The proposed work will include theory and practical application of AA to several difficult nonlinear PDEs from fluid mechanics and optics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012439","Distributed Synchronous and Asynchronous Stochastic Optimization Algorithms over Networks","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","07/27/2020","Ming Yan","MI","Michigan State University","Standard Grant","Stacey Levine","07/31/2023","$200,000.00","","yanm@math.msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1271","9263","$0.00","The number of installed internet of things (IoT) devices reached 26.66 billion in 2019, and this number will reach 75 billion by 2025. These devices collect massive volumes of datasets, and the analysis of these datasets can significantly improve our daily lives. However, how to process these datasets efficiently is still challenging. First, it is impossible to transfer all the data to a location because of the large volume and privacy concerns. Second, the networks formed by these devices are complex. Thus, existing distributed methods can not be directly applied to this scenario, and novel algorithms based on the communication between these devices have to be developed to make sense of these large-scale datasets.<br/><br/>In this project, the PI will tackle the major drawbacks of existing decentralized consensus algorithms and greatly promote the efficiency and scalability of large-scale decentralized algorithms. To achieve this goal, the PI will systematically investigate the theoretical understanding of decentralized algorithms and two major challenges, i.e., large-scale data and large-scale networks. There are three objectives. The first objective is a better convergence rate for existing, and new, decentralized deterministic algorithms. The success of this objective will be the first step that will form the foundation of the next two objectives. The second objective is to develop decentralized stochastic algorithms with variance reduction for large-scale data. The last objective is asynchronous decentralized algorithms. This project will pave the way for new research endeavors to deal with large-scale distributed datasets and largely push the research boundaries of decentralized optimization in various application domains. This research will impact the use of decentralized algorithms in fields including wireless sensor networks, machine learning, the internet of things, and healthcare.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011838","Development of Adaptive Sparse Grid Discontinuous Galerkin Methods for Multiscale Kinetic Simulations in Plasmas","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","07/27/2020","Yingda Cheng","MI","Michigan State University","Standard Grant","Yuliya Gorb","07/31/2024","$200,000.00","","ycheng@math.msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1271","9263","$0.00","This project aims at designing efficient numerical schemes for simulating complex plasma phenomena. Plasma is a state of matter similar to gas in which a certain portion of the particles is ionized.  Understanding the complex behaviors of plasmas has led to important advances in areas ranging from  space physics, fusion energy, to high-power microwave generation and large scale particle accelerators.  There is strong need for laying out mathematical and algorithmic foundations for the design of efficient numerical methods so that we can advance basic research in plasma simulations. The algorithms developed in this project have the potential to provide high fidelity simulations in plasma physics with manageable computational cost and will have applications and impacts in multiscale simulations in fusion devices. The principal investigator (PI) will organize  special events at professional meetings and workshops to promote the participation of female researchers. This project provides research training opportunities for graduate students. <br/><br/>The objective of the project is to make significant advances on the design and analysis of a class of numerical methods called adaptive sparse grid (aSG) discontinuous Galerkin (DG) methods. The methods incorporate high order accurate DG solver that excels at transport simulations and the dimension reduction technique by aSG approach. The aim of this proposal is to advance the algorithmic foundations of the schemes for time-dependent PDEs, and push them onto the broader arena of multiscale simulations and applications for fusion science. The PI will investigate several fundamental issues including the analysis of CFL conditions, development of multiscale time stepping, postprocessing and hybrid aSG schemes. For a class of multiscale kinetic problems bridging kinetic and fluid models, by utilizing the multiresolution offered in the aSG-DG framework, the research will take advantage of both multiscale simulation tools and multiresolution on hierarchically defined meshes to achieve acceleration in computations. The schemes will be applied to simulations of runaway electrons in tokamak devices.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1952339","FRG: Collaborative Research: Robust, Efficient, and Private Deep Learning Algorithms","DMS","COMPUTATIONAL MATHEMATICS","08/15/2020","10/15/2020","Andrea Bertozzi","CA","University of California-Los Angeles","Standard Grant","Yuliya Gorb","07/31/2024","$434,750.00","Stanley Osher, Bao Wang","bertozzi@math.ucla.edu","10889 WILSHIRE BLVD STE 700","LOS ANGELES","CA","900244201","3107940102","MPS","1271","075Z, 079Z, 1616, 9263","$0.00","This project develops robust, accurate, and efficient next-generation deep learning algorithms with data privacy and theoretical guarantees for solving challenging artificial intelligence (AI) problems. The methods will have robustness to adversarial attacks with theoretical guarantees.  The project will push artificial intelligence gains in performance and privacy to mobile devices. A broad range of applications includes autonomous driving, drug and material discovery, medical treatment planning, national defense, privacy-preserving machine learning at the edge, federated learning, and also blockchain. Moreover, the developed tools will significantly scale the existing scientific simulations to ultra-large scale and high-dimensional scenarios. This project will partially support one graduate student per year at each campus.<br/><br/>Our approach toward trustworthy deep learning is theoretically principled by modern partial differential equations and optimization algorithms and theories.  The project involves new algorithmic and theoretical techniques to tackle graph representation in high-dimensional non-convex, non-smooth AI settings. In particular, the project will study (1) developing adversarial robust deep learning algorithms and their theoretical foundations; (2) improving the accuracy of deep learning leveraging new stochastic optimization and principled neural network unit design assisted neural architecture search; (3) advancing deep neural networks compression with algorithms and hardware co-design; (4) designing new data privacy mechanisms to optimally tradeoff between utility and privacy; (5) inventing new quantitative analysis tools to decipher the mysteries of deep learning theoretical challenges; (6) quantifying uncertainties of sophisticated deep learning algorithms. The project trains a diverse body of graduate and undergraduate students at UC Irvine, UCLA, and University of Utah through collaborative education and research activities in applied mathematics, computer science, data science, and general biological, physical, and sociological disciplines.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1952735","FRG: Collaborative Research: Randomized Algorithms for Solving Linear Systems","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","04/24/2020","Per-Gunnar Martinsson","TX","University of Texas at Austin","Standard Grant","Yuliya Gorb","06/30/2024","$677,023.00","Rachel Ward","pgm@ices.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271","1616, 9263","$0.00","The objective of this project is to develop faster and more energy-efficient algorithms for one of the most fundamental tasks in computational science: solving large systems of coupled linear equations. Faster algorithms will both accelerate computations that can already be performed, and enable computations that are beyond the reach of existing methods. More energy efficient algorithms will help to reduce the power consumption of data centers, and to extend the battery life of mobile devices such as cell phones and tablet computers. The fundamental innovation behind our approach is to harness mathematical properties of large collections of random numbers to build new stochastic algorithms that dramatically outperform existing deterministic ones. In a nutshell, the idea is to use randomized sampling, and randomized averaging, to reduce the effective dimensionality of the problems to be processed. In addition the project provides research training opportunities for postdoctoral fellows and graduate students.<br/><br/>We seek to develop computationally efficient methods for solving linear systems of equations involving large numbers of variables, both in terms of asymptotic complexity, and in terms of practical speed at realistic problem sizes. Such systems of equations arise ubiquitously in science and engineering, and solving them is often the bottleneck in terms of time that decides how large of a problem can be handled. In particular, this is what limits how large of a data set can be analyzed, or how realistic a computational simulation can be when modelling some physical phenomenon. By developing faster and more efficient algorithms, we will accelerate computations that are done today, and enable many others that are outside the reach of currently existing methods.  The project is premised on the recent development of new randomized algorithms for solving linear algebraic problems. Such methods have proven to dramatically outperform classical deterministic methods for certain tasks such as computing low rank factorizations to matrices - the crucial computational step in e.g. Principal Component Analysis, the PageRank algorithm by Larry Page and Sergey Brin, numerical coarse graining when modeling complex multiscale systems, and many more. Randomized algorithms have also been used to build faster solvers for linear systems. However, while the theoretical results obtained at this point are extremely encouraging, it remains to develop randomized linear solvers that are decisively faster in practical applications. To achieve this goal, the project will support a research group that brings together four researchers with complementary skills in numerical linear algebra, random matrix theory, computational harmonic analysis, optimization, and high performance computing.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012652","Deep Neural Networks for Structured Data: Regression, Distribution Estimation, and Optimal Transport","DMS","COMPUTATIONAL MATHEMATICS","09/01/2020","05/26/2020","Wenjing Liao","GA","Georgia Tech Research Corporation","Standard Grant","Yuliya Gorb","08/31/2024","$342,394.00","Tuo Zhao","wliao60@gatech.edu","926 DALNEY ST NW","ATLANTA","GA","30332","4048944819","MPS","1271","079Z, 9263","$0.00","In the past decade, deep learning has made astonishing breakthroughs in real-world applications, including for example, computer vision, natural language processing, speech recognition, healthcare, and robotics. Deep learning uses multiple layers of linear transformations followed by nonlinear activations to represent abstractions in the data.  It is a common belief that deep neural networks are good at learning various geometric structures hidden in data sets, such as rich local regularities, global symmetries, or repetitive patterns. However, little theory has been established to explain the power of deep neural networks for analyzing complex data sets containing geometric structures. This project will develop the theoretical and computational foundations to better understand how deep neural networks exploit geometric structures in data sets and achieve outstanding performance. The results will provide new insights on developing new deep learning models and methodologies.<br/><br/>This project focuses on three sets of related but distinct problems. The first set focuses on efficient approximation of functions on low-dimensional manifolds using deep neural networks. Existing theories show that deep learning estimators converge to the true function extremely slowly in high dimensions. When the function is supported on a low dimensional manifold, the PIs plan to prove a fast convergence rate depending on the intrinsic dimension of the manifold. This project will make contributions in function approximation theory, error analysis in statistical regression and classification, and adaptive theory of deep learning. The second set of problems concerns estimation of probability distributions supported on a low-dimensional manifold by deep generative models. These models utilize two neural networks to minimize the Integral Probability Metric (IPM) between the estimator and the data distribution, over the class of distributions generated by a deep generator network. The function class in IPM is realized by a deep discriminator network. This project will design proper network architectures of the generator and the discriminator, and prove performance guarantees of deep generative models. The third set of problems will focus on efficiently computing the optimal transport between two probability distributions using deep neural networks. After reformulating the optimal transport problem as a min-max optimization problem parametrized by two neural networks, the PIs propose a primal dual stochastic gradient descent algorithm to solve it.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2044945","Mathematical Analysis and Numerical Methods for Peridynamics and Nonlocal Models","DMS","COMPUTATIONAL MATHEMATICS","06/01/2020","10/14/2020","Xiaochuan Tian","CA","University of California-San Diego","Standard Grant","Yuliya Gorb","06/30/2022","$58,381.00","","xatian@ucsd.edu","9500 GILMAN DRIVE","LA JOLLA","CA","920930021","8585344896","MPS","1271","9263","$0.00","Improvements in computer technology are fueling the development of more realistic mathematical models for complex applications, including nonlocal models that are more realistic than conventional local models for studying various phenomena from physics and biology to materials and social sciences. An example is the peridynamics model, a spatially nonlocal mechanics theory, which has been successfully used to model material defects and predict dynamics of crack formation in various engineering applications. Although new nonlocal models have been gaining popularity in various applications, the study of mathematics behind them is still at the nascent stage, impeding the further development of computational tools. The goal of this project is to develop efficient and reliable numerical methods for simulating nonlocal models and establish related mathematical analysis as part of the rigorous validation and verification process. It aims to improve the effectiveness and robustness of nonlocal modeling while retaining modeling accuracy. On the educational side, this project will provide training to students in both mathematics and computational mechanics. <br/><br/>This project aims to develop state-of-the-art multiscale modeling techniques to improve computational efficiency while retaining the accuracy of nonlocal models for predicting dynamic fractures, with new theoretical methodologies built to study the analytic properties of the models.  Three specific methods of multiscale modeling will be addressed, in which the treatment of boundary traces and interfacial conditions plays pivotal roles. The first is the seamless coupling of nonlocal and local models via heterogeneous localization of nonlocal interactions at the interface. A novel nonlocal trace theorem is used to ensure the well-posedness of the coupling. The goal is to treat the interface as a free boundary based on the development of the solution. The second is a quasi-nonlocal coupling method inspired by the atomistic-to-continuum coupling method. It is aimed at building a bridge between the discrete atomistic model and continuous nonlocal model. The third is to design appropriate nonlocal boundary conditions to reduce the computational cost for problems on unbounded domains. A new notion of nonlocal Neumann boundary condition will be introduced, which will shed light on domain decomposition methods and the coupling of nonlocal models.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1945224","CAREER: Shape Analysis in Submanifold Spaces: New Directions for Theory and Algorithms","DMS","COMPUTATIONAL MATHEMATICS","02/01/2020","08/15/2022","Nicolas Charon","MD","Johns Hopkins University","Continuing Grant","Yuliya Gorb","01/31/2025","$351,590.00","","charon@cis.jhu.edu","3400 N CHARLES ST","BALTIMORE","MD","212182608","4439971898","MPS","1271","1045, 9263","$0.00","Shape analysis has now become an integral component of data science as it is key to modelling and analyzing quantitatively the geometric variability within datasets for applications as diverse as computer vision, speech/motion recognition, morphogenesis or computational anatomy. Among the variety of geometric structures that are studied in this field, curves, surfaces and more generally manifolds are both very natural objects but also particularly challenging to process and analyze due to the non-canonical structure of the corresponding shape spaces. This has in part hindered the development and effectiveness of shape analysis frameworks for such data, if compared for instance to the more widely studied case of images. This project attempts to bridge a few of these important gaps, both on the theoretical and computational side and develop new scalable algorithms for morphological analysis adapted to the growing size and complexity of real datasets. The project will also promote those research topics among students at various levels of the educational system, with the creation of an upper-level undergraduate course on differential and computational geometry, training of PhD students and K-12 outreach activities through the Women in Science and Engineering (WISE) program in particular.<br/><br/>Building up on several prior works on shape spaces and metrics, the specific research objectives of this project are (1) to advance the analysis and comparison of relaxed shape matching problems deriving from Riemannian metrics on spaces of manifolds; (2) to investigate supervised and unsupervised deep learning approaches to improve the efficiency of manifold registration algorithms; and (3) to study novel extensions of those models to account for partial or incomplete data and model joint shape/topological variations across shapes. As part of this project's outcome, Python pipelines will be developed and made openly accessible to the scientific community with the long term goal of expanding the potential scope of applications of those methods.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012609","Quantum Computational Signal Classification","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","08/11/2022","Vasileios Maroulas","TN","University of Tennessee Knoxville","Continuing Grant","Yuliya Gorb","07/31/2024","$300,000.00","George Siopsis","vmaroula@utk.edu","201 ANDY HOLT TOWER","KNOXVILLE","TN","379960001","8659743466","MPS","1271","075Z, 7203, 9263","$0.00","Developments in artificial intelligence are opening up new avenues for human-machine teaming. For example, the brain-computer interface (BCI) technology extracts and interprets information generated by brain activity without depending on any external device or muscle intervention. Improving human-machine interactions requires the analysis and interpretation of physiological signals to effectively assess individual states. These signals are typically nonstationary, noisy, and nonlinear, and current signal processing methods may fail. Embedding a signal into a point cloud, this project, Quantum Computational Signal Classifications (QuATOMIC) abides by the stringent nature of signals, and considers the detection of shape patterns of the signals? point clouds. These shape patterns are characterized by their pertinent topological properties, which are summarized in a persistence diagram. A persistence diagram consists of two dimensional points whose positioning highlights signals? features and deconvolves them from any underlying noise. On the other hand, point clouds consist of many discrete points, and the computation of these diagrams is a rather formidable task. Indeed, subsampling typically takes place leading to loss of vital information.  <br/><br/>The PIs will adopt a quantum topological framework which considers all points in a point cloud, and relies on principles of quantum machine learning algorithms. Moreover, when it comes to actual analysis of signals and their associated diagrams, one may need (i) to compute a distance between them so that they are differentiated, or (ii) to quantify their uncertainty and estimate a probability density function on the space of persistence diagrams. Computing a distance between two persistence diagrams requires the solution of an optimal matching problem. The PIs will develop a novel distance that is formulated and computed in a quantum way. Propagating a distribution of a persistence diagram to quantify uncertainty requires to compute a distribution of a random point process. This is a non-trivial, highly combinatorial problem, which QuATOMIC will bypass by considering a quantum computing approach based on either quantum circuits (gate model), or the principles of quantum annealing. Having at hand a measure of quantifying the difference among persistence diagrams and their uncertainty, QuATOMIC will further generate a novel quantum supervised machine learning scheme for signals.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1929284","Institute for Computational and Experimental Research in Mathematics","DMS","COMPUTATIONAL MATHEMATICS, ANALYSIS PROGRAM, MATHEMATICAL SCIENCES RES INST","09/01/2020","09/11/2023","Brendan Hassett","RI","Brown University","Continuing Grant","Yuliya Gorb","08/31/2025","$23,660,619.00","Bjorn Sandstede, Jill Pipher, Kavita Ramanan, Benoit Pausader","Brendan_Hassett@brown.edu","1 PROSPECT ST","PROVIDENCE","RI","029129127","4018632777","MPS","1271, 1281, 7333","9150","$0.00","The Institute for Computational and Experimental Research in Mathematics (ICERM) is a national institute whose mission is to catalyze fundamental research in the mathematical sciences. Its focus is the fruitful interplay between mathematics and computers, developed through computation and experimentation. ICERM pursues this mission by supporting theoretical advances related to computation and by addressing mathematical problems posed by the use of the computer. Mathematics influences an ever-widening range of scientific and industrial enterprises - including cryptography, data analysis, fluid dynamics, image processing, and industrial design - and computation is at the heart of this interaction. The institute has a special focus on training the next generation in computational skills, preparing them for a variety of scientific careers. ICERM works to increase the participation of members of groups underrepresented in mathematics. To support these goals, it provides a sophisticated research infrastructure including access to high-performance computing and state-of-the-art software resources.<br/><br/>ICERM convenes leading scientists from academia and industry, together with students and early-career researchers, in programs that generate new mathematics and that accelerate the development of technology arising from new mathematics. The institute pursues its goals through semester-long programs, with support for postdoctoral fellows and graduate students; week-long workshops disseminating the latest research and catalyzing new collaborations; and team-based research programs exposing graduate and undergraduate students to experimental methodologies and computer-aided tools. Its independent Scientific Advisory Board chooses topics based on proposals from the scientific community; the resulting programs are open to students and researchers from across the country and around the world. ICERM supports data-driven explorations in both pure and applied areas of mathematics through a culture of open exchange of ideas and an environment rich in computational tools. The institute also hosts numerous outreach activities and public events showing the beauty and social impact of mathematical research and computational advances.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012606","Collaborative Research: Nonoscillatory Phase Methods for the Variable Coefficient Helmholtz Equation in the High-Frequency Regime","DMS","COMPUTATIONAL MATHEMATICS","09/01/2020","07/24/2020","Per-Gunnar Martinsson","TX","University of Texas at Austin","Standard Grant","Yuliya Gorb","08/31/2023","$111,866.00","","pgm@ices.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271","9263","$0.00","The importance of the numerical simulation of physical phenomena by computers cannot be overstated. Such computations have become essential tools both in scientific research and in industrial research and development. This project concerns the numerical simulation of the scattering of waves. Such simulations have applications to sonar and radar, as well as in medical imaging, geophysics, and many other applications. Wave phenomena become more complicated to model as the frequency of the wave increases, and our current ability to accurately model high-frequency waves is quite limited. This project seeks to develop new methods for modeling high-frequency waves efficiently and to high accuracy. The project provides research training opportunities for graduate students. <br/><br/>The numerical simulation of the scattering of waves from inhomogeneous media has important applications in radar and sonar, medical imaging, geophysics, and a host of other scientific applications. In many cases of interest, such simulations can be performed by solving the variable coefficient Helmholtz equation. The solutions of this equation are oscillatory, and the difficulty of calculating them using conventional approaches grows quickly with the frequency of the oscillations. Recently, one of the investigators developed a new class of solvers for the variable coefficient Helmholtz equation that achieve extremely high accuracy and have run times that scale much more slowly with increasing frequency than conventional solvers. They operate by solving the nonlinear Riccati equation that is satisfied by the logarithms of solutions of the Helmholtz equation. Currently, these solvers only apply in special cases. This project aims to extend them to the general case to develop a method for the variable coefficient Helmholtz equation that is significantly faster than current techniques.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012825","Fast Algorithms for Nonlinear Optimal Control of Geodesic Flows of Diffeomorphisms","DMS","COMPUTATIONAL MATHEMATICS","07/01/2020","06/05/2020","Andreas Mang","TX","University of Houston","Standard Grant","Stacey Levine","06/30/2024","$299,930.00","","andreas@math.uh.edu","4300 MARTIN LUTHER KING BLVD","HOUSTON","TX","772043067","7137435773","MPS","1271","9263","$0.00","Optimal control problems play a critical role in numerous computational sciences applications, including those in medicine, geosciences, manufacturing, national security, or economics. Optimal control problems are a systematic tool to infer knowledge from data, enabling scientific discovery and decision making. They are typically formulated as data-fitting problems with dynamical systems (the simulation problem) as constraints. This simulation problem describes the possible behavior of a natural or engineered system under investigation for given values of input variables (for example, brain tumor and tumor growth rates). In practice, the values are typically not known and cannot be measured directly. One needs to infer them from observational data (for example, a series of patient images) by optimizing a performance goal. This process constitutes the control problem; the unknown variables are the controls of the simulation problem. Solving optimal control problems poses significant mathematical challenges. The project will consider control problems that can have up to billions of unknowns. For decision making, one needs to equip the solutions of the control problem with confidence intervals. This is achieved using a statistical framework, which adds massive computational costs. Moreover, distinct control variable realizations can yield simulation outputs that match the observational data equally well, leading to what is known as ill-posed problems. To alleviate this ambiguity, prior knowledge about plausible solutions can be introduced based on regularization models. However, choosing adequate regularization models remains a significant challenge. This project aims to provide fast, scalable, and robust software tailored to modern computing architectures to address the massive computational costs. The project will focus on learning appropriate regularization models from data. The area of application is statistical shape analysis for classifying objects, and, in particular, the classification of patients (diseased versus healthy) based on the anatomical shape variability of organs. Upon completion, the research will produce a generic mathematical and algorithmic framework for transport-related optimal control problems and more generally inverse problems, along with software infrastructure that applies to a range of problems in (biomedical) imaging sciences, atmospheric sciences, computer vision, remote sensing, data science, and deep learning. The project will provide training for two graduate students and summer research projects for undergraduates.<br/><br/>The research will develop effective, scalable computational methods for nonlinear optimal control of geodesic flows of diffeomorphisms. The novelty is the design of hardware-accelerated computational kernels and efficient numerical schemes that exploit problem structure and rigorously follow mathematical principles for studying shape variability. This is achieved through the design of a Bayesian framework for statistical shape analysis. The quantification of shape variability of distinct realizations of an object under investigation is done through the lens of geodesic flows of diffeomorphisms that map one object to another. In particular, one quantifies the proximity between two shapes by the length of the geodesic path that connects them. From a statistical point of view, one can study shape variability in a database by identifying an average geometry (the ""statistical template"") of a particular object under investigation, and then studies how individual datasets deviate from this average. The project will focus on adaptive, hierarchical numerical schemes, enabling high-accuracy computations if desired, and low-accuracy approximations when possible. The solvers will feature fast computational kernels, maximizing single-node, and single-GPU throughput while maintaining scalability on (heterogeneous) high-performance computing platforms. Work packages include preconditioning, fast hierarchical computational kernels for evaluating forward and adjoint operators, mixed-precision implementations on heterogeneous architectures, and computational methods that exploit problem structure to speed up the solution and allow for high acceptance rates when sampling from high-dimensional probability distributions. In particular, the project will provide methodology for (i) the solution of nonlinear initial value control problems, (ii) uncertainty quantification, (iii) statistical template estimation from large imaging databases, and (iv) learning regularization operators from data.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012022","New Advanced Time Integration Methods for Multiphysics Systems and Applications","DMS","COMPUTATIONAL MATHEMATICS","09/01/2020","09/02/2022","Vu Thai Luan","MS","Mississippi State University","Continuing Grant","Yuliya Gorb","08/31/2024","$130,749.00","","luan@math.msstate.edu","245 BARR AVE","MISSISSIPPI STATE","MS","39762","6623257404","MPS","1271","9150, 9263","$0.00","Many important systems in science and engineering involve multiple physical processes. Complex interactions between these components can result in dynamics over a wide range of time scales, and this feature poses significant challenges for computational simulations. Prominent examples come from the vastly differing time scales in atmospheric phenomena, a central issue of numerical weather prediction (NWP) and climate modeling. Similar challenges arise in computational modeling of dynamics of coupled oscillators such as fibers, fluids, or flexible solids, with many applications in animation and medical imaging. The goal of this project is to develop new fast and accurate time integration methods for complex coupled models and to apply them to NWP and climate simulations as well as to other examples. On the educational side, the project will directly involve and train one doctoral student, as well as offer research opportunities to other undergraduate and graduate students in mathematics.<br/><br/>This project considers general coupled multiphysics systems. The goal is to develop new advanced exponential Rosenbrock/Runge-Kutta and multi-rate time integration methods for multiphysics models. The project has three research objectives. First, the PI plans to derive new parallel and adaptive exponential methods for stiff multiphysics systems. With this in place, the PI aims to derive new time-stepping methods that have optimized structures and local error control for efficiency. Second, the PI plans to develop a complete theory for constructing two new classes of multirate methods for partitioned multiphysics systems. Third, building on existing codes and ongoing collaborations with numerical analysts, meteorologists, and computer scientists, the PI will investigate the performance of newly-developed methods on applications mentioned previously.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012560","Erosion, Transport, and Dispersion in Granular and Porous Media","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","12/12/2022","Matthew Moore","FL","Florida State University","Continuing Grant","Yuliya Gorb","07/31/2023","$249,636.00","Bryan Quaife","mnmoore2@fsu.edu","874 TRADITIONS WAY","TALLAHASSEE","FL","323060001","8506445260","MPS","1271","9263","$0.00","Naturally occurring porous and granular materials, such as soil, sand, and clay, play a pivotal role in regulating the Earth's water resources by filtering contaminants and, over long timescales, supplying fresh water. Understanding of this contamination and filtration cycle relies on the phenomenon of transport and dispersion in porous media, with the added complexity that continually flowing groundwater can, over time, alter the details of the porous medium itself such as the size, shape, and position of individual sand grains. These effects are most noticeable during rapid events such as the gravitational collapse of a sinkhole, but can also occur due to the accumulation of slower processes, such as mechanical or chemical erosion. This project will leverage advanced computational methods to study in detail the interplay between fast and slow processes by which groundwater flow alters porous medium properties. By gaining a deeper understanding of the underlying physical processes, the project offers the societal benefit of better management of water resources in the face external factors, such as contamination or sinkhole formation. For example, the understanding developed herein may enable identification of specific regions most susceptible to contamination or to collapse. Graduate students will be involved and receive mentoring and interdisciplinary training in this project. <br/><br/>This project is to analyze a set of complex, dynamical problems that arise in geophysical porous-media applications by using a host of newly developed computational tools and reduced mathematical models. The particular problems of interest include: (1) the erosion of microscopic constituents of porous media leading to anisotropic macroscopic properties; (2) the modified transport of tracers through the medium, including anomalous dispersion; and (3) the occurrence of catastrophic events, such as sink hole collapse, resulting from interaction between groundwater seepage, erosion, and buoyancy forces. The project will address several computational challenges and opportunities. First the range of scales is vast: spatial scales range from microscopic granular constituents to large geological aquifers; timescales range from that of a sudden sinkhole collapse to years required mechanical and chemical erosion. The systems are inherently multicomponent, with coupling between the fluid and solid phases. Although the governing PDEs are linear, the presence of moving boundaries introduces nonlinear feedback between geometry and flow. One challenge in computational fluid dynamics is to obtain high-fidelity simulations of dense suspensions of dynamic bodies. Using integral equation methods in conjunction with accurate quadrature, fast summation methods, contact algorithms, and high-order time stepping, this project will use fast numerical methods to accurately simulate dense suspensions of anisotropic eroding, dissolving, and sedimenting bodies. Mixed-scale, deep neural networks will be used to learn from the data generated by high-fidelity numerical simulations to parameterize coarse-grained models based on the multiphase framework.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1952848","The Second International Conference on Computational Methods and Applications in Engineering","DMS","COMPUTATIONAL MATHEMATICS","04/01/2020","03/12/2020","Hyeona Lim","MS","Mississippi State University","Standard Grant","Yuliya Gorb","03/31/2023","$13,999.00","Mohsen Razzaghi, Vu Thai Luan, Amanda Diegel","hlim@math.msstate.edu","245 BARR AVE","MISSISSIPPI STATE","MS","39762","6623257404","MPS","1271","7556, 9150, 9263","$0.00","This award supports participation in the Second International Conference on Computational Methods and Applications in Engineering held at Mississippi State University on May 7-9, 2020.  With the rapid development of high-performance computing and its applications, robust mathematical models and their efficient computational algorithms and simulations have emerged as an essential analysis tool in science and engineering. In this regard, various professional scientific/engineering societies host cross-disciplinary conferences and meetings in related areas. However, a truly multidisciplinary conference with a focused theme, which provides a forum for mathematical scientists and engineers to share their research, is needed in the field of computational mathematics, sciences, and engineering. Moreover, this effort should reach researchers from many different countries. For this purpose, an interdisciplinary conference was successfully organized in 2018 by Mississippi State University and Universitatea Politehnica Timisoara, Romania. The main objective of this project is to continue to carry the same theme and tradition of the first conference and to host ?The Second International Conference on Computational Methods and Applications in Engineering? on the campus of Mississippi State University. A mission of the conference is to further expand the established collaboration between the organizing institutions and to provide a joint forum where computational scientists and engineers from all over the world exchange research ideas in related fields. <br/><br/>The conference offers five plenary lectures to be given by experts. The conference will also feature around 50 mini-symposium talks and 80 contributed papers. The mini-symposium topics include: 1) Recent Developments in Non-conforming Finite Element Methods, 2) Recent Advances in Time-Integration of Partial Differential Equations (PDEs), 3) Instability, Transition and Turbulence in Fluids: from Fundamentals to Applications, 4) Constitutive Modeling of Engineering Materials and Computational Simulations, 5) Lower Length Scale Methods in Machine Learning, 6) Recent Advances in Numerical PDEs: Fast Algorithms and Applications, 7) Numerical Methods and Models for High-Performance Computational Fluid Dynamics, and 8) Numerical Methods for Optimization Problems with PDE Constraints. Proceedings of the conference will be published as refereed manuscripts in a special issue of the Journal of Computational and Applied Mathematics. The conference will provide graduate students and early career researchers with an opportunity to present their work, meet other researchers and educators, and learn of recent developments in the field of computational methods and engineering applications.  More details are available on the conference web site https://www.iccmae2020.math.msstate.edu/<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012031","Divergence-Free Hybridizable Discontinuous Galerkin Methods for the Incompressible Navier-Stokes Equations on Moving Domains and Their Application to Fluid-Structure Interaction","DMS","COMPUTATIONAL MATHEMATICS","09/01/2020","07/05/2022","Guosheng Fu","IN","University of Notre Dame","Continuing Grant","Yuliya Gorb","08/31/2023","$263,507.00","","gfu@nd.edu","940 Grace Hall","NOTRE DAME","IN","465565708","5746317432","MPS","1271","9263","$0.00","Fluid-structure interaction (FSI) problems can occur in many fields of engineering, and are a crucial consideration in the design of many systems, such as stability and response of aircraft wings in the aerospace industry, flow of blood through arteries in biomedical applications, and response of bridges and tall buildings to winds in civil engineering. These problems are often too complex to solve analytically and so they have to be analyzed by means of numerical simulations. Efficient, accurate, and robust numerical methods to solve FSI problems are of fundamental importance to these applications. In this project, the PI will concentrate his efforts on the development, analysis, and implementation of high-order strongly mass-conserving finite element methods for incompressible flow problems on moving domains and their application to FSI problems. This project provides research training opportunities for graduate students.<br/><br/>The PI will (1) develop a novel divergence-free hybridizable discontinuous Galerkin (div-free-HDG) scheme for the incompressible Navier-Stokes (INS) equations on moving domains using the Arbitrary Lagrangian-Eulerian (ALE) framework, (2) extend the ALE-div-free-HDG fluid solver to moving-domain FSI problems that model the interaction of incompressible fluids with compressible or incompressible hyperelastic structures. The div-free-HDG scheme for INS on fixed meshes enjoys features such as higher-order accuracy, global and local conservation properties, energy-stability, pressure robustness, minimal amount of numerical dissipation and computational efficiency. The extension of the div-free-HDG scheme to moving domain problems within the ALE framework poses further theoretical and numerical challenges due to the divergence-conforming velocity finite element space used therein. The PI will use a novel alternative formulation of the div-free-HDG scheme, which does not require the divergence conformity of the velocity finite element space, that can be efficiently adapted to the ALE framework for moving domain INS and FSI problems. This work will be the first systematic study of ALE strongly mass-conserving finite element methods for moving domain INS and FSI problems. Rigorous stability analysis will be derived for the methods and their convergence properties will be investigated. Various strategies to further improve the efficiency of these schemes will be studied.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012238","Collaborative Research: RUI: Computational Ptychography: Fast Algorithms, Recovery Guarantees, and Applications to Bio-Imaging","DMS","COMPUTATIONAL MATHEMATICS","09/01/2020","09/02/2022","Adityavikram Viswanathan","MI","Regents of the University of Michigan - Ann Arbor","Continuing Grant","Yuliya Gorb","08/31/2024","$173,904.00","Yulia Georgieva-Hristova","adityavv@umich.edu","1109 GEDDES AVE, SUITE 3300","ANN ARBOR","MI","481091079","7347636438","MPS","1271","9229, 9251, 9263","$0.00","Ptychography refers to an imaging technique where overlapping regions of an object are illuminated, usually by placing a pinhole (and possibly a mask) between a light source and the object, and sequentially moving the pinhole. The resulting diffraction patterns are then sampled and used to calculate an approximate image of the object. The underlying physics of this imaging process dictates that one can only directly collect the intensity of the diffraction patterns, and not the critically important phase information. This makes the recovery of an accurate image extremely challenging. Nevertheless, through careful application of heuristic algorithms, practitioners have successfully employed these methods in a vast array of important applications such as the study of drug delivery mechanisms in complex bio-molecules, study of solar cells and battery chemistry, and the study of fracture dynamics in materials science. Despite these impressive results, several challenges remain, including the need to image larger and larger specimens at increasingly higher resolutions, and the growing size of datasets generated by a new generation of advanced imaging apparatus. This project seeks to develop fast, highly efficient, noise-robust, and mathematically rigorous computational methods in support of this next generation of high-throughput, high-resolution ptychographic imaging. The broader impacts of this project include curriculum development and training of students, including those from underrepresented groups, application of the computational methods to bio-imaging applications in the lab, and knowledge dissemination to raise the scientific literacy of the public.<br/><br/>Mathematically, much progress has been recently made in understanding ptychographic imaging and in analyzing novel algorithms for signal recovery from phase-less measurements. However, these algorithms and their attendant analysis often assume one collects the modulus of generalized linear measurements, where the discretized measurements are highly random. In line with applications, a focus of this project is on designing practical measurement schemes of the type actually used in ptychographic imaging. Another major difficulty in realistic phase-less imaging applications is that the imaging system's measurement masks/probes can often only be approximately implemented and partially known. Hence, another major objective of this project is the development of novel theoretical and algorithmic results for the blind ptychography problem. In either case, the emphasis is on constructing provably accurate recovery algorithms that are fast enough to scale to large problems in multiple dimensions. These tasks require developing and using a broad range of mathematical tools. Techniques from time-frequency analysis, frame theory, spectral graph theory, high-dimensional probability, and compressive sensing will be necessary for analyzing the measurement schemes and for providing rigorous theoretical guarantees for the developed recovery algorithms. Finally, a key component of this project is the application of these computational methods to real ptychographic phase-less imaging setups and bio-imaging applications. More specifically, a novel wide-field, high-resolution lense-less on-chip microscopy platform will be designed, which puts the theoretical techniques developed as part of this project into practice.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1943186","CAREER: Tailored Entropy Stable Discretizations of Nonlinear Conservation Laws","DMS","COMPUTATIONAL MATHEMATICS","09/01/2020","09/05/2023","Jesse Chan","TX","William Marsh Rice University","Continuing Grant","Yuliya Gorb","08/31/2025","$359,747.00","","Jesse.Chan@rice.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","MPS","1271","1045, 9251, 9263","$0.00","The simulation of fluid flow is foundational to many scientific fields, ranging from environmental and aerospace engineering to solar physics.  However, next-generation modeling and analysis is computationally challenging using existing tools.  Tailored numerical methods have the potential to address such limitations.  For example, projection-based reduced order models decrease computational costs associated with many-query scenarios (such as engineering design or uncertainty quantification) by replacing a high fidelity model with a less expensive low-dimensional surrogate.  Similarly, high order accurate schemes are particularly effective at resolving fine-scale features in transient vorticular flows.  Unfortunately, when applied to the equations of fluid dynamics, these numerical methods experience non-physical instabilities which can cause simulations to fail unexpectedly.  The goal of this project is to enable robust and efficient simulations using discretely ""entropy stable"" schemes.  By building fundamental energetic principles directly into a discretization, entropy stable methods retain accuracy while inheriting verifiable properties which improve ""out-of-the-box"" robustness. <br/><br/>Discretely entropy stable high order discretizations for nonlinear conservation laws have seen rapid development over the last 7 years.  This project will extend this methodology to three areas where existing approaches are suboptimal or unavailable: (1) high order methods on non-conforming meshes, (2) high order physical-frame discretizations for domain boundaries with fine-scale features, and (3) reduced order modeling.  Additionally, the PI will integrate aspects of the proposed research with an educational program aimed at promoting computational science and improving retention among college students and K-12 teachers.  Specifically, the PI will (1) design and supervise senior capstone research projects for engineering undergraduates, and (2) organize a summer research program for K-12 teachers centered around numerical modeling and discovery-based learning. The summer research program will also provide graduate students with mentoring experience, and the PI will follow up by partnering with teachers to incorporate concepts from numerical computing into reusable classroom modules.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012140","Collaborative Research: Computational Ptychography: Fast Algorithms, Recovery Guarantees, and Applications to Bio-Imaging","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","09/01/2020","06/15/2023","Guoan Zheng","CT","University of Connecticut","Continuing Grant","Yuliya Gorb","02/29/2024","$146,568.00","","guoan.zheng@uconn.edu","438 WHITNEY RD EXTENSION UNIT 11","STORRS","CT","062691133","8604863622","MPS","1253, 1271","9263","$0.00","Ptychography refers to an imaging technique where overlapping regions of an object are illuminated, usually by placing a pinhole (and possibly a mask) between a light source and the object, and sequentially moving the pinhole. The resulting diffraction patterns are then sampled and used to calculate an approximate image of the object. The underlying physics of this imaging process dictates that one can only directly collect the intensity of the diffraction patterns, and not the critically important phase information. This makes the recovery of an accurate image extremely challenging. Nevertheless, through careful application of heuristic algorithms, practitioners have successfully employed these methods in a vast array of important applications such as the study of drug delivery mechanisms in complex bio-molecules, study of solar cells and battery chemistry, and the study of fracture dynamics in materials science. Despite these impressive results, several challenges remain, including the need to image larger and larger specimens at increasingly higher resolutions, and the growing size of datasets generated by a new generation of advanced imaging apparatus. This project seeks to develop fast, highly efficient, noise-robust, and mathematically rigorous computational methods in support of this next generation of high-throughput, high-resolution ptychographic imaging. The broader impacts of this project include curriculum development and training of students, including those from underrepresented groups, application of the computational methods to bio-imaging applications in the lab, and knowledge dissemination to raise the scientific literacy of the public.<br/><br/>Mathematically, much progress has been recently made in understanding ptychographic imaging and in analyzing novel algorithms for signal recovery from phase-less measurements. However, these algorithms and their attendant analysis often assume one collects the modulus of generalized linear measurements, where the discretized measurements are highly random. In line with applications, a focus of this project is on designing practical measurement schemes of the type actually used in ptychographic imaging. Another major difficulty in realistic phase-less imaging applications is that the imaging system's measurement masks/probes can often only be approximately implemented and partially known. Hence, another major objective of this project is the development of novel theoretical and algorithmic results for the blind ptychography problem. In either case, the emphasis is on constructing provably accurate recovery algorithms that are fast enough to scale to large problems in multiple dimensions. These tasks require developing and using a broad range of mathematical tools. Techniques from time-frequency analysis, frame theory, spectral graph theory, high-dimensional probability, and compressive sensing will be necessary for analyzing the measurement schemes and for providing rigorous theoretical guarantees for the developed recovery algorithms. Finally, a key component of this project is the application of these computational methods to real ptychographic phase-less imaging setups and bio-imaging applications. More specifically, a novel wide-field, high-resolution lense-less on-chip microscopy platform will be designed, which puts the theoretical techniques developed as part of this project into practice.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012634","Collaborative Research:  Efficient, Accurate, and Structure-Preserving Numerical Methods for Phase Fields-Type Models with Applications","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","06/17/2020","Steven Wise","TN","University of Tennessee Knoxville","Standard Grant","Yuliya Gorb","07/31/2024","$200,000.00","","swise1@utk.edu","201 ANDY HOLT TOWER","KNOXVILLE","TN","379960001","8659743466","MPS","1271","9263","$0.00","The project will develop computational methods for simulations of phase transformations in materials at the atomic and nanometer scales, aiming at understanding behavior at large time scales. With these simulations, the project will contribute to the understanding of processes such as complex biological growth and cancer, multi-phase active-particle and ionic fluids relevant in biological growth and development, and in the study of other complex phenomena in physics, and material engineering. The focus will be on a particular class of models: gradient flow equations with singular energy potentials. The project will develop theory and software; the codes developed in this project will be scaled up to conduct real-world three-dimensional simulations. In addition, some numerical algorithms to be developed could impact the field of deep learning. This project will provide interdisciplinary applied mathematics and scientific computing training and research experiences for both graduate and undergraduate students at the two institutions involved.<br/><br/>In the proposed gradient flow models, a singularity is involved in the energy potential, so that the positivity-preserving property becomes a crucial feature to make the numerical approximation well-defined. In addition, energy stability and optimal rate convergence analysis will be considered for these gradient model with singular energy potential, such as the doubly degenerate Cahn-Hilliard model describing surface diffusion, a new phase field crystal model with heat transport for simulating solidification, a new quasi-incompressible Cahn-Hilliard-Navier-Stokes model for two-phase density mismatched flow, the Poisson-Nernst-Plank model for ionic mixtures, and multi-phase magneto-hydrodynamics equations. Novel finite difference, mixed finite element, and/or Fourier pseudo-spectral spatial approximations will be utilized. Convergence analysis up to the third order temporal accuracy will be investigated in details, which will be the first such work for gradient flows with singular potential. Moreover, numerical solvers for these highly nonlinear schemes will be designed and analyzed, based on the preconditioned steepest decent and Nesterov accelerated methods. Highly efficient adaptive nonlinear multigrid methods based will also be tested and studied in details.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012235","Finite Element Methods for Nonstationary Magnetohydrodynamics","DMS","COMPUTATIONAL MATHEMATICS","07/01/2020","07/05/2022","Ke Shi","VA","Old Dominion University Research Foundation","Continuing Grant","Yuliya Gorb","06/30/2024","$164,287.00","","kshi@odu.edu","4111 MONARCH WAY","NORFOLK","VA","235082561","7576834293","MPS","1271","9263","$0.00","The word magnetohydrodynamics derives from magneto-, meaning magnetic field, hydro-, meaning water, and dynamics, meaning movement. It describes the interaction of electrically-conducting fluids and electromagnetic fields. The fundamental concept behind magnetohydrodynamics (MHD) is that magnetic fields can induce currents in a moving conductive fluid, which in turn polarizes the fluid and reciprocally changes the magnetic field itself.  Examples of such fluids include plasmas, liquid metals, and salt water or electrolytes. Applications of MHD play a role in many disciplines such as astrophysics, engineering related to liquid metal, and controlled thermonuclear fusion. Due to its significant role in applications, there have been many studies on the MHD systems from both theoretical and practical viewpoints. Designing and analyzing numerical methods to solve this system is in general a challenging task due to the multi-physical nature of the problem. The aim of this project is to develop novel numerical methods for solving MHD systems efficiently and accurately. The project provides opportunities for graduate and undergraduate student involvement in the research.<br/><br/>The governing equations of the MHD model display a nonlinear coupling between the nonstationary Navier-Stokes equations of fluid dynamics and Maxwell's equations of electromagnetism. With conventional numerical methods, the approximation may converge to a ""wrong'' solution when the exact solution has singularities. In addition, for incompressible MHD models, both the velocity and magnetic fields are divergence free, and numerical computations that do not automatically preserve this property can suffer severe errors. This research aims to design robust structure-preserving numerical methods for MHD equations with high order convergent approximations for both smooth and nonsmooth domains. To achieve this goal, the project employs hybridizable discontinuous Galerkin methods (HDG) in view of their high order accuracy, easy implementation, flexible meshing, and local structure preserving for physical moments, etc. Because many applications require repeated simulations to obtain enough statistical data, this research project will also develop state-of-the-art ensemble HDG algorithms and will combine HDG schemes with other model reduction techniques to further enhance efficiency for large scale computations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012554","When Can We Cluster Data? Improved Conditions for Perfect Recovery and Numerical Methods","DMS","COMPUTATIONAL MATHEMATICS, EPSCoR Co-Funding","08/15/2020","06/12/2020","Brendan Ames","AL","University of Alabama Tuscaloosa","Standard Grant","Yuliya Gorb","12/31/2023","$129,374.00","","bpames@ua.edu","301 ROSE ADMIN BLDG","TUSCALOOSA","AL","354870001","2053485152","MPS","1271, 9150","9150, 9263","$0.00","The clustering procedure is ubiquitous in science and engineering, especially in analysis of massive data sets and complex networks. The purpose of clustering is to divide a given data set into groups of similar items, called clusters. Although many heuristics for clustering exist (and are widely used), the theoretical properties of this learning task are less well-understood. Relatively few theoretical analyses have been performed establishing conditions under which we may expect to successfully cluster data. The goal of this project is to establish realistic theoretical guarantees for clustering, both in terms of data amenable to clustering as well as in the development of effective, computationally efficient algorithms. The project will facilitate interdisciplinary research via applications in image processing, astronomy and physics, mathematical biology, social network analysis, and high-dimensional statistics. The project will also provide educational opportunities for graduate and undergraduate students through the development of new courses focusing on the interaction of machine learning and large-scale optimization, interdisciplinary undergraduate research programs, and K-12 outreach programs.<br/><br/>The project focuses on two main research thrusts. The first concerns the generalization of average case analyses and theoretical guarantees for perfect recovery for convex relaxations of model problems for clustering, such as the densest submatrix localization and graph partition problems. The goal of these analyses is to extend the existing state of the art to probabilistic models for data that are more representative of data observed in practical applications. Extensive average planted case analyses will be performed to establish computational and information-theoretic bounds for perfect recovery under generalizations of the stochastic block model. The second thrust will focus on the design, analysis, and implementation of numerical methods for large-scale semidefinite and nonlinear optimization, with specific focus on the algorithms for model problems for clustering and classification.  Theoretical convergence analysis and numerical simulation will be performed to illustrate the efficacy of the methods. This project is jointly funded by the Computational Mathematics program and the Established Program to Stimulate Competitive Research (EPSCoR).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012490","Collaborative Research: Models, Algorithms, Simulations, and Applications for Three-Phase Systems with Solidification and Moving Contact Lines","DMS","COMPUTATIONAL MATHEMATICS","09/01/2020","07/29/2020","XIAOFENG YANG","SC","University of South Carolina at Columbia","Standard Grant","Yuliya Gorb","08/31/2024","$135,000.00","","xfyang@math.sc.edu","1600 HAMPTON ST # 414","COLUMBIA","SC","292083403","8037777093","MPS","1271","9150, 9263","$0.00","This project will develop mathematical models and numerical algorithms to address challenges in modeling fluids with multiple phases such as liquid, solid and ice. Phenomena with multiple fluid phases play an important role in many natural phenomena and industrial applications, such as atmospheric icing, additive manufacturing, and thermal spraying.  For example, when a rain drop impacts onto a cold solid surface, it spreads on the solid and at the same time freezes due to the low temperature. The physical problem involves three phases (liquid, solid of the same material, and air) and the interfaces are governed by different physics. The numerical models to be developed will advance the understanding of the underlying physics and provide guidance to the design of icephobic surfaces for aircrafts, 3D printers, and thermal spraying devices. Students will be involved and trained in the computational mathematics and interdisciplinary aspects of this project.<br/><br/>This project has the following goals: (i) to derive a variational phase-field model to describe the evolution of the solidification front as well as the liquid-air interface, with the consideration of contact line dynamics, non-equilibrium solidification, and variable density/viscosity; (ii) to develop efficient, easy-to-implement, and energy-stable numerical schemes with discrete energy laws for the proposed models; and (iii) to perform numerical simulations to validate the models and numerical schemes, and further study physically motivated problems. The model satisfies a physically consistent energy law, which is a necessary condition for a faithful description of real physics. The developed numerical schemes are energy-stable with the advantage of allowing large time steps, which is particularly important to this multi-physics problem with disparate time scales. The developed codes will allow us to simulate the solidification of flowing drops made of different materials in a wide variety of applications.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012480","Collaborative Research: Models, Algorithms, Simulations, and Applications for Three-Phase Systems with Solidification and Moving Contact Lines","DMS","COMPUTATIONAL MATHEMATICS","09/01/2020","07/29/2020","Pengtao Yue","VA","Virginia Polytechnic Institute and State University","Standard Grant","Yuliya Gorb","08/31/2024","$165,000.00","","ptyue@math.vt.edu","300 TURNER ST NW","BLACKSBURG","VA","240603359","5402315281","MPS","1271","9263","$0.00","This project will develop mathematical models and numerical algorithms to address challenges in modeling fluids with multiple phases such as liquid, solid and ice. Phenomena with multiple fluid phases play an important role in many natural phenomena and industrial applications, such as atmospheric icing, additive manufacturing, and thermal spraying.  For example, when a rain drop impacts onto a cold solid surface, it spreads on the solid and at the same time freezes due to the low temperature. The physical problem involves three phases (liquid, solid of the same material, and air) and the interfaces are governed by different physics. The numerical models to be developed will advance the understanding of the underlying physics and provide guidance to the design of icephobic surfaces for aircrafts, 3D printers, and thermal spraying devices. Students will be involved and trained in the computational mathematics and interdisciplinary aspects of this project.<br/><br/>This project has the following goals: (i) to derive a variational phase-field model to describe the evolution of the solidification front as well as the liquid-air interface, with the consideration of contact line dynamics, non-equilibrium solidification, and variable density/viscosity; (ii) to develop efficient, easy-to-implement, and energy-stable numerical schemes with discrete energy laws for the proposed models; and (iii) to perform numerical simulations to validate the models and numerical schemes, and further study physically motivated problems. The model satisfies a physically consistent energy law, which is a necessary condition for a faithful description of real physics. The developed numerical schemes are energy-stable with the advantage of allowing large time steps, which is particularly important to this multi-physics problem with disparate time scales. The developed codes will allow us to simulate the solidification of flowing drops made of different materials in a wide variety of applications.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2105487","Advances in Numerical Methods for Wave Propagation in Inhomogeneous Media","DMS","COMPUTATIONAL MATHEMATICS","09/01/2020","11/16/2020","Lise-Marie Imbert-Gerard","AZ","University of Arizona","Standard Grant","Yuliya Gorb","06/30/2023","$122,313.00","","lmig@math.arizona.edu","845 N PARK AVE RM 538","TUCSON","AZ","85721","5206266000","MPS","1271","9263","$0.00","The scientific thrust of this project is devoted to the creation of methods for the numerical simulation of wave propagation in complicated materials with variable material properties. Generalized Plane Wave functions, introduced by the PI during her PhD, have already been proven to lead to be efficient tools for simple problems. Analyzing the corresponding methods will be a central focus of our work, with application to noise reduction in turboreactors.  The proposed work is expected to enable noticeable improvements in the numerical methods used to study acoustic effects in an air flow around a turboreactor. As recently reported by the Washington Post, airplanes have a huge impact on noise pollution. Taking into account noise reduction in the design of future aircrafts is very challenging, and will impact public health and policy.<br/><br/>Although GPW-based schemes represent a very promising numerical tool, little is known analytically about their performance. Sharper and more detailed estimates are necessary, however, to increase their impact on the community. This proposal focuses on the numerical simulation of wave propagation problems in inhomogeneous media, modeled by variable coefficients, in two and three dimensions. The principal application targeted is wave propagation in aeroacoustics in collaboration with Airbus SAS, where the source of inhomogeneity is the non-uniform flow, but the methods considered in this project will also apply to other variable material properties such as permittivity or sound speed. Novel mathematical and computational challenges need to be addressed in order to avoid the numerical error introduced a priori by a piece-wise constant approximation of the coefficients. Trefftz methods rely, in broad terms, on the idea of approximating solutions to PDEs using basis functions which are exact solutions, making explicit use of information about the ambient medium. This project is concerned with the design, mathematical analysis and computer implementation of numerical methods adapted to variable coefficients via Generalized Plane Wave (GPW) basis functions. The following research directions are proposed: (1) construction of GPWs for the convected Helmholtz equation, (2) h-version of convergence analysis, corresponding to refining the mesh, (3) p-version of convergence analysis, corresponding to increasing the number of basis functions with a fixed mesh, (4) implementation of a prototype GPW-Trefftz code for performance comparison with other methods.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012326","Finite Element Methods for the Surface Stokes Equation","DMS","COMPUTATIONAL MATHEMATICS","09/01/2020","09/02/2022","Alan Demlow","TX","Texas A&M University","Continuing Grant","Yuliya Gorb","08/31/2024","$209,995.00","","demlow@math.tamu.edu","400 HARVEY MITCHELL PKY S STE 30","COLLEGE STATION","TX","778454375","9798626777","MPS","1271","9263","$0.00","The Navier-Stokes system of partial differential equations is widely used to model fluid flows in physical applications.  These equations have importance for example in modeling emulsions, foams, and biological membranes. The goal of this project is to computationally solve related equations that are posed on surfaces instead of on flat domains or spaces.  For example, membranes of cells can be thought of as fluids that flow and deform, and the surface of such a cell can be modeled using a surface Navier-Stokes system.  Constructing accurate and efficient numerical methods for such surface fluid problems involves overcoming some challenges different from those encountered in the well-studied case of fluids on flat domains.  Various ways of solving these issues have been proposed in recent years.  The project will provide foundational theoretical backing for one major class of such methods and give new insight into its practical properties. The project provides training for graduate students through involvement in the research.<br/><br/>Surface finite element methods (SFEM) have grown into an important practical tool for simulations for physical models involving partial differential equations posed on surfaces.  Many finite element methods exist for solving scalar elliptic problems on surfaces, but not much work has been done for surface vector Laplace-type operators such as surface (Navier-)Stokes system for modeling fluid flow on surfaces.   The main goal of this project is to develop and analyze new finite element algorithms for surface partial differential equations involving the Stokes operator.  The first part of the project will focus on algorithms for the stationary (linear) Stokes problem.  A new divergence-conforming trace finite element method will be developed.  This method will provide a new tool for solving problems involving surface fluid models with coupled bulk effects.  In addition, further theoretical analysis will be carried out for both this new algorithm and existing ones, with the focus being mostly on geometric errors which arise in SFEM due to the approximation of the actual surface on which the problem is posed by a discrete counterpart. Their behavior is well understood for scalar elliptic problems, but not for vector Laplace-type operators.  Finally, algorithms will be developed and studied for time-dependent Stokes and Navier-Stokes systems on prescribed and evolving surfaces.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011148","Imaging and Sensing via Plasmonic Nanohole Resonances: Quantitative Analysis and Numerical Inversion","DMS","COMPUTATIONAL MATHEMATICS","09/01/2020","08/03/2022","Junshan Lin","AL","Auburn University","Continuing Grant","Yuliya Gorb","06/30/2024","$221,487.00","","jzl0097@auburn.edu","321-A INGRAM HALL","AUBURN","AL","368490001","3348444438","MPS","1271","9150, 9263","$0.00","Plasmonic structures patterned with subwavelength holes can induce various types of resonances, which lead to the so-called extraordinary optical transmission (EOT) and strongly localized optical field near the hole apertures. Such remarkable phenomenon has found significant applications in biological and chemical sensing, optical lenses, and other novel optical devices. This project will examine the fundamental mathematical and computational issues arising from the imaging and sensing problems that arise from these plasmonic structures. Specifically, this project will develop analytical and computational tools to solve the underlying inverse problems in an efficient and innovative manner. The outcome of the project will provide experimentalists with essential mathematical tools in applications of nano-plasmonic structures for biochemical sensing and to provide new avenues for super-resolution imaging.  This project will also provide interdisciplinary applied mathematics training and research experiences for both graduate and undergraduate students.<br/><br/>The project will address key scientific challenges in the mathematical investigation of plasmonic nanohole resonances and their applications in imaging and sensing.  First, analytical tools based upon a combination of boundary integral equation approach, asymptotic analysis, and the Gohberg-Sigal theory will be developed for characterization of spectral sensitivity when plasmonic nanoholes are used in biochemical sensing. In addition, in order to accelerate the solution of related inverse spectral problems, efficient finite element-boundary integral equation eigensolvers will be designed to address the significant computational challenges brought by multiscale nature of the underlying problems. Finally, motivated by the studies of plasmonic nanohole resonances, the PI proposes a new super-resolution imaging modality by using illumination pattern generated from a collection of subwavelength hole resonantors. The new illumination pattern allows for probing the high spatial frequency component of the imaging sample in order to break the diffraction limit. In this regard, the PI will investigate the mathematical modeling, and develop deconvolution and optimization type numerical approaches for the corresponding inverse problems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012857","Numerical Methods for Geometric Partial Differential Equations with Applications in Numerical Relativity","DMS","Gravity Theory, COMPUTATIONAL MATHEMATICS","07/01/2020","06/09/2020","Michael Holst","CA","University of California-San Diego","Standard Grant","Yuliya Gorb","06/30/2024","$450,000.00","Randolph Bank, Lee Lindblom","mholst@math.ucsd.edu","9500 GILMAN DRIVE","LA JOLLA","CA","920930021","8585344896","MPS","1244, 1271","9263","$0.00","This project is concerned with the approximate solution of systems of stationary and evolution partial differential equations (PDE) arising at the intersection of mathematical physics and geometric analysis.  Such systems of equations, known as Geometric PDE, with both constraints and extra degrees of freedom, appear in a wide range of physical and mathematical problems; examples include Maxwell's equations (or more generally the Yang-Mills equations on a curved background), and Einstein's field equations and other Hamiltonian systems. The initial-value formulation for such systems yields a constrained evolution system which has to be augmented with side conditions in order to get a unique evolution.  The non-dynamical geometric PDE (as constraints or otherwise) are of great interest in their own right; examples include the Yamabe problem, the Hamiltonian and momentum constraints in the Einstein equations, and the Monge-Ampere equations, among others.  One of the most challenging features of this class of problems, for both mathematical analysis and computational simulation, is the underlying spatial domain which has the structure of a manifold with potentially complicated topology.  Moreover, both the geometry and the topology may evolve over time, depending on the particular model.  The results of this project have the potential for broad impact on areas of mathematics such as geometric analysis, as well as in astrophysics and general relativity.  The methods developed here will contribute to the advancement of numerical methods for complex three-dimensional constrained nonlinear dynamical simulations.  The simulation technology produced will provide powerful tools for the exploration of mathematical and computational models in astrophysics and relativity, as well as in some areas of pure mathematics such as geometric analysis. This project provides research training opportunities for graduate students.<br/> <br/>The primary technical aims of this project are to develop new discretization techniques for a class of geometric PDE that includes the Einstein equations.  The emphasis is on modeling cases that present particular challenges for current state-of-the-art methods and software currently used for the Einstein equations, such as the case of extreme mass ration binary black hole systems.  The tools will be the development of approximation theory, together with reliable and provably convergent adaptive methods, for the intrinsic discretization of the class of nonlinear geometric PDE on Riemannian 2- and 3- manifolds.  Most of the approaches to date, such as surface finite element methods for two-dimensional problems, are based on exploiting the embedding of the surface into three space, and then on use of method-of-lines discretization for separating the space and time discetizations.  For applications such as general relativity, a more general approach is needed that does not rely on the existence of such an embedding, and does not on an a priori spatial slicing.  This project studies the development of truly intrinsic discretizations that use no extrinsic information to produce a discretization, to allow for the development of numerical methods for evolution PDE on Riemannian 2- and 3-manifolds with arbitrary topology and without imposing an a priori discrete spatial slicing.  The approach is to develop atlas-based discretization techniques and space-time discretizations based on explicit tent-pitching methods or fully implicit space-time discetizations.  For the design of such methods and their analysis, researchers will exploit variational crimes frameworks developed by their team and collaborators for analyzing numerical methods posed on surfaces, and through use of the finite element exterior calculus framework.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012429","Collaborative Research: Next-Generation Cutting Planes: Compression, Automation, Diversity, and Computer-Assisted Mathematics","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","07/28/2020","Yuan Zhou","KY","University of Kentucky Research Foundation","Standard Grant","Yuliya Gorb","07/31/2024","$179,768.00","","yuan.zhou@uky.edu","500 S LIMESTONE","LEXINGTON","KY","405260001","8592579420","MPS","1271","9150, 9263","$0.00","Mixed-integer optimization is a powerful mathematical decision-making technology related to operations research, data sciences, and artificial intelligence. This project considers applications in which high-stake decisions need to be made quickly and account for unknown future event or risk. In such applications, simulation methods and machine learning cannot give sufficient confidence for protecting against the possibility of catastrophic failures. Instead, one requires multi-parametric optimization to precompute responses, certify their safety, and guarantee the level of performance. In this direction, the investigators will study a key component of optimization algorithms called general purpose cutting planes in a novel multi-parametric setting suitable for process control in chemical engineering and optimizing compilers for high-performance computing platforms, aiming for major theoretical and computational advances that will generalize to many important applications. Broader impacts include the training of undergraduate and graduate students in computational mathematics and research skills, as well as development of high-quality open-source research software, and of further connections between several research communities within mathematics, computer science, and engineering.<br/><br/>Mixed-integer (linear and nonlinear) optimization is concerned with finite-dimensional, non-convex optimization problems that include discrete decision variables such as those that model ""yes/no"" decisions. Systems of this type arise in all areas of industry and the sciences. Algorithms for mixed-integer optimization build upon convex optimization technology by relaxation, approximation, convexification, and decomposition techniques. Increases in system size in the presence of Big Data technologies creates new challenges that need to be addressed by a next generation of algorithms. This project studies convexification, specifically, cutting planes in multi-row and multi-cut cutting plane systems that are effective and efficient from the aspects of compression, automation, and diversity. In particular, spaces of extreme continuous piecewise linear cut-generating functions with prescribed features will be computed; these consist of semi-algebraic cells, parametrizing sub-additive piecewise linear functions, glued at their boundaries. The computation of each cell requires the proof of a theorem, and automated theorem proving technology, based on metaprogramming and semi-algebraic computations, will be developed. The investigators will apply the new cutting plane techniques to two target applications for which guaranteed correctness and performance is mission-critical: model predictive control in chemical process engineering and optimizing compilers for high-performance computing platforms. The multi-parametric optimization problems in both applications will benefit from the parametric nature of the new cutting planes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012269","Collaborative Research:  Efficient, Accurate, and Structure-Preserving Numerical Methods for Phase Fields-Type Models with Applications","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","06/17/2020","Cheng Wang","MA","University of Massachusetts, Dartmouth","Standard Grant","Yuliya Gorb","07/31/2024","$150,000.00","","cwang1@umassd.edu","285 OLD WESTPORT RD","NORTH DARTMOUTH","MA","027472356","5089998953","MPS","1271","9263","$0.00","The project will develop computational methods for simulations of phase transformations in materials at the atomic and nanometer scales, aiming at understanding behavior at large time scales. With these simulations, the project will contribute to the understanding of processes such as complex biological growth and cancer, multi-phase active-particle and ionic fluids relevant in biological growth and development, and in the study of other complex phenomena in physics, and material engineering. The focus will be on a particular class of models: gradient flow equations with singular energy potentials. The project will develop theory and software; the codes developed in this project will be scaled up to conduct real-world three-dimensional simulations. In addition, some numerical algorithms to be developed could impact the field of deep learning. This project will provide interdisciplinary applied mathematics and scientific computing training and research experiences for both graduate and undergraduate students at the two institutions involved. <br/><br/>In the proposed gradient flow models, a singularity is involved in the energy potential, so that the positivity-preserving property becomes a crucial feature to make the numerical approximation well-defined. In addition, energy stability and optimal rate convergence analysis will be considered for these gradient model with singular energy potential, such as the doubly degenerate Cahn-Hilliard model describing surface diffusion, a new phase field crystal model with heat transport for simulating solidification, a new quasi-incompressible Cahn-Hilliard-Navier-Stokes model for two-phase density mismatched flow, the Poisson-Nernst-Plank model for ionic mixtures, and multi-phase magneto-hydrodynamics equations. Novel finite difference, mixed finite element, and/or Fourier pseudo-spectral spatial approximations will be utilized. Convergence analysis up to the third order temporal accuracy will be investigated in details, which will be the first such work for gradient flows with singular potential. Moreover, numerical solvers for these highly nonlinear schemes will be designed and analyzed, based on the preconditioned steepest decent and Nesterov accelerated methods. Highly efficient adaptive nonlinear multigrid methods based will also be tested and studied in details.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012371","RUI: Computational Models for Coupled Free/Porous Media Flow","DMS","COMPUTATIONAL MATHEMATICS","09/01/2020","07/22/2022","Svetlana Tlupova","NY","SUNY College of Technology Farmingdale","Continuing Grant","Yuliya Gorb","08/31/2024","$160,114.00","","tlupovs@farmingdale.edu","2350 BROADHOLLOW RD","FARMINGDALE","NY","117351006","6314202687","MPS","1271","9263","$0.00","This project will study fluid flow models with applications in human health and the environment. The focus is on models that combine a free fluid part and a porous media part. For example, in physiology, such fluid flow models help to understand transport of oxygen and nutrients between blood vessels and tissue. In hydrology, such models can be used to study and predict contamination by toxic chemicals from leaky underground storage tanks or landfills mixing with groundwater. In industrial filtration, the flow models studied in this project can be incorporated into more complex models to optimize the design of the three-way catalytic converter used to reduce vehicle emission levels. Efficient computer simulation of these coupled free/porous flows remains challenging due to the multi-physics nature of the systems. This research aims to develop accurate and efficient numerical simulation techniques for such models. The project provides training through undergraduate research experiences.<br/><br/>This project studies models of coupled flow systems using the incompressible Stokes equations in the free domain and the Darcy equations in the porous domain. An advection-diffusion equation is added to the system to model the transport phenomena at the free/porous interface. The research aims to develop, analyze, and implement an integrated numerical model of this system of equations in three dimensions. The main goals are to (i) address severe limitations of the direct solution, due to incompatibilities in the differential operators in the free and porous subdomains, (ii) develop robust, high accuracy, and well-conditioned integral equation formulations, (iii) apply rigorous analysis on the iterative methods to deduce optimal convergence, and (iv) add the ability to combine different methods of discretization to effectively model heterogeneous porous media. The project will develop a new boundary integral formulation, with regularization and correction for high accuracy, and a simple quadrature based on implicit representation of the surface. Efficient domain decomposition methods with new transmission conditions based on non-local operators will be used to speed up the iteration process. High-performance computing techniques and a kernel-independent treecode algorithm will be implemented to increase the speed of computations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012451","Collaborative Research: On Some Fundamental Computational Issues in Simulating Interaction Models","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","08/15/2020","12/09/2022","Jingfang Huang","NC","University of North Carolina at Chapel Hill","Continuing Grant","Yuliya Gorb","07/31/2024","$258,886.00","","huang@email.unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275995023","9199663411","MPS","1253, 1271","1515, 9263","$0.00","This project will investigate some fundamental computational issues for mathematical interaction models arising from scientific and engineering applications. Examples of these models include the electromagnetic and gravitational interactions in physics, interactions between molecules or cells in biology, and more general fractional differential equations and network models in material science, quantum theory, and social science. It is evident that modern interaction models are becoming more complex and demanding more accurate and efficient computational methods to handle the large scale interactions on high-performance computers. This project will (1) introduce novel representations of interaction models that are suitable for accelerated computation, (2) design efficient algorithms for interaction evaluations, (3) develop advanced open source tools, and (4) apply them to applications in nano-photonic devices, remote sensing, and medical imaging devices. This project will also train graduate students, including those from under-represented groups in STEM fields. This project will support one graduate per year for all 3 years on one campus and one graduate per year for years 2 and 3 on the other campus.<br/> <br/>In most interaction models, kernels usually depend on the spatial or temporal locations that may include the contributions from the interfaces between different materials. They may even depend on the given density functions at both the source and target locations. It is critical to find suitably compressed kernel representations for easier analysis and accelerated computation. This project will start from the optimal representations of the layered media Green?s functions for acoustic and electromagnetic waves that are spatially variant due to the contributions from the layer interfaces. These will be found through optimal integration contours and the corresponding discretized basis functions. The PIs will also generalize the partial-wave and plane-wave frame representations of the Laplace layer potentials to Yukawa, Helmholtz, and layered media potentials. The result will lead to better compressed density, kernel, and potential representations of more challenging non-local models in physics, biology, material science, social science, and image analysis. The PIs will develop effective numerical schemes for computing the compressible features and accelerating their algebraic operations by utilizing a multi-resolution framework to identify the interaction kernel features at different scales. The project also aims to create advanced open source software packages for the commonly used Laplace, Yukawa, and Helmholtz equations. Finally, through collaborations with application domain scientists and engineers, the numerical tools will be used in the design of optimal nano-photonic devices such as passive cooling devices, which may lead to a reduced carbon footprint and help socioeconomically disadvantaged communities lower their energy bills.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2010107","High Order Schemes: Robustness, Efficiency, and Stochastic Effects","DMS","COMPUTATIONAL MATHEMATICS","07/01/2020","06/26/2020","Chi-Wang Shu","RI","Brown University","Standard Grant","Yuliya Gorb","06/30/2024","$350,000.00","","chi-wang_shu@brown.edu","1 PROSPECT ST","PROVIDENCE","RI","029129127","4018632777","MPS","1271","9150, 9263","$0.00","This project concerns algorithm design and analysis of efficient, highly accurate numerical methods for solving partial differential equations. Such equations are used in simulation of systems arising in diverse application fields such as aerospace engineering, semi-conductor device design, astrophysics, and biology.  Even with today's fast computers, efficient computational solution of partial differential equations remains a challenge, and it is essential to design improved algorithms that can be used to obtain accurate solutions in these application models.  The research aims to produce a suite of powerful computational tools suitable for computer simulations of the complicated solution structure in these applications. The project provides training for a graduate student through involvement in the research.<br/><br/>This project conducts research in algorithm development, analysis, and application of high order numerical methods, including discontinuous Galerkin (DG) finite element methods and finite difference and finite volume weighted essentially non-oscillatory (WENO) schemes, for solving linear and nonlinear convection-dominated partial differential equations, emphasizing scheme robustness, efficiency, and the treatment of stochastic effects.  The project focuses on algorithm development and analysis. Topics of investigation include a new class of multi-resolution WENO schemes with increasingly higher order of accuracy, an inverse Lax-Wendroff procedure for high-order numerical boundary conditions for finite difference schemes on Cartesian meshes solving problems in general geometry, efficient and stable time-stepping techniques for DG schemes and other spatial discretizations, high order accurate bound-preserving schemes and applications, entropy stable DG methods, optimal convergence and superconvergence analysis of DG methods, numerical solutions of stochastic differential equations, and the study of modeling, analysis, and simulation for traffic flow and air pollution.  Applications motivate the design of new algorithms or new features in existing algorithms; mathematical tools will be used to analyze these algorithms to give guidelines for their applicability and limitations and to enhance their accuracy, stability, and robustness; and collaborations with engineers and other applied scientists will enable the efficient application of these new algorithms.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012296","Numerical Methods for Waves: Nonlocal, Nonlinear, and Multiscale Systems","DMS","COMPUTATIONAL MATHEMATICS","07/01/2020","07/01/2022","Thomas Hagstrom","TX","Southern Methodist University","Continuing Grant","Yuliya Gorb","06/30/2024","$342,492.00","","thagstrom@smu.edu","6425 BOAZ LANE","DALLAS","TX","75205","2147684708","MPS","1271","9263","$0.00","The reliable simulation of complex physical phenomena can benefit society and help satisfy human curiosity in countless ways. Examples range from the very small, such as the design of nanoscale devices and emerging applications of quantum systems, to the very large, such as natural disasters caused by earthquakes and tsunamis, as well as our understanding of the dynamics and evolution of the cosmos. Although computational capabilities are increasing, with a push towards exascale systems, the computer hardware itself is becoming more heterogeneous and difficult to use efficiently, and the challenges posed by the models one wishes to solve are also rapidly growing. The need to develop and deploy better algorithms is urgent if the tremendous promise of the new computing technologies is to be realized. This research program is focused on the invention of new fast and accurate methods for solving comprehensive models of physical systems where wave propagation plays a central role, with applications throughout the range of problems outlined above.<br/><br/>A primary obstacle to simulating waves is the multiscale nature of most applied problems. On the one hand, the defining feature of waves is their ability to propagate long distances relative to their wavelength, effectively leading to problems posed on unbounded domains. On the other, waves interact with media that may vary at or below the wavelength scale. A central theme in such models is the appearance of nonlocal operators; one main goal of the project is the construction of fast, accurate, and memory-efficient algorithms to evaluate them. This includes the development of (i) effective and mathematically justified domain truncation algorithms for general wave propagation problems, which at present are only available for a limited class of systems, (ii) methods for numerically constructing accurate reduced-order models of wave propagation in the presence of subwavelength variations in material properties, capable of efficiently treating engineered materials without assumptions of scale separation or periodicity, and (iii) low-memory algorithms for fractional and other operator functions. The second goal of this project is the extension of robust and efficient discretization schemes to second-order nonlinear wave equations derived from action principles, yielding, in particular, new methods to solve equations arising in general relativity and gauge theories.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011490","Collaborative Research: Advancing Theoretical Understanding of Accelerated Nonlinear Solvers, with Applications to Fluids","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","08/01/2020","04/27/2021","Leo Rebholz","SC","Clemson University","Standard Grant","Yuliya Gorb","07/31/2024","$196,555.00","","rebholz@clemson.edu","201 SIKES HALL","CLEMSON","SC","296340001","8646562424","MPS","1253, 1271","102Z, 9150, 9263","$0.00","Many mathematical models used to describe and predict behavior of physical, biological, chemical, and financial systems lead to systems of equations for which the problem coefficients depend on an unknown solution. These are known as nonlinear problems, and they are solved iteratively, by generating a sequence of successive approximations.  For many such problems, even state of-the-art solution methods can be slow, can fail, and may not be robust with respect to changes in the underlying problem data. This project aims to develop faster and more reliable iterative solution techniques using methods that recombine information from previous approximations to create a more accurate next approximation.  Theory will be developed to mathematically show how these methods improve current solution techniques, and the improved methods will be demonstrated on a wide range of systems that arise from important practical problems in optics and fluid mechanics. This project provides research training for graduate students.<br/><br/>The efficient solution of systems of nonlinear equations is essential to the high-fidelity simulation technology necessary for predictive physical modeling throughout engineering and the life sciences.  An extrapolation technique commonly referred to as Anderson acceleration (AA) has been known since 1965 to often improve the efficiency and robustness of iterative solvers for nonlinear problems. It has been successfully used in a surprisingly wide variety of applications, however theoretical understanding of its convergence properties remains largely open. Better theoretical understanding of mathematical algorithms is fundamentally important for both practical implementation and for the creation of the next generation of algorithms. The aim of this proposal is to improve theoretical understanding for AA, and to develop robust and efficient variants with improved convergence properties, both in general settings and for specific nonlinear PDEs. The main theoretical components are (1) the analysis of a variant using principal component analysis; (2) the design and analysis of robust adaptive damping and algorithmic depth strategies for noncontractive operators; (3) the analysis of the superlinear convergence of accelerated Newton iterations for degenerate problems.  The proposed work will include theory and practical application of AA to several difficult nonlinear PDEs from fluid mechanics and optics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1952644","FRG: Collaborative Research: Robust, Efficient, and Private Deep Learning Algorithms","DMS","COMPUTATIONAL MATHEMATICS","08/15/2020","10/15/2020","Jack Xin","CA","University of California-Irvine","Standard Grant","Yuliya Gorb","07/31/2023","$140,247.00","","jxin@math.uci.edu","160 ALDRICH HALL","IRVINE","CA","926970001","9498247295","MPS","1271","075Z, 079Z, 1616, 9263","$0.00","This project develops robust, accurate, and efficient next-generation deep learning algorithms with data privacy and theoretical guarantees for solving challenging artificial intelligence (AI) problems. The methods will have robustness to adversarial attacks with theoretical guarantees.  The project will push artificial intelligence gains in performance and privacy to mobile devices. A broad range of applications includes autonomous driving, drug and material discovery, medical treatment planning, national defense, privacy-preserving machine learning at the edge, federated learning, and also blockchain. Moreover, the developed tools will significantly scale the existing scientific simulations to ultra-large scale and high-dimensional scenarios. This project will partially support one graduate student per year at each campus.<br/><br/>Our approach toward trustworthy deep learning is theoretically principled by modern partial differential equations and optimization algorithms and theories.  The project involves new algorithmic and theoretical techniques to tackle graph representation in high-dimensional non-convex, non-smooth AI settings. In particular, the project will study (1) developing adversarial robust deep learning algorithms and their theoretical foundations; (2) improving the accuracy of deep learning leveraging new stochastic optimization and principled neural network unit design assisted neural architecture search; (3) advancing deep neural networks compression with algorithms and hardware co-design; (4) designing new data privacy mechanisms to optimally tradeoff between utility and privacy; (5) inventing new quantitative analysis tools to decipher the mysteries of deep learning theoretical challenges; (6) quantifying uncertainties of sophisticated deep learning algorithms. The project trains a diverse body of graduate and undergraduate students at UC Irvine, UCLA, and University of Utah through collaborative education and research activities in applied mathematics, computer science, data science, and general biological, physical, and sociological disciplines.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012259","Development and Analysis of Algorithms to Simulate Multi-Component Multi-Phase Porous Flows","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","05/21/2020","Noel Walkington","PA","Carnegie-Mellon University","Standard Grant","Yuliya Gorb","07/31/2024","$400,000.00","","noelw@andrew.cmu.edu","5000 FORBES AVE","PITTSBURGH","PA","152133815","4122688746","MPS","1271","9263","$0.00","One of the goals of science is to understand and explain natural phenomena in order to predict and forecast outcomes. The continual development of mathematical tools to express many of the fundamental laws of nature has resulted in models with unparalleled predictive power. Mathematical models involve complex systems of equations expressing the physical processes of interest, and form the conceptual foundation of modern engineering and science. These equations exhibit all of the depth, difficulties, and subtleties of the physical systems being modeled, and sophisticated computational methodologies are required for their solution. This project focuses on the development of computational tools and software that engineers and scientists need to simulate problems arising in geology. One of the physical problems motivating this work is the need to model deep sea beds and permafrost regions where vast quantities of frozen methane, carbon dioxide, and other gases are trapped. These gases diffuse from deep within the earth and get trapped in permafrost, under glaciers, and in the cold depths of the deep ocean where they may freeze. Predicting the evolving state of these regions through geologic cycles and changes in climate is essential for environmental modeling. This project will develop and analyze computational tools and software required to model these regions where multiple fluids and gases undergo freezing, thawing, and dissolution as they flow. In addition to the technological developments, this project will also support the education and training of the next generation of scientists needed to sustain discovery and scientific leadership in these disciplines.<br/><br/>The work proposed centers around the development and analysis of computational tools needed to simulate flows in porous media containing multiple fluids, which may combine to form multiple phases and states (solid, liquid, gas). The thermodynamics of mixtures and phase changes is used to model the properties and states of the fluids at the pore scale, which appear constitutively in the macroscopic balance law of mass, momentum, and energy. This proposal focuses on the challenging problem of integrating pore scale and continuum models of these systems into a consistent framework where computational tools can be utilized to simulate these complex physical problems.  Convexity and homogeneity of the free energy (or concavity of entropy) enter these models in a subtle way, and are essential for proving stability of solutions. Numerical schemes will be developed that faithfully inherit these important attributes; in addition, convexity properties will be exploited to facilitate robust algorithms for the solution of the nonlinear systems that arise. Development of mathematical tools required to analyze the stability, robustness, convergence, and correctness of these algorithms will be undertaken.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012686","Collaborative Research: Data-Driven Variational Multiscale Reduced Order Models for Biomedical and Engineering Applications","DMS","COMPUTATIONAL MATHEMATICS","06/01/2020","05/27/2020","Alessandro Veneziani","GA","Emory University","Standard Grant","Yuliya Gorb","05/31/2024","$226,222.00","","ale@mathcs.emory.edu","201 DOWMAN DR","ATLANTA","GA","303221061","4047272503","MPS","1271","079Z, 9263","$0.00","Mathematical models are a fundamental tool for improving our knowledge of natural and industrial processes. Their use in practice depends on their reliability and efficiency. Reliability requires a fine-tuning of the model parameters and an accurate assessment of the sensitivity to noisy inputs. Efficiency is particularly critical in optimization problems, where the computational procedure identifies the best working conditions of a complex system.  These requirements lead to solving many times models with millions or even billions of unknowns. This process may require days or weeks of computations on high-performance computing facilities. To mitigate these costs, we need new modeling strategies that allow model-runs in minutes to hours on local computing facilities (such as a laptop).  Reduced order models (ROMs) are extremely low-dimensional approximations that can decrease the computational cost of current computational models by orders of magnitude. Having in mind biomedical and wind-engineering applications, this project proposes novel methods of model reduction. Data and numerical results from the expensive (or high-fidelity) models are combined with machine learning approaches, to obtain ROMs that attain both efficiency and accuracy at an unprecedented level. The new data-driven ROM framework will finally make possible the numerical simulation of aortic dissections, pediatric surgery, or wind farm optimization on a laptop in minutes, and aims at becoming a critical and trustworthy tool in decision-making processes.<br/><br/>Data assimilation (DA), uncertainty quantification (UQ), and shape optimization (SO) are central to the development of computational models for significant biomedical and engineering applications.   Since these applications require a large number of model simulations, running an expensive full order model (FOM) is generally prohibitively expensive.  For systems that display dominant structures, reduced order models (ROMs) can decrease the FOM computational cost by orders of magnitude.   Thus, for the clinical and engineering applications above, ROMs appear as a natural and practical alternative to the prohibitively expensive FOMs running on high-performance computing facilities.   Unfortunately, to capture all the geometric scales in the hemodynamics of aortic dissections or to cope with the large Reynolds number in the wind farm optimization, hundreds and thousands of ROM modes are necessary. These relatively high-dimensional ROMs are still not viable to effectively perform DA, UQ, or SO for these applications.  What is needed is ROMs that are not only low-dimensional and efficient, but also accurate.  To develop ROMs that are accurate in realistic, under-resolved regimes, the ROM closure problem needs to be solved, i.e., the effect of the discarded ROM modes on the ROM dynamics needs to be modeled.  The proposed research puts forth a new data-driven ROM paradigm that centers around the hierarchical structure of variational multiscale (VMS) methodology and utilizes modern machine learning (ML) and numerical and observational data to develop structural ROM closures that can dramatically increase the ROM accuracy at a modest computational cost.  The novel data-driven VMS-ROM paradigm maintains the low computational cost of current ROMs but dramatically increases the ROM accuracy.  Biomedical applications in thoracic and pediatric surgery (aortic dissections and Fontan procedure ? where the fate of the patient depends significantly on the shape of the vessels) as well as wind-engineering applications are specifically targeted. The data-driven VMS-ROM framework will finally make possible the efficient DA, UQ, and SO in these and, possibly, other fields relying on mathematical and computational modeling. This project will support one graduate student each year at each of the three institutions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012546","Task-Aware Quantization in Data Science: Theory and Fast Algorithms","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","07/20/2020","Rayan Saab","CA","University of California-San Diego","Standard Grant","Yuliya Gorb","07/31/2024","$250,000.00","","rsaab@ucsd.edu","9500 GILMAN DRIVE","LA JOLLA","CA","920930021","8585344896","MPS","1271","075Z, 079Z, 9263","$0.00","Machine learning algorithms are ubiquitous, and their applications in data science are on the rise. This project focuses on developing computationally efficient algorithms in data-science applications where discretization, also known as quantization, plays a fundamental role. Here quantization is the process that replaces real numbers, like those obtained from sensor measurements, by elements in a finite set. This makes them amenable to efficient digital representation, storage, compression, and transmission. Applications of interest include deep learning, an area that has led to sensational breakthroughs in a stunning range of areas. One of its frontiers is building neural networks on hardware that can be put into handheld and wearable devices as well as those in smart homes. For that, neural networks must be efficiently quantized; a key goal of this project is to devise algorithms for this task. Another application concerns edge devices, such as sensors in a sensor network, which communicate and perform computations under severe power limitations. A goal of this project is to develop computationally efficient algorithms for quantizing and compressing their data to enable reducing power use. A third application involves recommender systems, which collect users? discretized ratings of products and transform them into other product recommendations for others. The project provides training for graduate students through involvement in the research.<br/><br/>This project focuses on developing computationally efficient quantization algorithms with provable error guarantees. It is motivated by three important application areas. First, in settings where the goal is discretizing the parameters of a function, as in the compression of deep neural networks, it seeks quantization algorithms to generate functionally equivalent networks that require many fewer bits to store. The second motivating area involves settings where inference tasks must be done on edge-devices, under communication and computation constraints, as in sensor-networks. Here, the focus is on computationally efficient measurement, quantization, and inference algorithms that entail minimal memory and power requirements. Third, in applications where signal recovery is the goal and measurements are inherently binary and expensive to collect, as in recommender systems, the focus is on devising and studying efficient adaptive algorithms for sequential selection of the measurements. This project, which aims to develop state of the art task-aware algorithms, entails developing and using tools from several areas of mathematics, including methods from geometric functional analysis and non-asymptotic random matrix theory. Connections with frame theory, compressed sensing, and noise-shaping quantization will also be established. In analyzing the algorithms, discrete geometry, optimization, and numerical analysis techniques will be developed and employed. To compare theoretical guarantees associated with this project with best possible ones, approximation theory will be essential.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011444","Numerical Analysis and Methods for Fluid Deformable Surfaces and Their Interaction with the Bulk","DMS","COMPUTATIONAL MATHEMATICS","07/15/2020","07/21/2022","Maxim Olshanskiy","TX","University of Houston","Continuing Grant","Stacey Levine","06/30/2023","$200,818.00","","molshan@math.uh.edu","4300 MARTIN LUTHER KING BLVD","HOUSTON","TX","772043067","7137435773","MPS","1271","9263","$0.00","Fluid surfaces that deform are ubiquitous in cell and tissue biology as well as in modeling of emulsions and foams.  Computer modeling plays an increasingly important role in better understanding of processes involving such surfaces as well as interfacial phenomena. The present project aims to develop accurate and reliable numerical methods for the simulation of fluidic deformable surfaces and their interaction with the bulk. Development of such methods will facilitate understanding the functionality of lipid bilayers, the actin cortex, epithelial cell sheets, and the properties of other thin structures exhibiting in-plane viscosity and lateral mobility. The project provides research training for a graduate student.<br/><br/>The project will consider models of fluids on surfaces. For these, continuum-based modeling leads to systems of partial differential equations posed on time-dependent manifolds. For example, lipid membranes are fluidic thin layers that can be modeled as two-dimensional viscous surface fluids with bending elasticity. The project will develop and analyze a geometrically unfitted finite element method for fluid systems posed on deformable surfaces such as surface Stokes and surface Navier-Stokes equations, tangential fluid equations coupled with in-plane elasticity and equations governing out-of-plane (geometrical) motions, as well as interface-bulk coupled fluid systems. The project focus is on splitting schemes for the resulting coupled systems. The methods build on formulation of governing equations in terms of tangential differential calculus and employ time-independent unfitted background meshes. The approach will allow for implicitly given complex shapes that may undergo topological transitions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011494","Zero-Order and Stochastic  Methods for Large-Scale Optimization","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","07/22/2020","Jorge Nocedal","IL","Northwestern University","Standard Grant","Yuliya Gorb","07/31/2024","$200,000.00","","j-nocedal@northwestern.edu","633 CLARK STREET","EVANSTON","IL","602080001","3125037955","MPS","1271","9263","$0.00","The promise of artificial intelligence (AI) has been a topic of both public and private interest for decades. It has recently blossomed thanks to the rapidly evolving and expanding field of machine learning, which has produced impressive results in perceptual tasks and has emerged as the core technology of modern AI. The intelligent systems that have been borne out of machine learning - such as search engines, recommendation platforms, and speech and image recognition software - have become an indispensable part of modern society. Rooted in statistics and relying heavily on the efficiency of numerical algorithms, machine learning techniques capitalize on the world's increasingly powerful computing platforms and the availability of very large data sets. One of the pillars of machine learning is optimization, which, in this context, involves the numerical computation of parameters for a system designed to make decisions based on yet unseen data. That is, based on currently available data, these parameters are chosen to be optimal with respect to a given learning problem. The central role that optimization plays in machine learning has inspired great numbers in various research communities to tackle even more challenging machine learning problems, and to design new optimization methods that are more widely applicable. This project is devoted to the development of a new generation of optimization methods that will help advance the field of machine learning by reducing computing time and allowing for the formulation of larger and more complex models. This will help AI expand into many domains such as medicine, robotics and logistics. This project provides research training opportunities for graduate students.<br/><br/>In technical terms, the goal of this proposal is to develop new algorithms for stochastic optimization problems, such as those arising in machine learning, statistics and black-box simulations. It consists of two interrelated projects encompassing algorithm design, convergence analysis, and numerical testing on realistic applications. The first project deals with constrained optimization problems in which the objective function is stochastic and the constraints are deterministic. The proposed methods use varying sample sizes to gradually reduce the variance in the gradient approximation; they have been studied in the context of unconstrained optimization, but their extension to the constrained setting is not simple because the projections or proximal operators used to enforce the constraints introduce discontinuities. The second project studies zero-order methods for the solution of noisy unconstrained optimization problems. Unlike derivative-free methods that construct quadratic models of the objective function using interpolation techniques, the proposed methods invest significant effort in computing a good approximation to the gradient of the noisy function and delegate the construction of a quadratic model to quasi-Newton updating. The two projects are interrelated and when combined will yield algorithms that scale into the millions of variables and parallelize easily. Their efficiency will be demonstrated in the solution of problems arising in reinforcement learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2001711","Conference on Foundations of Computational Mathematics","DMS","COMPUTATIONAL MATHEMATICS","03/01/2020","08/05/2020","Randall LeVeque","WA","University of Washington","Standard Grant","Yuliya Gorb","06/30/2020","$0.00","","rjl@uw.edu","4333 BROOKLYN AVE NE","SEATTLE","WA","981950001","2065434043","MPS","1271","7556, 9263","$0.00","This award supports participation of US-based researchers in the triennial international conference ""Foundations of Computational Mathematics (FoCM 2020)"" held in Vancouver, BC, Canada on June 15-24, 2020. Computational mathematics is increasingly important in all branches of science and engineering, and increasing computational power has radically changed the relationship between mathematics and computation. The Foundations of Computational Mathematics (FoCM) Society is an international nonprofit organization that supports and promotes research at the interface of mathematics and computation and fosters interaction among mathematics, computer science, and other areas of computational science.  The FoCM 2020 conference is expected to attract an estimated 500 participants, including at least 150 junior participants (graduate students, postdoctoral fellows, and junior faculty), with perhaps 100 of these from the US.  This award provides partial funding for some US participants, particularly junior participants who might otherwise not be able to attend. It will advance the international exposure of research conducted in the US and will have lasting effects in the form of new collaborations between US and international participants.<br/><br/>The conference comprises three 3-day sessions of 7 workshops each (21 total), combined with plenary and semi-plenary talks each day.  Besides the plenary speakers, each workshop will have two semi-plenary speakers. Workshops span a wide range of computational mathematics topics, with ties to pure mathematics, computer science, data science, scientific computing, and other related fields. For more information, see <br/>http://focm-society.org/2020/<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011943","Robust and  Efficient Numerical Methods for Electromagnetic Wave Propagation in Complex Media","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","08/03/2020","Jichun Li","NV","University of Nevada Las Vegas","Standard Grant","Yuliya Gorb","07/31/2024","$252,172.00","","jichun.li@unlv.edu","4505 S MARYLAND PKWY","LAS VEGAS","NV","891549900","7028951357","MPS","1271","9150, 9263","$0.00","This project will develop novel mathematical modeling and robust computational methods for simulating wave propagation in complex media such as metamaterials and graphene. This interdisciplinary research has direct applications in nanotechnology and materials through the advancement of discovery and understanding of new phenomena in nanooptics and stealth technology brought by metamaterials and graphene. Graphene can be used to generate picosecond laser pulses because of its wide absorption range, fast decay, and high stability properties. Graphene can be used in sensors to concurrently sense mass, gas, tension, diseases, and explosives; graphene can be used in low-cost display screens of mobile devices, lithium-ion batteries with fast recharge capacity, hydrogen storage for fuel cell-powered cars, and low-cost fuel cells and water desalination, etc. All of these applications benefit from accurate and efficient numerical algorithms for solving the associated mathematical models by reducing the cost of physical experiments. This project will provide support for one PhD student per year. <br/> <br/>The focus of this project is to develop and analyze robust and efficient finite element methods for solving electromagnetic wave propagation problems in complex media. Theoretical analysis and practical algorithms will be developed with the following objectives: (1) Further explore some perfectly matched layer (PML) models recently developed for metamaterials, develop and analyze time-domain finite element methods using both edge elements and discontinuous Galerkin methods for solving them; (2) Explore graphene models and efficient FEM algorithms to simulate wave propagation in graphene; (3) Develop robust and efficient a posteriori error estimators for time-dependent Maxwell?s equations in metamaterial and graphene, explore possible superconvergence points for high-order triangular and tetrahedral edge elements; (4) Develop, and analyze efficient numerical methods for Maxwell's equations with random inputs with applications for random metamaterials. The developed algorithms and codes in the project will lead to a better understanding of metamaterials and graphene, and their physical effects, so that researchers can design and use them in applications.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012875","Construction of New Parallel Time Integrators","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","08/22/2023","Mayya Tokman","CA","University of California - Merced","Continuing Grant","Yuliya Gorb","07/31/2024","$250,142.00","Tommaso Buvoli","mtokman@ucmerced.edu","5200 N LAKE RD","MERCED","CA","953435001","2092012039","MPS","1271","9263","$0.00","For many problems in science and engineering experimental data and observations do not provide a complete picture of a system's behavior and computer simulations have become an indispensable tool for studying its evolution. However, the complexity and scale of many application problems make even computer modeling a challenging task. This is particularly true when a system undergoing complex dynamics is modeled using time dependent partial differential equations. In fact, special mathematical techniques known as time integrators must be developed to ensure that the evolution of the system is reproduced on a computer with a reasonable fidelity and in a reasonable time. It is also important that such time integration algorithms have the ability to take advantage of the parallel computational capabilities offered by both supercomputers and workstations. This project will develop new time integration methods that exploit parallelism and novel mathematical ideas in order to achieve higher accuracy and better efficiency when simulating complex systems that evolve over a wide range of temporal and spatial scales. General methods applicable to problems across science and engineering will be developed as well as special schemes particularly optimized for certain applications.  The project will explore the advantages of the new numerical approaches in the context of real-world problems such as computer design of efficient engines and weather prediction. This project will also contribute to educating and mentoring undergraduate and graduate students.<br/><br/>Employing parallelism effectively in the spatial discretization of partial differential equations has proven to be revolutionary in computational science.  Recent developments in time integration provide an opportunity to extend these gains to the time domain. This project will combine ideas from exponential and polynomial interpolation-based temporal integration to construct new parallel time integrators. Both parallelization across the method (i.e. over each time iteration) and parallelization across time steps (i.e.  simultaneous computation of the solution over multiple time intervals) will be explored. New approaches for fine-tuning the parameters to optimize performance of the new methods will also be investigated.  The behavior of the new methods will be studied in context of real application problems such as modeling reactive flows involved in combustion.  An additional objective of this work is to provide a guide for determining which of the new techniques are best suited for problems with a given structure.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011733","Advancements in Divergence-Free Approximations for Incompressible Flow","DMS","COMPUTATIONAL MATHEMATICS","07/01/2020","07/05/2022","Michael Neilan","PA","University of Pittsburgh","Continuing Grant","Yuliya Gorb","06/30/2023","$286,039.00","","neilan@pitt.edu","4200 FIFTH AVENUE","PITTSBURGH","PA","152600001","4126247400","MPS","1271","9263","$0.00","Accurate computations of fluid flow models have a direct impact on simulations and predictions in various applications, e.g., weather and climate, aircraft design, etc. Typically, such computations are based on discretizations of partial differential equations that model the physics of the underlying system. These approximations introduce errors into the simulations that need to be rigorously quantified in order to make reliable simulations and predictions. This project will construct accurate, structure-preserving computational schemes that exactly enforce the underlying physical laws at the discrete level in fluid flow models. This attribute leads to high fidelity schemes that are robust with respect to several model parameters. A particular focus of the project is to develop and analyze computational algorithms that reduce geometric error and thus yield provably accurate answers. In addition, the project aims to provide user-friendly methods; in particular, the project will incorporate modules into current computational and open source software to improve usability, portability, and outreach.<br/><br/>This project will construct finite element methods for the Stokes and Navier-Stokes equations that exactly enforce the divergence-free constraint at the discrete level. Such discretizations have several desirable properties, for example, improved stability and error estimates with respect to model parameters, exact conservation properties for any discretization parameter, and characterizations of discrete divergence-free subspaces.  However, current divergence-free finite element methods are impractically high-order and arduous to implement. This project will identify and construct simple divergence-free finite element methods with an emphasis on the three-dimensional setting and on methods that can be incorporated into current finite element software. Divergence-free finite element methods on domains with curved boundaries that are robust with respect to both model parameters and the geometry will also be developed and analyzed. This will consist of studying both isoparametric divergence-free finite element methods and fictitious domain approaches.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012465","Fast Optimization Methods and Application to Data Science and Nonlinear Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","07/28/2020","Long Chen","CA","University of California-Irvine","Standard Grant","Yuliya Gorb","07/31/2024","$249,999.00","","chenlong@math.uci.edu","160 ALDRICH HALL","IRVINE","CA","926970001","9498247295","MPS","1271","079Z, 9263","$0.00","This projects incorporates several recent developments in optimization methods and nonlinear multigrid methods to provide a new technique to improve the computational efficiency of practical applications. Successful integration of our fast optimization methods will open a wide new area of applications ranging from numerical solution of partial differential equations to optimization methods for large-scale machine learning. Social media such as Facebook and GitHub  will be used to disseminate basics on applied and computational mathematics and promote the research to a wider audience in both academia and industry, as well as increase the public awareness of how computational mathematics help the advancement of research in other physical and data sciences. This project will provide training opportunities for graduate students.<br/><br/>The project focuses on a particular nonlinear multigrid method, the fast subspace descent (FASD) method, for solving optimization problems arising from various applications such as numerical solution of partial differential equations and data science problems. For example, the nonlinear multigrid methods to be studied can address the challenging problems in engineering applications including gradient flow in phase field models, Poisson-Boltzmann equation in math biology, and convex composite optimization problems in data science. Acceleration has been one of the most productive ideas in modern optimization theory. This framework brings more insight and mathematical tools for the design and analysis of old and new optimization methods, especially the accelerated gradient descent methods. Another important aspect of this project will be the rigorous theoretical foundation for a large class of optimization methods.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012011","Partition of Unity Multivariate Approximation for the Volume of Fluid Method","DMS","COMPUTATIONAL MATHEMATICS","09/01/2020","06/17/2020","Alfa Heryudono","MA","University of Massachusetts, Dartmouth","Standard Grant","Yuliya Gorb","08/31/2024","$199,988.00","Mehdi Raessi","aheryudono@umassd.edu","285 OLD WESTPORT RD","NORTH DARTMOUTH","MA","027472356","5089998953","MPS","1271","9263","$0.00","This project will advance the understanding of multi-phase flows that are encountered in many scientific and engineering applications. Multi-phase flow problems exhibit highly dynamic, complex interfaces, and the project will develop computational tools to predict the evolution of such interfaces; the challenge is that these interfaces may be largely deformed with intricate localized patterns. Methods for numerically tracking and predicting the dynamics of the interfaces must be able to correctly capture local features with optimal computational costs and high accuracy. This project aims to develop and analyze techniques for fast and highly accurate interface reconstruction methods with emphasis on three-phase (liquid-gas-solid) flow. An application of interest here is deposition of eye drops onto 3D realistic eye geometries. The project also involves research training and integrated education of students in an interdisciplinary setting and the development of codes to support reproducible research.<br/><br/>The volume-of-fluid (VOF) method is one of the most commonly used interface tracking methods in multi-phase flow simulations. Research in this project involves the development of techniques to improve the accuracy of the interface reconstruction scheme for the volume of fluid method for simulating multi-phase problems on complex geometries. The three most important aspects we are investigating are (1) robust and highly-accurate partition of unity multivariate approximation volume-of-fluid (PUMA-VOF) method; (2) simultaneous space-time schemes for advection-type partial differential equations (PDEs) on time-varying domains; (3) mathematical modeling and numerical simulation of problems with moving geometries. The research will include theory and practical application of PUMA-VOF on the field of scientific simulations on complex geometries.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1953271","Dimension Reduction for Nonlinear Stochastic Systems","DMS","COMPUTATIONAL MATHEMATICS, CDS&E-MSS","08/15/2020","07/28/2022","Pierre Gremaud","NC","North Carolina State University","Continuing Grant","Yong Zeng","07/31/2024","$200,000.00","Alen Alexanderian","gremaud@math.ncsu.edu","2601 WOLF VILLAGE WAY","RALEIGH","NC","27607","9195152444","MPS","1271, 8069","9263","$0.00","Predictive computational models play a central role not only in engineering and the sciences, but also in society at large. This project addresses fundamental issues common to virtually all computational models. If a model is too simple, the underlying phenomenon will not be faithfully described; if a model is too complex, its predictive power will be minimal. There is, somewhere, a happy middle; this project is about how to find the right balance in terms of model complexity. How complex should a computational model be to be useful? Both the mathematical community and domain scientists have long been worried about the lower bound ? the minimum complexity. Models have be faithful to the underlying biology, chemistry or physics but how much of the science should one include? Quantum and relativistic effects can safely be ignored on many problems but what should be included and what can be left out to describe complex chemical reactions or physiological models? This project is about finding the lowest complexity sufficient for the tasks at hand. Models of complex systems, however, present features that render the task of making prediction with quantified uncertainties challenging. Such features include high-dimensional uncertain input parameters, time and/or space dependent quantities of interest, inherent stochasticity, as well as computational expense of simulating complex models. Research in this project will bring about key advances in modeling under uncertainty by developing mathematical techniques and computational methods to address such challenges in models of complex systems. The overarching goal is to develop methods that allow domain scientists to simplify their models so as to facilitate forward uncertainty quantification and parameter estimation at reasonable costs. Students will be trained and mentored in the interdisciplinary aspects of this project. In addition, his project involves the development of new course material that reflects and addresses challenges in present-day scientific computing.<br/><br/>The research in this project makes important contributions to computational modeling under uncertainty by developing mathematical theory and algorithms for (i) multiscale sensitivity analysis of stochastic compartment models, (ii) derivative- and variance-based sensitivity analysis methods for time-dependent stochastic systems, (iii) model complexity reduction in compartment models, and (iv) goal oriented multilevel dimension reduction for fast parameter estimation. The algorithms will be applied to models from biochemistry and physiology. A family of complex models of neurovascular coupling will be analyzed with the methods to be developed during the project, including dimension reduction, model complexity reduction and parameter estimation based on existing murine data. The model complexity reduction framework can be used in a broad range of models, where modelers can benefit from removing certain model components. Overall, by enabling dimension reduction in broad classes of models, the project bridges gaps in the processes of modeling, prediction under uncertainty, and parameter estimation: models with most essential components will be discovered and computational budget can be focused on quantifying uncertainty in only those model parameters that are most important to model output.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011319","A Computational Approach to the Design of a Bioartificial Pancreas","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","07/28/2020","Suncica Canic","CA","University of California-Berkeley","Standard Grant","Yuliya Gorb","07/31/2024","$300,000.00","","canics@berkeley.edu","1608 4TH ST STE 201","BERKELEY","CA","947101749","5106433891","MPS","1271","9263","$0.00","The main goal of this project is optimal design of an implantable, bioartificial pancreas for the treatment of Type 1 diabetes. The design is based on transplanting the healthy pancreatic cells into a gel medium (agarose gel), and encapsulating the cell-containing medium between two nanopore semi-permeable membranes to block the patient's immune cells from attacking the transplant. Encapsulated tissue transplantation is a novel approach to eliminating long-term use of immunosuppressants, which is one of the major challenges in transplantation therapy. The nanopore membranes are designed to block the immune cells while allowing passage of nutrients to keep the transplant viable as long as possible. The team around the collaborator Dr. S. Roy, Director of the Biodesign Laboratory at UCSF, is exploring a design of an implantable bioartificial pancreas, which will be implanted in the patient's arm, and connected to an artery and a vein similar to an arterio-venous graft. The key challenge in the development of the bioartificial pancreas is maintaining the survival of transplanted cells for an extended period of time, by providing sufficient access to nutrients, of which oxygen is the limiting factor. Involvement of graduate and undergraduate students, as well as high school students (particularly girls), in several aspects of this research is planned. The synergistic approach to the proposed project will provide a first, long-term viable implantable bioartificial pancreas without the need for immunosuppressive therapy.  <br/> <br/>This project addresses the development of a multi-physics, multi-scale mathematical and computational model to study the design of an implantable, bioartificial pancreas for the treatment of Type 1 diabetes. The implantable, bioartificial pancreas will consist of an encapsulated chamber containing the transplanted pancreatic cells called islets, and a graft connecting the chamber to the patient?s cardiovascular system. The encapsulation chamber is modeled as a multi-layered poroelastic medium consisting of two semi-permeable membranes encapsulating a poroelastic gel holding the cells. The encapsulation strategy prevents the host?s immune cells from attacking the transplant. The proposed mathematical macro-scale model captures filtration of blood serum within the encapsulated multi-layered poroelastic islet chamber, and the fluid-structure interaction between the blood flow and the arterio-venous graft carrying blood to the islet chamber. To study oxygen supply to the transplanted cells, the fluid-structure interaction model is coupled to three nonlinear advection-reaction-diffusion models describing oxygen concentration in the tubular graft, in the poroelastic membrane, and in the islet chamber.  A novel partitioned, loosely coupled scheme for the numerical solution of this problem is proposed. At the micro-scale, a Smoothed Particle Hydrodynamics solver will be used to study the influence of the fine poroelastic medium structure on oxygen supply to the transplanted cells. Deep Neural Networks will be used to study parameter estimation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1937254","RTG: Research Training in Applied Mathematics at Columbia University","DMS","PROBABILITY, APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, ANALYSIS PROGRAM, WORKFORCE IN THE MATHEMAT SCI","08/01/2020","08/10/2023","Kui Ren","NY","Columbia University","Continuing Grant","Pedro Embid","07/31/2025","$1,530,557.00","Michael Weinstein, Qiang Du, Daniela De Silva, Ivan Corwin","kr2002@columbia.edu","202 LOW LIBRARY 535 W 116 ST MC","NEW YORK","NY","10027","2128546851","MPS","1263, 1266, 1271, 1281, 7335","7301","$0.00","This Research Training Group (RTG) project is a joint effort of the Department of Applied Physics and Applied Mathematics, the Department of Mathematics, and the School of Engineering and Applied Sciences at Columbia University. It aims to create a cutting-edge research and training program in modern applied mathematics. By substantially enriching research and educational experiences for trainees, and by directly coupling into key educational and research initiatives in the School of Engineering and Applied Sciences and across the University, the activities will have a significant impact on applied mathematics education and training at Columbia. The RTG project will engage high school as well as undergraduate students from the New York metropolitan area and across the country (through the Summer Research Program), inspiring mathematical careers for underrepresented groups in the United States.<br/><br/>The project includes three main ingredients: (i) a group of research topics in applied mathematics at the frontier of engineering applications; (ii) a coherent mentoring-learning program on applied mathematics research and career development for undergraduate and graduate students as well as postdoctoral scholars; and (iii) a systematic plan to modernize undergraduate and graduate curriculum in applied mathematics and scientific computation. The senior investigators and the trainees will form groups to tackle challenging and rewarding mathematical and computational problems, including linear and nonlinear wave propagation in novel complex (and possibly random) structures, physics- and data-enabled algorithms for material discovery, hybrid inverse problems and imaging, mathematical theory of machine learning, harmonic analysis of large data sets, and uncertainty quantification. They will collaborate with leading engineers at Columbia to connect their mathematical and computational discoveries with applications in nonlinear optics and photonics, materials science, medical imaging, climate modeling, and general data science. The senior members of this RTG project are strongly committed to training and mentoring undergraduates, graduate students, and postdoctoral scholars. Their extensive and varied experiences in teaching and mentorship will be invaluable to the professional growth of the trainees.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011615","Robust Least Squares Discretization for Mixed Variational Formulations","DMS","COMPUTATIONAL MATHEMATICS","09/01/2020","10/19/2020","Constantin Bacuta","DE","University of Delaware","Standard Grant","Yuliya Gorb","08/31/2024","$214,994.00","","bacuta@udel.edu","220 HULLIHEN HALL","NEWARK","DE","197160099","3028312136","MPS","1271","9150, 9251, 9263","$0.00","This project aims to enable more reliable, fast, and accurate simulation methods for a variety of applications in science and engineering, such as electromagnetism, elasticity and acoustics, fluid flow, and diffusion through heterogenous porous media. The project focuses on efficient computational methods based on finite element analysis. Specific applications include modeling compressible gas dynamics and computational fluid mechanics for atmospheric prediction and ocean fluid flow behavior, as well as computational solution of the time-harmonic Maxwell model with applications in nano-optics and analog signal packages. This project will provide interdisciplinary applied mathematics training and research experiences for students.<br/><br/>The project will develop, analyze, and implement robust and efficient numerical algorithms for solving partial differential equations (PDEs) that admit variational formulations with different types of test and trial spaces. When approximating the solutions of these PDEs, it is desirable to obtain robust estimates of all physical quantities in the presence of parameters, such as diffusion coefficient or frequency. It is also important to obtain good approximations of the solution, even in the case of low regularity near boundaries or along material discontinuities, or in the case of low data regularity. The focus of the project is on approximating PDE models with parameters and discontinuous coefficients. The project develops a general discretization and algorithm development method that bridges between the field of symmetric saddle point problems and the field of preconditioning elliptic symmetric problems. The  project aims to:  introduce a new saddle point least-squares theory that allows non-conforming trial spaces to approximate discontinuous solutions of PDEs; construct locally smooth projection type of trial spaces that lead to higher order of approximation for the solution or related quantities of interest; introduce optimal test spaces and balanced norms that allow robust  approximation for parametric problems; and construct efficient preconditioning techniques for general mixed variational formulations. The research will broaden the mathematical theory and the range of applications of the mixed finite-element approximation field and will create new connections among mixed variational formulations, adaptive and multilevel techniques, and preconditioning parametric or fractional norms.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011544","Fast Electrostatics and Brownian Hydrodynamics in Doubly-Periodic Geometries","DMS","COMPUTATIONAL MATHEMATICS","07/01/2020","06/17/2020","Aleksandar Donev","NY","New York University","Standard Grant","Yuliya Gorb","06/30/2024","$289,453.00","","ad139@nyu.edu","70 WASHINGTON SQ S","NEW YORK","NY","100121019","2129982121","MPS","1271","9263","$0.00","New computational tools are required for large-scale modeling of a broad range of biological and engineered systems such as lipid bilayer membranes in biological cells and engineered vesicles, thin liquid crystal films in displays, confined electrolytes in batteries, and colloidal monolayers in materials science. These systems are all quasi two-dimensional (2D) because the system is bounded in the third (normal) direction, they all involve particles (lipid molecules, liquid crystal molecules, ions, colloids) suspended in a solvent fluid, and in all of these systems diffusion via Brownian motion needs to be modeled accurately. This project will develop novel mathematical techniques and computational codes for computational modeling of these types of systems. The new algorithms will allow the research team to study collective diffusion in quasi-planar systems over unprecedented length and time scale, vastly expanding our ability to answer fundamental science questions about diffusion in quasi-2D materials, as well as helping us engineer better devices and materials such as battery electrodes. The PI will involve and train several undergraduate, Ph.D students and a postdoctoral fellow in the project.<br/><br/>The project team will develop novel computational techniques for modeling collective diffusion in a broad range of physical systems such as electrolyte solutions, lipid bilayer membranes, thin liquid crystal films, colloidal monolayers on a liquid-liquid interface or sedimented on a bottom wall, and colloidal clusters. The team will develop numerical techniques based on the Fast Fourier Transform and Chebyshev polynomials that can compute electrostatic and hydrodynamic interactions in doubly-periodic geometries in linear time in the number of particles. The team will develop tools for long-time Brownian HydroDynamics simulations of many-particle systems by designing algorithms to efficiently generate Brownian velocities in the presence of hydrodynamic interactions. The team will develop efficient public-domain parallel codes for electrostatics and Brownian dynamics, capable of handling hundreds of thousands of particles over long time scales. The team will also use the developed techniques to illuminate physical phenomena such as electro-hydrodynamic flows, collective diffusion in colloidal monolayers, and collective dynamics in driven colloidal layers. In particular, the team will characterize diffusion of ions in electrolytes, as well as lipids and protein inclusions in bilayers, over a broad range of time scales. This will elucidate the range of applicability of the widely-used Poisson-Nernst-Planck equations for electric double layers, as well as the Saffman model of membrane hydrodynamics. This project will support one graduate student in the second and third years.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012292","Learning High-Dimensional Non-Linear Maps Arising from Physical Phenomena via Symmetry and Structure-Preserving Deep Neural Networks","DMS","COMPUTATIONAL MATHEMATICS","07/01/2020","07/19/2023","Leonardo Andres Zepeda Nunez","WI","University of Wisconsin-Madison","Standard Grant","Yuliya Gorb","06/30/2024","$199,999.00","Qin Li","zepedanunez@wisc.edu","21 N PARK ST STE 6301","MADISON","WI","537151218","6082623822","MPS","1271","9263","$0.00","Machine learning, in particular deep learning, has fueled several breakthroughs in language and image processing in recent years. Following its success in applications to business and medicine, several efforts have been made to extend the range of deep learning applications to scientific and engineering tasks. Progress in this area has been hampered by two main issues: scientific tasks often have more stringent accuracy requirements, and the required data is usually either scarce or expensive to obtain. However, some of these tasks have vast pools of associated knowledge, and by incorporating problem-specific knowledge, new deep learning architectures can achieve the necessary accuracy while requiring significantly less data. The objective of this project is twofold: 1) to design deep learning systems that bypass computationally-expensive classical simulations of nonlinear systems, with applications in quantum chemistry and design of new materials such as solar cells and nano-materials; and 2) to expand the capabilities of classical nonlinear methods, for example by introducing novel neural networks to produce sharper images for biomedical, radar, and seismic imaging. This project will provide interdisciplinary applied mathematics training and research experiences for students.<br/><br/>The goal of this project is to design deep neural networks specifically tailored for two scientific applications: density functional theory, which is used to simulate materials at the microscopic level, and inverse problems, which are focused on recovering quantities of interest from boundary data, such as is done in CT, MRI, and ultrasound imaging. The main result of the project will be novel networks that leverage the physical and analytical properties of each application to satisfy the symmetries and structures of the underlying physics. For the first application, the goal is to create an efficient representation of the electron density of a given system from the position of the nuclei, thus bypassing the solution of the Kohn-Sham equations within the density functional theory framework. In the second application, inverse scattering problems modeled by the Helmholtz equation are considered. The project focuses on networks inspired by the butterfly algorithm, a fast method tailored to handle Fourier integral operators that are used to describe the linearized inverse scattering problem. A nonlinear generalization of the butterfly algorithm, dubbed a butterfly-net, will be extended to handle data at several frequencies following a dyadic partition, to stabilize the training step. The resulting wide-band butterfly network will be used to study the super-resolution of details below the Nyquist level.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011140","Tensors, Topics, Truth, and Time: Methods for Real Tensor Applications","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","07/23/2020","Deanna Needell","CA","University of California-Los Angeles","Standard Grant","Yuliya Gorb","07/31/2024","$299,873.00","","deanna@math.ucla.edu","10889 WILSHIRE BLVD STE 700","LOS ANGELES","CA","900244201","3107940102","MPS","1271","9251, 9263","$0.00","With the recent surge of applications involving large-scale data comes a critical need to develop efficient, robust, and practical methods for data analysis. With more and more applications having multi-modal data (data coming from many distinct sources and of different types, often having a temporal component), the need for mathematical developments to handle and understand this data is critical. The key mathematical object at the heart of such study is the tensor ? a multi-dimensional array that can be viewed as an algebraic extension of the common notion of a mathematical matrix.  The mathematics of tensors has received a lot of recent attention, however, there are still many key lacunae in the scientific understanding of these objects as well as their use in modern data analytic techniques. The project focuses on the development of computationally feasible methods to detect patterns within such tensor data as well as the geometric properties of tensors that can be used for compression. The team will partner with the California Innocence Project (CIP), a nonprofit whose goal is to free innocent persons who have been convicted of a crime. The data involved are inmate letters and case files, all of which are highly multi-modal since they include, for example, court documents, interview testimonials, forensic data, images, and more. The goals in this context will be to facilitate the assessment procedure that CIP uses to decide what cases are likely to be successful, what commonalities they share, and what populations may need more attention. The partnership with CIP will serve not only as a means of direct societal impact but also as a feedback mechanism to test and validate the developed mathematical approaches.<br/><br/>We focus on two technical thrusts. The first thrust is centered around methods to detect patterns in tensor data without impossible unfoldings, in an online setting, and allowing for topic structures. The second thrust focuses on dimension reduction, developing geometry preserving reduction maps that act on tensors and map to tensors, along with related important methods that utilize such maps. The first thrust will go beyond existing research in several ways. First, it will provide much improved topic detection in dynamic applications. Second, it will develop provable convergence of features in the stochastic online setting. Third, it will offer improved topic structures using a deep model. The second thrust focuses on the mathematics of tensor dimension reduction and will provide provable guarantees for such, along with analysis of the related algorithms. Such practical techniques and understanding simply do not yet exist for true tensor data. The proposed research program will therefore further mathematical understanding of tensor geometries while also providing practical approaches that can be used in any field needing to analyze multi-modal data. The transition of these results to society will be facilitated through connections between the PI and nonprofits, including the California Innocence Project. The project also includes a novel outreach and educational component, including integration of high school student programs, community change programs, teachers, and future teachers in summer workshops and events throughout the year.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011622","On Low-Rank Regularization for Ill-Posed Nonlinear Parameter Estimation","DMS","COMPUTATIONAL MATHEMATICS, MSPA-INTERDISCIPLINARY","09/01/2020","09/02/2022","Alexandra Smirnova","GA","Georgia State University Research Foundation, Inc.","Continuing Grant","Yuliya Gorb","08/31/2024","$200,000.00","","asmirnova@gsu.edu","58 EDGEWOOD AVE NE","ATLANTA","GA","303032921","4044133570","MPS","1271, 7454","068Z, 9263","$0.00","This research has been inspired by numerous challenges in studying the transmission dynamics of infectious diseases. The investigator will focus on estimating parameters of data-enabled mathematical models of infectious disease aiming to generate forecasts of future incidence cases. The project will develop regularized computational algorithms for this data estimation which presents many challenges and includes uncertainties. The models and optimization methods to be used are important in anticipating the resources needed for disease management. Data on past and present infectious diseases will be studied, and the investigator will collaborate with the university's School of Public Health. Apart from applications in epidemiology, this project will have a broad impact on scientific disciplines including signal and image processing, biomedical imaging, gravitational sounding, chaos theory, ocean acoustics, and others. The project includes graduate student training through involvement in the research.<br/><br/>The project aims to develop computational algorithms for estimating parameters using optimization. From an optimization standpoint, parameter estimation and forecasting from data comes down to solving an ill-posed minimization problem constrained by a system of ordinary or partial differential equations. For uncertainty quantification, multiple runs of the inversion algorithm must be carried out, preferably in real time. To address this challenge, the project will construct a family of trust-region optimization algorithms with low-rank updates for the Jacobian operator that will reduce the computational cost of a quasi-Newton step and, at the same time, incorporate an extra layer of stability in the iterative process. In case of nonlinear least squares with non-zero residuals, low-rank updates for stable Hessian evaluation will be investigated. Theoretical and numerical analysis of the new methods will be first carried out for normally solvable ill-posed operator equations and then extended to essentially ill-posed problems. The successful completion of this project will advance the understanding of ill-posed inverse problems and facilitate more stable and efficient simulations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1952777","FRG: Collaborative Research: Randomized Algorithms for Solving Linear Systems","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","04/24/2020","Joel Tropp","CA","California Institute of Technology","Standard Grant","Yuliya Gorb","07/31/2024","$375,000.00","","jtropp@cms.caltech.edu","1200 E CALIFORNIA BLVD","PASADENA","CA","911250001","6263956219","MPS","1271","1616, 9263","$0.00","The objective of this project is to develop faster and more energy-efficient algorithms for one of the most fundamental tasks in computational science: solving large systems of coupled linear equations. Faster algorithms will both accelerate computations that can already be performed, and enable computations that are beyond the reach of existing methods. More energy efficient algorithms will help to reduce the power consumption of data centers, and to extend the battery life of mobile devices such as cell phones and tablet computers. The fundamental innovation behind our approach is to harness mathematical properties of large collections of random numbers to build new stochastic algorithms that dramatically outperform existing deterministic ones. In a nutshell, the idea is to use randomized sampling, and randomized averaging, to reduce the effective dimensionality of the problems to be processed. In addition the project provides research training opportunities for postdoctoral fellows and graduate students.<br/><br/>We seek to develop computationally efficient methods for solving linear systems of equations involving large numbers of variables, both in terms of asymptotic complexity, and in terms of practical speed at realistic problem sizes. Such systems of equations arise ubiquitously in science and engineering, and solving them is often the bottleneck in terms of time that decides how large of a problem can be handled. In particular, this is what limits how large of a data set can be analyzed, or how realistic a computational simulation can be when modelling some physical phenomenon. By developing faster and more efficient algorithms, we will accelerate computations that are done today, and enable many others that are outside the reach of currently existing methods.  The project is premised on the recent development of new randomized algorithms for solving linear algebraic problems. Such methods have proven to dramatically outperform classical deterministic methods for certain tasks such as computing low rank factorizations to matrices - the crucial computational step in e.g. Principal Component Analysis, the PageRank algorithm by Larry Page and Sergey Brin, numerical coarse graining when modeling complex multiscale systems, and many more. Randomized algorithms have also been used to build faster solvers for linear systems. However, while the theoretical results obtained at this point are extremely encouraging, it remains to develop randomized linear solvers that are decisively faster in practical applications. To achieve this goal, the project will support a research group that brings together four researchers with complementary skills in numerical linear algebra, random matrix theory, computational harmonic analysis, optimization, and high performance computing.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012285","A Fitted Finite Element Method for the Modeling of Complex Materials","DMS","COMPUTATIONAL MATHEMATICS","09/01/2020","08/03/2022","Jeffrey Ovall","OR","Portland State University","Continuing Grant","Yuliya Gorb","08/31/2024","$200,000.00","","jovall@pdx.edu","1600 SW 4TH AVE","PORTLAND","OR","972015522","5037259900","MPS","1271","9263","$0.00","Partial differential equations (PDEs) provide the principle mathematical models of physical phenomena that undergo continuous spatial and/or temporal variation, and the approximation of their solutions is of fundamental importance in a broad spectrum of scientific and engineering applications. Finite element methods (FEM) for solving PDEs are favored in the scientific community because of their flexibility in representing materials with complex geometries and spatially-varying material properties, and their ability to resolve local features of the solution, such as sharp transitions (e.g. shocks, layers) and singularities (unbounded derivatives). FEM works by partitioning the region of interest into a mesh consisting of smaller computational cells, and approximating the solution of the PDE in terms of ?simple? functions defined on these cells. This project aims to increase the flexibility of FEM by allowing for significantly more general cell shapes and function types, to more efficiently model complex materials. Publicly-available software will be produced, together with supporting mathematical theory and numerical experiments illustrating its practical performance on problems exhibiting challenging and realistic features.<br/><br/>The PI and collaborators will develop theory and practical algorithms for computing with finite elements defined on meshes consisting of rather general curvilinear polygons. Among the issues that will be addressed are: (i) interpolation/approximation theory for the  resulting finite element spaces, which contain special locally-harmonic functions in addition to local polynomials; (ii) basis selection and efficient and accurate quadrature rules for assembling the finite element linear system; (iii) efficient and reliable a posteriori error estimators, and self-adaptive refinement techniques based on them; (iv) development of freely-available software, hosted on a public repository, that includes example problems. The types of problems that motivate this work are those involving PDE models of complex materials that may have multiple complicated interfaces between material types. Numerical examples supplied in the articles will highlight the performance of the proposed method on such problems, making relevant comparisons with competing approaches where feasible.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012255","Collaborative Research: Data-Driven Variational Multiscale Reduced Order Models for Biomedical and Engineering Applications","DMS","COMPUTATIONAL MATHEMATICS","06/01/2020","05/27/2020","Omer San","OK","Oklahoma State University","Standard Grant","Yuliya Gorb","05/31/2024","$149,996.00","","osan@okstate.edu","401 WHITEHURST HALL","STILLWATER","OK","740781031","4057449995","MPS","1271","079Z, 9150, 9263","$0.00","Mathematical models are a fundamental tool for improving our knowledge of natural and industrial processes. Their use in practice depends on their reliability and efficiency. Reliability requires a fine-tuning of the model parameters and an accurate assessment of the sensitivity to noisy inputs. Efficiency is particularly critical in optimization problems, where the computational procedure identifies the best working conditions of a complex system.  These requirements lead to solving many times models with millions or even billions of unknowns. This process may require days or weeks of computations on high-performance computing facilities. To mitigate these costs, we need new modeling strategies that allow model-runs in minutes to hours on local computing facilities (such as a laptop).  Reduced order models (ROMs) are extremely low-dimensional approximations that can decrease the computational cost of current computational models by orders of magnitude. Having in mind biomedical and wind-engineering applications, this project proposes novel methods of model reduction. Data and numerical results from the expensive (or high-fidelity) models are combined with machine learning approaches, to obtain ROMs that attain both efficiency and accuracy at an unprecedented level. The new data-driven ROM framework will finally make possible the numerical simulation of aortic dissections, pediatric surgery, or wind farm optimization on a laptop in minutes, and aims at becoming a critical and trustworthy tool in decision-making processes.<br/><br/>Data assimilation (DA), uncertainty quantification (UQ), and shape optimization (SO) are central to the development of computational models for significant biomedical and engineering applications.   Since these applications require a large number of model simulations, running an expensive full order model (FOM) is generally prohibitively expensive.  For systems that display dominant structures, reduced order models (ROMs) can decrease the FOM computational cost by orders of magnitude.   Thus, for the clinical and engineering applications above, ROMs appear as a natural and practical alternative to the prohibitively expensive FOMs running on high-performance computing facilities.   Unfortunately, to capture all the geometric scales in the hemodynamics of aortic dissections or to cope with the large Reynolds number in the wind farm optimization, hundreds and thousands of ROM modes are necessary. These relatively high-dimensional ROMs are still not viable to effectively perform DA, UQ, or SO for these applications.  What is needed is ROMs that are not only low-dimensional and efficient, but also accurate.  To develop ROMs that are accurate in realistic, under-resolved regimes, the ROM closure problem needs to be solved, i.e., the effect of the discarded ROM modes on the ROM dynamics needs to be modeled.  The proposed research puts forth a new data-driven ROM paradigm that centers around the hierarchical structure of variational multiscale (VMS) methodology and utilizes modern machine learning (ML) and numerical and observational data to develop structural ROM closures that can dramatically increase the ROM accuracy at a modest computational cost.  The novel data-driven VMS-ROM paradigm maintains the low computational cost of current ROMs but dramatically increases the ROM accuracy.  Biomedical applications in thoracic and pediatric surgery (aortic dissections and Fontan procedure ? where the fate of the patient depends significantly on the shape of the vessels) as well as wind-engineering applications are specifically targeted. The data-driven VMS-ROM framework will finally make possible the efficient DA, UQ, and SO in these and, possibly, other fields relying on mathematical and computational modeling. This project will support one graduate student each year at each of the three institutions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012469","State and Parameter Estimation: Variationally Stable Models and Physics-Informed Learning","DMS","COMPUTATIONAL MATHEMATICS","08/15/2020","07/29/2020","Wolfgang Dahmen","SC","University of South Carolina at Columbia","Standard Grant","Yuliya Gorb","07/31/2024","$224,607.00","Zhu Wang","dahmen@math.sc.edu","1600 HAMPTON ST # 414","COLUMBIA","SC","292083403","8037777093","MPS","1271","9150, 9263","$0.00","Advancing technology and science in a variety of areas, such as civil infrastructure, material science, and manufacturing, can often be formulated mathematically as design and control problems, or more generally, as inversion tasks. Such tasks often need to be based on incomplete information given, on the one hand, in terms of data collected by sensors, and on the other hand, in terms of a mathematical model which may be incomplete or depend on a large number of uncalibrated parameters. An illustrative example concerns the estimation of groundwater porous media flow where the data are pressure heads taken from boreholes and the model is Darcy's law for the pressure equation with an unknown parameter:  permeability field. A similar situation is encountered in many seemingly different application scenarios such as Electron Impedance Tomography where one wants to infer inner tissue structure from voltage responses at a number of electrodes, located at the surface of the object. A common challenge in these problems is that the available data are not sufficient to effectively learn the underlying physical process, and that the problem may have a prohibitively large computational complexity.  The key objective of this project is to develop robust methods for fusing the information provided by the mathematical model and by the data so as to ensure that the required computational complexity remains affordable while the resulting estimators have a high and quantifiable predictive capability. To warrant the applicability of the work to a broad range of applications, a sufficiently general problem setting for state and parameter estimation will be considered. A central role will be played by the interplay between classical model-based approaches and novel data-driven methodologies from data science. This project will give students and young researchers a clear orientation on the principal role of a variety of relevant mathematical concepts and machine learning algorithms.<br/><br/>A guiding theme in this project is the search for alternatives to Bayesian inversion with a stronger emphasis on deterministic accuracy quantification with rigorous complexity estimates revealing intrinsic information limits. The main conceptual framework is the so called Parametrized-Background Data-Weak method, which opens a ?geometric perspective? with the following important ramifications: it is based on stable variational formulations for the parametric partial differential equations, well beyond the classical elliptic model classes, by invoking suitable problem-adapted nonsymmetric weak formulations. Distinguishing data from the functionals and sensors, and lifting the latter to the properly identified trial space, induces an infinite-dimensional ?coordinate system? that accommodates the generation of optimal reduced models as well as a machine learning framework for regression so as to still respect intrinsic problem metrics. Different from the conventional approaches, our method does not cast the inversion task directly into any a priori fixed discrete form.  Thus, it avoids introducing ambiguous regularization terms, clipping possibly important scale information and coupling less compatible metrics. This allows one to identify optimality benchmarks reflecting essential recovery limitations and construct estimators that meet these benchmarks or come close within a proper accuracy-complexity balance. Moreover, using again stable weak formulations on a continuous level, the PIs will explore ways of reducing (highly ill-posed) parameter estimation typically formulated as a non-convex optimization problem to more benign state estimation in combination with a convex optimization problem. This sheds light on the interplay between the underlying variational formulations, structure of solution manifolds, and their approximability by reduced basis methods or highly nonlinear deep neural networks. This research will lead to rigorous complexity and accuracy quantification, and reduce the need for ad hoc and ambiguous problem truncations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012253","Collaborative Research: Data-Driven Variational Multiscale Reduced Order Models for Biomedical and Engineering Applications","DMS","COMPUTATIONAL MATHEMATICS","06/01/2020","05/27/2020","Traian Iliescu","VA","Virginia Polytechnic Institute and State University","Standard Grant","Yuliya Gorb","05/31/2024","$150,000.00","","iliescu@vt.edu","300 TURNER ST NW","BLACKSBURG","VA","240603359","5402315281","MPS","1271","079Z, 9263","$0.00","Mathematical models are a fundamental tool for improving our knowledge of natural and industrial processes. Their use in practice depends on their reliability and efficiency. Reliability requires a fine-tuning of the model parameters and an accurate assessment of the sensitivity to noisy inputs. Efficiency is particularly critical in optimization problems, where the computational procedure identifies the best working conditions of a complex system.  These requirements lead to solving models with millions or even billions of unknowns many times. This process may require days or weeks of computations on high-performance computing facilities. To mitigate these costs, we need new modeling strategies that allow model-runs in minutes to hours on local computing facilities.  Reduced order models (ROMs) are low-dimensional approximations that can decrease the computational cost of current computational models by orders of magnitude. Having in mind biomedical and wind-engineering applications, this project proposes novel methods of model reduction. Data and numerical results from the expensive (or high-fidelity) models are combined with machine learning approaches, to obtain ROMs that attain both efficiency and accuracy at an unprecedented level. The new data-driven ROM framework will make possible the numerical simulation of aortic dissections, pediatric surgery, or wind farm optimization on a laptop in minutes, and aims at becoming a critical and trustworthy tool in decision-making processes. This project will support one graduate student each year at each of the three institutions.<br/><br/>Data assimilation (DA), uncertainty quantification (UQ), and shape optimization (SO) are central to the development of computational models for significant biomedical and engineering applications.   Since these applications require a large number of model simulations, running an expensive full order model (FOM) is generally prohibitively expensive.  For systems that display dominant structures, reduced order models (ROMs) can decrease the FOM computational cost by orders of magnitude. Thus, for the clinical and engineering applications above, ROMs appear as a natural and practical alternative to the prohibitively expensive FOMs running on high-performance computing facilities. Unfortunately, to capture all the geometric scales in the hemodynamics of aortic dissections or to cope with the large Reynolds number in the wind farm optimization, hundreds and thousands of ROM modes are necessary. These relatively high-dimensional ROMs are still not viable to effectively perform DA, UQ, or SO for these applications.  What is needed is ROMs that are not only low-dimensional and efficient, but also accurate.  To develop ROMs that are accurate in realistic, under-resolved regimes, the ROM closure problem needs to be solved, that is, the effect of the discarded ROM modes on the ROM dynamics needs to be modeled. The proposed research puts forth a new data-driven ROM paradigm that centers around the hierarchical structure of variational multiscale (VMS) methodology and utilizes modern machine learning and numerical and observational data to develop structural ROM closures that can dramatically increase the ROM accuracy at a modest computational cost.  The novel data-driven VMS-ROM paradigm maintains the low computational cost of current ROMs but dramatically increases the ROM accuracy.  Biomedical applications in thoracic and pediatric surgery (aortic dissections and Fontan procedure ? where the fate of the patient depends significantly on the shape of the vessels) as well as wind-engineering applications are specifically targeted. The data-driven VMS-ROM framework will finally make possible the efficient DA, UQ, and SO in these and, possibly, other fields relying on mathematical and computational modeling.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012015","High Order Schemes for Gradient Flows and Interfacial Motion","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","07/28/2020","Selim Esedoglu","MI","Regents of the University of Michigan - Ann Arbor","Standard Grant","Yuliya Gorb","07/31/2024","$269,999.00","","esedoglu@umich.edu","1109 GEDDES AVE, SUITE 3300","ANN ARBOR","MI","481091079","7347636438","MPS","1271","9251, 9263","$0.00","Many important phenomena in a wide variety of scientific and engineering fields are described by moving curves or surfaces. For example, in materials science, the internal structure of most metals and ceramics reveal millions of tiny individual crystallites stuck together. The network of surfaces that delineate the boundaries of these tiny crystallites and thus separate them from one another begins to move when the material is heated during common manufacturing processes such as forging or annealing. The shapes and sizes of the crystallites, defined by this network of surfaces, have implications for important physical characteristics of the material, such as its conductivity and yield strength. Another, very different example comes from computer vision, where a common technique for automatically separating the foreground object from the background in a digital image is to start with a curve, such as a large circle containing the foreground object, and then prescribe an update rule that shrinks the circle until it runs into the edges of the object, shrink-wrapping around it and capturing its outline in the process. The outline can then be compared to a library of shapes, for recognition purposes. In both applications, as in many others, the equations describing the motion of the interfaces involved often fall into an important class known as gradient flow, or steepest descent: The evolution can be characterized as the fastest way to decrease an appropriate cost function or energy. This project will develop highly accurate and reliable numerical methods for simulating these evolutions on the computer. It includes support for research training of a graduate student, as well as summer research opportunities for undergraduate students.<br/><br/>The project will develop very general, problem independent techniques for boosting the order of accuracy in time of existing numerical schemes for evolution equations that arise as gradient flow (steepest descent) for an energy. A natural stability condition in the numerical analysis of gradient flows is energy stability: whether the cost function is dissipated from one time step to the next. The new techniques for boosting the order of accuracy of existing schemes will preserve desirable stability properties. For example, if the existing scheme is first order accurate in time and unconditionally energy stable, its order of accuracy will improve to second order or higher, but its unconditional stability will be preserved. Moreover, the improvement in accuracy will be achieved by merely calling multiple times per time step a black-box implementation of the original scheme. A primary goal of the project will be to extend the technique to popular numerical methods (the level set method, threshold dynamics) for geometric motions of interfaces that arise as gradient flow, such as multiphase motion by mean curvature.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012868","Computational Methods for Applications in Imaging and Remote Sensing","DMS","COMPUTATIONAL MATHEMATICS","07/01/2020","06/09/2020","Luminita Vese","CA","University of California-Los Angeles","Standard Grant","Yuliya Gorb","06/30/2024","$300,000.00","Igor Yanovsky","lvese@math.ucla.edu","10889 WILSHIRE BLVD STE 700","LOS ANGELES","CA","900244201","3107940102","MPS","1271","9263","$0.00","The investigators, along wit their students and collaborators, will develop novel mathematical formulations and computational techniques for applications in data science, remote sensing, atmospheric sciences, and medical imaging.  This multidisciplinary research includes advancement of discovery and understanding of many natural phenomena and the development of new imaging sciences methods for the medical field. Super-resolution of hurricane imagery will be of value to science, where many aspects of hurricane formation and strength prediction are still unknown, and to society, which could benefit from more accurate information being used in forecasts of storm strength and development. Improving the quality of images distorted by atmospheric turbulence will have applications in defense, while improving image registration algorithms will tremendously help research, diagnosis, and treatment decisions in the medical field. This project will provide support for one graduate student per year.<br/><br/>The project's activities will provide links between efficient mathematical formulations, imaging approaches and applications in remote sensing, atmospheric sciences, and medical imaging, where similar approaches have not yet been attempted. Novel variational approaches, iterative and numerical analysis techniques will be developed for solving these and related inverse problems. In particular, this investigation will study novel robust variational approaches and their numerical approximations, including: a new combined deconvolution and geometric correction variational model for restoration of atmospherically-distorted images; local and nonlocal total variation regularized super-resolution method and an efficient computational algorithm for space-time deconvolution of low-resolution sequences; novel applications of multiscale hierarchical decompositions to blind deconvolution and image registration. The investigators will promote multidisciplinary teaching, training and learning.  Mathematics  students will be exposed to a broad range of topics and techniques: (i) in applied and computational mathematics, image processing and analysis, and (ii) topics outside mathematics, including remote sensing, atmospheric sciences, and medical imaging.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012415","Numerical Algorithms and Simulations for Multiphase Flows of Multiple Immiscible Incompressible Fluids","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","08/03/2022","Suchuan Dong","IN","Purdue University","Continuing Grant","Yuliya Gorb","07/31/2024","$205,349.00","","sdong@purdue.edu","2550 NORTHWESTERN AVE STE 1900","WEST LAFAYETTE","IN","479061332","7654941055","MPS","1271","9263","$0.00","This research project aims to develop mathematical and computational tools, methods, and algorithms for simulating and understanding a class of multiphase multicomponent flow problems that are of practical engineering significance and fundamental physical importance. The systems under study in this project have relevance to the environment, energy, and materials science. For example, such multiphase systems occur in modeling for remediation of oil spills. Another example is the novel class of functional surfaces called liquid infused surfaces discovered in the past decade, which exhibit a variety of attractive properties such as self-cleaning, anti-icing and anti-fouling. These multiphase multicomponent problems underlie numerous technological advances, from printed electronic circuits and sensors, to opto-fluidic microscopes and waveguides, to water-resistant fabrics, to oil recovery and carbon sequestration. The project aims to develop improved efficient and effective computational methods to tackle the challenges in simulations for such systems. This project provides research training opportunities for graduate and undergraduate students. <br/><br/>The research aims at devising efficient and effective methods for simulating and understanding the dynamics of a system of three or more immiscible incompressible fluids with different physical properties such as densities, viscosities, and pairwise surface tensions. These systems pose enormous computational and algorithmic challenges to numerical simulations, because of the multitude of fluid interfaces, three-phase lines, and contact lines and contact angles involved. The project builds upon the reduction-consistent and thermodynamically-consistent formulations developed in recent years and will provide computational prediction capability and effective techniques for illuminating and understanding the interactions among multiple fluid components, multiple types of fluid interfaces, and multiple types of contact lines.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012424","Computational Retinal Hemodynamics","DMS","COMPUTATIONAL MATHEMATICS","09/01/2020","08/11/2022","Shravan Veerapaneni","MI","Regents of the University of Michigan - Ann Arbor","Continuing Grant","Yuliya Gorb","08/31/2023","$282,586.00","","shravan@umich.edu","1109 GEDDES AVE, SUITE 3300","ANN ARBOR","MI","481091079","7347636438","MPS","1271","9263","$0.00","Blood flow in the retina, also termed retinal hemodynamics, has long been known to be affected by glaucoma, a neurodegenerative condition that is the leading cause of irreversible but preventable blindness. Alterations in retinal hemodynamics are also indicators of several other disease pathologies, including systemic diseases such as hypertension and diabetes. Consequently, numerous imaging modalities have been developed to non-invasively measure hemodynamic parameters in the retina. Examples include color Doppler imaging, laser Doppler flowmetry, optical coherence tomography, and fundus photography. While hemodynamic analysis via imaging has been available for more than a century, the advent of high-resolution retinal images combined with novel automated annotation techniques created the need for accurate numerical simulations of blood flow through retinal microvasculature. The primary goal of this project is to develop stable, high-accuracy, optimal algorithms for direct numerical simulation of particulate blood flow through patient-specific arterial graphs. The project provides training for graduate students through involvement in the research.<br/><br/>This project addresses two computational bottlenecks that arise in large-scale simulations of particulate flows using boundary integral methods. First, a new high-order nearly-singular integration scheme in three dimensions using concepts from exterior calculus and harmonic polynomial approximations will be developed. The appealing feature of these schemes will be that they work directly on user-supplied boundary meshes (e.g., triangulated arterial graphs). If smooth line integrals on the given meshes can be evaluated to high accuracy, then singular and nearly singular integrals can both be computed to high accuracy. This contrasts with existing methods, which often require pre-processing. Second, to improve the robustness and accuracy of simulations without imposing excessive constraints on mesh sizes, complementarity constraint based contact resolution techniques will be developed. While the primary focus of this project is on simulating retinal hemodynamics, the computational methods under development will be applicable to more general microscale particulate flow, including flows of droplets, bacteria, and colloids.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2020623","Workshop on Mathematical Machine Learning and Application","DMS","COMPUTATIONAL MATHEMATICS","04/01/2020","03/18/2020","Jinchao Xu","PA","Pennsylvania State Univ University Park","Standard Grant","Leland Jameson","09/30/2021","$24,000.00","","xu@math.psu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271","079Z, 7556, 9263","$0.00","This award supports participation in the 2020 Workshop on Mathematical Machine Learning and Application held at Penn State University on April 26-29, 2020. The workshop aims to bring together active scientists in the emerging field of data science to discuss recent advances in the study of algorithm development, theoretical analysis, and applications of machine learning.  One focus of the workshop is on theoretical understanding of why and how deep learning works from mathematical viewpoints. This grant provides supports of participation of US-based invited speakers and US-based junior participants (graduate students, postdocs and early career researchers who lack their own funding). The main session of the workshop will take place during the period from April 27 to 29, with about 20 invited talks and a poster session. A short course featuring introductory lectures on the mathematics of deep learning will be held prior to the workshop on Sunday, April 26, with junior participants as the main target audience.<br/><br/>In this workshop, researchers in mathematical machine learning and related fields from the United States and other countries around the world will discuss state-of-the-art methodologies and developments and propose future directions in mathematical data science and its applications. Examples of topics to be discussed in the workshop include: machine learning in physical modeling and computational engineering, non-convex optimization in machine learning, approximation theory of deep neural networks, interactions between deep learning and partial differential equations, architecture design and interpretation of convolutional neural networks, deep learning in computer vision and natural language processing, and deep learning with grammars, automata, and rules. More details of this workshop are available at https://ccma.math.psu.edu/2020workshop/.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011996","Collaborative Research: Integrated Optoelectronic Optimization of Thin-Film Solar Cells with Light-Trapping Structures","DMS","COMPUTATIONAL MATHEMATICS","08/15/2020","10/19/2020","Akhlesh Lakhtakia","PA","Pennsylvania State Univ University Park","Standard Grant","Yuliya Gorb","07/31/2024","$150,000.00","","akhlesh@psu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271","9263","$0.00","Although recent years have seen a rapid drop in the cost of standard thick crystalline-silicon solar-cells, small-scale photovoltaic generators of energy (solar cells) must become ubiquitous for human progress to become truly unconstrained by energy economics. Using an integrated optoelectronic computer model developed under a previous NSF grant, the Principal Investigators (PIs), have shown that thin-film solar cells containing absorber layers with optimally graded electrical properties can have theoretical electrical generation efficiencies of over 34%, a large increase over previous designs and competitive with heavier standard solar cells. Once manufactured, such solar cells could be incorporated in wearables, textiles, car roofs, etc, and deployed with less infrastructure than current crystalline-silicon devices.  Further improvement to the design requires the incorporation of light-trapping structures, such as antireflection coatings to improve the absorption of light, that are jointly optimized with the composition of the electricity generating layers by grading the bandgap parameters.  In addition, simplified designs better suited to manufacture need to be investigated.  These additional steps require mathematical improvement to the optoelectronic model, and the investigation of several new combinations of materials with simplified bandgap grading. <br/><br/>This is a multidisciplinary project with two major goals: mathematical and physical. The mathematical goal is to enhance the integrated optoelectronic model by (i) using modern methods of numerical analysis to improve the efficiency of the photonics solver, and (ii) improving the robustness and reliability of the Hybridizable Discontinuous Galerkin method (HDG) finite element method applied to the drift-diffusion system for charged-particle transport. In particular, the PIs will analyze and implement a completely new approach by hybridizing the rigorous coupled-wave approach (RCWA) with the C method for solving Maxwell?s equations in 2D and 3D. As the HDG solver for the drift-diffusion problem needs improved robustness and efficiency to handle layered designs more suitable for manufacturing, the PIs will analyze and implement a dual-weighted residual approach to a posteriori error estimation of the total current and investigate the use of Anderson acceleration for the non-linear solver.  It is expected that the software developed on this project will be useful to the wider photonics community. The physical goal is to use the newly developed fast and adaptive solver so that the improved algorithms can be used to simultaneously optimize light-trapping structures and bandgap grading parameters. The light-trapping structures will include multilayered antireflection coatings, nanocone arrays, and combinations of both. The PIs expect to spur the development of colored solar cells to power miniature electronic and optical devices on clothes, car roofs, tents, etc. Wearable solar cells could be designed to perform not only in sunlight but also in indoor light.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012268","Collaborative Research: Euler-Based Time-Stepping with Optimal Stability and Accuracy for Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","08/15/2020","07/29/2020","David Shirokoff","NJ","New Jersey Institute of Technology","Standard Grant","Yuliya Gorb","07/31/2024","$196,874.00","","david.g.shirokoff@njit.edu","323 DR MARTIN LUTHER KING JR BLV","NEWARK","NJ","071021824","9735965275","MPS","1271","9263","$0.00","Principled simulations of many real-world problems (such as fluid flow, geophysical phenomena, and quantum mechanics) require an evolution in time with high accuracy, yet in a structurally simple and robust fashion. This project develops novel time integration methods for complex multi-physics problems, while not incurring fundamental problems that reduce the accuracy or stability of many existing methods. The developed methods are founded in new mathematical theories, and are used to devise more accurate and robust simulations of shallow water flows with dispersive effects, which are important in the understanding of tsunamis, storm surge, and coastal flooding.  This project will support one graduate student for two years at NJIT and one graduate student per year at the second institution, Temple.<br/><br/>This project develops methods for the time integration of differential equations that are implemented as sequences of generalized Euler steps, including: multistage diagonally implicit Runge-Kutta (DIRK) and multistep implicit-explicit (IMEX) methods. Such methods are significant as they reduce the implementation burden on a practitioner to the solution of a fully- or semi-implicit Euler step for their initial-boundary-value problem. The key research contributions are: (A) a full algebraic theory of weak stage order, and its use to design optimized high-order DIRK methods devoid of order reduction; (B) a stability theory for IMEX methods applied to differential algebraic equations, and the co-design of IMEX splittings and scheme coefficients to overcome stability limitations prevalent in existing methods. Applications include new efficient time-stepping for the dispersive shallow water equations and related differential algebraic equations. The collaborative mentoring of graduate students at two campuses is an important component of this project.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012427","Computational Riemannian Geometry: High-Order Methods, Analysis, and Structure Preservation","DMS","COMPUTATIONAL MATHEMATICS","06/15/2020","06/08/2020","Evan Gawlik","HI","University of Hawaii","Standard Grant","Yuliya Gorb","05/31/2024","$135,304.00","","egawlik@hawaii.edu","2425 CAMPUS RD SINCLAIR RM 1","HONOLULU","HI","968222247","8089567800","MPS","1271","9150, 9263","$0.00","Riemannian geometry plays a fundamental role in mathematical physics and geometric analysis, and computational methods for Riemannian geometry have surprisingly many practical applications.  Equations that govern time-varying Riemannian metrics, for example, are prototypes for curvature-driven flows that arise in science and engineering like surface tension-driven flow.  Such equations also underly several algorithms that are used widely in computer graphics, machine vision, and medical imaging.  Examples include algorithms for surface parameterization, texture mapping, and surface registration.  Computational Riemannian geometry also plays an essential role in gravitational wave astronomy, where accurate numerical simulations of Einstein?s equations are needed to make inferences about gravitational wave signals.  Despite its importance, Riemannian geometry is, in certain respects, underserved by traditional tools of numerical analysis, which are tailored toward problems posed in Euclidean space.  This project centers on developing novel computational methods for Riemannian geometry.  The computational methods will be made freely available in a public repository, and graduate students will participate in their development. <br/> <br/>The main goal of this project is to design and analyze high-order methods for three families of problems in computational Riemannian geometry: (1) the numerical solution of intrinsic geometric flows with finite element methods, (2) intrinsic curvature approximation with finite elements, and (3) the efficient computation of interpolants, geodesics, Riemannian means, and the Riemannian exponential map on matrix manifolds. These three problems are tightly intertwined. The vast majority of geometric flows in Riemannian geometry are curvature-driven flows, so their discretization with finite elements goes hand in hand with the construction of finite element approximations of the Riemann curvature tensor and its contractions. In turn, tensor field and frame field discretizations play an important role in curvature approximation, underscoring the need for efficient algorithms for computations on matrix manifolds. This project aims to design numerical methods for the aforementioned problems that are high-order, provably convergent, and structure-preserving. This project will support one graduate student each year.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012860","Computational Forward and Inverse Radiative Transfer","DMS","COMPUTATIONAL MATHEMATICS","07/01/2020","05/28/2020","Hong-Kai Zhao","NC","Duke University","Standard Grant","Yuliya Gorb","06/30/2024","$250,001.00","","zhao@math.duke.edu","2200 W MAIN ST","DURHAM","NC","277054640","9196843030","MPS","1271","9263","$0.00","The radiative transfer equation (RTE) is an important modeling tool with applications in biomedical imaging, clinical radiation therapy treatment planning, study of the composition and structure of atmosphere, and other fields. Because of its complicated structure, the RTE presents challenges to analysis and simulation. This research project aims at developing novel, accurate, and e?cient computational methods for both forward and inverse radiative transfer problems. More generally, the insights obtained in this project are expected to provide new perspectives on solving a class of integral equations. The mathematical tools and computational algorithms under development will be disseminated broadly for advancing scienti?c and technological progress. Integration of research with education at di?erent levels will provide training for computational mathematicians. Supervised research projects and seminars related to the proposed research will be available to junior/senior undergraduates and graduate students. Participation of members of underrepresented groups will be encouraged.<br/><br/>Solutions to radiative transfer equations behave very di?erently in di?erent regions/regimes. These challenges require well-designed and well-understood numerical algorithms that can take into account special properties and structures of the RTE and its solution associated with the underlying application. Although studies and developments of numerical methods for RTE based on di?erential and probabilistic formulations have been done, integral-formulation-based approaches are less understood and not fully developed. This project will systematically develop and analyze e?cient numerical algorithms based on integral formulation and also explore a combination of integral and di?erential formulations. The key idea is to utilize dimension reduction, careful treatment of singularity, and the special structures of the resulting dense matrix to develop fast solvers. This research is applicable to numerical simulation of radiation hydrodynamics and modeling of wave propagation in random media.<br/>Further applications in inverse problems that are modeled by RTE, such as optical tomography, photoacoustic tomography, ?uorescence imaging, etc., will be studied as well.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011324","Multilevel Graph-Based Methods for Efficient Data Exploration","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","07/28/2020","Yousef Saad","MN","University of Minnesota-Twin Cities","Standard Grant","Yuliya Gorb","12/31/2023","$244,217.00","","saad@umn.edu","200 OAK ST SE","MINNEAPOLIS","MN","554552009","6126245599","MPS","1271","079Z, 9263","$0.00","Graph theory helps scientists and engineers  model various types of relations between entities in a set, whether members of a social network, or molecules in a chemical compound for example.  Not surprisingly, with the advent of data-based methodologies that work by unraveling and exploiting relations between data items, graph theory tools are finding their way in a very broad range of applications.  The primary goal of this project is to examine a class of methods that manipulate graphs, specifically by developing effective multilevel algorithms that take advantage of divide and conquer approaches. In multilevel techniques, smaller and smaller graphs are extracted from some original graph with the goal of keeping as much of its intrinsic information as possible.  These smaller graphs are then employed instead of the original ones, resulting in significant gains in performance. This project addresses issues that are of great relevance to many current data-based methodologies and will be applicable across various disciplines. As such it will help promote interest in problems related to the current shift toward such methodologies because its research theme blends mathematical methods, innovations in algorithms, and applications. On the educational side, special courses and tutorials will be offered to graduate students from other disciplinary fields who wish to explore research in data sciences. This project will support one graduate student per year for each of the three years.<br/><br/>The rapid expansion of machine learning methodologies into a great variety of disciplines is pushing the demand for numerical methods that can effectively deal with large datasets.  Among these methods, those based on graph representations of data figure prominently.  The goal of this project is to develop effective multilevel algorithms that are rooted in graph theoretical approaches, for performing various machine learning tasks.  A primary focus of the planned research is that of ""graph coarsening"", a technique whereby an original graph is substantially reduced in size by agglomerating nearby nodes together, to produce a faithful representative of the original graph.  The project will exploit a class of methods based on multilevel coarsening, in which coarsening is applied recursively for a few levels.  The ultimate goal of a multilevel coarsening approach is to make it possible to perform the heavy computations with the coarsened graph which is much smaller, resulting in much faster processing, with minimal loss in accuracy. Coarsening is an effective alternative to random sampling, a well-established method that consists of replacing the original data by a subset of its columns or rows that are selected at random or quasi- randomly. This project will study, both empirically and theoretically, various coarsening strategies. For example, coarsening will be studied from the angle of a projection method for approximating eigenvectors.  Coarsening methods that try to preserve the eigenvectors exactly will also be studied.  Among the many possible applications of graph coarsening the project will specifically consider their use in speeding up the training of a class of neural networks known as Graph Convolutional Networks (GCNs).  A number of other research issues, all under the general theme of graph-based methods, will also be investigated.  For example, the project will study how a form of hypergraph coarsening can be used to provide a solution to the ""graph sparsification"" problem, whereby a sparser version of a given graph is sought, or to the ""column subset selection problem"" which consists of selecting important rows (or columns) from a given data matrix.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012243","An Accelerated Decomposition Framework for Structured Sparse Optimization","DMS","COMPUTATIONAL MATHEMATICS","07/15/2020","07/11/2020","Daniel Robinson","PA","Lehigh University","Standard Grant","Yuliya Gorb","06/30/2024","$200,000.00","Frank Curtis","dpr219@lehigh.edu","526 BRODHEAD AVE","BETHLEHEM","PA","180153008","6107583021","MPS","1271","9263","$0.00","There has been an explosion in the availability of data that is collected from countless sources and through various modalities. For instance, medical image archives are increasing by 20-40% each year and over 400 million procedures per year involve at least one medical image.  A goal among engineers and scientists is the design of advanced scientific tools that can use data to aid humanity.  Many such tools already exist but their success is tightly bound to the idea of problem ?sparsity?.  For example, when predicting whether a patient in an intensive care unit will develop septic shock, only a few medical measurements are truly helpful in making such predictions. Since there are few important measurements compared to the total measurements available to a doctor, the prediction problem can be viewed as ?sparse?. Despite the success of existing methods for sparse problems, their inadequacy for many modern machine learning and other types of problems has gradually been noticed by researchers. Since covariates often come in groups (e.g., genes that regulate hormone levels), one may wish to select them jointly instead of individually so that the models deployed make practical sense. Similar concerns occur in other important healthcare settings such as in the prediction of Parkinson's disease. This project will design, analyze, implement, and validate a new optimization framework that can handle these more complicated notions of ?sparsity? beyond the simplest ones currently analyzed in theory and used in practice. This project provides research training opportunities for graduate students.<br/><br/>The minimization of a function composed of a loss/data-fitting term and a regularization function is of immense interest throughout science and engineering.  The past decade has witnessed an explosion of interest in problems involving sparsity-promoting regularization such as the L1-norm. Moving past simple L1-norm regularization, researchers are continually realizing the potential benefits of using more intricate regularization functions that promote structured sparsity, such as the group L1-norm and elastic net functions. The proposed project involves the design, analysis, and implementation of new algorithms for solving optimization problems that involve such structure promoting regularization.  The algorithms will be designed to be broadly applicable, scalable, and efficient, and will be shown to possess strong convergence rate guarantees.  The novelty of the proposed algorithmic framework is a carefully defined ""space decomposition with subspace acceleration"" mechanism.  This mechanism adaptively decomposes the search space, and employs subspace steps based on proximal point and reduced-space Newton-type techniques.  The step decomposition aspect of the methodology makes it more scalable and efficient than, say, straightforward first-order methods.  The PIs will also enhance their general approach by designing new innovative strategies that combine domain decomposition and subspace acceleration in such a way that good complexity properties are obtained, accurate solution support estimates can be reliably achieved, and state-of-the-art numerical performance is attained.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012882","Computational and Multi-Scale Methods for Nonlinear Electromagnetic Models in Plasmas and Nanocomposites","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","06/22/2020","Vrushali Bokil","OR","Oregon State University","Standard Grant","Yuliya Gorb","07/31/2024","$224,854.00","Pallavi Dhagat, Nathan Gibson","bokilv@math.oregonstate.edu","1500 SW JEFFERSON ST","CORVALLIS","OR","973318655","5417374933","MPS","1271","9263","$0.00","This project is an inter-disciplinary collaboration involving mathematical modeling, computational simulation and experimental data for accelerating the design of advanced electromagnetic nanocomposite materials as well as alternative power generators. Nanocomposites, made of ferromagnetic nanoparticles in a dielectric, non-magnetic matrix, offer unparalleled opportunities for innovation in electromagnetic materials. The ability to predict electromagnetic material properties as a function of size, shape and concentration of inclusions in the host matrix, from computational simulations of physics-based models, will crucially aid in the digital fabrication of nanocomposites. These advances in design will enable applications including microwave frequency antennas and gradient refractive index lenses, printed electronic circuits and systems, to name a few. This objective is related to the Materials Genome Initiative's mission to accelerate materials innovation via computation. A second objective involves Magnetohydrodynamic (MHD) power generation, which is potentially a significant component of a secure U.S. energy portfolio. The lack of moving parts in an MHD power generator increases the overall efficiency of the power plant and potentially decreases carbon emissions significantly. Computational simulations of physics-based models will aid in the optimal design of these thermally efficient energy systems. The models we consider are also essential to correctly modeling solar flares which can trigger geomagnetic storms disrupting power and communications costing millions of dollars in losses. Thus our techniques will advance applications in astrophysics, space weather prediction and clean energy systems, among others. <br/><br/>The major goal of this project is to develop novel numerical discretizations and computational multiscale electromagnetic models incorporating uncertainties in nonlinear material properties. The resulting methods will enable optimal design strategies in the applications discussed above. We will validate the effectiveness of our methods using experimental data provided by our collaborators, which will also be used to calibrate statistical descriptions of uncertainties. One area of research involves a model-driven robust design methodology for a magnetic nanocomposite material with the desired properties critically needed for advanced devices. A second area, involves nonlinear models for magnetic fields in plasma. The PIs each have demonstrated records of integration of research into education and are dedicated educators committed to recruiting minorities and creating welcoming environments. The PIs will train three doctoral students on theoretical, computational and experimental aspects of this interdisciplinary project. The partnerships with government labs and industry will provide internship opportunities for the graduate students.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012414","Efficient Numerical Methods and Algorithms for Nonlinear Stochastic Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","07/22/2020","Xiaobing Feng","TN","University of Tennessee Knoxville","Standard Grant","Yuliya Gorb","07/31/2024","$275,000.00","","xfeng@utk.edu","201 ANDY HOLT TOWER","KNOXVILLE","TN","379960001","8659743466","MPS","1271","9263","$0.00","Modeling in industry, engineering, and domain sciences often involves various degrees of randomness and uncertainty effects.  A large and important class of models incorporating uncertainty are random and/or stochastic partial differential equations (SPDEs). This research project will address several important SPDEs and aims to develop improved numerical methods that are stable, accurate, and efficient, with focus on nonlinear problems and adequate sampling methods.  The resulting numerical methods and algorithms are anticipated to provide much-needed tools for computational modeling of systems described mathematically by SPDEs from many scientific, engineering, and industry applications such as materials science, fluid and quantum mechanics, wave scattering, mathematical finance, and stochastic optimal control. Moreover, the project will train graduate students through involvement in the research, helping them develop applied and computational mathematics knowledge and skills needed for successful careers in either academia or industry. <br/><br/>This research project develops advanced numerical methods and algorithms for general nonlinear random and/or stochastic partial differential equations (R/SPDEs). Current approaches for solving R/SPDEs face considerable challenges at large scales: the sheer amount of computation involved in such systems prevents the use of high spatial and temporal resolutions, and solver optimization is often not considered. In the meantime, R/SPDEs become more complex as additional nonlinearities and sources of noise are considered. This presents a big challenge but also a great opportunity to the numerical PDE community. The project focuses on developing efficient numerical methods and algorithms for solving nonlinear SPDEs that arise from various scientific and engineering applications, including stochastic Allen-Cahn and Cahn-Hilliard equations and stochastic nonlinear wave and Schrodinger equations. The numerical methods under development will aim to feature stability with respect to mesh sizes and physical parameters, structure-preserving properties, and amenability to fast and parallelizable implementation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2027438","RAPID: Analysis of Multiscale Network Models for the Spread of COVID-19","DMS","OFFICE OF MULTIDISCIPLINARY AC, APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY","04/15/2020","04/14/2020","Andrea Bertozzi","CA","University of California-Los Angeles","Standard Grant","Zhilan Feng","03/31/2022","$200,000.00","Mason Porter","bertozzi@math.ucla.edu","10889 WILSHIRE BLVD STE 700","LOS ANGELES","CA","900244201","3107940102","MPS","1253, 1266, 1271, 7334","096Z, 7914, 9263","$0.00","The current pandemic of coronavirus disease 2019 (COVID-19) has upended the daily lives of more than a billion people worldwide, and governments are struggling with the task of responding to the spread of the disease. Uncertainty in transmission rates and the outcomes of social distancing, ""shelter-at-home"" executive orders, and other interventions have created unprecedented challenges to the United States health care system. This project will address these issues directly using advanced mathematical modeling from dynamical systems, stochastic processes, and networks. The mathematical models, which are formulated with the specific features of COVID-19 in mind, will provide insights that are critical to people on the front lines who need to make recommendations for intervention strategies and human-behavior patterns to best mitigate the spread of this disease in a timely manner. The project will train a postdoctoral scholar, a PhD student, and two undergraduate students in the research needed to solve these complex problems. <br/><br/>The standard approach for epidemic modeling, at the community scale and larger, is compartmental models in which individuals are in one of a small number of states (for example, susceptible, infected, recovered, exposed, latent), with individuals moving between states. The COVID-19 epidemic can be modeled in this way, with resistance as part of the dynamics. The simplest examples of such models for large populations are coupled ordinary differential equations that describe the fraction of a population in each of the states. To model the stochasticity of infection and latency, models with self-exciting point processes can be fit to real-world data. This project compares the dynamical systems and stochastic models of relevance to COVID-19 transmission. The models also incorporate network structure for the transmission pathways. The project extends prior research on contagions on multilayer networks by incorporating multiple transmission methods and coupling between the spread of the contagion itself and human behavior patterns. The project leverages high-resolution societal mixing patterns in epidemics, as they influence both (1) observations and demographics of who has been diagnosed with COVID-19 and (2) who transits the disease, sometimes without being diagnosed.<br/><br/><br/>This award is co-funded with the Applied Mathematics program and the Computational Mathematics program (Division of Mathematical Sciences), and the Office of Multidisciplinary Activities (OMA) program.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012548","DMS-EPSRC Collaborative Research: Sharp Large Deviation Estimates of Fluctuations in Stochastic Hydrodynamic Systems","DMS","COMPUTATIONAL MATHEMATICS","08/15/2020","08/12/2020","Tobias Schaefer","NY","CUNY College of Staten Island","Standard Grant","Yuliya Gorb","07/31/2024","$147,603.00","","tobias@math.csi.cuny.edu","2800 VICTORY BLVD","STATEN ISLAND","NY","103146609","7189822254","MPS","1271","9263","$0.00","Extreme events can be highly impactful. They are typically rare, which is fortunate if their consequences are negative on society, but also makes them difficult to predict. The focus of this project is to develop computational tools that can be applied to gain understanding of how extreme events occur in complex stochastic systems. Examples are models for the forecasting of extreme weather-related events like tropical storms and flooding as well as the spread of pollutants in case of ocean oil spills. These tools will enable researchers to ask questions beyond what is currently possible. This will lead to transformative improvement of current predictive models, which is essential for efficient management of natural and man-made disasters. Further applications include the characterization of extreme events in stochastic models that behave similar to fluids, for example in the context of epidemics, traffic, and star formation. This collaborative project will support one graduate student per year at NYU.<br/><br/>Rare events are difficult to observe in controlled (numerical or physical) experiments, even for low-dimensional systems. The difficulty increases with the number of degrees of freedom, which makes high-dimensional systems even harder to analyze ? fluids described by stochastic hydrodynamic models are a particular example of interest. As a result the questions that researchers can ask in order to gain insights about extreme events in these systems are often limited. The goal of this project is to analyze rare but important events in complex systems by developing new mathematical and computational tools to establish their most likely way of occurrence and calculate sharp asymptotic estimates (with prefactor included) of their probability and recurrence time. The aim is to create a toolbox applicable to a wide range of models with a large number of degrees of freedom described by stochastic partial differential equations (PDEs), like advection-diffusion equations and Navier-Stokes equations, and transferable across disciplinary borders. These tools will be applied to stochastic hydrodynamic systems in order to gain deeper insights of classical turbulence. In addition, the efficiency of this novel approach will be demonstrated in the context of real-world applications, in particular the advection of pollutants and the capsizing of ships.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012286","Innovative Numerical Methods for High-Dimensional Applications","DMS","COMPUTATIONAL MATHEMATICS","07/01/2020","07/05/2022","Jianfeng Lu","NC","Duke University","Continuing Grant","Yuliya Gorb","06/30/2024","$293,120.00","","jianfeng@math.duke.edu","2200 W MAIN ST","DURHAM","NC","277054640","9196843030","MPS","1271","079Z, 9263","$0.00","This project aims to develop efficient numerical algorithms for a class of important systems in science and engineering that are modeled with high-dimensional partial differential equations (PDE) such as the many-body Schrdinger equation. Examples of such systems include many-body quantum mechanics, dynamics of chemical systems, learning and control of complex systems, and spectral methods for high-dimensional data. The numerical solution of high-dimensional PDE has been one of the greatest challenges in computational science and remains a formidable task even with today's computational power and algorithmic advances. Efficient numerical simulations present opportunities for major breakthroughs in scientific understanding. This project will employ modern techniques to develop novel efficient numerical algorithms for such important systems. Graduate students will be trained through involvement in the research.<br/><br/>The research project combines mathematical analysis and algorithmic design to make progress in numerical methods for high-dimensional PDE. The research will draw from and further develop ideas and tools from recent advances in computational physics, quantum chemistry, and machine learning. In particular, the project will use modern techniques for large-scale optimization and nonlinear parameterization of high-dimensional functions. Specifically, the PI will (1) develop novel highly efficient coordinate algorithms for large-scale eigenvalue problems, and (2) develop and analyze efficient methods based on neural-network parameterization of the solutions for high-dimensional PDE.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011603","Collaborative Research: Integrated Optoelectronic Optimization of Thin-Film Solar Cells with Light-Trapping Structures","DMS","COMPUTATIONAL MATHEMATICS","08/15/2020","10/19/2020","Peter Monk","DE","University of Delaware","Standard Grant","Yuliya Gorb","07/31/2024","$349,824.00","","monk@udel.edu","220 HULLIHEN HALL","NEWARK","DE","197160099","3028312136","MPS","1271","9150, 9263","$0.00","Although recent years have seen a rapid drop in the cost of standard thick crystalline-silicon solar-cells, small-scale photovoltaic generators of energy (solar cells) must become ubiquitous for human progress to become truly unconstrained by energy economics. Using an integrated optoelectronic computer model developed under a previous NSF grant, the Principal Investigators (PIs), have shown that thin-film solar cells containing absorber layers with optimally graded electrical properties can have theoretical electrical generation efficiencies of over 34%, a large increase over previous designs and competitive with heavier standard solar cells. Once manufactured, such solar cells could be incorporated in wearables, textiles, car roofs, etc, and deployed with less infrastructure than current crystalline-silicon devices.  Further improvement to the design requires the incorporation of light-trapping structures, such as antireflection coatings to improve the absorption of light, that are jointly optimized with the composition of the electricity generating layers by grading the bandgap parameters.  In addition, simplified designs better suited to manufacture need to be investigated.  These additional steps require mathematical improvement to the optoelectronic model, and the investigation of several new combinations of materials with simplified bandgap grading. <br/><br/>This is a multidisciplinary project with two major goals: mathematical and physical. The mathematical goal is to enhance the integrated optoelectronic model by (i) using modern methods of numerical analysis to improve the efficiency of the photonics solver, and (ii) improving the robustness and reliability of the Hybridizable Discontinuous Galerkin method (HDG) finite element method applied to the drift-diffusion system for charged-particle transport. In particular, the PIs will analyze and implement a completely new approach by hybridizing the rigorous coupled-wave approach (RCWA) with the C method for solving Maxwell?s equations in 2D and 3D. As the HDG solver for the drift-diffusion problem needs improved robustness and efficiency to handle layered designs more suitable for manufacturing, the PIs will analyze and implement a dual-weighted residual approach to a posteriori error estimation of the total current and investigate the use of Anderson acceleration for the non-linear solver.  It is expected that the software developed on this project will be useful to the wider photonics community. The physical goal is to use the newly developed fast and adaptive solver so that the improved algorithms can be used to simultaneously optimize light-trapping structures and bandgap grading parameters. The light-trapping structures will include multilayered antireflection coatings, nanocone arrays, and combinations of both. The PIs expect to spur the development of colored solar cells to power miniature electronic and optical devices on clothes, car roofs, tents, etc. Wearable solar cells could be designed to perform not only in sunlight but also in indoor light.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012266","Collaborative Research: Computational Harmonic Analysis Approach to Active Learning","DMS","COMPUTATIONAL MATHEMATICS","07/01/2020","05/19/2020","Alexander Cloninger","CA","University of California-San Diego","Standard Grant","Yuliya Gorb","06/30/2024","$219,501.00","","acloninger@ucsd.edu","9500 GILMAN DRIVE","LA JOLLA","CA","920930021","8585344896","MPS","1271","079Z, 9263","$0.00","Research in supervised learning is concerned with uncovering relationships between training data and some function or label that is attached to each datum, with the goal of generalizing to new samples. Modern machine learning tools, such as deep networks, typically require a huge set of training data in order to classify the rest of the data with sufficient confidence. Obviously, assigning an accurate label to a datum can be an expensive task, involving a great deal of human effort. This project seeks to develop methods to classify large amounts of data with a theoretically minimal number of training labels. The key to classifying with a small number of labels comes with the ability to choose at which data points a label will be queried. This collaborative research project will study these methods, known as active machine learning, from a geometric and harmonic analysis perspective, focusing on both algorithmic insights and theoretical guarantees. The ability to perform classification with a small number of labeled points has important implications in a variety of applications, including remote sensing classification, medical data analysis, and general applications where it is expensive to collect labels.<br/><br/>This project applies knowledge in computational harmonic analysis, function approximation, and machine learning to the study of active learning models, focusing on algorithmic insights, efficient implementations, and performance guarantees for both novel algorithms and currently existing machine learning algorithms. Mathematical tools, including localized kernel construction, approximation analysis in terms of intrinsic dimensionality, and harmonic analysis of eigenfunctions of operators on graphs and manifolds, have natural applications in the study of these areas. Specifically, the project addresses four fundamental questions that arise in the field: (1) How do you conservatively propagate the sampled labels to new points when the labels form a hierarchical clustering with possibly zero minimal separation between clusters? (2) Does the mechanism of kernel active learning generalize to graphs, where naive choice of points to sample becomes a combinatorial optimization problem? (3) Can we incorporate the structure of a neural network (or general parametric) classifier into the choice of labels queried and provably bound the generalization error for predictions on the rest of the data? (4) How can we tailor our framework to transfer learning and high-dimensional imaging?<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012391","Optimization Problems with Quasi-Equilibrium Constraints: Control, Identification, and Design","DMS","COMPUTATIONAL MATHEMATICS","07/01/2020","07/05/2022","Carlos Rautenberg","VA","George Mason University","Continuing Grant","Yuliya Gorb","06/30/2024","$199,922.00","","crautenb@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","MPS","1271","9263","$0.00","A wide range of problems in applied sciences involve constraints on variables of interest. These naturally arise in modeling of complex physical phenomena but also appear as a result of hierarchy or competition. Two different classes of these constraints can be described: explicit, where the bounds are known in advance, and implicit, where the bounds depend on the solution of the problem itself. One simple example of an implicitly constrained problem is that of finding the position of an elastic membrane with an obstacle that deforms upon the action of the membrane. In this example, the membrane position is the variable of interest, and the position of the obstacle is the implicit bound or constraint. The control and parameter identification for this class of implicitly constrained problems represent a significant challenge for a large variety of problems.  Some possible applications include the design of composite materials that sustain large forces without plastic deformation, the manufacture of multilayer organic light emitting diodes (OLEDs), and the detection of subsurface cracks in buildings that may compromise structural integrity and lead to catastrophic failure.<br/><br/>An increasing number of challenging problems in applied sciences involve non-differentiable structures as well as partial differential operators, thus leading to nonsmooth distributed parameter systems. Many of these problems have, directly in the problem formulation,  an additional form of implicit constraint resulting in a quasi-variational inequality (QVI). This is commonly found in elastoplasticity, friction mechanics, superconductivity, and also arises as the result of competition of a finite resource in generalized Nash games. Structurally speaking, QVIs are nonconvex and nonsmooth problems that possess a variational formulation with a constraint not known a priori and depending on the state itself.  Many design, control or identification problems involve QVIs. In particular, these are formulated as an optimization problem with the QVI as constraint, and where the design variable or the unknown parameter is of piecewise constant nature. This significantly increases the difficulty of the overall problem but it links it directly to real life applications. This proposal focuses on a class of optimization problems with quasi-variational constraints. The formulation is wide enough to include problems associated to water accumulation in real topographical data, non-isothermal elastoplasticity, and current flow on organic multilayer structures (LEDs). We aim at the development of solution algorithms of QVIs, and optimization thereof. The approaches will include an appropriate form of Moreau-Yosida regularization of the implicit constraint, and novel forms of regularization to guarantee a piecewise constant nature of solution parameters. The new methods developed here will enable the solution of problems that are currently intractable.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012355","Collaborative Research: Computational Harmonic Analysis Approach to Active Learning","DMS","COMPUTATIONAL MATHEMATICS","07/01/2020","05/19/2020","Hrushikesh Mhaskar","CA","Claremont Graduate University","Standard Grant","Yuliya Gorb","06/30/2024","$270,448.00","","Hrushikesh.Mhaskar@cgu.edu","150 E 10TH ST","CLAREMONT","CA","917115909","9096079296","MPS","1271","079Z, 9263","$0.00","Research in supervised learning is concerned with uncovering relationships between training data and some function or label that is attached to each datum, with the goal of generalizing to new samples. Modern machine learning tools, such as deep networks, typically require a huge set of training data in order to classify the rest of the data with sufficient confidence. Obviously, assigning an accurate label to a datum can be an expensive task, involving a great deal of human effort. This project seeks to develop methods to classify large amounts of data with a theoretically minimal number of training labels. The key to classifying with a small number of labels comes with the ability to choose at which data points a label will be queried. This collaborative research project will study these methods, known as active machine learning, from a geometric and harmonic analysis perspective, focusing on both algorithmic insights and theoretical guarantees. The ability to perform classification with a small number of labeled points has important implications in a variety of applications, including remote sensing classification, medical data analysis, and general applications where it is expensive to collect labels.<br/><br/>This project applies knowledge in computational harmonic analysis, function approximation, and machine learning to the study of active learning models, focusing on algorithmic insights, efficient implementations, and performance guarantees for both novel algorithms and currently existing machine learning algorithms. Mathematical tools, including localized kernel construction, approximation analysis in terms of intrinsic dimensionality, and harmonic analysis of eigenfunctions of operators on graphs and manifolds, have natural applications in the study of these areas. Specifically, the project addresses four fundamental questions that arise in the field: (1) How do you conservatively propagate the sampled labels to new points when the labels form a hierarchical clustering with possibly zero minimal separation between clusters? (2) Does the mechanism of kernel active learning generalize to graphs, where naive choice of points to sample becomes a combinatorial optimization problem? (3) Can we incorporate the structure of a neural network (or general parametric) classifier into the choice of labels queried and provably bound the generalization error for predictions on the rest of the data? (4) How can we tailor our framework to transfer learning and high-dimensional imaging?<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2042888","Inverse Problems with Internal Data","DMS","COMPUTATIONAL MATHEMATICS","07/01/2020","10/14/2020","John Schotland","CT","Yale University","Standard Grant","Yuliya Gorb","06/30/2023","$315,029.00","","john.schotland@yale.edu","105 WALL ST","NEW HAVEN","CT","065118917","2037854689","MPS","1271","9263","$0.00","Advances in imaging technologies such as computed tomography (CT), magnetic resonance imaging (MRI) and super resolution microscopy have transformed the practice of clinical medicine and basic biomedical research. Although the development of such technologies is well known to depend upon progress in physics and engineering, it is less well known that applied and computational mathematics has also played an essential role. This research project studies mathematical questions that arise in new medical biomedical imaging modalities in which new novel measurements play a key role. The research will study novel mathematical algorithms that will lead to improvements in optical imaging both with respect to resolution (visualizing structures at smaller scales) and computational speed. In particular, the project aims to devise robust and accurate image reconstruction algorithms that may lead to the detection and characterization of disease at much earlier stages than is currently possible. The principal investigator has research interests in applied mathematics and theoretical physics. He is also a physician. Graduate students will be trained to function in this interdisciplinary environment.<br/><br/>The objective of this project is to investigate inverse problems with internal data that arise in biomedical optical imaging. Two classes of problems will be considered. (i) Teh PI will develop mathematically-justified methods for imaging below the diffraction limit of resolution, also known as superresolution imaging. The proposed work includes both analysis of the inverse scattering problem with internal sources and the development of reconstruction algorithms. The algorithms will be tested and characterized using data from physically realistic numerical simulations. (ii) The PI will study inverse problems that arise in acousto-optic imaging. The research will focus on the regime of coherent multiple scattering which leads to considerable mathematical simplifications compared to incoherent imaging. In particular, the PI will develop reconstruction methods for recovering the absorption and scattering coefficients of the radiative transport equation from coherent acousto-optic measurements. Finally, the role of improvements in modeling of the acousto-optic effect on image reconstruction will be investigated.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011902","Collaborative Research:  Advancing Chemical Separation Simulations: Computational Algorithms and Optimization with Implicit Adsorption Isotherms","DMS","COMPUTATIONAL MATHEMATICS, EPSCoR Co-Funding","07/01/2020","06/17/2020","Eleanor Jenkins","SC","Clemson University","Standard Grant","Yuliya Gorb","06/30/2024","$159,996.00","","lea@clemson.edu","201 SIKES HALL","CLEMSON","SC","296340001","8646562424","MPS","1271, 9150","9150, 9263","$0.00","The unprecedented growth of biopharmaceuticals in recent years has led to better strategies for managing chronic diseases in humans including diabetes, immunodeficiencies, and cancer.  These therapeutics are often produced using purified proteins extracted from biological sera, which has created a need for technologies that produce these proteins efficiently, quickly, and in sufficient quantities to meet the growing demand. The global market for biologics is the fastest growing market in the pharmaceutical industry with global revenues near $163 billion; it is expected to grow annually by 10.9%.  FDA approval rates for protein therapeutics increased threefold from 2013 to 2017.  There are currently over 200 approved biotherapeutic drugs on the market with over 1500 in clinical trials and more in the pipeline.  The work in this project seeks to aid bio-manufacturers in expanding their production capacity in existing facilities by developing an accurate computational simulation framework for describing new methods of protein separation strategies.  The simulation will be used with optimization algorithms to help engineers improve the performance of adsorption membranes which in turn will reduce bottlenecks in manufacturing.<br/><br/>This project is motivated by the need for efficient new separation and purification processes for protein therapeutics. The emergence of biologics, for example drugs derived from biotechnology, as a leading way to manage chronic diseases in humans has created a pressing need for lower cost, faster biomanufacturing operations to make these products available and more affordable for growing patient populations. This research project will develop numerical approaches to solve the mathematical descriptions needed to simulate these processes. The mathematical descriptions will incorporate new, more complex ion-exchange relationships that define the solid phase adsorption as an implicit function of the liquid phase adsorption, a significant change from the standard explicit mathematical relationships.  The goals of this project are to develop, validate, analyze, and use computational tools to inform the design of new, rapid membrane chromatography purification processes for bio-manufacturing environments.  Specifically, the research team will work on four major research activities: (1) development and testing of a computational framework; (2) analysis of computational models for nonlinear and implicit models of chromatographic adsorption processes; (3) validation of the computational tools using experimental data; and (4) simulation-based optimization using the developed computational framework to understand the effects of the design parameters on desired outcomes. <br/><br/>This project is jointly funded by the Computational Mathematics program of DMS, and the Established Program to Stimulate Competitive Research (EPSCoR).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1952751","FRG: Collaborative Research: Randomized Algorithms for Solving Linear Systems","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","04/24/2020","Vladimir Rokhlin","CT","Yale University","Standard Grant","Yuliya Gorb","07/31/2023","$375,172.00","","rokhlin@cs.yale.edu","105 WALL ST","NEW HAVEN","CT","065118917","2037854689","MPS","1271","1616, 9263","$0.00","The objective of this project is to develop faster and more energy-efficient algorithms for one of the most fundamental tasks in computational science: solving large systems of coupled linear equations. Faster algorithms will both accelerate computations that can already be performed, and enable computations that are beyond the reach of existing methods. More energy efficient algorithms will help to reduce the power consumption of data centers, and to extend the battery life of mobile devices such as cell phones and tablet computers. The fundamental innovation behind our approach is to harness mathematical properties of large collections of random numbers to build new stochastic algorithms that dramatically outperform existing deterministic ones. In a nutshell, the idea is to use randomized sampling, and randomized averaging, to reduce the effective dimensionality of the problems to be processed. In addition the project provides research training opportunities for postdoctoral fellows and graduate students.<br/><br/>We seek to develop computationally efficient methods for solving linear systems of equations involving large numbers of variables, both in terms of asymptotic complexity, and in terms of practical speed at realistic problem sizes. Such systems of equations arise ubiquitously in science and engineering, and solving them is often the bottleneck in terms of time that decides how large of a problem can be handled. In particular, this is what limits how large of a data set can be analyzed, or how realistic a computational simulation can be when modelling some physical phenomenon. By developing faster and more efficient algorithms, we will accelerate computations that are done today, and enable many others that are outside the reach of currently existing methods.  The project is premised on the recent development of new randomized algorithms for solving linear algebraic problems. Such methods have proven to dramatically outperform classical deterministic methods for certain tasks such as computing low rank factorizations to matrices - the crucial computational step in e.g. Principal Component Analysis, the PageRank algorithm by Larry Page and Sergey Brin, numerical coarse graining when modeling complex multiscale systems, and many more. Randomized algorithms have also been used to build faster solvers for linear systems. However, while the theoretical results obtained at this point are extremely encouraging, it remains to develop randomized linear solvers that are decisively faster in practical applications. To achieve this goal, the project will support a research group that brings together four researchers with complementary skills in numerical linear algebra, random matrix theory, computational harmonic analysis, optimization, and high performance computing.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012216","RUI: Commutativity in Numerical Computation","DMS","COMPUTATIONAL MATHEMATICS","07/01/2020","06/11/2020","Brian Sutton","VA","Randolph-Macon College","Standard Grant","Yuliya Gorb","06/30/2022","$64,552.00","","bsutton@rmc.edu","204 HENRY ST","ASHLAND","VA","230051502","8047527268","MPS","1271","9229, 9263","$0.00","This project concerns consistency in scientific inferences. Multiple observations of the same phenomenon rarely produce identical results. Statistical noise may be the first complication that comes to mind, but there are plenty of other possible discrepancies as well: different antenna arrangements; different camera angles; different modalities, e.g., images and text; and more. Inferring the true underlying phenomenon requires sophisticated mathematics. This project focuses on matrix methods. Hiding within the simple numerical entries of a matrix are intricate patterns called eigenvectors that are connected to the harmonics of musical instruments. Even though different kinds of measurements may produce different numerical values, they may share the same eigenvectors when observing the same objects. One of the goals of the project is to pull consistency out of inconsistent data. In theory, measurements on the same object from different instruments should agree in certain ways, but because of statistical noise and other sources of error and uncertainty, each instrument provides an inexact view of the world, and the two instruments will not agree perfectly with each other. The goal is to bring the measurements into alignment using mathematics and therefore likely into better agreement with the true state of the universe. The project will be completed at a Primarily Undergraduate Institution, and introducing undergraduate students to research in STEM fields is a primary objective.<br/><br/>The mathematical focus of the project is simultaneous diagonalization of commuting Hermitian matrices. In theory, commuting Hermitian matrices share a common eigenvector matrix. However, numerically-computed eigenvectors may differ wildly in the presence of ill conditioning. A numerical method for simultaneous diagonalization seeks, either explicitly or implicitly, small perturbations of the input matrices that commute exactly. The project objectives include contributions to theory, method, and application. First, a reconsideration of ""near commutativity"" is planned, in which eigenvalues are fixed in place and attention shifts from the space of Hermitian matrices to the unitary group of eigenvector matrices. Second, the project will pursue new numerical methods for simultaneous diagonalization, motivated in part by relatively recent spectral divide-and-conquer methods. Third, the new approaches will be applied to applications such as independent component analysis and unsupervised machine learning with multimodal data.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011911","Collaborative Research:  Advancing Chemical Separation Simulations: Computational Algorithms and Optimization with Implicit Adsorption Isotherms","DMS","COMPUTATIONAL MATHEMATICS","07/01/2020","06/17/2020","Anastasia Wilson","GA","AUGUSTA UNIVERSITY RESEARCH INSTITUTE, INC.","Standard Grant","Yuliya Gorb","06/30/2024","$140,000.00","","anawilson@augusta.edu","1120 15TH ST STE CJ3301","AUGUSTA","GA","309120004","7067212592","MPS","1271","9263","$0.00","The unprecedented growth of biopharmaceuticals in recent years has led to better strategies for managing chronic diseases in humans including diabetes, immunodeficiencies, and cancer.  These therapeutics are often produced using purified proteins extracted from biological sera, which has created a need for technologies that produce these proteins efficiently, quickly, and in sufficient quantities to meet the growing demand. The global market for biologics is the fastest growing market in the pharmaceutical industry with global revenues near $163 billion; it is expected to grow annually by 10.9%.  FDA approval rates for protein therapeutics increased threefold from 2013 to 2017.  There are currently over 200 approved biotherapeutic drugs on the market with over 1500 in clinical trials and more in the pipeline.  The work in this project seeks to aid bio-manufacturers in expanding their production capacity in existing facilities by developing an accurate computational simulation framework for describing new methods of protein separation strategies.  The simulation will be used with optimization algorithms to help engineers improve the performance of adsorption membranes which in turn will reduce bottlenecks in manufacturing.<br/><br/>This project is motivated by the need for efficient new separation and purification processes for protein therapeutics. The emergence of biologics, i.e., drugs derived from biotechnology, as a leading way to manage chronic diseases in humans has created a pressing need for lower cost, faster biomanufacturing operations to make these products available and more affordable for growing patient populations. This research project aims to develop numerical approaches to solve the mathematical descriptions needed to simulate these processes. The mathematical descriptions will incorporate new, more complex ion-exchange relationships that define the solid phase adsorption as an implicit function of the liquid phase adsorption, a significant change from the standard explicit mathematical relationships.  The goals of this project are to develop, validate, analyze, and use computational tools to inform the design of new, rapid membrane chromatography purification processes for bio-manufacturing environments.  Specifically, the research team will work on four major research activities: (1) development and testing of a computational framework; (2) analysis of computational models for nonlinear and implicit models of chromatographic adsorption processes; (3) validation of the computational tools using experimental data; and (4) simulation-based optimization using the developed computational framework to understand the effects of the design parameters on desired outcomes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012250","Multifidelity Nonsmooth Optimization and Data-Driven Model Reduction for Robust Stabilization of Large-Scale Linear Dynamical Systems","DMS","COMPUTATIONAL MATHEMATICS","06/01/2020","07/05/2022","Benjamin Peherstorfer","NY","New York University","Continuing Grant","Yuliya Gorb","05/31/2024","$400,000.00","Michael Overton","pehersto@cims.nyu.edu","70 WASHINGTON SQ S","NEW YORK","NY","100121019","2129982121","MPS","1271","9263","$0.00","Autonomous systems play an increasingly important role in engineering applications and in society as a whole, from cars to airplanes to medical devices. Truly autonomous systems will have to be able to act and make decisions under uncertainty. The key component that decides what action an autonomous system takes is the controller of the system, which guarantees that the system always remains in stable and safe states. Thus, designing controllers to stabilize systems is an important problem in a wide range of applications that include virtual or physical systems acting in an environment. The computational methodologies that will be developed in this project aim towards a reliable stabilization of large-scale systems from data alone, even when only little data and data polluted with noise are available. These algorithms have the potential to have significant impact on critical issues such as efficiency, safety, and reliability of autonomous systems. The project will promote cross-disciplinary collaborations from machine learning to control theory to numerical analysis to scientific computing and will support education and diversity by creating novel courses and outreach activities that integrate underrepresented groups in the above disciplines.<br/><br/>Robust stabilization typically requires solving nonsmooth, nonconvex optimization problems that are computationally and mathematically challenging. Furthermore, in many situations, models of the systems of interest are unavailable. Rather, data are sampled from the systems and stabilization has to be achieved via learning from these data. This project develops and integrates new methods for nonsmooth optimization via gradient sampling and data-driven (nonintrusive) model reduction via the Loewner framework. The first contribution will be a multifidelity version of the gradient sampling algorithm for nonsmooth optimization that exploits low-cost, low-fidelity gradient approximations of a computationally expensive objective to accelerate the estimation of gradients. If successful, this multifidelity approximation has the potential to make tractable gradient sampling for large-scale optimization problems and at the same time maintain the rigorous convergence guarantees that gradient sampling is known for. The second contribution is to exploit the stability radius of robust controllers to reduce the number of data points (samples) that are required to learn reduced models for stabilizing systems. To that end, a new approach for learning reduced models from data is proposed that allows the learned models to divert from the real system dynamics by as much as can be compensated for by the robustness (stability radius) in favor of reducing the number of data points. If the project is successful, the developed methodologies will enable efficiently and rigorously stabilizing systems that are large-scale and from which few data points and/or high-noise data are available.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012382","Collaborative Research: On Some Fundamental Computational Issues in Simulating Interaction Models","DMS","COMPUTATIONAL MATHEMATICS","08/15/2020","07/05/2022","Min Hyung Cho","MA","University of Massachusetts Lowell","Continuing Grant","Yuliya Gorb","07/31/2024","$199,405.00","","minhyung_cho@uml.edu","600 SUFFOLK ST STE 212","LOWELL","MA","018543624","9789344170","MPS","1271","9263","$0.00","This project will investigate some fundamental computational issues for mathematical interaction models arising from scientific and engineering applications. Examples of these models include the electromagnetic and gravitational interactions in physics, interactions between molecules or cells in biology, and more general fractional differential equations and network models in material science, quantum theory, and social science. It is evident that modern interaction models are becoming more complex and demanding more accurate and efficient computational methods to handle the large scale interactions on high-performance computers. This project will (1) introduce novel representations of interaction models that are suitable for accelerated computation, (2) design efficient algorithms for interaction evaluations, (3) develop advanced open source tools, and (4) apply them to applications in nano-photonic devices, remote sensing, and medical imaging devices. This project will also train graduate students, including those from under-represented groups in STEM fields. This project will support one graduate per year for all 3 years on one campus and one graduate per year for years 2 and 3 on the other campus.<br/> <br/>In most interaction models, kernels usually depend on the spatial or temporal locations that may include the contributions from the interfaces between different materials. They may even depend on the given density functions at both the source and target locations. It is critical to find suitably compressed kernel representations for easier analysis and accelerated computation. This project will start from the optimal representations of the layered media Green?s functions for acoustic and electromagnetic waves that are spatially variant due to the contributions from the layer interfaces. These will be found through optimal integration contours and the corresponding discretized basis functions. The PIs will also generalize the partial-wave and plane-wave frame representations of the Laplace layer potentials to Yukawa, Helmholtz, and layered media potentials. The result will lead to better compressed density, kernel, and potential representations of more challenging non-local models in physics, biology, material science, social science, and image analysis. The PIs will develop effective numerical schemes for computing the compressible features and accelerating their algebraic operations by utilizing a multi-resolution framework to identify the interaction kernel features at different scales. The project also aims to create advanced open source software packages for the commonly used Laplace, Yukawa, and Helmholtz equations. Finally, through collaborations with application domain scientists and engineers, the numerical tools will be used in the design of optimal nano-photonic devices such as passive cooling devices, which may lead to a reduced carbon footprint and help socioeconomically disadvantaged communities lower their energy bills.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012207","Efficient Monte Carlo Methods for Nonequilibrium Statistical Physics","DMS","COMPUTATIONAL MATHEMATICS","08/15/2020","07/28/2020","Brian Van Koten","MA","University of Massachusetts Amherst","Standard Grant","Yuliya Gorb","07/31/2024","$200,000.00","","vankoten@math.umass.edu","COMMONWEALTH AVE","AMHERST","MA","01003","4135450698","MPS","1271","9263","$0.00","The PI will develop and analyze efficient computational methods for the simulation of nonequilibrium systems. This work will focus on fundamental problems from chemistry, such as the calculation of reaction rates. Potential applications include drug design, the analysis and interpretation of single-molecule experiments, and the development of a better understanding of the chemical reaction networks that regulate and sustain life. The PI will implement the methods and disseminate them in open-source software. This software will be designed for use by scientists, and will interface with existing computational chemistry software. The educational component of the proposed work will bring diverse groups of high school students onto the campus of the host institution for a summer course in data science emphasizing the use of computer simulations to understand problems such as the COVID-19 pandemic and racial bias in jury selection. This project will support one undergraduate student in year 1 and 1 graduate student each year of years 2 and 3.<br/><br/>Nonequilibrium can be used to describe two types of quantities: (a) averages over the steady-state distribution of an irreversible stochastic process and (b) dynamic properties of reversible or irreversible stochastic processes, for example mean first passage times. Typical nonequilibrium calculations involve rare events. For example, when calculating the folding rate of a protein, the time step used in simulation may be ten or more orders of magnitude below the time between folding events, rendering direct simulation impractical. However, classical rare event methods like importance sampling do not usually apply in the nonequilibrium case. The PI will analyze and improve a new class of rare event methods that adapt the principle of stratified survey sampling to nonequilibrium calculations. Building on ideas from stochastic approximation and the theory of multigrid methods, the PI will provide a convergence analysis, develop practical a posteriori error estimates, and identify classes of problems for which stratification is more efficient than competing methods.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011699","Deep Learning for Inverse Problems","DMS","COMPUTATIONAL MATHEMATICS","09/15/2020","06/26/2020","Lexing Ying","CA","Stanford University","Standard Grant","Yuliya Gorb","08/31/2024","$400,000.00","","lexing@math.stanford.edu","450 JANE STANFORD WAY","STANFORD","CA","943052004","6507232300","MPS","1271","075Z, 079Z, 9263","$0.00","In the past few years, deep learning has become the dominant approach for computer vision, image processing, speech recognition, and many other applications in machine learning and data science. This success is a synergy of several ingredients: (1) neural networks (NNs) as a flexible framework for representing high-dimensional functions and maps, (2) simple algorithms such as back-propagation and stochastic gradient descent for tuning the model parameters, (3) highly effective general software packages such as Tensorflow and Pytorch, and (4) unprecedented computing power. Despite the successes however, several key challenges remain: (1) the NN architectural design is still an art and it lacks basic mathematical principles in many cases, and (2) the NN training often requires an enormous amount of data, which is not available in many applications. Many computational problems in physical sciences also face the same challenges as those in data science: high-dimensionality, complicated or unspecified models, and large computational cost. Some well-known examples are many-body quantum systems, deterministic and stochastic control, molecular dynamics, uncertainty quantification, and inverse problems. It is natural to leverage the recent developments of NNs in the study of these problems. This project focuses on inverse problems, that is, recovering unknown problem parameters from observation data. It is a field of enormous importance, with applications in physics, chemistry, medicine, earth sciences, and defense. However, many inverse problems are known to be computationally challenging. This project will use deep learning as a means for solving these inverse problems more efficiently. The PI plans to develop a new applied linear algebra course with a machine learning focus and to organize workshops at the interface of deep learning and physical sciences. The project will train graduate and undergraduate students through the research and support one graduate student per year.<br/><br/>As a tool for representing high-dimensional maps, neural nets (NN) offer a flexible way for representing the full inverse maps and learn the data distribution prior via training. The rich mathematical and physical theories behind inverse problems provide theoretical guidance for designing compact yet effective NN architectures and hence it is possible to avoid the need for an enormous amount of data. In the theoretical part, this project plans to identify the commonly-used mathematical operators in many inverse problems and design novel NN modules for these operators. Two such examples are the pseudodifferential operators and the Fourier integral operators. Using analytical results from partial differential equations and numerical linear algebra, both types of operators can be represented compactly and accurately as NN modules. In the application part, this project considers five inverse problems: electric impedance tomography, optical tomography, inverse acoustic/electromagnetic scattering, seismic imaging, and travel-time tomography. The NN for the inverse map is then assembled using the modules from the theory part, along with existing primitives such as convolutional NN. The whole NN is then trained end-to-end with the training data. The research results such as publications and software will be made available in public domain. The project will also lead to broader impacts in several areas. First, this project advocates for a more principled approach for NN architecture design based on mathematical theories, sparsity considerations, and invariance/equivariance principles. Second, the project covers inverse problems from five different topics. By working with scientists and engineers, the PI plans to apply the technologies developed to practical applications.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1955925","Topology for Data Science: An Introductory Workshop for Undergraduates","DMS","INFRASTRUCTURE PROGRAM, TOPOLOGY, STATISTICS, COMPUTATIONAL MATHEMATICS, Algorithmic Foundations, CDS&E-MSS","01/15/2020","05/19/2023","Stacey Hancock","MT","Montana State University","Standard Grant","Joanna Kania-Bartoszynska","06/30/2023","$30,474.00","David Millman","stacey.hancock@montana.edu","216 MONTANA HALL","BOZEMAN","MT","59717","4069942381","MPS","1260, 1267, 1269, 1271, 7796, 8069","7556, 7926, 7929, 9150","$0.00","Topology for Data Science (T4DS) is a day-long workshop designed to introduce undergraduate students to data science and topology, to be held on March 25, 2020, in Bozeman, MT. The workshop is scheduled to coincide with the National Conference on Undergraduate Research (NCUR)---a gathering of nearly 4,000 talented undergraduate students from across the world---hosted by Montana State University, March 26-28. This award will support the development and dissemination of workshop materials and will fund travel and participation of 28 undergraduates. An additional 22 students from local communities or those already planning to attend NCUR will also have the opportunity to participate. For a day, the participants will be immersed in the fast-growing area of data science, through the lens of topology. This workshop is the first of its kind: T4DS engages students in a hands-on, collaborative experience, requiring only discrete mathematics and a desire to try something new as prerequisites.<br/><br/>T4DS will start with an overview of how to ""think with data"" through data exploration and visualization, continuing with a brief journey into the field of topology and how to use topological descriptors to summarize data. In the afternoon, students will investigate how to cluster data based on those topological descriptors, and will apply what they've learned to a new data set. The day will conclude with a reception, where a panel of five faculty members representing topology and data science will discuss their experiences with including undergraduates in research and potential career opportunities in data science. The content of T4DS will cross the disciplinary lines of computer science, statistics, and mathematics. It will blend topological data analysis, data mining, and broader data science content, delivered using an active-learning pedagogy. Most of the participants will not have any experience in topology, yet they will cluster data using topological descriptors, which will give them a glimpse into the topological data cycle. Moreover, this workshop will lay the foundation for developing materials on other aspects of data science, which will allow the organizers to broaden the offering of similar tutorials throughout Montana and surrounding states, including tribal colleges and geographically remote rural areas. After the workshop, tutorials will be distributed through Github and the Carpentries Lab---a repository of high-quality, community-reviewed, discoverable lessons--- reaching a large, diverse, international community. The conference website and workshop application can be found at http://www.montana.edu/datascience/t4ds/.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012585","Design and Analysis of Highly Efficient Algorithms for Complex Nonlinear Systems","DMS","COMPUTATIONAL MATHEMATICS","08/15/2020","05/02/2023","Jie Shen","IN","Purdue University","Continuing Grant","Yuliya Gorb","12/31/2022","$253,487.00","","shen@math.purdue.edu","2550 NORTHWESTERN AVE STE 1900","WEST LAFAYETTE","IN","479061332","7654941055","MPS","1271","9263","$0.00","This project focuses on the development and analysis of innovative, structure preserving algorithms for complex nonlinear systems in science and engineering applications. This project will not only lead to efficient numerical algorithms for a large class of complex nonlinear systems of current interests, but also contribute through numerical simulation to a better understanding of some fundamental issues in  materials science, fluid mechanics and other related fields. This project will also provide  opportunities for the involved  students to learn critical skills of computational and applied mathematics and to develop state-of-the-art numerical algorithms for science and engineering applications. This project will support one graduate student per year.<br/><br/>Complex nonlinear systems that possess dissipative or conservation properties are ubiquitous in modeling of real-world phenomena. It is a major challenge to construct efficient and accurate numerical schemes that can preserve important dissipative or conservation properties, and in certain cases, positivity of physical variables. This project will overcome these challenges by extending the flexible and robust scalar auxiliary variable or SAV approach, which has proven to be highly effective for gradient flows. In particular, the SAV approach will be extended to deal with additional difficulties such as those in (i) systems with physical constraints such as mass and/or surface area conservations; (ii) highly anisotropic systems and systems with nonlinear mobilities; (iii) systems with positivity preserving or maximum principles; (iv) systems coupling gradient flows with other conservation laws, and (v) optimizations. The proposed methodology will lead to numerical predictive tools that extend the applicability of mathematical and experimental analysis, and contribute to better understanding of complex physical systems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012330","Simulating Large-Scale Morphogenesis in Planar Tissues","DMS","COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY, MSPA-INTERDISCIPLINARY","06/15/2020","06/04/2020","Min Wu","MA","Worcester Polytechnic Institute","Standard Grant","Yuliya Gorb","05/31/2024","$200,000.00","","Mwu2@wpi.edu","100 INSTITUTE RD","WORCESTER","MA","016092247","5088315000","MPS","1271, 7334, 7454","068Z, 9263","$0.00","Cutting-edge developments in biotechnology and medicine involve reconstructing large-scale tissues and organs. This work can be limited by lack of knowledge in tissue morphogenesis, the process by which living tissues develop their size-and-shape characteristics. Though live-imaging techniques have enabled the observation of morphogenetic processes, progress in fundamental understanding has been slow. This project aims to improve tools for modeling a wide range of living tissues that are relatively planar and have been extensively studied experimentally. The project will develop methods for numerical simulation of morphogenesis processes and attempt to reproduce the observed large-scale morphogenesis structures in planar tissues. The project provides graduate student training through involvement in the research.<br/><br/>This project concerns numerical simulation of large-scale continuum models for tissue morphogenesis that involve free boundaries, bulk-interface coupling, and highly nonlinear interactions. The work centers on a new mathematical model in which the field variables are nonlinearly coupled via reaction-convection equations and non-standard spatial partial differential equations. The project will develop semi-implicit and fully implicit time-stepping methods to avoid a potential time-step restriction for explicit time-stepping methods. Due to the high nonlinearity of the system, the boundary configuration must be updated together with the velocity field as well as other field variables. For this purpose, a novel interface-tracking method based on reference-map techniques will be investigated. Linear analysis close to trivial solutions will be conducted to assist the design of fast-converging iterative methods for solving the nonlinear system derived from the implicit time-stepping discretization of the original model. Simulations to understand in vitro micro-tissue and in vivo epithelial-tissue morphogenesis from live-imaging data will be carried out.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1949953","Tenth Annual Graduate Student Mini-Conference in Computational Mathematics","DMS","COMPUTATIONAL MATHEMATICS","01/01/2020","07/22/2022","Hans-Werner van Wyk","AL","Auburn University","Standard Grant","Yuliya Gorb","12/31/2022","$10,650.00","Yanzhao Cao, Junshan Lin, Thi Thao Phuong Hoang","hzv0008@auburn.edu","321-A INGRAM HALL","AUBURN","AL","368490001","3348444438","MPS","1271","7556, 9150, 9263","$0.00","This award supports the participation of graduate students in the Tenth Annual Graduate Student Mini-Conference in Computational Mathematics, held at Auburn University on April 25-27, 2020. This two-day conference centers on recent advances in the theory and numerical approximation of partial differential equation models with applications in the areas such as materials science, optics, turbulence, hydrology, biomedical flows, and climate systems. Established in 2009, the conference aims to provide graduate students with a timely opportunity to present their research, exchange ideas, and build their collaborative networks in a setting that is supportive yet similar to that of a larger conference. The conference organizers are committed to supporting the participation of graduate students, early career researchers, and researchers from underrepresented groups.<br/><br/>Many important applications in science and engineering are modeled by partial differential equations, and there has been an increasing need for accurate and robust numerical methods for such models. Conference topics include robust and efficient numerical simulations, reduced order models, optimization, uncertainty quantification, and data assimilation. The conference organizers estimate an attendance of around 45 participants, including two plenary speakers, thirty graduate students, and their research advisors. The student speakers will be selected from attendees based on their curriculum vitae and recommendation by their advisors about their research achievements.<br/>The conference website is http://www.auburn.edu/cosam/departments/math/compconference/.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012764","Collaborative Research: Next-Generation Cutting Planes: Compression, Automation, Diversity, and Computer-Assisted Mathematics","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","07/28/2020","Matthias Koeppe","CA","University of California-Davis","Standard Grant","Yuliya Gorb","07/31/2024","$180,232.00","","mkoeppe@ucdavis.edu","1850 RESEARCH PARK DR, STE 300","DAVIS","CA","956186153","5307547700","MPS","1271","9263","$0.00","Mixed-integer optimization is a powerful mathematical decision-making technology related to operations research, data sciences, and artificial intelligence. This project considers applications in which high-stake decisions need to be made quickly and account for unknown future event or risk. In such applications, simulation methods and machine learning cannot give sufficient confidence for protecting against the possibility of catastrophic failures. Instead, one requires multi-parametric optimization to precompute responses, certify their safety, and guarantee the level of performance. In this direction, the investigators will study a key component of optimization algorithms called general purpose cutting planes in a novel multi-parametric setting suitable for process control in chemical engineering and optimizing compilers for high-performance computing platforms, aiming for major theoretical and computational advances that will generalize to many important applications. Broader impacts include the training of undergraduate and graduate students in computational mathematics and research skills, as well as development of high-quality open-source research software, and of further connections between several research communities within mathematics, computer science, and engineering.<br/><br/>Mixed-integer (linear and nonlinear) optimization is concerned with finite-dimensional, non-convex optimization problems that include discrete decision variables such as those that model ""yes/no"" decisions. Systems of this type arise in all areas of industry and the sciences. Algorithms for mixed-integer optimization build upon convex optimization technology by relaxation, approximation, convexification, and decomposition techniques. Increases in system size in the presence of Big Data technologies creates new challenges that need to be addressed by a next generation of algorithms. This project studies convexification, specifically, cutting planes in multi-row and multi-cut cutting plane systems that are effective and efficient from the aspects of compression, automation, and diversity. In particular, spaces of extreme continuous piecewise linear cut-generating functions with prescribed features will be computed; these consist of semi-algebraic cells, parametrizing sub-additive piecewise linear functions, glued at their boundaries. The computation of each cell requires the proof of a theorem, and automated theorem proving technology, based on metaprogramming and semi-algebraic computations, will be developed. The investigators will apply the new cutting plane techniques to two target applications for which guaranteed correctness and performance is mission-critical: model predictive control in chemical process engineering and optimizing compilers for high-performance computing platforms. The multi-parametric optimization problems in both applications will benefit from the parametric nature of the new cutting planes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011843","Collaborative Research: Novel Microlocal-Analysis and Domain-Decomposition Based Fast Algorithms for Elastic Wave Modeling and Inversion in Variable Media","DMS","COMPUTATIONAL MATHEMATICS","08/01/2020","07/27/2020","Yassine Boubendir","NJ","New Jersey Institute of Technology","Standard Grant","Yuliya Gorb","03/31/2024","$99,877.00","","boubendi@njit.edu","323 DR MARTIN LUTHER KING JR BLV","NEWARK","NJ","071021824","9735965275","MPS","1271","9263","$0.00","Wave propagation is an important phenomenon in many science and engineering disciplines. Computational wave propagation has become a fundamental, vigorously growing technology in diverse disciplines, ranging from radar, sonar, seismic imaging, medical imaging, submarine detection, stealth technology, remote sensing and electronics to microscopy and nanotechnology. These applications are important in particular for the petroleum industry, medical imaging, and material sciences. One of the most challenging problems in computational wave propagation is how to carry out large-scale high frequency wave propagation efficiently and accurately. The investigators in this project will develop novel, fast algorithms for high frequency elastic wave propagation and inversion. In particular, they will focus on techniques including microlocal-analysis and domain-decomposition based fast Huygens sweeping methods and fast multiscale Gaussian beam methods to tackle this long-standing challenge.  Graduate students will be involved and receive interdisciplinary training. <br/><br/>The project is motivated by science and engineering applications, and it will foster innovations in several theoretical and computational aspects. The goal is to develop efficient and accurate Hadamard-Babich expansion based fast Huygens sweeping methods and multiscale Gaussian wavepacket transform based fast multiscale Gaussian beams for elastic wave propagation in variable media in the high frequency regime and in the presence of caustics. Several avenues of research will be pusrued. First, the proposed new methods will address the challenges in large-scale high-frequency elastic wave modeling and inversion in the presence of caustics. Second, advances will be made in developing novel Hadamard-Babich expansion, domain decomposition, and butterfly-algorithm based fast Huygens sweeping methods for partial differential equation-based Eulerian geometrical optics and computational wave propagation. Both the Hadamard-Babich expansion and domain-decomposition based fast Huygens sweeping method and the fast multiscale Gaussian beam method are capable of producing uniform asymptotic solutions beyond caustics for wave propagation in the high-frequency regime. Third, the new methods will provide efficient tools not used before for many elastic wave-related applications in inhomogeneous media, such as seismic imaging and inversion, and medical imaging and inversion.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012453","Scalable Computational Methods for Large-Scale Stochastic Optimization under High-Dimensional Uncertainty","DMS","COMPUTATIONAL MATHEMATICS","09/01/2020","09/09/2022","Peng Chen","TX","University of Texas at Austin","Continuing Grant","Yuliya Gorb","10/31/2022","$310,000.00","Omar Ghattas","pchen402@gatech.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271","9263","$0.00","Large-scale simulation in computational science and engineering is often carried out not only to obtain insight about a system, but also as a basis for decision-making. When the decision variables represent the design or control of an engineered or natural system, and the system is governed by partial differential equations (PDEs) with uncertain input due to lack of knowledge or intrinsic variability, the task of determining the optimal design or control leads to a PDE-constrained stochastic optimization problem. Such problems abound across all areas of science and engineering. Examples include optimal control of subsurface flows, plasma fusion reactors, and chemical and materials processes; optimal structural design of aerospace, automotive, and civil infrastructure systems; and shape, layout, or topology optimization of biomedical, electronic, and nano-structured devices. There are several critical challenges in solving such problems including high dimensionality stemming from uncertainty and/or optimization variable spaces, and the need to solve large-scale PDEs with numerous  samples of the uncertain parameters. This project will develop, analyze, and implement scalable computational methods to make tractable the solution of large-scale PDE-constrained stochastic optimization problems under high-dimensional uncertainty. These methods will be applied to subsurface flow problems with societal impact; software will be developed and disseminated widely in open source form. Graduate students will be involved and will receive interdisciplinary training. <br/><br/>This project exploits the intrinsic structure of the stochastic optimization problems--in particular the intrinsic low dimensionality, smoothness, and geometry of the random parameter-to-objective map. Specifically, the components of the research include: (1) Analysis of the rank or spectrum decay of the Hessian of this map to prove intrinsic low-dimensionality for several classical stochastic PDE-constrained optimization problems. (2) Extension of local quadratic approximation-based stochastic optimization to that based on approximation of the Hessian as a translation invariant operator, higher order Taylor approximation, and multi-point Taylor approximation with mixture models. (3) Application to a specific large-scale and challenging problem of optimal flow control in a subsurface porous medium with a random permeability field. The methods developed in this project will apply to a wide class of PDE-constrained stochastic optimization problems. To make the methods accessible to broader communities and allow stochastic optimization specialists to prototype new algorithms and quickly run experiments, a Python library, SOUPy (Stochastic Optimization under high-dimensional Uncertainty in Python), will be implemented and released. Users will be able to rapidly prototype new PDE models and objective functions, as well as quickly implement new algorithms, conduct numerical experiments, and solve challenging problems in new domains in SOUPy.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012410","Novel Decomposition Techniques Enabling Scalable Computational Frameworks for Large-Scale Nonlinear Optimization Problems","DMS","COMPUTATIONAL MATHEMATICS","09/01/2020","07/22/2020","Andreas Waechter","IL","Northwestern University","Standard Grant","Yuliya Gorb","08/31/2023","$180,000.00","","waechter@iems.northwestern.edu","633 CLARK STREET","EVANSTON","IL","602080001","3125037955","MPS","1271","9263","$0.00","This research project aims to develop improved numerical optimization algorithms. The research considers situations in which decisions must be made in the absence of perfect information, either due to the lack of reliable data or due to unforeseen events. Most state-of-the-art methods tackle optimization in this setting by considering many potential scenarios, which can result in formulations that are too large to be solved directly. The methodology in this project is fundamentally different and aims to create new decomposition frameworks for large-scale nonlinear continuous optimization. The algorithms under development will be tested on realistic questions in electrical power systems. For example, the decomposition algorithm will be able to break down the optimization of a large-scale power grid into computations for the high-voltage transmission grid and computations related to the many distribution networks that are attached to the transmission grid. This project provides research training opportunities for a graduate student.<br/><br/>The project aims to create novel decomposition frameworks that lead to new practical numerical algorithms able to tackle significantly larger instances of certain structured problems in nonlinear nonconvex optimization than currently possible. This will result in computational tools for the solution of stochastic optimization problems when sample average approximation gives rise to very large deterministic instances and will significantly expand the array of tractable stochastic two-stage and bi-level optimization problems. The key innovation is a smoothing technique that overcomes the predicament that optimal subsystem solutions need not be differentiable functions of the overarching system variables. In all aspects of the research, theory will be developed that characterizes the properties of problem reformulations and the convergence guarantees for new algorithms. One expected outcome of this project is high-quality open-source software for public use, capable of exploiting parallel computing resources.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012271","Collaborative Research: Euler-Based Time-Stepping with Optimal Stability and Accuracy for Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","08/15/2020","07/29/2020","Benjamin Seibold","PA","Temple University","Standard Grant","Yuliya Gorb","07/31/2023","$99,999.00","","seibold@temple.edu","1801 N BROAD ST","PHILADELPHIA","PA","191226003","2157077547","MPS","1271","9263","$0.00","Principled simulations of many real-world problems (such as fluid flow, geophysical phenomena, and quantum mechanics) require an evolution in time with high accuracy, yet in a structurally simple and robust fashion. This project develops novel time integration methods for complex multi-physics problems, while not incurring fundamental problems that reduce the accuracy or stability of many existing methods. The developed methods are founded in new mathematical theories, and are used to devise more accurate and robust simulations of shallow water flows with dispersive effects, which are important in the understanding of tsunamis, storm surge, and coastal flooding.  This project will support one graduate student for two years at NJIT and one graduate student per year at the second institution, Temple.<br/><br/>This project develops methods for the time integration of differential equations that are implemented as sequences of generalized Euler steps, including: multistage diagonally implicit Runge-Kutta (DIRK) and multistep implicit-explicit (IMEX) methods. Such methods are significant as they reduce the implementation burden on a practitioner to the solution of a fully- or semi-implicit Euler step for their initial-boundary-value problem. The key research contributions are: (A) a full algebraic theory of weak stage order, and its use to design optimized high-order DIRK methods devoid of order reduction; (B) a stability theory for IMEX methods applied to differential algebraic equations, and the co-design of IMEX splittings and scheme coefficients to overcome stability limitations prevalent in existing methods. Applications include new efficient time-stepping for the dispersive shallow water equations and related differential algebraic equations. The collaborative mentoring of graduate students at two campuses is an important component of this project.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2044349","Optimization Techniques for Geometrizing Real-World Data","DMS","COMPUTATIONAL MATHEMATICS","06/01/2020","08/08/2020","Soledad Villar","MD","Johns Hopkins University","Standard Grant","Yuliya Gorb","07/31/2021","$28,201.00","","svillar3@jhu.edu","3400 N CHARLES ST","BALTIMORE","MD","212182608","4439971898","MPS","1271","9263","$0.00","Data is a common denominator to scientific fields, governments, and private enterprises. Being able to exploit data to find patterns has produced scientific breakthroughs and shifted business paradigms in the last several decades. This project focuses on mathematical and algorithmic techniques for specific data science problems, tailored to currently relevant domain problems, technologies, and volumes of data. The theoretical problems we consider are (i) clustering (which essentially consists on grouping data according to similarity in an unsupervised way), (ii) dimensionality reduction (reducing the volume of the data while preserving its relevant features), and (iii) quadratic assignment (finding correspondences between different datasets). The main underlying application we consider in this project is computational biology, in particular the processing of single-cell sequencing data. The technology for single-cell sequencing has been very recently developed and it is improving quickly, producing new datasets, problems and challenges that are interesting from a mathematical point of view and have potentially enormous impact. The project will have mathematicians working closely to computational biologists with the goal of identifying data science problems occurring in the scientific domain and to develop appropriate algorithms and mathematical tools.<br/><br/>Given single-cell genetic expression data indicating how many times each gene is expressed in each cell, one objective is to select a few genes that can be used to identify different classes of cells. This problem is known in the computational biology literature as genetic marker selection. In a first approach we assume the class of each cell is known and the problem can be posed as supervised dimensionality reduction. We model it as a projection factor recovery problem, and we approach it using optimization tools such as semidefinite and linear programming. The objective is two-fold, we aim to study mathematical properties of the model we devise, and to develop an efficient tool to be used by practitioners. A second stage of the project is to make the problem unsupervised, therefore clustering will be a fundamental step. We will study stability properties of clustering methods and we will provide an efficient algorithm to evaluate the quality of clusters, based on statistical and optimization techniques. The potential use of this tool is general to data science and not just gene expression datasets. Finally, a third objective is to align datasets coming from different experiments. This problem is ubiquitous in data science, with graph matching and shape matching as some particular cases. In the context of computational biology the alignment problem is known as batch correction and it can be modeled with optimal transport or as a quadratic assignment problem. We will develop alignment algorithms and study their convergence and recovery properties under different data models.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2136075","Novel Virtual Element Methods with Applications in Interface Problems","DMS","COMPUTATIONAL MATHEMATICS","11/15/2020","01/12/2022","Shuhao Cao","MO","Washington University","Standard Grant","Yuliya Gorb","06/30/2023","$72,279.00","","scao@umkc.edu","ONE BROOKINGS DR","SAINT LOUIS","MO","631304862","3147474134","MPS","1271","9263","$0.00","Interface problems arise from many important complex multiphysics and biological systems, such as those involving the evolutions of multi-fluid/material interfaces, tumor growth, or stem cell deformation. Computer-aided simulation is a cost-friendly tool for the studies of these challenging interface problems. To approximate the governing mathematical equations of these systems, Virtual element method (VEM) is an emerging powerful tool in the scientific computing community. The objective of this research project is to develop both theoretical and practical aspects of various VEMs. Being able to reliably answer the question ""can we trust our simulation results?"" justifies the use of VEMs in simulating these complex systems. Meanwhile, this project strives to provide the public with a state-of-the-art VEM computer program that saves valuable computing resources. In addition, this research project creates opportunities to pass the torch on to graduate students to become the next generation computational mathematicians.<br/><br/>Solving elliptic partial differential equations with high-contrast diffusion coefficients play a central role in the modeling these complex systems. This project shall develop an in-depth robust a priori error analysis of VEM on elliptic interface problems. Different from the existing VEM analysis, this project devises a new novel paradigm to study the error analysis for the interface VEM, and further clarifies the dependence of the VEM convergence on the polytopal mesh geometries, justifying the VEM's applicability on interface-fitted mesh which may become extremely irregular or degenerate near the interfaces. Meanwhile, this project learns from the novelty of VEM framework to improve the analyses of traditional approaches for interface problems. The VEM's meta-formulation for elliptic problems enables us to construct immersed finite element spaces naturally in higher order and/or in 3-D.  Higher order interface VEMs, the a posteriori error estimation, and the adaptive polytopal mesh refinement are to be studied to render VEM more efficient and effective. This integrated study enables us to attack the challenging 3-D interface problems, which, in turn, broadens the scope in terms of both theory and tools for the whole numerical partial differential equation community. Last but not least, a portable and highly-vectorized VEM software library shall be made publicly available, including the semi-structured interface-fitted mesh generation, vectorized assembling, polytopal adaptivity, and fast multigrid solvers. The portability of the computer code enables the researchers to incorporate the VEM into existing software libraries dealing with interface problems, thus facilitating the interdisciplinary research in simulating those complex systems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2016095","Collaborative Research: Expanding the Reach of Industrial Career Training for Graduate Students","DMS","INFRASTRUCTURE PROGRAM, COMPUTATIONAL MATHEMATICS","07/01/2020","06/20/2020","David Edwards","DE","University of Delaware","Standard Grant","Swatee Naik","06/30/2022","$26,601.00","Louis Rossi","dedwards@udel.edu","220 HULLIHEN HALL","NEWARK","DE","197160099","3028312136","MPS","1260, 1271","7556, 9150, 9263","$0.00","The 16th annual Graduate Student Mathematical Modeling Camp (GSMMC) will be held June 9?12, 2021 at the University of Delaware, followed the week after by the 36th annual Mathematical Problems in Industry (MPI) workshop, June 14?18, 2021 at the University of Vermont.  GSMMC is a mentored, problem-solving workshop, at which small teams of Ph.D. students from across the U.S. are guided through successful mathematical modeling of real-world problems presented by faculty or experienced postdoctoral mentors. Under careful mentoring, student participants build their modeling, teamwork and presentation skills during the week: via the teamwork on modeling and simulating the problems; through the final team presentations made at the end of the week; and in writing the final reports that are produced. Training activities also include numerical simulations and the preparation of a final report outlining their discoveries.  These skills are put to use and consolidated the following week at MPI, where industrial participants present immediate modeling challenges facing their industries, on which academic participants (faculty, postdocs, and the Ph.D. students from GSMMC) work. Significant progress on the industrial problems is usually made, and Ph.D. student participants take the lead in presenting the findings to the industrial participants from industry in final presentations at the week's end. In addition to building their skillsets and resumes, student participants are exposed to valuable networking interactions with a range of industrial participants.<br/><br/>The GSMMC-MPI program is designed to integrate interdisciplinary research and education for graduate students. The GSMMC is focused on graduate student education and training: its chief intellectual merit lies in the development and analysis, by students, of the mathematical models for the problems presented. Problems are highly interdisciplinary, presenting students with a novel intellectual challenge. With the preparatory training provided by the GSMMC, students are ready for the more open-ended, research-level environment of MPI. The questions posed at MPI challenge participants to design new ways of modeling and analyzing industrial mathematics problems in emerging areas of technology. Mathematical modeling, analytical techniques, numerical simulations, and data analysis must all be used effectively. The collaborative approach to problem solving, which brings together mathematicians ranging from graduate students to experienced faculty, is central to the structure of MPI and provides significant additional training to graduate students, while promoting effective scientific communication. Full details for the Camp may be found at https://www.mathsci.udel.edu/events/conferences/gsmmc-2021, and for MPI at https://mpi2021.w3.uvm.edu/.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012487","Collaborative Research: Nonoscillatory Phase Methods for the Variable Coefficient Helmholtz Equation in the High-Frequency Regime","DMS","COMPUTATIONAL MATHEMATICS","09/01/2020","08/02/2022","James Bremer","CA","University of California-Davis","Standard Grant","Yuliya Gorb","06/30/2022","$28,340.00","","bremer@math.ucdavis.edu","1850 RESEARCH PARK DR, STE 300","DAVIS","CA","956186153","5307547700","MPS","1271","9263","$0.00","The importance of the numerical simulation of physical phenomena by computers cannot be overstated. Such computations have become essential tools both in scientific research and in industrial research and development. This project concerns the numerical simulation of the scattering of waves. Such simulations have applications to sonar and radar, as well as in medical imaging, geophysics, and many other applications. Wave phenomena become more complicated to model as the frequency of the wave increases, and our current ability to accurately model high-frequency waves is quite limited. This project seeks to develop new methods for modeling high-frequency waves efficiently and to high accuracy. The project provides research training opportunities for graduate students. <br/><br/>The numerical simulation of the scattering of waves from inhomogeneous media has important applications in radar and sonar, medical imaging, geophysics, and a host of other scientific applications. In many cases of interest, such simulations can be performed by solving the variable coefficient Helmholtz equation. The solutions of this equation are oscillatory, and the difficulty of calculating them using conventional approaches grows quickly with the frequency of the oscillations. Recently, one of the investigators developed a new class of solvers for the variable coefficient Helmholtz equation that achieve extremely high accuracy and have run times that scale much more slowly with increasing frequency than conventional solvers. They operate by solving the nonlinear Riccati equation that is satisfied by the logarithms of solutions of the Helmholtz equation. Currently, these solvers only apply in special cases. This project aims to extend them to the general case to develop a method for the variable coefficient Helmholtz equation that is significantly faster than current techniques.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012510","DMS-EPSRC Collaborative Research: Sharp Large Deviation Estimates of Fluctuations in Stochastic Hydrodynamic Systems","DMS","COMPUTATIONAL MATHEMATICS","08/15/2020","08/12/2020","Eric Vanden-Eijnden","NY","New York University","Standard Grant","Stacey Levine","07/31/2023","$228,545.00","","eve2@cims.nyu.edu","70 WASHINGTON SQ S","NEW YORK","NY","100121019","2129982121","MPS","1271","9263","$0.00","Extreme events can be highly impactful. They are typically rare, which is fortunate if their consequences are negative on society, but also makes them difficult to predict. The focus of this project is to develop computational tools that can be applied to gain understanding of how extreme events occur in complex stochastic systems. Examples are models for the forecasting of extreme weather-related events like tropical storms and flooding as well as the spread of pollutants in case of ocean oil spills. These tools will enable researchers to ask questions beyond what is currently possible. This will lead to transformative improvement of current predictive models, which is essential for efficient management of natural and man-made disasters. Further applications include the characterization of extreme events in stochastic models that behave similar to fluids, for example in the context of epidemics, traffic, and star formation. This collaborative project will support one graduate student per year at NYU.<br/><br/>Rare events are difficult to observe in controlled (numerical or physical) experiments, even for low-dimensional systems. The difficulty increases with the number of degrees of freedom, which makes high-dimensional systems even harder to analyze ? fluids described by stochastic hydrodynamic models are a particular example of interest. As a result the questions that researchers can ask in order to gain insights about extreme events in these systems are often limited. The goal of this project is to analyze rare but important events in complex systems by developing new mathematical and computational tools to establish their most likely way of occurrence and calculate sharp asymptotic estimates (with prefactor included) of their probability and recurrence time. The aim is to create a toolbox applicable to a wide range of models with a large number of degrees of freedom described by stochastic partial differential equations (PDEs), like advection-diffusion equations and Navier-Stokes equations, and transferable across disciplinary borders. These tools will be applied to stochastic hydrodynamic systems in order to gain deeper insights of classical turbulence. In addition, the efficiency of this novel approach will be demonstrated in the context of real-world applications, in particular the advection of pollutants and the capsizing of ships.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2012658","Polynomial Optimization and Finite Element Methods for Nonlinear Mechanics","DMS","COMPUTATIONAL MATHEMATICS","06/15/2020","08/25/2022","Federico Fuentes","NY","Cornell University","Standard Grant","Stacey Levine","08/31/2021","$61,947.00","","federico.fuentes@cornell.edu","341 PINE TREE RD","ITHACA","NY","148502820","6072555014","MPS","1271","9263","$0.00","The purpose of this interdisciplinary project is to devise a new generation of computational methods based on the combination of finite element methods and polynomial optimization to analyze problems in nonlinear mechanics, which often exhibit a complex evolution over time and space. Some examples include fluid flows, convection, and nonlinear elasticity. Computing these systems? equilibria and producing a detailed diagnosis of their stability can be of notorious difficulty, but are of profound importance for elucidating the underlying physical mechanisms involved. These novel algorithms and rigorous analysis will allow the improvement of longstanding results in fluid mechanics related to the stability and dynamics of canonical shear flows. The results may lead to a deeper knowledge of turbulent losses in fluid systems, which could play a critical role in engineering problems within the transport and energy sectors.<br/><br/>The project has two parts. The first part focuses on rigorously establishing the nonlinear stability of fluid flows with the goal of sharpening the lower bounds on the global stability threshold of shear flows (the largest Reynolds number under which any initial velocity field eventually converges to the laminar flow), such as plane Couette and plane Poiseuille flows. This will be achieved by carefully constructing Lyapunov functionals with the computer using polynomial sum-of-squares constraints and a special framework to pose the incompressible Navier-Stokes equations. The second part proposes the first connection between finite element analysis and sparse polynomial optimization. The combination has some nice theoretical implications, since finite element error analysis is deeply rooted in functional analysis and approximation theory, while the nascent field of polynomial optimization is closely tied to results in real algebraic geometry. From the practical standpoint, the computational methods developed will form a general framework to directly solve nonlinear partial differential equations (PDEs) in general domains while concurrently globally optimizing relevant quantities of interest (e.g. energy, heat transport, etc.). The resulting numerical methods provide a systematic pathway to compute exact coherent states of physical systems without using homotopic continuation. This is essential in problems where non-unique solutions do not bifurcate from a trivial state, like in plane Couette and pipe flows.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2023264","Midwest Numerical Analysis Day 2020","DMS","COMPUTATIONAL MATHEMATICS","04/01/2020","03/26/2020","Xiaoming He","MO","Missouri University of Science and Technology","Standard Grant","Yuliya Gorb","03/31/2022","$5,000.00","Jue Yan","hex@mst.edu","300 W 12TH ST","ROLLA","MO","654096506","5733414134","MPS","1271","7556, 9263","$0.00","This award supports participation of early-career researchers in the annual conference ""The Midwest Numerical Analysis Day"" held at the campus of Missouri University of Science and Technology, Rolla, MO, on September 25-26, 2020. The Midwest Numerical Analysis Day has provided a forum since the 1990s for computational mathematicians in the Midwest area to share their research on numerical methods and their analysis. Since many engineers will participate in the Midwest Numerical Analysis Day 2020, this conference will provide an important platform for computational scientists and engineers to communicate with each other on recent development, analysis, and applications of various numerical methods, and find common interests for future collaborations. The Midwest Numerical Analysis Day has also served as a yearly regional conference to provide an opportunity for graduate students and postdocs to present their research on numerical methods. <br/><br/>The topics of this conference focus on the algorithm development, analysis, and applications of efficient, accurate, and stable numerical methods, especially those for solving multi-physics and multi-scale problems. In recent years, the inherent multi-physics and multi-scale features of many sophisticated and challenging real-world problems accentuate the importance to develop more efficient, accurate, and stable numerical methods for the relevant partial differential equations. In order to address these needs, the Midwest Numerical Analysis Day 2020 intends to create a forum for early-career and senior researchers from different fields, including computational mathematics, computer science, physics, and various engineering fields, to discuss recent advances on relevant numerical methods with the corresponding numerical analysis and applications.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011743","RUI: Algorithms and Complexity in Chip-Firing Games and Graph Gonality","DMS","ALGEBRA,NUMBER THEORY,AND COM, COMPUTATIONAL MATHEMATICS, Combinatorics","08/01/2020","06/10/2021","Ralph Morrison","MA","Williams College","Continuing Grant","Leland Jameson","07/31/2023","$99,445.00","","10rem@williams.edu","880 MAIN ST","WILLIAMSTOWN","MA","012672600","4135974352","MPS","1264, 1271, 7970","9229, 9263","$0.00","This mathematics research project studies ""chip-firing games"" on graphs from a computational and algorithmic perspective.  Chip-firing games, which are based on redistributing items throughout a network or graph, have appeared in a wide variety of mathematical and computational areas over the past three decades.  They originated in dynamical systems as part of the abelian sandpile model, the first known example of a system to display an important property known as self-organized criticality. A more recent perspective has treated chip-firing games on graphs as a discrete, combinatorial tool for studying algebraic curves. This has led to a deeper understanding of the connections between the mathematical fields of graph theory and algebraic geometry.  A key concept in this framework is the divisorial gonality of a network, which measures how difficult certain chip-firing games are to win on that network; this number has already been connected to key invariants from graph theory, such as treewidth. This project will deepen understanding of chip-firing games from a computational perspective, first designing and then implementing efficient algorithms for studying these games and their difficulty. Once implemented, these tools will be used for research in such disparate fields as algebraic geometry, graph theory, and dynamical systems, as well as in classrooms as pedagogical tools. In addition to these mathematical applications, the chip-firing problems that are known to be computationally difficult will serve as a good benchmark for computational methods and techniques. This project involves undergraduate students in the research, providing those students with key skills for future careers in both pure and applied areas of STEM.<br/><br/>The project will consider several versions of gonality, on both finite and metric graphs: divisorial gonality, the minimum degree of a positive rank divisor on a graph; geometric gonality, defined in terms of harmonic morphisms to a tree; stable divisorial gonality, which allows for refinements before computing the divisorial gonality; and higher gonalities, which ask for the minimum degree of a divisor with prescribed rank. Although purely combinatorial in nature, these topics connect deeply to such areas of algebraic geometry as tropical geometry, Berkovich theory, and Brill-Noether theory. There are three main components of the overarching project: (1) To study the theoretical aspects of computing graph gonality and related topics vis-a-vis computational complexity.  This includes studying the computational complexity of bounding the different versions of gonality, both in general and for special classes of graphs; designing algorithms for computing gonalities; and studying questions with important computational consequences, like finding upper and lower bounds on gonalities. Key tools here will be modifications of such existing algorithms as Dhar's burning algorithm. (2) To implement computational tools for studying chip-firing games on graphs. This will include tools for both combinatorial and metric graphs, which will also be made freely available to both researchers and teachers. (3) To apply these tools to study chip-firing games, graph theory, and algebraic geometry.  Such projects include studying gonality of random graphs, investigating long-standing conjectures on graph gonalities, performing computations relevant to algebraic curves, and investigating embedded aspects of tropical geometry.  In some cases, the computations themselves will be of paramount importance; in other cases, they will simply guide the direction of research in fruitful directions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2001695","The 50th John Barrett Memorial Lecture in 2020 on Approximation, Applications, and Analysis of Nonlocal, Nonlinear Models.","DMS","COMPUTATIONAL MATHEMATICS","04/01/2020","01/17/2020","Abner Salgado","TN","University of Tennessee Knoxville","Standard Grant","Malgorzata Peszynska","03/31/2021","$26,670.00","Tadele Mengesha","asalgad1@utk.edu","1331 CIR PARK DR","Knoxville","TN","379163801","8659743466","MPS","1271","7556, 9263","$0.00","This award supports the participation of students, postdocs, early career researchers, and under-represented groups seeking to attend the 50th anniversary of the John Barrett Memorial Lectures which will be held on May 11-13, 2020 at University of Tennessee, Knoxville. This three day workshop will be focused on ""Approximation, Applications, and Analysis of Nonlocal, Nonlinear Models"".  Nonlocal models are a type of mathematical model of relatively recent vintage that has proved to be very effective for describing certain challenging physical phenomena, such as fracture in solid mechanics. The workshop will bring together experts from the mathematical, computational scientific, and engineering communities who are very unlikely to meet otherwise, but nevertheless all work with nonlocal models and their applications. The meeting will provide a platform for the exchange of ideas. The workshop encourages the inclusion and participation of junior scientists and members of under-represented groups in STEM. This award will present them the opportunity to interact with and learn from leading researchers working with nonlocal models, along the way contributing towards the development of the next generation of researchers in nonlocal theories. <br/> <br/>The technical focuses of the workshop are on the approximation, applications and analysis of nonlocal models, which have presented new challenges to mathematical and numerical analysis, and their computational implementation. Recent applications include, but are not limited to: heat and mass diffusion, nonlocal mechanics, pattern formation, image processing, self-organized dynamics, population dispersal, Levy fights, and jump processes. Invited speakers and participants will bring expertise from a wide array of related fields, including: mathematical and numerical analysis of nonlocal and fractional model, numerical methods and discretization schemes, multi-scale modeling and adaptivity in nonlocal models, software implementation in nonlocal models, peridynamics models for material failure and damage, nonlocal heat transfer and mass diffusion, anomalous transport in nature, and other engineering and scientific applications in which nonlocal modeling is useful.<br/><br/>The conference website is https://www.math.utk.edu/barrett/.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
