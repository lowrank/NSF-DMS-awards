"AwardNumber","Title","NSFOrganization","Program(s)","StartDate","LastAmendmentDate","PrincipalInvestigator","State","Organization","AwardInstrument","ProgramManager","EndDate","AwardedAmountToDate","Co-PIName(s)","PIEmailAddress","OrganizationStreet","OrganizationCity","OrganizationState","OrganizationZip","OrganizationPhone","NSFDirectorate","ProgramElementCode(s)","ProgramReferenceCode(s)","ARRAAmount","Abstract"
"1211292","Mathematics and Computation of Nonlinear Problems in Diffractive Optics Modeling","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/01/2012","08/12/2015","Gang Bao","MI","Michigan State University","Standard Grant","Victor Roytburd","08/31/2016","$260,000.00","","bao@math.msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1266, 1271","","$0.00","Our proposed mathematical modeling techniques and computational methods will address key scientific challenges in applied mathematics including numerical solution of nonlinear Maxwell's equations in second harmonic generation with strong nonlinearities; multiscale modeling of second harmonic generation via Density Functional Theory, numerical solution of the inverse diffraction problems; and optimal design of guided mode grating resonance filters. We will initiate a mathematical modeling study of second harmonic generation for metal and diectric interfaces. A significant challenge is to explore novel multiscale, multi-physics models involving to capture the useful microscopic effects. Novel computational methods and mathematical modeling techniques will be developed to solve the underlying PDE problems.  When nonlinear optical effects become significantly strong, numerical methods based on the linearization of the essentially nonlinear problem are inadequate. Novel techniques must be explored to develop stable numerical schemes. New robust solution methods for the associated optimal design and  inverse problems will also be developed to investigate the critical ill-posedness of the model problems.<br/><br/>The goal of this project is to develop new mathematical models and computational algorithms that meet the basic research needs and provide the necessary modeling tools for scientists in the areas of diffractive optics and nonlinear optics. The proposed project has the potential not only to evolve new science, but also to lead to novel mathematics and computational methods. The capabilities for controlling and manipulating light are of paramount significance for many areas of our society, and have applications in critical areas such as energy, sensing, imaging, and information technology. Nonlinear diffractive optics is a fundamental and vigorously growing technology with diverse applications including fast optical switches, plasmonic materials, optical computing, optical microscopy, spectroscopy, and optical metamaterials. The recent enabling high-performance computing facilities and modern lithographic techniques have led to a substantial surge of applications of subwavelength structures, establishing diffractive optics and nonlinear diffractive optics as two of the most rapidly advancing areas of modern optical science. The continuous technology developments have given rise to exciting innovation such as ""invisibility cloaks"" and ""superlenses""; near-field or super-resolution optical microscopy, and other resonance phenomena. The future development and analysis of modern optics devices and theory will benefit from the availability of efficient computational modeling tools and mathematical analysis techniques. Our computational models and optimal design tools will provide an inexpensive and easily controllable virtual prototype of the structures in the design and fabrication of optical devices, potentially leading to faster information processing devices that consume less power, sensors with higher sensitivity, and nonlinear optical devices with high conversion efficiency."
"1217142","Single-grid Multi-level Solvers for Coupled PDE Systems","DMS","COMPUTATIONAL MATHEMATICS","09/01/2012","08/04/2014","Jinchao Xu","PA","Pennsylvania State Univ University Park","Continuing Grant","Leland Jameson","08/31/2015","$450,415.00","James Brannick, Ludmil Zikatanov","xu@math.psu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271","9263","$0.00","The goal of this project is to develop and study a special class of multilevel methods that combine techniques from the Geometric Multigrid (GMG) and Algebraic Multigrid (AMG) methodologies, which we refer to as the ""single-grid multilevel method"" (SGML). The focus is discretized partial differential equations, for which detailed information on the underlying geometric grid is generally available to the user. The research team is designing solvers that use information from the finest grid (hence termed the single-grid method) to select a simple and fixed coarsening that allows for explicit control of the overall grid and operator complexities of the multilevel solver. The central new idea that we are investigating concerns the design and analysis of algorithms for adaptive construction of the MG relaxation scheme when used as a smoother. In contrast to existing AMG methods, in which the smoother is fixed and coarsening is the key component in the setup phase, SGML will construct the smoother in the setup phase to complement its simple geometry-based coarsening process. It should be noted that the algebraic construction of the smoother can also benefit from using properties of the geometric grid, for example, to obtain a suitable partitioning of the unknowns in parallel. The SGML approach (together with the many of the promising algebraic techniques for constructing the MG interpolations developed over the last decade) is also under consideration. The PI and co-PIs, though, are focusing on the SGML method because of its ability to explicitly control complexity, which in turn allows for (nearly) optimal load balancing and predictable communication patterns, such that the method is well suited for parallel computing. <br/><br/>Overall, the iterative solvers under development are designed to be implemented in open source parallel codes and made available to the scientific computing community. This will provide a computational framework for future algorithm research and development in related areas as well as powerful tools for simulation. In summary, the proposed methodology constructs solvers using all the information available to increase the efficiency of numerical modeling and simulation of physical phenomena on parallel multi-core computing architectures. Educational activities include the training of graduate students."
"1216547","Non-quadratic Penalization in Generalized Local Regularization for Linear and Nonlinear Inverse Problems","DMS","COMPUTATIONAL MATHEMATICS","09/15/2012","07/30/2014","Patricia Lamm","MI","Michigan State University","Continuing Grant","Leland Jameson","08/31/2016","$300,000.00","","lamm@math.msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1271","9263","$0.00","Variational methods with non-quadratic penalty terms (such as those associated with total variation or sparsity constraints) are extremely effective solution methods for the resolution of sharp features of nonsmooth solutions to applied inverse problems.  Unfortunately, such globally-defined methods are often associated with large computational costs, a situation made even worse by the scale of the underlying problem (e.g., large imaging data sets).   Using their expertise in methods of generalized local regularization, the investigator and her colleagues develop localized non-quadratic regularization methods for ill-posed inverse problems as a way to reduce computational costs while still maintaining the sharp resolution of solutions.   <br/><br/>Applications of these new methods include problems of image deblurring, nonlinear autoconvolution, blind deconvolution, fractional integration/differentiation, and inverse and backward heat conduction. The methods developed by the investigator and her colleagues lead to faster, less computationally-intensive techniques for the accurate reconstruction of pictures in a wide number of applications, from satellite image gathering, biomedical imaging (CT scans, PET scans, etc.), to geophysical exploration.  The improved methods enable the analysis of more data in a shorter amount of time,  and with less overall expense.  In addition to imaging applications, these new methods are also applicable to the problem of determining hidden cracks and weaknesses in structures and materials, and the detection of ozone levels in the atmostphere, as well as to problems arising in the analysis of nano-structures."
"1160352","FRG: Collaborative Research: Variational multiscale approaches to biomolecular structure, dynamics and transport","DMS","COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY","09/15/2012","02/20/2014","Guowei Wei","MI","Michigan State University","Standard Grant","Mary Ann Horn","08/31/2015","$319,477.00","Kelin Xia","wei@math.msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1271, 7334","1616, 9263","$0.00","A major feature of biological science in the 21st Century will be its transition from a phenomenological and descriptive discipline to a quantitative and predictive one.  Revolutionary opportunities have emerged for mathematically driven advances in biological research. Experimental exploration of self-organizing biomolecular systems, such as HIV viruses, molecular motors and proteins in Alzheimer's disease, has been a dominating driven force in scientific discovery and innovation in the past few decades.  However, the emergence of complexity in self-organizing biological systems poses fundamental challenges to their quantitative description because of the excessively high dimensionality.  This Focused Research Group (FRG) will provide a platform, led by leading researchers from Michigan State University, University of Wisconsin-Madison and Pennsylvania State University, who will synergistically merge their expertise in theoretical modeling, scientific computing and mathematical analysis, for quantitative descriptions of biomolecular systems.   The research addresses grand challenges in the structure, function and dynamics of self-organizing biomolecular systems due to exceptionally massive data sets. These challenges are tackled through the introduction of new variational multiscale models, which reduces the dimensionality and number of degrees of freedom by a macroscopic continuum description of the aquatic/membrane environment, and a microscopic discrete description of biomolecules. Additionally, to further reduce the dimensionality of excessively large biomolecular systems, the investigators introduce a coarse-grained approach based on the density cluster dynamics which extracts stable manifolds in molecular dynamics simulations. This FRG project offers innovative new approaches to the massive data management, dimensionality reduction, computer simulation, theoretical modeling and mathematical analysis of biomolecular systems.<br/><br/>This project is a timely effort to promote the quantitative transition of biological science, which will lead to emerging new fields in both mathematical and biological sciences. In particular, the proposed effort will significantly strengthen the leading role that the U.S. researchers can play in mathematical molecular biosciences by aggressively pursuing cutting-edge research and collaboratively training a new generation of mathematicians in this emerging interdisciplinary field.  Three annual workshops and international meeting will be held in Michigan State (Year 1), Wisconsin (Year 2) and Penn State (Year 3) to strengthen the collaboration and extend the societal impact."
"1237586","The Ninth Mississippi State - UAB Conference on Differential Equations and Computational Simulations","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/15/2012","07/31/2012","Hyeona Lim","MS","Mississippi State University","Standard Grant","James Curry","08/31/2013","$35,000.00","Jerome Goddard, Roy Koomullil","hlim@math.msstate.edu","245 BARR AVE","MISSISSIPPI STATE","MS","39762","6623257404","MPS","1266, 1271","7556, 9150","$0.00","The ""Ninth Mississippi State - UAB Conference on Differential Equations and Computational Simulations"" will be held for two and a half days during October 4-6, 2012 at McCool Hall at Mississippi State University, Mississippi State, Mississippi. The website for this conference is http://www.ccs.msstate.edu/deconf/de2012. <br/>The mission of the meeting is to provide a joint forum where mathematicians, scientists, and engineers from industry, federal laboratories, and academia can exchange ideas on theoretical, applied, and computational developments in differential equations. The emphasis of this year's conference will be on reaction-diffusion equations with applications. The primary objective of the conference is to optimally fulfill the aforestated mission, while at the same time to promote research and education in mathematical and computational analysis of differential equations and associated simulations. <br/><br/>The conference is a collaborative endeavor between the Department of Mathematics and Statistics and the Center for Computational Sciences (CCS), a High Performance Computing Collaboratory (HPCC) member center, at Mississippi State University, and the Department of Mechanical Engineering at University of Alabama at Birmingham. This award provides travel support to graduate students and recent Ph.D.s for an opportunity to present their work, meet other researchers, educators and practitioners, learn about recent developments in the proposed interdisciplinary field, and produce a new generation of mathematical models and challenges."
"1216568","Computational Methods and Data Assimilation in Nonlinear Dynamics","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/15/2012","12/10/2013","Daniel Anderson","VA","George Mason University","Standard Grant","Leland Jameson","08/31/2016","$90,000.00","","danders1@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","MPS","1266, 1271","9263","$0.00","Computer simulation is a critical ingredient of modern science. Simulations that depend on the solution of differential equations are subject to small modeling, truncation, and &#64258;oating point arithmetic errors. A relatively new set of algorithms, called set-oriented methods, have been developed for the analysis of structures in computational dynamics. We propose to build a foundation for analyzing the possible effect of the errors on these techniques and others used in computational dynamics. The second major focus of this project is the interpretation of data collected from experimental systems and nature when only a partial mathematical model is available. We will<br/>investigate a range of techniques which, depending on the completeness of the available model, can be used to attempt to reconstruct the model and dynamical behavior of the process, with potential to predict or control the process. Complex deterministic time series from physical, and biological/medical settings that are produced by network dynamics will be particular applications.<br/><br/>The project focuses on two major areas: the development of new approaches to study computer simulation validity, and the interpretation of experimental data from nonlinear processes. Computer simulation is a critical ingredient of modern science. Simulations are subject to errors both in modeling and computation. The proposal builds a foundation for analyzing the possible effect of the errors on set-oriented simulation results, for physically relevant models. The second major focus of this project is the interpretation of data collected from experimental systems and nature when only a partial mathematical model is available. We will investigate a range of techniques which can be used to attempt to reconstruct the model and dynamical behavior, with potential to predict or control the process."
"1216297","RUI: Adaptively Weighted Finite Element Methods for PDEs and Optimal Least-Squares Metrics","DMS","COMPUTATIONAL MATHEMATICS","09/15/2012","09/13/2012","Chad Westphal","IN","Wabash College","Standard Grant","Rosemary Renaut","08/31/2015","$112,897.00","","westphac@wabash.edu","301 W WABASH AVE","CRAWFORDSVILLE","IN","479332417","7653616221","MPS","1271","9229, 9263","$0.00","The overall effectiveness of numerical methods for partial differential equations may be severely limited by solutions that lack smoothness on a relatively small subset of the domain.  Problems may have singularities induced by the geometry of the domain; convection dominated regimes may result in interior or boundary layers; discontinuous material coefficients can cause sharp gradients; or solutions may blow up at interior points when operator coefficients are singular or degenerate.  This project proposes a systematic study of weighted finite element methods where standard norms and inner products are replaced with weighted norms and inner products.  In the least-squares finite element setting, these weight functions serve to redefine the metric under which the error is minimized and, as such, the relative accuracy of the numerical solution can be balanced throughout the domain in an optimal way.  For some problems, the right choice of weights can recover convergence where the analogous nonweighted case does not converge and, in other problems, convergence rates are enhanced by an appropriate set of weights.  This project will develop robust adaptive methods for a wide class of linear and nonlinear problems, where the weights are chosen from coarse scale problems within a mesh refinement strategy.<br/><br/>The efficient numerical solution of partial differential equations is of great importance throughout the applied sciences.  Finite element methods constitute a popular and flexible approach to solving a wide range of problems, and the development of robust, accurate, and efficient finite element algorithms is in high demand for applications including mechanics of deformable solids, fluid flow, transport, and electromagnetics.  This project aims to develop a new class of adaptive finite element methods that are motivated by the success of weighted-norm least squares methods and adaptive mesh refinement algorithms.  Robust adaptive algorithms allow for better numerical simulations by focusing computational resources on the most challenging aspects of the problem, increasing overall accuracy and decreasing computational time.  In models of glacier flow, for example, regions of the ice near the surface and the ground require more resolution than the majority of the interior ice, and accurate models must be able to allocate the computational work in an optimal way.  Successful results from this project will enhance the current understanding of how adaptive algorithms can be designed to evolve optimally from coarse scale approximations."
"1216481","Data assimilation in scientific computing","DMS","COMPUTATIONAL MATHEMATICS, CDS&E-MSS","09/15/2012","09/08/2012","Jan Mandel","CO","University of Colorado at Denver-Downtown Campus","Standard Grant","Leland Jameson","08/31/2017","$399,981.00","Loren Cobb","Jan.Mandel@ucdenver.edu","1380 LAWRENCE ST STE 300","DENVER","CO","802042055","3037240090","MPS","1271, 8069","9263","$0.00","In this project, the investigators and their colleagues deepen and extend their asymptotic analysis of data assimilation algorithms for systems of nonlinear partial differential equations in the presence of measurement error and stochastic perturbation. This research includes the development of a stochastic convergence theory for ensemble and particle filters in infinite-dimensional Banach spaces, a corresponding statistical theory for finite-dimensional asymptotics, and a study of the behavior of spectral approximations for the spatio-temporal covariance structures of those filters. Of special importance is the computational efficiency and statistical convergence of wavelet and FFT spectral approximations in very-high-dimensional non-Gaussian cases. Connections between probability measures on Sobolev spaces, random fields in spatial statistics, and stochastic spectral expansions are exploited to effectively reduce the dimensionality of the system. The goal is to develop and demonstrate very fast and memory-efficient algorithms that provably converge in a suitable stochastic sense to the correct answer. Using high-performance computing facilities, the investigators' model of the spread of wildland fires, expressed as a coupled weather-fire system driven by real-world or Monte Carlo data, serves as the primary testbed for assessing the computational efficiency and statistical convergence properties of a wide variety of data assimilation algorithms and approximation methods.<br/><br/>Data assimilation is the art and science of incorporating real-time information, as it arrives, into a running complex simulation, in such a way that the simulation adjusts and adapts in a robust and reasonable way to the new data. The subject area of greatest interest to this project is the tracking of wildland fires as they spread across extended terrains that can include forests, grasslands, and human communities. For this purpose the investigators maintain a wildland fire-and-weather simulator that runs in a high-performance computing facility, embedded in a data assimilation framework so that the model can correct itself in response to incoming data (overhead photographs, weather station data, etc) as it arrives. The general methodology of data assimilation is of interest to many areas of science, and so it is critical that the algorithms employed be computationally very efficient and statistically robust, and that they can be proven to converge in the appropriate limit to the right answer. This project is dedicated to the development and study of such algorithms, and to rigorous analytical proofs of convergence and efficiency. Doctoral students and post-doctoral associates involved in the project receive a highly interdisciplinary exposure to computational and applied mathematics, statistics, meteorology, atmospheric physics, and fire science."
"1217324","RUI: Using computational homology to detect DNA Copy Number Aberrations in Breast Cancer","DMS","COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY","09/01/2012","03/20/2015","Javier Arsuaga","CA","San Francisco State University","Standard Grant","Yuliya Gorb","08/31/2016","$239,987.00","","jarsuaga@ucdavis.edu","1600 HOLLOWAY AVE BUILDING NAD R","SAN FRANCISCO","CA","941321722","4153387090","MPS","1271, 7334","9178, 9229, 9263","$0.00","The analysis of large complex data sets poses a major challenge for computational mathematics. Topological Data Analysis (TDA) applies concepts from algebraic topology to address this challenge. Topological techniques have been used successfully in engineering and biology but are seldom applied to the analysis of genomic data. In cancer genomics, the identification of copy number aberrations (CNAs) such as gains and losses of DNA segments is an important problem because CNAs are known to contain cancer genes and therefore to be involved in misregulation of key signaling pathways. CNAs may occur independently or may co-occur. The latter are believed to act synergistically and therefore result in unforeseen consequences. For example, the finding that CNAs in 8p12 and 11q13.3 are co-amplified in some breast cancers led to the discovery of functional interactions between the MYC and the TP53 pathways. Such interactions offer an important paradigm for cancer research because many tumors are believed to use similar mechanisms for their progression. Identification of co-occurring CNAs has traditionally been hindered both by the large sample sizes required to find co-occurrences and by the lack of mathematical methods to identify them efficiently. Recently, large microarray-based data sets have become available for breast cancer. The proposed research aims to develop a new TDA-based method to detect independent and co-occurring CNAs in breast cancer. In the proposed approach each CNA profile is characterized by a set of biologically-meaningful topological spaces. Topological invariants of these spaces (i.e., Betti numbers) will be used to de-noise the data and identify CNAs. This project will yield broadly-applicable methods for: (1) representing complex data sets in forms that are amenable to topological analysis; (2) determining the statistical significance of TDA results; (3) computing topological invariants from large data sets.<br/><br/>Rapid advances in the sciences have generated large, complex data sets of unprecedented proportions. New mathematical methods are urgently needed in order to solve fundamental problems in the analysis of such high-dimensional data. In the field of genomics, thousands of measurements have been obtained with the goal of unveiling molecular signatures that characterize essential biological processes. This field has significantly influenced the direction of breast cancer research because of its potential for differentiating various subtypes, pathways and prognoses of the disease. Currently, the major approach to detecting genomic signatures is focused on the identification of single independent events. However, there is increasing evidence that copy number aberrations (CNAs)-- such as amplifications and deletions of the genome--are not always independent of one another; rather, they may co-occur with synergistic and unforeseen consequences. For example, co-occurring CNAs detected in breast cancer have led to the identification of cross-talk between different signaling pathways. The systematic search for co-occurring CNAs has been hampered by a lack of mathematical methods adequate to identify them. The PI proposes to develop new methods in Topological Data Analysis to identify co-occurring CNAs in breast cancer. Further, because copy number changes are associated with other diseases and with evolutionary processes, this project will have important impacts across the sciences, both basic (e.g. evolution and development) and applied (e.g. diseases with a genetic component such as cancer, autism and multiple sclerosis). The proposed research will advance the field of mathematical genetics/genomics with new tools for analyzing complex interactions among genetic elements in genetic/genomic data. The methods developed also have the potential for extension to identify co-occurring events in large, complex longitudinal data sets. Furthering its broader impacts, the project will implement a series of public lectures on real-life applications of computational mathematics with special outreach to local school teachers, students and professionals."
"1216554","Collaborative Research: Methods for Stochastic and Nonlinear Optimization","DMS","COMPUTATIONAL MATHEMATICS","08/01/2012","07/24/2012","Richard Byrd","CO","University of Colorado at Boulder","Standard Grant","Rosemary Renaut","07/31/2016","$120,000.00","","richard@cs.colorado.edu","3100 MARINE ST","BOULDER","CO","803090001","3034926221","MPS","1271","9263","$0.00","The projects described in this proposal are designed to advance the capabilities of optimization methods for a class of stochastic and deterministic optimization problems. The first project focuses on  problems where the objective function is given by an expectation or a loss function. We propose dynamic sample algorithms that attempt to bridge the gap between stochastic and batch  methods. Their essential characteristic is that they adapt the sample size during the progression of the optimization in a manner that leads to low computational effort and high accuracy in the solution, when so desired. The second project deals with the design of new active-set methods for solving constrained optimization and convex regularized L1 problems.  Our work builds on two algorithms recently proposed in the literature: the block active-set method (also called the primal-dual active-set method), and the orthant-wise method  for solving L1 regularized problems. Our new algorithms are provably convergent and applicable to a wider class of applications. The third project addresses the need to improve the robustness of nonlinear optimization methods in the presence of infeasibility. Our first goal is to design an interior point method endowed with infeasibility detection capabilities, and to show how its main mechanism can be extended to other interior point methods. The second goal is to develop a convergence theory that is applicable to both active set and interior point methods consisting of three components:  an optimization phase, a feasibility phase, and a mechanism for transitioning between the two phases.<br/><br/>The methods developed in this project are useful in big data analysis, which is playing a vital role in genomics, materials science, meteorology, climate modeling and  information science. In all these disciplines, vast amounts of data have become available in the last decade, with the rate of  generation  accelerating exponentially.  The challenge is to process this large amount of information to make inferences and predictions, thereby accelerating our basic understanding of physical and social systems. For example, the complex physics simulations employed in the design of advanced materials, meteorology and climate modeling, require the use of detailed information obtained over a large set of scenarios. The optimization and machine learning methods developed in this project can be integrated in support of such simulations, thereby obviating the need for  extremely complex models that are difficult to study and generalize. Our work has direct impact in genomics and other areas of biology. For example, we plan to investigate its use in metagenomics, specifically de novo assembly of next generation DNA sequencing data.  Sequences  can be tagged with markers, or found in reference data sets like transcriptomes.  A goal is to use this new information to enable faster and more accurate de novo assembly.  In computer science and information technology, our new algorithms will be useful in the development of a new generation of speech recognition and computer vision systems. Speech recognition, which will play an increasingly important role in many technological applications, can only advance by incorporating more data more intelligently, and the algorithms described in this proposal are designed precisely for that purpose."
"1217223","Beyond the Method of Regularized Stokeslets","DMS","COMPUTATIONAL MATHEMATICS","08/15/2012","08/09/2012","Ricardo Cortez","LA","Tulane University","Standard Grant","Rosemary Renaut","07/31/2016","$120,000.00","","rcortez@tulane.edu","6823 SAINT CHARLES AVE","NEW ORLEANS","LA","701185665","5048654000","MPS","1271","9150, 9263","$0.00","The Method of Regularized Stokeslets is a numerical technique for the efficient computation of the motion of immersed elastic filaments or boundaries in incompressible Stokes flow. The method is based on desingularizing the expression for the fluid velocity resulting from forces applied on surfaces, curves or even scattered points. The main idea is to follow the derivation of the fundamental solution of the Stokes equations but replacing the delta function with a smooth approximation. The motivation for developing regularized Stokeslets is twofold: (1) when forces are distributed over a surface in three dimensions, the singular Stokeslet is integrable but numerical methods often have difficulty computing accurately the flow at fluid points very near the surface since the integrals have very spiky kernels (known as nearly-singular). Regularizing the kernels provides a stable computational technique; (2) the Stokes equations have more singular solutions derived from differentiating the Stokeslet (Stokes doublets, dipoles, stresslets, rotlets, etc.). Their higher singularity makes the integration over surfaces divergent but regularization methods provide a way to use these elements in computations.  The proposed work extends the popular method of regularized Stokeslets in several ways. It advances the theory of regularization methods, broadly defined to include the systematic derivation of higher-order elements for the computationally efficient modeling of swarms of microorganisms. The convergence of the method in the case of solid bodies moving in the fluid is addressed based on error analysis and corrections to the velocity field to improve the convergence rate. The theory also includes desired properties that the blobs must satisfy in order to attain the theoretical accuracy in computations, and to provide families of blobs that satisfy these properties. The theory of regularized Stokeslets is expanded to apply to other fluid models, such as the Brinkman equations for porous media and models of channels with permeable walls. The work extends the methods for applications with periodic boundary conditions in one, two or three coordinate directions.  The further advancement of the theory provides a richer and more complete set of tools for modeling small-scale flows driven by forces, microorganism motility, flows around particles near surfaces and more. <br/><br/>This project combines the development of new mathematical theory and computational methods to devise more accurate and more efficient ways of simulating the fluid motion around microorganisms and cilia.  The project will improve and extend a popular computational technique, called the method of regularized Stokeslets, which has been very useful in many applications in areas of biological fluid flows. Its uses include the removal of unwanted biofilms, microfiltration as a method for removing particulate matter, understanding the motion and behavior of bacterial flagella, understanding the forces required by self-propelled microswimmers, analyzing sperm motility and other issues related to human reproduction.  The popularity of the method is due to its usefulness in a wide variety of applications and to the relative ease of implementation compared to other methods.  However, the method of regularized Stokeslets can be improved in many ways by adding new components that will expand its applicability, by performing mathematical analyses that will shed light on new ways of implementing the model, and by assessing new computational methods that reach the results either more accurately or faster or both."
"1216672","Investigation of Auxiliary Subspace Techniques as a  General Tool for A Posteriori Error Estimation","DMS","COMPUTATIONAL MATHEMATICS","09/15/2012","08/06/2013","Jeffrey Ovall","KY","University of Kentucky Research Foundation","Continuing Grant","Junping Wang","02/28/2014","$115,812.00","","jovall@pdx.edu","500 S LIMESTONE","LEXINGTON","KY","405260001","8592579420","MPS","1271","9150, 9263","$0.00","A posteriori error estimation is an essential component of high-performance finite element computations.  Such estimates are used in practice not only to reliably determine when an approximate solution is accurate enough, but also to (efficiently) adaptively improve the approximation. This proposal considers auxiliary subspace error estimates, which are derived from computing an approximate error function in an auxiliary space. Such an approximate error function provides great flexibility, in principle, in how it may be used for adaptive finite, and we are here concerned estimation of and adaptivity with respect to: error in a variety of norms, higher-order derivatives in a variety norms, functional error for general classes of linear functionals, and error in eigenvalue and invariant subspace computations. The robustness of hierarchical error estimates of energy-norm error is well-established both in theory and in practice for low-order finite elements and second-order linear elliptic boundary value problems in two dimensions. This proposal aims to significantly extend both theory and practice not only to include the various error measures mentioned above, but also higher-order elements in two and three dimensions (p- and hp-adaptivity), as well as to different types of operators and finite elements, including systems of partial differential equations.  Additionally, an adaptive convergence theory would also be developed, where possible. A key component of the proposed research is the development of a basic framework in which clear guidance concerning an appropriate choice of auxiliary space for computing the approximate error function is provided by considering a few basic properties of the underlying problem and the space which was used for the approximate solution.<br/><br/>The ability to automatically detect and adapt to relevant fine and coarse-scale features in the modeling of composite materials is often indispensable as an aid for design of such materials, as well as for remote sensing in the presence of complex media (e.g. non-destructive exploration for natural resources).  This proposal concerns the development of a general and very flexible approach to error estimation and adaptive improvement of approximations in a variety of contexts, providing careful development of specific cases of interest, such as those mentioned above.  A clear theoretical framework for error estimation and adaptivity, together with several important practical realizations, will not only aid practitioners in making appropriate choices in their particular contexts, but will also make it easier to train students to be able to develop such tools for problem where little (if any) are available.  The various projects in the proposal include both national and international collaboration,as well as the education and involvement of graduate students.  Additionally, much of the software developed in conjunction with this proposal will be made freely available by the proposer from his website."
"1216740","Adaptive Discontinuous Galerkin Methods and Applications","DMS","COMPUTATIONAL MATHEMATICS","08/01/2012","07/24/2012","Ohannes Karakashian","TN","University of Tennessee Knoxville","Standard Grant","Rosemary Renaut","07/31/2016","$173,512.00","","okarakas@utk.edu","201 ANDY HOLT TOWER","KNOXVILLE","TN","379960001","8659743466","MPS","1271","9150, 9263","$0.00","In its broad outlines, the research program outlined in this proposal aims at the development, analysis and computer implementation of numerical methods designed to approximate the solutions of some partial differential equations with important applications in the fields of Engineering, Physics, the Biomedical Sciences and Mathematics. While the discontinuous Galerkin method will constitute the core methodology of this effort, a wide range of themes will be covered: A priori and a posteriori error estimates, adaptive methods, efficient solution of linear and nonlinear systems using multigrid and domain decomposition methods, flexible data structures and implementation on multicore and parallel processors and finally, applications to practical and analytical problems. A particularly appealing component is the development of generic a posteriori error estimators. These could find wide acceptability among scientists who do not have the mathematical background that is necessary to the construction of the traditional a posteriori estimators. A judicious balance will be struck between algorithm and code development, on one hand, and the rigorous analysis of their properties, on the other.  <br/><br/>Since the dawn of the modern era, scientists have been successful in describing natural phenomena by using partial differential equations (PDE's) as models. The Einstein equations that describe phenomena at the largest (cosmic) scales, the Schrodinger equation that describes phenomena at the smallest (atomic) scales and the Navier-Stokes equations that  are used to model a plethora of fluid flows are but a few of such PDE's without which the modern world would not be what it is today. Yet such PDE's are almost impossible to solve exactly and since the beginning, scientists have resorted to numerical calculations to approximate the unknown solutions. Naturally, advances in numerical techinques must keep pace with advances in PDE's and quite recently adaptive numerical techniques have emerged as a very promising tool in tackling even the most difficult approximation tasks. In carrying out the research projects outlined in this proposal, the P.I. will develop novel and promising adaptive numerical algorithms, analyze their properties and implement them on state of the art computers. These methods and computer codes will become part of the arsenal of tools enabling engineers, physicists and mathematicians to understand the phenomena described by the particular PDE's they are using. For example, one research activity proposed herein is to numerically investigate the ways in which a malignant tumor changes shape. Finally, in maintaining the essential tradition of training the next generation of teachers and researchers, a graduate student will participate in these projects in partial fulfillment of his Ph.D. degree."
"1203237","Conference: Recent Developments in Discontinuous Galerkin Finite Element Methods for Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","02/01/2012","01/20/2012","Xiaobing Feng","TN","University of Tennessee Knoxville","Standard Grant","Leland Jameson","01/31/2013","$21,000.00","Yulong Xing, Ohannes Karakashian","xfeng@utk.edu","201 ANDY HOLT TOWER","KNOXVILLE","TN","379960001","8659743466","MPS","1271","7556, 9150, 9263","$0.00","The principal investigator (PI) and Co-PIs organize the 2012 John H. Barrett Memorial Lectures in the University of Tennessee at Knoxville from May 9-11, 2012 (www.math.utk.edu/~xfeng/barrett/). The Barrett Lectures have been held annually since 1972. Each year a different topic is chosen, representing the research interests of the mathematics faculty of the University of Tennessee. Since 1993, the lectures have consisted of three one-hour survey talks by each of two or three leading researchers representing different themes and directions in a single field. The topic of the 2012 Barrett Lectures is: ``Recent Developments in Discontinuous Galerkin Finite Element Methods for Partial Differential Equations"". The main speakers of the 2012 Barrett Lectures are Franco Brezzi of University of Pavia(Italy) and Chi-Wang Shu of Brown University. Each of them will deliver three one-hour survey lectures on recent developments in discontinuous Galerkin finite element methods with respective emphases on interior penalty and local discontinuous Galerkin methods. In addition to the main speakers, ten speakers are also invited to give one-hour talks on topics related to one of the main lectures and on applications of discontinuous Galerkin finite element methods to hyperbolic conservation laws and Hamilton-Jacobi equations, convection-diffusion equations, shallow water equations, porous media flows, elasticity, high frequency wave equations, and materials phase transitions. Moreover, a poster session is also scheduled in the Lectures, giving the opportunity to those who attend the meeting to present their work in these areas.<br/><br/>The Barrett Lectures are partly funded by a grant from the University of Tennessee and have often received additional support from the National Science Foundation. They attract wide interest, with an audience of between 40 and 60 participants from the whole country, in addition to faculty and students from Knoxville and the Oak Ridge National Laboratory. They represent one of the few long standing lecture series in mathematics in the southeastern United States. The main objective of the 2012 Barrett Lectures is to provide the participants with an exposition of modern discontinuous Galerkin finite element methods for partial differential equations arising from various scientific/engineering/industrial applications, through in-depth survey lectures and informal discussions with the leading researchers in the field. Additional goals are to foster interdisciplinary collaboration, particularly with researchers in the domain sciences departments and in the College of Engineering at the University of Tennessee and several other southeastern institutions, and to generate a set of written surveys in the subject, which the organizing committee will endeavor to have published in book form. The fund being requested from the NSF will be spent providing partial support towards travel and accommodation for thirty graduate students, postdocs, and junior researchers who do not have research grants."
"1210886","Applied Matrix Theory and Complex Approximation:  Estimating Norms of Functions of Matrices","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/15/2012","08/27/2013","Anne Greenbaum","WA","University of Washington","Continuing Grant","Michael Steuerwalt","06/30/2017","$352,892.00","","greenbau@math.washington.edu","4333 BROOKLYN AVE NE","SEATTLE","WA","981950001","2065434043","MPS","1266, 1271","9263","$0.00","Many questions in applied and computational mathematics, such as questions about the stability of differential or difference equations or questions about the convergence of iterative methods for solving linear systems, are really questions about norms of functions of matrices, such as matrix exponentials or matrix powers. In the case of a real symmetric matrix (or, more generally, a normal matrix), these questions are answered in terms of the matrix eigenvalues, but when the matrix is highly nonnormal (meaning that its eigenvectors are nearly linearly dependent or it does not have a complete set of eigenvectors), eigenvalues tell only part of the story. The asymptotic behavior of powers of matrix exponentials or the matrix itself for large exponents is still determined by the eigenvalues, but transient behavior is not. In this project, the principal investigator will use other sets in the complex plane that can be associated with a matrix, such as the field of values or the epsilon-pseudospectrum, to give more information about the behavior of such matrix functions e.g. for finite powers. In the other direction, new results about the behavior of such matrix functions will lead to new insights into problems in complex approximation theory.<br/><br/>This award will support work in the mathematical areas of matrix theory and complex analysis that is fundamental in many application areas in science and engineering. A range of mathematical methods is available for describing the long-term behavior of systems (will a radiation level eventually decay to zero, will flutter in an aircraft eventually die out), but a more crucial question may be what happens in the near-term. While a computer simulation may answer this question for a specific scenario, general results about what determines the transient behavior of such systems are often lacking. This project will provide better mathematical tools for analyzing such questions for a wide class of models. The award will support graduate student training in these areas through research assistantships."
"1216732","Finite Volume Methods and Software for Hyperbolic Problems","DMS","COMPUTATIONAL MATHEMATICS, CI REUSE","09/01/2012","08/29/2012","Randall LeVeque","WA","University of Washington","Standard Grant","Rosemary Renaut","08/31/2016","$399,777.00","","rjl@uw.edu","4333 BROOKLYN AVE NE","SEATTLE","WA","981950001","2065434043","MPS","1271, 6892","7433, 9263","$0.00","This proposal will fund research on finite volume methods for solving linear and nonlinear hyperbolic systems of partial differential equations, and the continued development of the open source software package Clawpack.  This software provides an implementation of a class of wave propagation algorithms that has been extensively tested and used by students and researchers in many fields, and also incorporates adaptive mesh refinement (AMR).  Specific goals of this research include:  (1) Development of Discontinuous Galerkin (DG) methods in the Clawpack framework, which could potentially provide higher order of accuracy for a certain class of problems and greater efficiency in spite of their higher cost per time step.  (2)  Solution of three-dimensional orthotropic poroelastic wave propagation problems, with applications to the continuing investigation of Extracorporeal Shock Wave Therapy (ESWT).  (3) Development of adjoint equation technology for AMR error estimation and sensitivity analysis, with application to tsunami modeling in particular.  (4) Development of multilevel Monte-Carlo capabilities and exploration of this and other uncertainty quantification techniques, with application to the probabilistic assessment of natural hazards.<br/><br/>The class of algorithms being investigated can be used to solve a wide range of practical problems in science and engineering that involve wave motion. These problems are modeled by partial differential equations that cannot be solved exactly, and so numerical approximations must be generated computationally at millions of grid points. Development of better algorithms for efficiently computing accurate solutions is a primary goal of this research. Much of the work is quite general and can be applied to many different problems, and the algorithms are implemented in an open source software package Clawpack that is freely available at www.clawpack.org. Work supported by this grant is strongly motivated by two specific applications of practical interest. One is the simulation of hazardous geophysical flows, particularly tsunamis, and the development of techniques to more rapidly and accurately predict the effects of a tsunami.  For risk assessment and hazard mitigation, it is also necessary to consider a range of potential earthquakes that could cause tsunamis in the future.  Mathematical and computational techniques will be investigated that can aid in efficiently estimating the probability of inundation from a large number of potential tsunamis at many different points in a coastal community. The other motivating application is the study of shock wave propagation in tissue and bone and the mechanical stress generated that can lead to biological response, such as bone growth or wound healing. These studies are important in gaining a better understanding of shock wave therapy, a clinical procedure that has exhibited some significant results.<br/><br/>"
"1216576","Collaborative Research: Efficient Unstructured Discontinuous Galerkin Methods for Global Nonhydrostatic Atmospheric Modeling","DMS","Physical & Dynamic Meteorology, Climate & Large-Scale Dynamics","08/01/2012","07/29/2012","Dale Durran","WA","University of Washington","Standard Grant","Leland Jameson","07/31/2017","$357,568.00","","drdee@uw.edu","4333 BROOKLYN AVE NE","SEATTLE","WA","981950001","2065434043","MPS","1525, 5740","1271, 4444, 7215, 9263, OTHR","$0.00","This is a proposal to develop efficient unstructured discontinuous Galerkin (DG) methods for global non-hydrostatic atmospheric modeling. As the horizontal resolution of numerical weather prediction models increases, it becomes advantageous to model non-hydrostatic motions. The dynamics of deep convective clouds are non-hydrostatic and these clouds produce important feedbacks on the larger-scale flow that are difficult to parameterize. To represent such clouds and similar small-scale processes, the equations solved by global atmospheric models must transition from hydrostatic to non-hydrostatic formulations. A host of challenging, non-trivial numerical problems arise when one enters the non-hydrostatic regime, including: I) developing efficient time-integrators and/or ""soundproof"" equation sets to confront the fast acoustic waves supported by the governing equations; II) effectively resolving multi-scale flow features, that may require adaptive mesh refinement (AMR); and III) constructing spatial discretization methods that conserve all important quantities and can be exploited to satisfy the above two conditions. Item (I) will be addressed by designing a suite of implicit-explicit (IMEX) time-integrators for our governing equations and discrete spatial operators to allow larger explicit time-steps with better conditioned implicit parts. In addition, the fully compressible (Euler) equations will be compared to sound-proof systems (anelastic, pseudo-incompressible) in meteorologically relevant test cases. Item (II) will be addressed by testing two forms of AMR: conforming and nonconforming methods. Conforming methods are traditionally used with continuous discretization methods and require no modifications to the partial differential equation (PDE) solver since the AMR is essentially a separate method. Nonconforming methods are traditionally used with discontinuous methods but can also be used with continuous methods. Nonconforming methods couple the PDE solver with the AMR approach in a seamless fashion thereby requiring modification of the PDE solver. Item (III) will be addressed by virtue of the DG method that is capable of delivering both local and global conservation of all prognostic variables and is also well suited for handling strong gradients (e.g., discontinuities) that may be introduced by the moist variables. <br/><br/>Long-range weather forecasting and studies of the Earth's climate use computers to simulate the weather over the entire globe. Individual thunderstorms and clusters of similar deep clouds produce rain and transport moisture, heat, and momentum vertically throughout the atmosphere. Limitations in computer power have prevented global simulations from using the fundamental equations describing fluid motion to calculate the behavior of these localized clouds. Instead, the net effects of such clouds on the global atmosphere are ""parameterized"" using necessarily crude approximations. The latest advancements in computer architecture have finally made it possible to simulate large clouds in global models, but there are major challenges that must be overcome. The mathematical equations on which global models are based must become better approximations to the fundamental equations of fluid motion, and an efficient flexible structure must be determined to hold the data describing the state of the global atmosphere. This research addresses both of these challenges."
"1217303","Collaborative Research:   Modeling and simulation of graphene growth","DMS","COMPUTATIONAL MATHEMATICS","09/01/2012","08/27/2012","John Lowengrub","CA","University of California-Irvine","Standard Grant","Leland Jameson","08/31/2015","$224,997.00","","lowengrb@math.uci.edu","160 ALDRICH HALL","IRVINE","CA","926970001","9498247295","MPS","1271","9263","$0.00","Nanoscale materials hold tremendous promise for the miniaturization of devices and components in applications ranging from biomedicine to nanoelectronics. As silicon-based nanodevices reach their natural size limitations, carbon-based materials such as nanotubes and graphene have emerged as exciting alternatives. Because graphene consists of a single 2D planar layer of carbon atoms, and possesses unique physical properties, graphene is thought to be better suited for large-scale circuit design than nanotubes, which typically exhibit large intrinsic resistance in contacts that limits their effectiveness. To realize their promise, large and defect-free graphene sheets must be grown or placed on non-metallic substrates. It is therefore important to understand the mechanisms that govern the growth and morphology of graphene. Indeed, controlling the graphene morphology has proven to be a major challenge, and the kinetics of graphene growth remain poorly understood. The investigators will address these issues here. The main objective of this proposal is to investigate the nonlinear dynamics of the mechanisms that govern the growth and morphology of graphene and develop strategies to control its growth by (1) developing and applying state-of-the-art adaptive numerical methods to large-scale computation and (2) performing analytical, numerical and modelling studies of important constituent processes. More specifically, the investigators will perform fundamental studies of the growth of graphene films from a thermal treatment of a silicon carbide substrate. This process is unique among epitaxial growth mechanisms because there is no deposition flux of carbon. Rather, silicon desorbs from the surface freeing carbon atoms to diffuse on the surface and nucleate first to form a precursor layer and then a graphene layer. A significant challenge is that the structure and morphology of graphene layers is determined both by atomic-scale phenomena and by the elastic interaction of surface features over length scales of hundreds of nanometers. Consequently, no single model is able to describe all the processes involved in the formation of graphene sheets on silicon carbide. The investigators will therefore adopt a multiple-scale approach that includes atomic scale simulations, genetic algorithms for determination of surface structure, and continuum models for shape evolution and patterning. The highly nonlinear nature of these problems makes fast, accurate and robust numerical methods essential to their study.<br/><br/>Nanocrystalline materials have physical properties that make them ideally suited for a wide range of potential applications including areas of Federal strategic interests such as nanotechnology, information technology (via advanced optoelectronic and magnetic storage units), biotechnology, (via biological or chemical sensors), and energy technology (via photovoltaic devices). Because of their unique structural and electronic properties, carbon-based devices, such as defect-free graphene layers, can extend miniaturization beyond the natural limits of their silicon-based counterparts. Recent advances in experimental techniques indicate that the key obstacle in achieving large and uniform graphene layers necessary for device applications is the roughness of the surface on which it grows. However, a quantitative understanding of the interaction among the surface properties and graphene growth processes remains elusive. The investigators will develop new mathematical theory and advance the state-of-the-art in numerical simulation to perform fundamental studies of graphene growth. These studies will provide guidance in the quantitative interpretation of experimental measurements on the dynamics of graphene layer formation and will suggest mechanisms to control graphene growth. The theory and methods developed here will also be useful in the study of other nanoscale materials arrays of semiconductor quantum dots. Two Ph.D. students will receive interdisciplinary training while performing the proposed work. The investigators will develop and teach a course on crystal and epitaxial growth for gifted high school students as part of the Calif. State Summer School for Mathematics and Science (COSMOS) at UC Irvine."
"1217273","Collaborative Research: Reactive instabilities, colloids and interfacial flows: Experiments, models and numerics","DMS","COMPUTATIONAL MATHEMATICS","12/15/2012","12/04/2012","John Lowengrub","CA","University of California-Irvine","Standard Grant","Leland Jameson","11/30/2015","$99,997.00","","lowengrb@math.uci.edu","160 ALDRICH HALL","IRVINE","CA","926970001","9498247295","MPS","1271","9263","$0.00","The investigators and their colleagues study novel instabilities in fluids driven by material complexity occurring only at interfaces. For instance, when two reacting micellar liquids are brought into contact, the reaction may produce a growing gel-like phase at the interface, which significantly stiffens the boundary between the fluids.  Another example arises from the presence of nanoscale colloidal particles which accumulate at interfaces. Intercolloid forces also endow the interface with stiffness, and may even jam the interface at sufficiently high volume fraction. The goal of this proposal is to develop comprehensive, physically appropriate models and simulations for these very difficult problems. The highly nonlinear nature of these problems makes fast, accurate and robust numerical methods essential to their study. The research team plans to investigate the nonlinear dynamics of interfaces endowed with complex physical properties and to develop strategies to control their pattern forming abilities by (1) developing and applying state-of-the-art adaptive numerical methods to large-scale computation; (2) performing analytical, numerical and modeling studies of important constituent processes; and (3) performing experiments to calibrate and validate the mathematical models, to test the model predictions, and to help elucidate the underlying physical processes.<br/><br/>Interfacial instabilities occur when driving forces compete with resistive forces with a consequence being the formation of complex patterns. Examples occur in diverse systems such as including filamentary microorganisms, growing biofilms, smoldering flame fronts, and lava flows. The goal of this project is to develop comprehensive, physically appropriate models and efficient numerical methods for solving such problems. Experiments will be performed to validate the models and test the model predictions, and to help elucidate the underlying physical processes. The research will focus on flows with complex interfacial physics such as reactions and nanoscale particles at interfaces. The research activities will provide new integrated theoretical, numerical and experimental results that can be used to (1) further explore these pattern forming systems that are driven out of equilibrium; (2)develop guidelines for controlling the evolving morphologies. While specific and novel applications are investigated here, the new mathematical and adaptive numerical techniques are expected have application beyond the present context.  In addition, this project will provide valuable interdisciplinary training opportunities for young researchers, and outreach programs are planned for middle school and undergraduate students (Penn State), high school students (UC Irvine) and undergraduate students (Ill. Inst. Techn.)."
"1160360","FRG: Collaborative research: Variational multiscale approaches to biomolecular structure, dynamics and transport.","DMS","COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY","09/15/2012","07/15/2016","Julie Mitchell","WI","University of Wisconsin-Madison","Standard Grant","Junping Wang","08/31/2017","$321,054.00","Qiang Cui","mitchelljc@ornl.gov","21 N PARK ST STE 6301","MADISON","WI","537151218","6082623822","MPS","1271, 7334","1616, 9263","$0.00","A major feature of biological science in the 21st Century will be its transition from a phenomenological and descriptive discipline to a quantitative and predictive one.  Revolutionary opportunities have emerged for mathematically driven advances in biological research. Experimental exploration of self-organizing biomolecular systems, such as HIV viruses, molecular motors and proteins in Alzheimer's disease, has been a dominating driven force in scientific discovery and innovation in the past few decades.  However, the emergence of complexity in self-organizing biological systems poses fundamental challenges to their quantitative description because of the excessively high dimensionality.  This Focused Research Group (FRG) will provide a platform, led by leading researchers from Michigan State University, University of Wisconsin-Madison and Pennsylvania State University, who will synergistically merge their expertise in theoretical modeling, scientific computing and mathematical analysis, for quantitative descriptions of biomolecular systems.   The research addresses grand challenges in the structure, function and dynamics of self-organizing biomolecular systems due to exceptionally massive data sets. These challenges are tackled through the introduction of new variational multiscale models, which reduces the dimensionality and number of degrees of freedom by a macroscopic continuum description of the aquatic/membrane environment, and a microscopic discrete description of biomolecules. Additionally, to further reduce the dimensionality of excessively large biomolecular systems, the investigators introduce a coarse-grained approach based on the density cluster dynamics which extracts stable manifolds in molecular dynamics simulations. This FRG project offers innovative new approaches to the massive data management, dimensionality reduction, computer simulation, theoretical modeling and mathematical analysis of biomolecular systems.<br/><br/>This project is a timely effort to promote the quantitative transition of biological science, which will lead to emerging new fields in both mathematical and biological sciences. In particular, the proposed effort will significantly strengthen the leading role that the U.S. researchers can play in mathematical molecular biosciences by aggressively pursuing cutting-edge research and collaboratively training a new generation of mathematicians in this emerging interdisciplinary field.  Three annual workshops and international meeting will be held in Michigan State (Year 1), Wisconsin (Year 2) and Penn State (Year 3) to strengthen the collaboration and extend the societal impact."
"1211934","The Central Region Conference on Numerical Analysis and Dynamical Systems","DMS","COMPUTATIONAL MATHEMATICS","09/01/2012","09/01/2012","Erik Van Vleck","KS","University of Kansas Center for Research Inc","Standard Grant","Junping Wang","08/31/2014","$18,500.00","Weishi Liu, Weizhang Huang","erikvv@ku.edu","2385 IRVING HILL RD","LAWRENCE","KS","660457552","7858643441","MPS","1271","7556, 9150, 9263","$0.00","This award will provide support to defray expenses of participants, especially junior investigators, women and mathematicians from under-represented groups in the sciences to attend the conference ``The Central Region Conference on Numerical Analysis and Dynamical Systems'' from May 3 to May 4, 2013 on the campus of the University of Kansas. The conference is motivated by the increased interaction and collaboration between numerical analysis and dynamical systems in the last decades. Numerical analysis is at the core of scientific computing and involves the study, development, and analysis of algorithms for obtaining numerical solutions to various mathematical models of real world problems. It is often cost effective to employ simulations to narrow down where expensive experimental procedures should be applied and to provide insight into the principles behind observed experimental phenomena. Dynamical systems theory is an area of applied mathematics where the behavior of complex dynamical systems is studied and qualitative methods are typically employed. Qualitative analysis has been found to be extremely useful in the development of robust and reliable numerical algorithms and in justifying numerical results, and numerical simulation has increasingly become a powerful tool in dynamical systems and has been used extensively to gain quantitative characterization of complex dynamic systems, provide necessary motivations, and verify theoretical findings.<br/><br/>The conference will serve several goals. In addition to facilitating greater interaction between researchers in numerical analysis and dynamical systems, The Central Region Conference on Numerical Analysis and Dynamical Systems will provide a forum in which young researchers, graduate students and postdoctoral fellows in the Central region of the United States can acquaint themselves with current issues at the forefront of research, present their own work, and interact with senior mathematicians in the field. Furthermore, the conference will provide strong motivation for interdisciplinary collaboration between numerical analysis and dynamical systems. Finally, the conference will play an active role in motivating applied mathematics and strengthening applied mathematics groups at universities in the region."
"1159937","FRG: Collaborative Research: Variational multiscale approaches to biomolecular structure, dynamics and transport","DMS","COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY","09/15/2012","09/04/2012","Chun Liu","PA","Pennsylvania State Univ University Park","Standard Grant","Mary Ann Horn","08/31/2016","$259,469.00","","cliu124@iit.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271, 7334","1616, 9263","$0.00","A major feature of biological science in the 21st Century will be its transition from a phenomenological and descriptive discipline to a quantitative and predictive one.  Revolutionary opportunities have emerged for mathematically driven advances in biological research. Experimental exploration of self-organizing biomolecular systems, such as HIV viruses, molecular motors and proteins in Alzheimer's disease, has been a dominating driven force in scientific discovery and innovation in the past few decades.  However, the emergence of complexity in self-organizing biological systems poses fundamental challenges to their quantitative description because of the excessively high dimensionality.  This Focused Research Group (FRG) will provide a platform, led by leading researchers from Michigan State University, University of Wisconsin-Madison and Pennsylvania State University, who will synergistically merge their expertise in theoretical modeling, scientific computing and mathematical analysis, for quantitative descriptions of biomolecular systems.   The research addresses grand challenges in the structure, function and dynamics of self-organizing biomolecular systems due to exceptionally massive data sets. These challenges are tackled through the introduction of new variational multiscale models, which reduces the dimensionality and number of degrees of freedom by a macroscopic continuum description of the aquatic/membrane environment, and a microscopic discrete description of biomolecules. Additionally, to further reduce the dimensionality of excessively large biomolecular systems, the investigators introduce a coarse-grained approach based on the density cluster dynamics which extracts stable manifolds in molecular dynamics simulations. This FRG project offers innovative new approaches to the massive data management, dimensionality reduction, computer simulation, theoretical modeling and mathematical analysis of biomolecular systems.<br/><br/>This project is a timely effort to promote the quantitative transition of biological science, which will lead to emerging new fields in both mathematical and biological sciences. In particular, the proposed effort will significantly strengthen the leading role that the U.S. researchers can play in mathematical molecular biosciences by aggressively pursuing cutting-edge research and collaboratively training a new generation of mathematicians in this emerging interdisciplinary field.  Three annual workshops and international meeting will be held in Michigan State (Year 1), Wisconsin (Year 2) and Penn State (Year 3) to strengthen the collaboration and extend the societal impact."
"1262428","Computational Methods in Numerical Algebraic Geometry","DMS","COMPUTATIONAL MATHEMATICS","09/01/2012","05/12/2015","Jonathan Hauenstein","NC","North Carolina State University","Standard Grant","Junping Wang","08/31/2015","$61,032.00","Jonathan Hauenstein","hauenstein@nd.edu","2601 WOLF VILLAGE WAY","RALEIGH","NC","27607","9195152444","MPS","1271","9263","$0.00","This project aims to contribute to numerical algebraic geometry by developing and implementing new algorithms used to solve polynomial systems arising in many applications.  One goal is the development of an algorithm for solving large-scale structured polynomial systems which naturally arise in computing overconstrained mechanisms as well as computing real and singular points on algebraic sets.  This algorithm will utilize the regeneration method, developed by Hauenstein, Sommese, and Wampler, which computes the solutions of a polynomial system by building from the solutions of smaller polynomial systems.  Regeneration together with the exploitation of structure will allow one to solve many naturally occurring polynomial systems which are beyond the reach of current methods.  Another goal is the training of one or more undergraduate students in this area. The students will also help with the development of some of the algorithms and testing of the software developed by this proposal.  Additionally, as a group, we will apply the newly developed algorithms to new problems arising from applications.<br/><br/>Polynomial systems naturally arise in many areas of science, engineering, economics, and biology with their solutions, for example, describing the design of specialized robots, equilibria of chemical reactions and economic models, and describing the stability of tumors.  The real solutions to these polynomial systems are often of particular interest to researchers as they often describe the physically meaningful solutions, e.g., a constructible robot.  The new algorithms and software developed will allow a broad range of scientists, engineers, and economists who encounter polynomial systems to compute physically meaningful solutions to systems which are beyond the reach of current solving techniques. Additionally, the students involved in this project will gain knowledge and research experience in the mathematical sciences."
"1216938","Collaborative Research:  Advanced Numberical Techniques for the Simulation of Magnetohydrodynamics","DMS","COMPUTATIONAL MATHEMATICS","09/01/2012","08/13/2012","Chun Liu","PA","Pennsylvania State Univ University Park","Standard Grant","Leland Jameson","08/31/2015","$30,544.00","","cliu124@iit.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271","9263","$0.00","The overall objective of this research is to develop numerical models and efficient energy-consistent methods for simulation of complex fluid systems and to obtain physically-accurate solutions for magnetohydrodynamic (MHD) systems, in particular. This work focuses on minimizing the computational cost of approximating solutions to these systems in order to develop practical simulations for this type of problem. The bottom line is to further develop discretization and solution algorithms that yield the most accuracy per computational cost. This is achieved by deriving discrete energy laws for MHD systems and proving that they are consistent with the continuous mathematical model. The investigators accomplish this by using the Energetic-Variational Approach (EVA) to further investigate the MHD model itself and determining which ""flavor"" of the MHD equations is the simplest model that captures the relevant physics. One of the main issues with using finite-element methods for solving complex fluid and electromagnetic problems has been the precise preservation of divergence-free solutions. Here, the investigators analyze discretization methods that satisfy these quantities accurately, while remaining amenable to efficient solution.  Finally, the main bottleneck in the discretization methods used so far is the slow convergence of the linear solvers. By further developing multigrid methods for systems of partial differential equations, the investigators create a robust and efficient algorithm for these complex systems.<br/><br/>The development of an efficient simulation framework for MHD systems has a major impact on the study of fusion energy, as this model is used to describe various phenomena that occur in fusion reactors, including tearing mode and sawtooth instabilities. With projects such as the International Thermonuclear Experimental Reactor (ITER) in France and the National Ignition Facility (NIF) at Lawrence Livermore National Lab attempting to obtain sustainable fusion energy, scientific computing in fields related to these projects is critical. In addition, the numerical tools being developed, such as energy-preserving finite-element discretizations and optimal multigrid solvers for systems of PDEs, are applicable to a wide variety of other problems in multi-physics and multi-scale systems.  Finally, the project supports a graduate student, training and exposing them to the latest scientific findings and tools related to modeling, discretization, and solution of problems in the computational modeling of plasma physics and complex fluids."
"1217177","Collaborative Research: Reactive Instabilities, Colloids, and Interfacial Flows: Experiments, Modeling, and Numerics","DMS","COMPUTATIONAL MATHEMATICS","12/15/2012","12/04/2012","Andrew Belmonte","PA","Pennsylvania State Univ University Park","Standard Grant","Leland Jameson","11/30/2016","$150,000.00","","andrew.belmonte@gmail.com","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271","9263","$0.00","The investigators and their colleagues study novel instabilities in fluids driven by material complexity occurring only at interfaces. For instance, when two reacting micellar liquids are brought into contact, the reaction may produce a growing gel-like phase at the interface, which significantly stiffens the boundary between the fluids.  Another example arises from the presence of nanoscale colloidal particles which accumulate at interfaces. Intercolloid forces also endow the interface with stiffness, and may even jam the interface at sufficiently high volume fraction. The goal of this proposal is to develop comprehensive, physically appropriate models and simulations for these very difficult problems. The highly nonlinear nature of these problems makes fast, accurate and robust numerical methods essential to their study. The research team plans to investigate the nonlinear dynamics of interfaces endowed with complex physical properties and to develop strategies to control their pattern forming abilities by (1) developing and applying state-of-the-art adaptive numerical methods to large-scale computation; (2) performing analytical, numerical and modeling studies of important constituent processes; and (3) performing experiments to calibrate and validate the mathematical models, to test the model predictions, and to help elucidate the underlying physical processes.<br/><br/>Interfacial instabilities occur when driving forces compete with resistive forces with a consequence being the formation of complex patterns. Examples occur in diverse systems such as including filamentary microorganisms, growing biofilms, smoldering flame fronts, and lava flows. The goal of this project is to develop comprehensive, physically appropriate models and efficient numerical methods for solving such problems. Experiments will be performed to validate the models and test the model predictions, and to help elucidate the underlying physical processes. The research will focus on flows with complex interfacial physics such as reactions and nanoscale particles at interfaces. The research activities will provide new integrated theoretical, numerical and experimental results that can be used to (1) further explore these pattern forming systems that are driven out of equilibrium; (2)develop guidelines for controlling the evolving morphologies. While specific and novel applications are investigated here, the new mathematical and adaptive numerical techniques are expected have application beyond the present context.  In addition, this project will provide valuable interdisciplinary training opportunities for young researchers, and outreach programs are planned for middle school and undergraduate students (Penn State), high school students (UC Irvine) and undergraduate students (Ill. Inst. Techn.)."
"1158859","Variational and Topological Methods: Theory, Applications, Numerical Simulations, and Open Problems","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, ANALYSIS PROGRAM","03/15/2012","03/01/2012","John Neuberger","AZ","Northern Arizona University","Standard Grant","Annalisa Calini","02/28/2013","$33,847.00","","John.Neuberger@nau.edu","601 S KNOLES DR","Flagstaff","AZ","86011","9285230886","MPS","1266, 1271, 1281","7556","$0.00","The PI and the organizers are holding the ""Variational and Topological Methods: Theory, Applications, Numerical Simulations, and Open Problems"" conference during June 6-9, 2012, at Northern Arizona University (NAU) in Flagstaff, AZ. This conference covers topics in variational and topological methods for nonlinear elliptic and parabolic partial differential equations (PDE), with two special emphasis sessions, in singular problems and in numerical simulations for nuclear physics. The scope of the conference will be fairly wide, to include theory, applications, and scientific computations, with emphasis on the two special session areas. The principal speakers, Monica Clapp (Instituto de Matemticas, UNAM, Mexico), Pavel Drbek (Univerzita v Plzni, Czech Republic), Jacques Giacomoni (Universit de Pau, France), Jean-Michel Rakotoson (Universit de Poitiers, France) and Peter Tak (Universitt Rostock, Germany) have all committed to giving a series of keynote lectures. This format was beneficial to researchers at all levels attending the previous two conferences organized with the support of NSF in 2002 and 2007 in NAU. The conference website is http://jan.ucc.nau.edu/~jmn3/var12/var12.html.  <br/> <br/>This award provides partial support to eligible participants, with priority given to underrepresented mathematicians, especially women, graduate students, postdocs, and junior faculty. One of the goals of the conference organizers is to encourage young researchers by providing them an opportunity to listen to and interact with experts.  It is a theme that there will be time in the schedule to allow this discussion, to include open problems for potential new research areas of mathematics that feature a blend of the analysis, scientific application, and numerical solution of the key relevant equations of our subject."
"1156412","ANTS-X: Algorithmic Number Theory Symposium 2012","DMS","ALGEBRA,NUMBER THEORY,AND COM, COMPUTATIONAL MATHEMATICS","02/01/2012","12/14/2011","Kiran Kedlaya","CA","University of California-San Diego","Standard Grant","tara smith","01/31/2013","$30,000.00","","kedlaya@ucsd.edu","9500 GILMAN DRIVE","LA JOLLA","CA","920930021","8585344896","MPS","1264, 1271","7556","$0.00","The tenth Algorithmic Number Theory Symposium (ANTS) meeting will be held July 9-13, 2012, at the University of California, San Diego. It will include approximately 5 invited lectures, about 25 contributed lectures chosen through a competitive review process, and a poster session. It is expected that 100-150 mathematicians will attend, including a sizable fraction of graduate students and postdocs and some scientists from nonacademic institutions. There will also be a proceedings volume issued shortly after the conclusion of the meeting. The ANTS meetings, held biannually since 1994, are the premier international forum for new research in computational number theory. They are devoted to algorithmic aspects of number theory, including elementary number theory, algebraic number theory, analytic number theory, geometry of numbers, arithmetic algebraic geometry, finite fields, and cryptography. <br/><br/>As an established conference series, ANTS attracts invited and contributed lectures of the highest quality, and serves as a forum for dissemination of new ideas and techniques throughout the research community in the area of computational number theory. The review process for contributed lectures and the subsequent production of a proceedings volume provides documentation of the presented results at the level of quality of an international research journal in mathematics. The ANTS meeting also serves an important training function, by drawing (with partial funding) many US-based graduate students and postdocs (for whom partial funding will be available), who will benefit both from exposure to the latest work in computational number theory and from the opportunity to present their own work. In addition, the interaction between academic, industry, and government researchers should prove mutually beneficial to all sides."
"1216366","Advances in robust multilevel preconditioning methods for sparse linear systems","DMS","COMPUTATIONAL MATHEMATICS","08/15/2012","08/03/2012","Yousef Saad","MN","University of Minnesota-Twin Cities","Standard Grant","Leland Jameson","07/31/2016","$300,001.00","","saad@umn.edu","200 OAK ST SE","MINNEAPOLIS","MN","554552009","6126245599","MPS","1271","9263","$0.00","The primary goal of this project is to investigate multi-level preconditioning techniques for solving linear systems of equations, placing a high emphasis on robustness issues. One of the key concepts used in these methods is that of coarsening, i.e., the method of reducing a set of variables of a system (called `fine' unknowns) to a smaller set (called `coarse' unknowns) which yields a good representation of the fine set. So far, coarsening has been viewed mostly from the angle of algebraic multi-Grid. A number of multi-level ILU type techniques, primarily based on coarsening ideas, will be studied. The research team will also investigate a new set of Multi-Level Low-Rank approximation techniques within Domain-Decomposition type methods. A number of factors make these methods very appealing, including their robustness and their potential effectiveness on  high-performance computers, e.g., ones employing GPGPUs. Finally, in an effort to tie the development of preconditioners more closely with applications, the research team will consider methodologies for developing what may be termed `application-tailored preconditioners.'<br/><br/>Though enormous progress has been made  in the last two decades in the solution of large sparse linear systems of  equations  by iterative methods, the state-of-the-art of these methods remains unsatisfactory in  many areas. Foremost among these is the lack of robustness of iterative techniques in dealing with a variety of real-life problems. Recent research on Preconditioned Krylov Subspace Methods (PKSMs) has aimed at achieving a good compromise between generality and efficiency by incorporating techniques  from different horizons, including multilevel concepts to improve scalability and adopting ideas from direct solution methods to improve robustness. At the same time that these improvements are being deployed, the demands on developers of iterative  solution methods are changing. Applications have become much more challenging, and new computational environments are making obsolete complex software that often took several years to mature. The aim  of this research proposal is to address new challenges and questions that have emerged for PKSMs in recent years as well as to explore more common research issues where progress is of vital importance. All general use codes that will be developed under this project will be freely distributed under the GNU public use license. The PI already has a long practice with distributing codes in this fashion. This project will have an impact on the training of graduate students in a field that is vital to the needs of academia, industry, and government laboratories. At a time where  there is a significant upsurge of demand for specialists in computational mathematics, the number of graduate students trained in this broad area has diminished. The PI will place a major effort in attracting and training students in topics related to  scientific computing and high-performance computing. Because it is important to sparkle the interest into these areas at an early stage of the student career, the proposal highlights plans for employing two undergraduate summer interns to work  on specific  topics of this proposal, throughout its duration. Among other training activities the PI will continue the practice of freely disseminating books, lecture notes, and MATLAB scripts for educational purposes."
"1207829","Challenges in Geometry, Analysis and Computation: High Dimensional Synthesis","DMS","COMPUTATIONAL MATHEMATICS, ANALYSIS PROGRAM","02/15/2012","08/26/2013","Yair Minsky","CT","Yale University","Standard Grant","Leland Jameson","03/31/2014","$50,000.00","Andrea Nahmod, Per-Gunnar Martinsson, Amit Singer","yair.minsky@yale.edu","105 WALL ST","NEW HAVEN","CT","065118917","2037854689","MPS","1271, 1281","7556, 9263","$0.00","This award will provide support to defray expenses of participants, especially junior investigators, women and mathematicians from under-respresented groups in the sciences to attend the conference ""Challenges in Geometry, Analysis and Computation: High Dimensional Synthesis"" to be held at Yale University during June 4-6,  2012.  The conference is motivated by the development in recent years of new powerful tools for overcoming the challenges associated with problems set in high dimensional spaces. These tools include compressive sensing, random projections, diffusion maps for parameterizing high-dimensional data sets, fast multipole methods, and many more. The premise of the meeting is that these different techniques share an intellectual heritage in a body of work originating from harmonic and functional analysis.  A major problem confronting scientists nowadays is  dealing with massive quantities of data.  Over the last decades, the development of powerful computers has been very useful in treating many computational problems. Nonetheless severe limitations occur when the amount of data becomes too large.   The interaction of Harmonic Analysis, Computational Mathematics, Combinatorial Geometry, Probability and Operator Theory has initiated a host of powerful methods to deal both with the processing and organizing of massive data sets, as well as efficient Numerical Analysis.  More importantly they reveal new mathematical structures and open fundamental questions which need to be addressed, questions related to the analysis of functions in high dimensions, their sampling, effective descriptions, and approximations for efficient computability.  Any further progress will have an enormous impact on our digital data driven world.  <br/><br/>The program for the conference features:   (1) Lectures by leaders in the field. The conference will feature about 15 lectures by distinguished researchers . (2) Panel discussion on future directions. The conference will feature a panel discussion with some of the principal investigators from the major federal research agencies and national laboratories (ONR, DARPA, AFOSR, ARO, Livermore National Lab, Pacific Northwest Lab, Oak Ridge Laboratory) joined by Ronald R. Coifman, Peter W. Jones, Vladimir Rokhlin whose research influenced and laid much of the mathematical foundations of the field. The purpose is to identify fields of research that are likely to be both in demand by applications, and intellectually ripe for substantial progress.  (3) Poster sessions. Younger researchers will be invited to present posters during the meeting with prime slots in the schedule reserved for poster sessions, and for a `poster blitz' presentation.   A major goal of this conference is to educate the younger generation about critical needs in the analysis of data, important open problems and underlying areas of mathematical research.  The scientific techniques under discussion are likely to have a profound impact on important applications. In particular help overcome key challenges in computing today and in the future (the ""deluge of data"" problem and the communication speed bottleneck).  The involvement of young researchers will contribute to work force development in key STEM areas."
"1217118","Computational methods for the study of rare events","DMS","COMPUTATIONAL MATHEMATICS","08/01/2012","07/16/2012","Maria Cameron","MD","University of Maryland, College Park","Standard Grant","Leland Jameson","07/31/2016","$287,174.00","","cameron@math.umd.edu","3112 LEE BLDG 7809 REGENTS DR","College Park","MD","207420001","3014056269","MPS","1271","9263","$0.00","The research problem is concerned with developing computational tools for (A) rare reactive events and (B) seismic modeling. (A): The problem of finding the most likely transition paths in systems that are modeled using stochastic differential equations with small noise is very difficult due to several issues: (1)transitions between metastable states of the system are rare, hence direct simulations are very hard; (2)high dimensionality; (3) expensive-to-evaluate force; (4) multiple local minimizers; (5) temperature dependence of the dominant reactive channel. The investigator plans to explore a Hamilton-Jacobi-based approach for the study of rare transitions. It has important advantages over existing path-based methods. This approach is guaranteed to find the global minimizer and requires no initial guess. Furthermore, it allows us to find the most likely transition paths between any attractors of the system, not only between equilibrium points. The main difficulties in this approach are associated with high dimensionality and the anisotropic and unbounded speed function in the Hamilton-Jacobi equation.  The investigator proposes several approaches for dealing with these problems.   (B):   The majority of methods for finding the sound speed inside the Earth (the seismic velocity) rely on vast computing resources and a good initial guess. The investigator and her colleagues propose an alternative approach that is computationally cheap and requires no initial guess. This approach is based on theoretical relationships between the time-migration velocity and the seismic velocity. The sound speed can be recovered by solving an elliptic partial differential equation with Cauchy data. Despite the fact that this problem is ill-posed, they have developed numerical techniques capable of solving it in the required interval of time. The investigator plans to continue research in this direction and incorporate methods from the field of computational stochastic processes. <br/><br/>Many processes are modeled using stochastic differential equations, which are evolution laws that involve a random term (noise).  Examples include small-scale processes in physics and chemistry such as chemical reactions and conformal changes in molecules.  Other examples come from stochastically-modeled computer networks, pricing of financial securities, and the distribution of money in society.  In the absence of noise a given system evolves toward one of its equilibrium states and stays there forever. But the presence of noise, even arbitrarily small, enables transitions between the equilibrium states. In many important cases these transitions are rare on the time-scale of the system but not rare on a human time-scale. This fact creates a need for techniques besides direct simulation for the study of these rare transitions. Such study will help to understand such phenomena as protein folding and mechanisms for gene expression.  Producing an accurate image of the Earth?s interior is a challenging aspect of such things as oil recovery and earthquake analysis.  First, seismic data always contain noise and the deeper the data come from the stronger its influence. Second, important and interesting geological features (e.g. oil deposition) typically occur where the subsurface structures are complicated and sound speeds vary severely in lateral (sideways) directions.  In result, the fundamental inverse problem of determining the sound speeds of the Earth is ill-posed and exceedingly difficult. Yet determination of sound speed is crucial for accurate seismic imaging. The approach proposed by the investigator and her colleagues will lead to cheaper and more efficient methods for its determination."
"1216868","Collaborative Research: Adaptive Methods and Finite Element Exterior Calculus for Nonlinear Geometric PDE","DMS","COMPUTATIONAL MATHEMATICS","09/01/2012","08/14/2012","Ryan Szypowski","CA","Cal Poly Pomona Foundation, Inc.","Standard Grant","Leland Jameson","08/31/2015","$37,077.00","","rsszypowski@cpp.edu","3801 W TEMPLE AVE","POMONA","CA","917682557","9098692948","MPS","1271","9263","$0.00","The primary technical aim of this project is to develop general approximation theory and reliable, convergent adaptive methods for the intrinsic discretization of a general class of nonlinear geometric elliptic and evolution PDE on Riemannian 2- and 3-manifolds.  The investigators will exploit the variational crimes framework they have developed for the finite element exterior calculus (FEEC), extending the FEEC to nonlinear elliptic problems, to problems on hypersurfaces, and to nonlinear parabolic and hyperbolic problems.  This framework will aid in the design, development, and convergence analysis of AFEM algorithms for use with FEEC.  This approach will allow for a more natural and general treatment of geometric error due to variational crimes in a posteriori analysis, following their recent approach for a priori analysis. After obtaining a solid theoretical framework for a posteriori analysis, yielding a posteriori error estimates and local indicators, they will develop and analyze adaptive finite element methods (AFEM) within the extended FEEC framework. The convergence analysis approach will be based on their recent published work on AFEM convergence analysis for mixed formulations of linear elliptic problems. The overall goal is to develop a complete AFEM convergence theory in FEEC, complementing the recently developed contraction frameworks for non-mixed formulations of Poisson-type problems and semilinear generalizations. Both prototype and production implementations will be produced, using the opensource FETK ToolKit, and the resulting software will be used in ongoing collaborations with physical scientists and engineers.<br/><br/>The investigators will study and develop methods for the approximate solution of systems of stationary and evolution partial differential equations (PDE) arising at the intersection of mathematical physics and geometric analysis. Such systems of equations, known as Geometric PDE, appear in a wide range of physical and mathematical problems; examples include Maxwell's equations (or more generally the Yang-Mills equations), Einstein's field equations, and other Hamiltonian systems. The Cauchy (or initial-value) formulation for such systems yields a constrained evolution system containing non-dynamical equations. These non-dynamical geometric PDE are of great interest in their own right; examples include the Yamabe problem, the Hamiltonian and momentum constraints in the Einstein equations, and the Monge-Ampere equations, among others. If our goals are achieved, the results of this project will have a broad impact on areas of mathematics such as geometric analysis, as well as in astrophysics and general relativity. The methods developed here will contribute to the advancement of numerical methods for complex three-dimensional constrained nonlinear dynamical simulations. The simulation technology we produce will provide powerful tools for the exploration of models in astrophysics and relativity as well as in some areas of pure mathematics such as geometric analysis. Graduate students involved in the project will be co-trained by both investigators; this will involve regular interaction between the members of the teams at both partner institutions.  The PI has previously collaborated on such a shared training structure with great success on past projects; this shared training and transfer of knowledge and skills between the two research groups will be an invaluable research resource to both groups."
"1216559","Novel Numerical Approximation Techniques for Non-Standard Sampling Regimes","DMS","COMPUTATIONAL MATHEMATICS","09/01/2012","08/13/2014","Anne Gelb","AZ","Arizona State University","Standard Grant","Leland Jameson","08/31/2016","$336,853.00","Rosemary Renaut, Janis Morey Naugle","annegelb@math.dartmouth.edu","660 S MILL AVENUE STE 204","TEMPE","AZ","852813670","4809655479","MPS","1271","9251, 9263","$0.00","Title: Novel Numerical Approximation Techniques for Non-Standard Sampling Regimes<br/><br/>Anne Gelb and Rosemary Renaut<br/><br/>The PIs build on their recently developed techniques that fuse methods<br/>from numerical approximation and inverse theory, such as for purposes<br/>of reconstruction fidelity, with those that exploit specific application<br/>information, such as sparsity.   Their methods  address both theoretical<br/>and practical considerations. Algorithms are proposed for function and/or<br/>image recovery,  as well as to characterize and extract important information<br/>from a data set, such as edges, or other features, without necessarily<br/>determining the underlying function.  Research objectives include (i)<br/>developing novel approximation approaches for functional and/or feature<br/>recovery from data that is deficient with respect to one or multiple<br/>perspectives, i.e. data is under-sampled or missing, may be noisy, is<br/>measured  via a dual representation, or is otherwise non-standard with<br/>respect to traditional numerical approximation techniques; (ii) developing<br/>numerical approximation operators that can be directly applied to practical<br/>data sets, or may provide a feedback to practitioners for improving sampling<br/>protocols; and (iii) integrating techniques from numerical linear algebra<br/>and statistical regularization that are specifically pertinent for obtaining<br/>robust but efficient solutions of ill-conditioned problems when handling<br/>practical data.  This research will provide rigorous analysis of all new<br/>algorithms in terms of  accuracy, efficiency, and robustness, especially<br/>in the presence of of noise, perturbations, or otherwise incomplete data<br/>information.<br/><br/>Practical data collection techniques are becoming increasingly more<br/>sophisticated.  User friendly software packages allow disciplinary<br/>scientists to successfully diagnose, predict, model, and determine<br/>important characteristics from a plethora of measured data.   Yet,<br/>recent investigations into various reconstruction algorithms for data<br/>collected under modern magnetic resonance imaging (MRI) protocols<br/>have clearly demonstrated shortcomings that arise when pragmatic<br/>algorithmic modifications are used without considering fundamental<br/>mathematical issues regarding accuracy and measurement error.  Some<br/>currently employed algorithms in fact yield both incorrect diagnoses<br/>and additional procedural costs.  This project extends the PIs prior<br/>research and addresses the development of novel mathematical techniques<br/>for handling issues associated with extracting functional and feature<br/>information from data acquired by non-standard sampling protocols.<br/><br/>"
"1216567","Collaborative Research: Methods for Stochastic and Nonlinear Optimization","DMS","COMPUTATIONAL MATHEMATICS, OPERATIONS RESEARCH","08/01/2012","07/24/2012","Jorge Nocedal","IL","Northwestern University","Standard Grant","Rosemary Renaut","07/31/2016","$300,000.00","","j-nocedal@northwestern.edu","633 CLARK STREET","EVANSTON","IL","602080001","3125037955","MPS","1271, 5514","073E, 9263","$0.00","The projects described in this proposal are designed to advance the capabilities of optimization methods for a class of stochastic and deterministic optimization problems. The first project focuses on  problems where the objective function is given by an expectation or a loss function. We propose dynamic sample algorithms that attempt to bridge the gap between stochastic and batch  methods. Their essential characteristic is that they adapt the sample size during the progression of the optimization in a manner that leads to low computational effort and high accuracy in the solution, when so desired. The second project deals with the design of new active-set methods for solving constrained optimization and convex regularized L1 problems.  Our work builds on two algorithms recently proposed in the literature: the block active-set method (also called the primal-dual active-set method), and the orthant-wise method  for solving L1 regularized problems. Our new algorithms are provably convergent and applicable to a wider class of applications. The third project addresses the need to improve the robustness of nonlinear optimization methods in the presence of infeasibility. Our first goal is to design an interior point method endowed with infeasibility detection capabilities, and to show how its main mechanism can be extended to other interior point methods. The second goal is to develop a convergence theory that is applicable to both active set and interior point methods consisting of three components:  an optimization phase, a feasibility phase, and a mechanism for transitioning between the two phases.<br/><br/>The methods developed in this project are useful in big data analysis, which is playing a vital role in genomics, materials science, meteorology, climate modeling and  information science. In all these disciplines, vast amounts of data have become available in the last decade, with the rate of  generation  accelerating exponentially.  The challenge is to process this large amount of information to make inferences and predictions, thereby accelerating our basic understanding of physical and social systems. For example, the complex physics simulations employed in the design of advanced materials, meteorology and climate modeling, require the use of detailed information obtained over a large set of scenarios. The optimization and machine learning methods developed in this project can be integrated in support of such simulations, thereby obviating the need for  extremely complex models that are difficult to study and generalize. Our work has direct impact in genomics and other areas of biology. For example, we plan to investigate its use in metagenomics, specifically de novo assembly of next generation DNA sequencing data.  Sequences  can be tagged with markers, or found in reference data sets like transcriptomes.  A goal is to use this new information to enable faster and more accurate de novo assembly.  In computer science and information technology, our new algorithms will be useful in the development of a new generation of speech recognition and computer vision systems. Speech recognition, which will play an increasingly important role in many technological applications, can only advance by incorporating more data more intelligently, and the algorithms described in this proposal are designed precisely for that purpose."
"1216857","Collaborative Research: Adaptive Hybridized DG Methods for Acoustic and Electromagnetic Scattering","DMS","COMPUTATIONAL MATHEMATICS","08/01/2012","07/18/2012","Ronald Hoppe","TX","University of Houston","Standard Grant","Leland Jameson","07/31/2016","$148,814.00","","rohop@math.uh.edu","4300 MARTIN LUTHER KING BLVD","HOUSTON","TX","772043067","7137435773","MPS","1271","9263","$0.00","In this project, the investigator and his colleagues will develop, analyze, and implement quasi-optimal adaptive hybridized Discontinuous Galerkin methods for acoustic and electromagnetic scattering problems as described by the Helmholtz equation and the time-harmonic Maxwell equation on bounded domains in two and three dimensional domains using general local bases. These methods feature traditional piecewise polynomial bases as well as special purpose wave elements, and multilevel preconditioned iterative solvers on adaptively refined simplicial, quadrilateral, and hexahedral meshes. The adaptive mesh refinement is driven by residual-type a posteriori error estimators. In particular, the team will prove convergence of the adaptive solution process as well as its quasi-optimality in terms of the computational complexity with respect to a properly specified approximation class. High quality software implementations will be used to test the algorithms and inform the analysis.<br/><br/>Advances in the state of the art in numerical methods for performing acoustic and electromagnetic simulations have potentially high impact in several applications. As an example more accurate simulation of acoustic wave propagation can be used to considerably enhance resolution of medical ultra sound scans, and thus expand the reach of non-invasive diagnostics. The emphasis of this project is the development of novel numerical methods that compute provably accurate approximations of physical acoustics and electromagnetics phenomena."
"1216907","Collaborative Research: New Formulation and Algorithms for Fluid-Structure Interaction, with Application to Tumor Growth","DMS","COMPUTATIONAL MATHEMATICS","09/15/2012","09/14/2012","Jianjun Paul Tian","VA","College of William and Mary","Standard Grant","Leland Jameson","07/31/2014","$130,000.00","","jtian@nmsu.edu","1314 S MOUNT VERNON AVE","WILLIAMSBURG","VA","231852817","7572213965","MPS","1271","9263","$0.00","Fluid-structure interaction (FSI) problems play prominent roles in many scientific and engineering fields, yet an accurate study of such problems remains highly challenging due to the strong nonlinearity and multi-physics involved. Current computational theory and methods for fluid-structure interactions lack sufficient accuracy and realistic material representations, and are limited to relatively simple structural configurations. The goal of this project is to overcome such limitations by establishing a new computational mathematical framework for accurate and efficient numerical investigation of complex FSI problems, particularly for tumor growth modeling and simulation. The PIs will derive new mathematical formulation that allows the study of general FSI problems with sophisticated structural settings, develop efficient numerical algorithms that ensure high accuracy in FSI computations, and apply the proposed mathematical formulation and computational methods to the individual-cell-based modeling and simulation of tumor growth. This proposal builds on the PIs? solid background in computational and applied mathematics and significant work on tumor modeling.<br/><br/>The proposed research will improve the understanding of the nonlinear dynamics in highly complex FSI problems through a combined mathematical and computational framework. Experimental measurements will also be used for validating the numerical results. The success of this project will not only provide a solid knowledge base for advancing the current state of computational FSI study, but also enable important discoveries in the fundamental mechanism of early tumor formation and development. The project experiences and findings will strengthen the research collaboration and curriculum development in computational mathematics and mathematical biology at both Old Dominion University and the College of William and Mary. Due to the close geographical proximity between the two schools, project impacts will be maximized through convenient communication between faculty and students and through joint programs between the two schools. Education and outreach activities will involve graduate and undergraduate students in the theory, methods and application of computational mathematics."
"1217008","A High Order Semi-Lagrangian Approach for the Vlasov Equation","DMS","COMPUTATIONAL MATHEMATICS","08/01/2012","07/16/2012","Jing-Mei Qiu","TX","University of Houston","Standard Grant","Leland Jameson","07/31/2016","$185,500.00","","jingqiu@udel.edu","4300 MARTIN LUTHER KING BLVD","HOUSTON","TX","772043067","7137435773","MPS","1271","9263","$0.00","In this proposal,  the investigator proposes to develop a very high order mesh-based numerical method for Vlasov simulations. In the phase space, the proposed methodology couples the high order finite element discontinuous Galerkin (DG) method for spatial advection and for computing long range forces by field equations (Maxwell's or Poisson's equations) and the high order finite difference weighted essentially non-oscillatory (WENO)  scheme for particle interactions in velocity directions via operator splitting. The methodology is designed to take advantages of the DG method in its flexibility and compactness in handling complicated geometry, and the WENO reconstructions in their robustness and stability in resolving complicated/under-resolved solution structures. To improve computational efficiency, the investigator proposes to use extra large numerical time steps by using semi-Lagrangian framework for advection. A suitable numerical solution space is designed to ensure high order coupling among different numerical methods in six-dimensional phase space. Spectral/integral deferred correction framework is proposed to guarantee high order temporal accuracy. Besides the high order accuracy in both space and time, the proposed scheme would be designed to be mass conservative and positivity preserving, which are two important properties of the analytical solution. The investigator and her group are going to perform convergence study, as well as track the time evolution of physically conserved quantities (e.g. momentum and energy) as a measurement of the quality of the proposed scheme.<br/><br/>The intellectual merit of the proposed activity lies in the development of a robust, efficient and highly accurate numerical algorithm under a semi-Lagrangian framework for Vlasov simulations.  The objective of the proposed project is to design a high order numerical approach that allows for relatively coarse spatial mesh with accuracy and extra large numerical time steps with stability. At the same time, theoretical accuracy and stability properties of the proposed scheme under relatively simple setting (e.g. linear equations) will be studied. The theoretical study will provide a solid foundation, as well as a good guidance, to the design of numerical algorithm. The well-developed algorithm will have impact in fusion simulations, as well as other applied fields such as astrophysics, semi-conductor device simulations. Further impact comes from the multidisciplinary nature of the proposed research, as well as the training of undergraduate and graduate students."
"1217006","Collab. Research: Instability analysis of the split-step method on spatially-varying  backgrounds, with applications to optical telecommunications and Bose-Einstein condensation","DMS","COMPUTATIONAL MATHEMATICS","09/15/2012","09/12/2012","Taras Lakoba","VT","University of Vermont & State Agricultural College","Standard Grant","Rosemary Renaut","08/31/2016","$181,836.00","","tlakoba@uvm.edu","85 S PROSPECT STREET","BURLINGTON","VT","054051704","8026563660","MPS","1271","9150, 9263","$0.00","The operator-splitting, or split-step, method (SSM) is widely used to numerically solve time-dependent partial differential equations arising in diverse applications, from hydrodynamics to quantum mechanics. To minimize the computational time, one needs to select the time step as large as possible. On the other hand, the upper bound on the time step is often set by the requirement that the numerical scheme be stable. The von Neumann analysis is used to obtain such upper bounds for model problems where the coefficients are constant. However, solutions of practically interesting equations are typically not constant in space. To justify the use of the von Neumann analysis for such problems, one often approximates non-constant coefficients by constant ones. However, for the SSM, this approach fails. Recently, we proposed an alternative approach to analyze the instability of the SSM when this method is used to simulate a solution close to the soliton (i.e., a bell-shaped solution) of the nonlinear Schroedinger equation. In this project, we will extend that analysis to more practically relevant settings that involve two applications: fiber optical telecommunications and Bose?Einstein condensates. This will provide an understanding of the development of the numerical instability in problems with essentially non-constant coefficients. We will then use this information to propose modifications of the SSM with relaxed stability requirements. Clearly, this will reduce the computational time.<br/><br/>This project will develop a systematic approach to studying a fundamental property ""stability"" of a widely used numerical method, the SSM. A numerical method must be stable in order to accurately model the physical process of interest. The current approach to the stability analysis consists in approximating the simulated processes by some constant values. We will not use this approximation, as we have demonstrated that it leads to incorrect predictions regarding the performance of the SSM. Our alternative approach will rely on a combination of techniques from numerical analysis and the theory of linear differential equations. It will provide an understanding of the performance limitations of the SSM. This, in turn, will allow us to propose more efficient and reliable modifications of this numerical method. The applications considered in this project will directly impact the modeling of fiber-optic communication systems and low-temperature atomic condensates. However, our approach will affect other applications of the SSM, which include environmental modeling, hydrology, heat conduction, and reacting flows. Moreover, the approach can be extended to related numerical methods, which are used in other applications such as the modeling of the interaction among molecules and chemical species through reactions and random motion (diffusion)."
"1216393","Computational problems in tensors and quantum information theory","DMS","COMPUTATIONAL MATHEMATICS","09/15/2012","09/11/2012","Shmuel Friedland","IL","University of Illinois at Chicago","Standard Grant","Leland Jameson","08/31/2016","$140,000.00","","friedlan@uic.edu","809 S MARSHFIELD AVE M/C 551","CHICAGO","IL","606124305","3129962862","MPS","1271","9263","$0.00","The first aim of this proposal is to develop theoretical and computational methods for common problems in tensors: small rank approximations, best rank approximations, uniqueness of best rank approximations, approximations of tensors preserving symmetries, rank of tensors, norm computations, finding the number of singular values tuples, computing singular value tuples, computing nonlinear eigenvalues. The second aim of this proposal is the use of theoretical and computational methods in tensors for central problems in Quantum Information Sciences: separability, the capacity of quantum channels and the computational complexity of these quantities.<br/><br/>High dimensional problems arise in many areas of applications such as mathematical biology, chemistry, physics, image processing, finance or engineering. The typical mathematical model uses tensors,  i.e., multidimensional arrays, to represent the physical model and the computational methods for simulation and optimization can usually be based on operations with these tensors. For higher order tensors the theory and the development of numerical methods is much more complicated than for matrices, i.e. two  dimensional arrays. The aim of this proposal to study, find and apply new techniques in tensors to advance the current machinery for applications in biology, engineering and science."
"1216927","Collaborative Research: A Computational Framework for Non-asymptotic Homogenization with Applications to Metamaterials","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/15/2012","07/16/2014","Igor Tsukerman","OH","University of Akron","Continuing Grant","Leland Jameson","06/30/2016","$196,755.00","","itsukerman@uakron.edu","302 BUCHTEL COMMON","AKRON","OH","443250002","3309722760","MPS","1266, 1271","9263","$0.00","The project is aimed at developing a non-asymptotic homogenization<br/>theory of Maxwell's equations in artificial periodic composites<br/>(metamaterials). Currently, there is a consensus that sufficiently<br/>large lattice cell sizes are necessary for some nontrivial physical<br/>effects to occur in such structures. (The most intriguing of these<br/>effects is high-frequency magnetism.) Classical homogenization<br/>theories work well in the zero-cell-size limit but are difficult to<br/>apply to large metamaterial cells. In contrast, the proposed theory is<br/>non-asymptotic and does not involve any series expansions with respect<br/>to the cell size. The electromagnetic field in the material is<br/>approximated by a finite set of functions (modes) usually but not<br/>necessarily Trefftz functions such as Bloch waves. The coarse-grained<br/>fields and flux densities are defined via curl-conforming and<br/>div-conforming interpolations, respectively. A linear map between<br/>these interpolants is established and defines an extended material<br/>tensor. In a certain canonical basis, this extended tensor has a<br/>classical block of 36 local parameters and a novel block quantifying<br/>nonlocal effects. From the differential-geometric perspective, this<br/>constitutive relationship can be viewed as a realization of<br/>Bossavit-Hiptmair's discrete Hodge operators (linear maps between<br/>discretized 1-forms that correspond to vector fields and 2-forms that<br/>correspond to fluxes).<br/><br/>Over the last decade, metamaterials have attracted unprecedented<br/>attention due to a variety of potential applications that include<br/>superlensing, electromagnetic cloaking, electromagnetically-induced<br/>transparency, efficient antennas, and more. Experimental<br/>demonstrations of these effects have been limited to proofs of<br/>principle and at optical frequencies have so far been incomplete.<br/>Subwavelength optical imaging has been achieved only in the<br/>quasi-static (near-field) regime, standard for the more conventional<br/>near-field optics; the so-called ""carpet cloak"" conceals surface bumps<br/>rather than 3D objects, and so on. Moreover, applications that do not<br/>depend critically on the effective medium description of metamaterials<br/>appear to be more easily achievable than the ones that do. The latter<br/>group includes, notably, superlensing and cloaking. This suggests<br/>that, to make further progress, theoretical and mathematical issues at<br/>the heart of metamaterial science must be unambiguously resolved. The<br/>main problem can be stated as follows. Given the composition of a<br/>metamaterial cell and the operating frequency, determine whether this<br/>metamaterial can be reasonably described as a continuous medium with<br/>some effective parameters, just like any natural optical material; if<br/>the answer is positive, develop a rigorous methodology for such a<br/>description. The proposed research is aimed at solving this problem in<br/>the most difficult case when the cell size of the composite is an<br/>appreciable fraction of the wavelength of light. The methodology, once<br/>developed, will allow the scientific community to delineate the<br/>possible from the impossible in the field of metamaterials.<br/>The intellectual merit of the proposed research is in the development<br/>of a new paradigm of non-asymptotic homogenization, of new<br/>computational methods related to it, and in the application of the<br/>proposed methodology to electromagnetic metamaterials, allowing one to<br/>gain a much deeper understanding of their properties and limitations.<br/>As a new area of research, non-asymptotic homogenization will also<br/>have a broader technical impact in other areas of applied physics and<br/>engineering, such as acoustics, heat transfer and possibly elasticity."
"1159138","FRG: Collaborative Research: Singularities, mixing and long time behavior in nonlinear evolution","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/01/2012","03/30/2012","Thomas Hou","CA","California Institute of Technology","Standard Grant","Michael Steuerwalt","06/30/2015","$250,000.00","","hou@acm.caltech.edu","1200 E CALIFORNIA BLVD","PASADENA","CA","911250001","6263956219","MPS","1266, 1271","1616, 9263","$0.00","The project seeks to advance knowledge in mathematics of fluids, a subjectwith links to engineering, physics, chemistry and many other sciences. The major goal of the project is the development of new techniques to achieve breakthroughs in our understanding of fluid dynamics phenomena. The project research will address fundamental properties of the classical equations of fluid dynamics, qualitative properties of solutions, and modeling applications. The project focuses on three main directions. The first set of problems concerns global regularity vs finite time blow up that will be investigated for a range of fundamental equations of fluid mechanics. Axi-symmetric solutions for 3D Euler and Navier-Stokes will be considered, new potentially singular scenarios will be studied and new regularity criteria will be sought. Active scalars, such as surface quasi-geostrophic equation coming from atmospheric science, will also be analyzed -- here the effort will concentrate on studying properties of solutions, search for new Lyapunov functionals and novel regularity estimates. In the second direction, we will seek more detailed information on long time dynamics. This will include research on some long-open conjectures for 2D Euler equation, including possible mechanisms of inverse energy cascade, mixing and small scales formation. We will also work on passive scalar models and mixing properties of flows in this context. Biomixing by chemotaxis will be investigated as well, with an eye towards applications in ecology and marine biology. The third direction focuses on complex fluid models. In many applications - for instance, in studies of particle suspensions or solutions - the microscopic structure of   particles in the fluid becomes important. The shape and interactions between the particles can be taken into account by adding kinetic equations to the fluid dynamics systems and introducing physically natural couplings. Analysis of solutions to such systems, their regularity and qualitative properties will be a part of the project work.<br/><br/>Fluids are ubiquitous in nature, science and engineering. Diverse phenomena involving fluids appear in atmospheric and ocean science, astrophysics, chemistry and biology, and are described by partial differential equations of fluid mechanics. These equations are some of  <br/>the most difficult partial differential equations to analyze. They   describe a wide range of complex phenomena, are nonlinear, and usually   nonlocal. Due to their complexity, even the classical equations such   as 3D Euler and Navier-Stokes are far from well understood. The   proposed research lies at the interface of several central areas of mathematics - partial differential equations, dynamical systems, functional analysis and Fourier analysis. This FRG project   brings together several researchers that have been at the forefront of recent developments in mathematical fluid mechanics. Different   participants bring different strengths to the project. It is expected that intensive collaboration within FRG framework will lead to   development of new ideas and approaches and result in a burst of activity in mathematics of fluids. New techniques and tools developed   are likely to have an impact in neighboring areas of mathematics,  biology, and atmospheric science. An important part of the FRG   activity will be training of junior researchers.  Mathematics of fluid  mechanics covers a broad range of effective techniques, which are   applicable beyond fluids. The training activities will include a   summer school, two workshops, group meetings, course development,   research seminars and research projects for advanced undergraduate   students. The principal investigators will advertise all training   activities broadly, and strive to recruit talented, motivated, and   diverse trainees. Special attention will be paid to recruitment of   groups under represented in mathematics."
"1213384","Gene Golub SIAM Summer School","DMS","COMPUTATIONAL MATHEMATICS","08/01/2012","07/30/2012","Francis Giraldo","CA","Naval Postgraduate School","Interagency Agreement","Leland Jameson","07/31/2013","$30,000.00","","fxgirald@nps.edu","1 UNIVERSITY CIR","MONTEREY","CA","939435098","8316562271","MPS","1271","7232, 7556, 9263","$0.00",""
"1217175","Collaborative Research: Adaptive Methods and Finite Element Exterior Calculus for Nonlinear Geometric PDE","DMS","COMPUTATIONAL MATHEMATICS","09/01/2012","08/14/2012","Michael Holst","CA","University of California-San Diego","Standard Grant","Leland Jameson","08/31/2016","$145,001.00","","mholst@math.ucsd.edu","9500 GILMAN DRIVE","LA JOLLA","CA","920930021","8585344896","MPS","1271","9263","$0.00","The primary technical aim of this project is to develop general approximation theory and reliable, convergent adaptive methods for the intrinsic discretization of a general class of nonlinear geometric elliptic and evolution PDE on Riemannian 2- and 3-manifolds.  The investigators will exploit the variational crimes framework they have developed for the finite element exterior calculus (FEEC), extending the FEEC to nonlinear elliptic problems, to problems on hypersurfaces, and to nonlinear parabolic and hyperbolic problems.  This framework will aid in the design, development, and convergence analysis of AFEM algorithms for use with FEEC.  This approach will allow for a more natural and general treatment of geometric error due to variational crimes in a posteriori analysis, following their recent approach for a priori analysis. After obtaining a solid theoretical framework for a posteriori analysis, yielding a posteriori error estimates and local indicators, they will develop and analyze adaptive finite element methods (AFEM) within the extended FEEC framework. The convergence analysis approach will be based on their recent published work on AFEM convergence analysis for mixed formulations of linear elliptic problems. The overall goal is to develop a complete AFEM convergence theory in FEEC, complementing the recently developed contraction frameworks for non-mixed formulations of Poisson-type problems and semilinear generalizations. Both prototype and production implementations will be produced, using the opensource FETK ToolKit, and the resulting software will be used in ongoing collaborations with physical scientists and engineers.<br/><br/>The investigators will study and develop methods for the approximate solution of systems of stationary and evolution partial differential equations (PDE) arising at the intersection of mathematical physics and geometric analysis. Such systems of equations, known as Geometric PDE, appear in a wide range of physical and mathematical problems; examples include Maxwell's equations (or more generally the Yang-Mills equations), Einstein's field equations, and other Hamiltonian systems. The Cauchy (or initial-value) formulation for such systems yields a constrained evolution system containing non-dynamical equations. These non-dynamical geometric PDE are of great interest in their own right; examples include the Yamabe problem, the Hamiltonian and momentum constraints in the Einstein equations, and the Monge-Ampere equations, among others. If our goals are achieved, the results of this project will have a broad impact on areas of mathematics such as geometric analysis, as well as in astrophysics and general relativity. The methods developed here will contribute to the advancement of numerical methods for complex three-dimensional constrained nonlinear dynamical simulations. The simulation technology we produce will provide powerful tools for the exploration of models in astrophysics and relativity as well as in some areas of pure mathematics such as geometric analysis. Graduate students involved in the project will be co-trained by both investigators; this will involve regular interaction between the members of the teams at both partner institutions.  The PI has previously collaborated on such a shared training structure with great success on past projects; this shared training and transfer of knowledge and skills between the two research groups will be an invaluable research resource to both groups."
"1216700","Collaborative Research: Efficient Unstructured Discontinuous Galerkin Methods for Global Nonhydrostatic Atmospheric Modeling","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, OPPORTUNITIES FOR RESEARCH CMG","08/01/2012","09/21/2018","Francis Giraldo","CA","Naval Postgraduate School","Interagency Agreement","Leland Jameson","07/31/2015","$348,878.00","","fxgirald@nps.edu","1 UNIVERSITY CIR","MONTEREY","CA","939435098","8316562271","MPS","1266, 1271, 7215","4444, 7215, 7232, 9263","$0.00",""
"1217268","RUI: Investigation of Discontinuous Galerkin Least-Squares Finite Element Methods for Singularly Perturbed Problems","DMS","COMPUTATIONAL MATHEMATICS","09/15/2012","09/12/2012","Runchang Lin","TX","Texas A&M International University","Standard Grant","Rosemary Renaut","08/31/2016","$159,357.00","","rlin@tamiu.edu","5201 UNIVERSITY BLVD","LAREDO","TX","780411920","9563263026","MPS","1271","9229, 9263","$0.00","The research objective of this project is to investigate discontinuousGalerkin least-squares finite element methods (DG-LS FEMs) for <br/>reaction-diffusion problems with singular perturbations. The numerical approximation of singularly perturbed problems is a practically important but still difficult subject. The analytical solutions to such problems typically contain boundary or interior layers, which cause nonphysical excessive numerical oscillations in the vicinity of layers in the solutions by standard finite element method and finite difference method. Many stabilization techniques have been developed to improve numerical solutions. The drawback of these techniques is the presence of problem-dependent parameters that need to be properly tuned according to a priori knowledge of layers, which nonetheless is not achievable in most complex problems. The DG-LS FEM is robust and efficient, which does not involve such problem-dependent parameters. The proposed research will advance knowledge and understanding of the DG-LS FEM as well as singular perturbation problems, provide a theoretical framework for the analysis of DG-LS FEMs, and establish a working principle of efficient and high quality adaptive schemes.<br/> <br/>Singularly perturbed problems have attracted a lot of attention from engineers, mathematicians and scientists because of a wide range of important applications such as fluid dynamics, electromagnetism, semiconductor research, chemotaxis, genetics, and computational biology. Numerical approximations are usually the only way for solving such problems. There is an urgent need for a problem-dependent-parameter-free numerical method for singularly perturbed problems. This project is to develop creative solutions to fulfill this need, which will lead to reliable and efficient numerical approaches for solving complex singularly perturbed reaction-diffusion problems."
"1217154","Accurate high performance computing for nonlinear collisional kinetic theory","DMS","COMPUTATIONAL MATHEMATICS","09/15/2012","05/04/2015","Irene Gamba","TX","University of Texas at Austin","Standard Grant","Junping Wang","08/31/2015","$167,677.00","Jeffrey Haack","gamba@math.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271","9263","$0.00","This work will implement, analyze, and benchmark accurate numerical schemes for nonlinear collisional kinetic equations and their extension to high performance computing. Kinetic equations describe physical systems at the mesoscopic level, where there are large numbers of interactions between particles but they are not frequent enough to be described as a continuum. At each point in phase space a nonlinear integral term models the effect of interactions with all of the other particles in the system. This integral is difficult and expensive to evaluate due to the delicate conservation structure of the interactions and its dimensionality, however it has many properties that makes it well-suited for parallel computation. This work seeks to overcome the computational bottleneck of the collisional integral term in kinetic models by adapting a conservative spectral numerical method to massively parallel computer architectures, and will investigate how this scales with increasing computational nodes. The proposed work will further enhance the method by applying high order space and time discretization to the transport terms in the system, which was previously infeasible due to the expense of evaluating the collision term, as well as investigating methods for reducing the complexity of the integration for further efficiency. It will also carefully investigate the order of accuracy of computation with regards to the velocity domain cutoff and quadrature. This work will extend the conservative spectral method to the case of anisotropic in angle collisional models, in particular the grazing collisions (Landau) limit and applications to collisional plasma models. Finally, this work will attempt to extend the ideas of asymptotic-preserving schemes to efficiently compute the collision term in stiff regimes.<br/><br/>Many important problems in science can be described at the molecular level as individual particles bouncing around, each with its speed and direction. These particles interact with each other as well as other objects through collisions that exchange energy and momentum, and the average behavior of these interactions can be felt as wind, for example. Kinetic models describe problems where particle density is low enough that collisional effects matter in the dynamics of the problem, but is not so strong that one can simply use the average behavior to describe the evolution. Kinetic models can characterize a wide variety of applications such as design of nano- and micro-scale devices, energy applications in plasma physics such as semiconductors and nuclear fusion, and atmospheric re-entry for spacecraft and satellites. In addition to physical applications, these models can be used for the modeling of biological and social dynamics, such as the dynamics of crowds in confined spaces, or modeling the flocking and herding of animals, which could be of security and environmental interest. This work will develop new simulation tools that are able to leverage high performance computing resources to perform high accuracy simulation of problems that were previously computationally infeasible, which can provide a broader view of kinetic applications."
"1217071","Collaborative Research:  Computational Methods for Simulating Complex Coastal Watersheds and Floodplains","DMS","COMPUTATIONAL MATHEMATICS","09/01/2012","08/31/2012","Clinton Dawson","TX","University of Texas at Austin","Standard Grant","Rosemary Renaut","08/31/2016","$165,000.00","","clint@ices.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271","9263","$0.00","Accurate and efficient computational modeling of rainfall flooding events presents significant challenges. These challenges are primarily due to the complex topology of coastal watersheds and floodplains, and in particular urban environments, which include numerous features relevant to flooding such as small-scale drainage channels, piping networks, etc, that receive stormwater from both the landfall of storm surge and runoff/overland flow due to rainfall.  The primary objective of this project is improve the predictive capability of coastal hydrodynamic models for flooding in complex coastal watersheds and floodplains using a novel multi-physics modeling paradigm. An adaptive multi-physics/multi-dimensional modeling approach will be investigated that can adaptively switch between various models in order to simultaneously optimize physical correctness and computational efficiency. The development of such an approach, along with the supporting concepts and numerical tools that will make its application to full-scale problems possible, is the main goal of the proposed research. This work will be explored in the context of discontinuous Galerkin methods, building and expanding on the PIs' extensive work in the area of shallow water modeling using high-order discontinuous Galerkin methods.<br/><br/>Recent storm events, for example Hurricane Irene, which led to extensive flooding along much of the U.S. East Coast, have demonstrated the severe vulnerability of coastal lowlands and watersheds to storm surge combined with torrential rainfall.  These types of disasters highlight the rising importance of effective emergency management and hazard mitigation, and the need for advanced, physics-based models to better understand their impacts.  The potential for future storms with destructive flooding in low-lying coastal areas due to inland storm surge combined with torrential rainfall is high.  Observations show an increase in hurricane intensity in the North Atlantic since the 1970s and research suggests continued increases in storm intensity and significant potential for heavy rainfall in many regions. The devastating flooding related to these events, along with predicted rapid coastal development, will result in greater coastal risk in the future and poses serious challenges to physical infrastructure, water quality, and sustainability of coastal communities.  The research under this project will have a significant impact on the development of the next generation of coastal hydrodynamic models.  Additional impacts resulting from the proposed activity include 1) a better scientific understanding and ability to predict the complex flooding scenarios due to combined storm surge propagation and torrential rainfall/runoff events, which can lead to more informed decision-making and emergency management planning.  that will help protect the coastal population and infrastructure; 2) the education and training of graduate students and other researchers through courses, seminars, workshops and direct involvement in the research. The project will expose the students to multi-discplinary collaboration in computational mathematics, civil engineering, hydrology, and coastal ocean science; and 3) the transfer of technology and findings to federal agencies such as the National Oceanic and Atmospheric Administration, the U.S. Army Corps of Engineers, various state and local agencies, coastal industries, and other academic institutions."
"1217203","Multiscale Computation of Highly Oscillatory Dynamical Systems","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/01/2012","07/24/2012","Bjorn Engquist","TX","University of Texas at Austin","Standard Grant","Junping Wang","08/31/2015","$497,235.00","Yen-Hsi Tsai","engquist@math.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1266, 1271","9263","$0.00","Highly oscillatory dynamical systems are computationally very challenging. Traditional numerical techniques require several function evaluations per wavelength. This is typically prohibitingly computationally costly. In earlier work the investigators have developed and analyzed numerical algorithms for efficient solution of such systems with well-defined scale separation. In this proposal the investigators tackle the harder problems where the scale separation is less clear and where the decomposition into slow and fast variables is not known. Abstractly, a full-scale model with state variables u is given. A number of slow variables, U, which include the local averages of u(t), is to be computed using a sequence of short time histories of u(t), starting from appropriate initial conditions consistently defined by U(t). Hence, the essential objectives that form this proposal are: (1) Under what conditions and in what sense do the multiscale approaches converge? What is the accuracy in the approximation of U, and what are the stability properties of the methods? (2) How can we find higher order accurate algorithms in a systematic way, when the dynamical system's right hand side can be decomposed into stiff and non-stiff parts? (3) Design such methods with a substantial reduction of computational complexity compared with existing techniques. The proposed research will delineate mathematically what it means for a dynamical system that appear to be highly oscillatory to possess slow modes. With this information, new efficient numerical algorithms can be devised and tested rigorously. The proposed research will establish a mathematical link between a variety of averaging theories and new effective numerical integrators and filtering techniques.<br/><br/>The proposed research is at the very mathematical and computational heart of many important applications in science and engineering, from astrophysics to quantum mechanics. In these applications there are rapid oscillations as, for example, vibrations of atoms that affects the overall system on a much slower time scale. This is traditionally difficult to simulate with reasonable computational cost.  The theories and algorithms developed in this proposal make such simulations practical and directly relate to important atomistic simulations that are used in place of actual physical experiments. They will have direct consequences, for example, in molecular biology for understanding drug functions at the cellular level, and also in the study of material properties and unstable events such as the formation and propagation of cracks, which may affect electronic components as well as the structural safety of airplanes."
"1216920","Novel Algorithms for Nonlinear Optimization","DMS","COMPUTATIONAL MATHEMATICS, OPERATIONS RESEARCH","08/01/2012","07/24/2012","Andreas Waechter","IL","Northwestern University","Standard Grant","Junping Wang","07/31/2015","$252,000.00","","waechter@iems.northwestern.edu","633 CLARK STREET","EVANSTON","IL","602080001","3125037955","MPS","1271, 5514","073E, 9263","$0.00","The two research objectives of this project concern the development, analysis, and implementation of novel numerical methods for the solution of nonlinear optimization problems.  The first thrust addresses the design of nonlinear programming (NLP) methods that can, in contrast to existing algorithms, reuse the factorization of derivative matrices for the solution of closely related problem instances.  Such hot-started methods are expected to lead to significant speedup of branch-and-bound algorithms for mixed-integer nonlinear optimization.  The second focus is the development of efficient parallel algorithms based on Generalized Benders Decomposition for the solution of decomposable NLPs, as they arise in design under uncertainty or two-stage stochastic optimization problems.  The emphasis lies in the fast computation of local solutions of nonconvex problems, whereas existing approaches are restricted to convex instances or limited to the much more time-consuming search for global optima.<br/><br/>Numerical optimization has become an indispensable tool in many areas of industry, economy and science, answering questions such as ""what is the best way to design and operate this plant"" or ""how should the electrical power grid be operated in order to be able to sustain failure of network components.""  While powerful computational methods are available for the optimization of systems that can be described by models that are either linear or restricted to non-discrete decisions, the solution of problems that are both nonlinear and discrete, as they frequently appear in practice, is often too time-consuming with current technology.  Therefore, the first part of the proposed research project aims at significantly accelerating a crucial key component in algorithms for nonlinear discrete optimization.  The second research objective of this project deals with the efficient exploitation of increasingly pervasive parallel computing power for the optimization of problems that consider many potential scenarios as a way of addressing the uncertainty of future circumstances."
"1217170","Optimization-Based Moment Models for Multiscale Kinetic Equations","DMS","COMPUTATIONAL MATHEMATICS","09/15/2012","08/06/2014","Cory Hauck","TN","University of Tennessee Knoxville","Continuing Grant","Leland Jameson","08/31/2017","$635,680.00","Ryan McClarren","chauck@utk.edu","201 ANDY HOLT TOWER","KNOXVILLE","TN","379960001","8659743466","MPS","1271","9150, 9263","$0.00","The focus of this proposal is the design, analysis, and implementation of optimization-based moment models for solving collisional kinetic equations with diffusive limits. In the field of computational kinetic theory, moment methods are an effective, yet highly complex tool for discretizing kinetic equations and capturing multiscale phenomena. They reduce the kinetic description of a many-particle system to a set of partial differential equations for velocity averages of the kinetic distribution. Optimization-based moment models are derived via the solution of a physically motivated, convex optimization problem that enforces important properties of the underlying kinetic equation. The driving application for this effort will be neutrino transport in core-collapse supernovae simulations, where the computational requirements for a fully resolved kinetic simulation are well beyond the capabilities of the largest supercomputers.<br/><br/>The design of tractable reduced models for complex systems is both timely and important. Indeed, for a broad range of physical, biological, and social science problems, methodologies are needed to extract relevant macroscopic features from intractable amounts of microscopic data.  In this context, the design and implementation of moment models is an important part of understanding the behavior of many-particle systems, for which direct numerical simulation is not possible.  Important examples include rarefied gases, radiation, and charged-particle transport---all of which play critical roles in advanced energy and technology applications of national interest.  Thus, among other things, the project will provide a rewarding and relevant research experience to students and postdocs."
"1226259","Collaborative Research: Advances in Nonlocal Dielectric Modeling and Free Energy Calculation for Protein in Ionic Solvent","DMS","COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY","09/01/2012","08/22/2012","Dexuan Xie","WI","University of Wisconsin-Milwaukee","Standard Grant","Mary Ann Horn","08/31/2016","$230,263.00","","dxie@uwm.edu","3203 N DOWNER AVE","MILWAUKEE","WI","532113153","4142294853","MPS","1271, 7334","9263","$0.00","The nonlocal dielectric approach can significantly enhance the classic Poisson dielectric model by considering the polarization correlations among water molecules. However, current studies on the approach are mostly restricted to the water solvent, due to modeling and algorithmic complications that arise in the case of ionic solvents. The current ionic models that do exist fail to incorporate crucial nonlocal dielectric effects. Recent developments also indicate that entropic changes due to protein-ligand association are critical to understanding binding affinity. The computation of entropy, however, remains a very difficult task. Motivated by these challenges, this project aims to develop new nonlocal continuum electrostatic models and new numerical quadratures for the direct calculation of entropy and free energy for protein in ionic solvent. The new nonlocal models will be constructed from a novel combination of the nonlocal dielectric approach with the fundamental measure theory of hard-sphere mixture fluids under the constrained functional optimization protocol. They are expected to significantly improve the accuracy of electrostatic potential calculations in comparison to the classic Poisson-Boltzmann equation, since they reflect both ionic size effects and polarization correlations among water molecules. The new numerical quadratures will be developed by using a special prismatic element interpolation constructed from a prismatic mesh of a bounded state region near a potential energy minimum point. The computing complexity will be further reduced through using a new nonlocal model for computing involved electrostatic potential. Lastly, new fast numerical algorithms and program packages will be developed for solving the new dielectric models and for implementing the new numerical quadratures.  <br/><br/>Calculation of electrostatic potential energy, entropy, and free energy for protein in ionic solvent is a fundamental task in biomolecular simulations. The new nonlocal dielectric models, numerical quadratures for computing entropy and free energy, and the accompanying efficient numerical algorithms and program packages produced from this project will be a considerable contribution to the fields of mathematical biology, computational biochemistry, computational mathematics, and computer science. They will play important roles in ion channel studies, rational drug design, and other bioengineering applications, and will improve our quantitative understanding of critical physiological processes, cellular energetics, and affinity in protein-ligand binding, and of health and disease in general.  The findings from this project are expected to have a significant impact on the development of mathematics, computer science, biochemistry, and bioengineering.  Because there has been substantial interest recently in algorithms for solving high-dimensional problems, any advances made in this project will have broad potential impact in a variety of areas that are related to high-dimensional integrals with integrands that decay exponentially."
"1216465","Partitioning of Coupled Flow Problems","DMS","COMPUTATIONAL MATHEMATICS","08/15/2012","07/01/2014","William Layton","PA","University of Pittsburgh","Continuing Grant","Rosemary Renaut","07/31/2016","$257,789.00","","wjl+@pitt.edu","4200 FIFTH AVENUE","PITTSBURGH","PA","152600001","4126247400","MPS","1271","9263","$0.00","    The investigator and his students conduct research in computational fluid dynamics and numerical analysis on the development, analysis and validation of modular, uncoupling algorithms for coupled flow problems. The research involves three related problems: nonlinear filter based turbulence models, geophysical simulation methods based on fast-slow wave splitting and time filters and coupled groundwater-surface water flows. The key idea of the first problem is to use simple turbulence models and adapt / refine the models through an uncoupled, modular filter step. This approach allows easy introduction of modern models into legacy codes. It also gives a clear path for improvement of model accuracy. The second research problem is to develop a mathematically sound understanding of the most commonly used tools in geophysical flow simulations of the (so called) CNLF method based on fast-slow wave splitting with time filtering. The third problem is to develop partitioned methods for coupled groundwater-surface water flow and contaminant transport problems. The methods studied will allow the solution of coupled, evolutionary problems for realistic parameter values by successive calls to separate programs optimized for each physical sub-process. The three projects treat problems of great importance and long-standing difficulty. The problems are selected to be ones where a fundamental breakthrough is necessary in both algorithms and numerical analysis to take a step forward. Each project involves development of one or more novel ideas that have promise to breakthrough a fundamental difficulty severely limiting current methods.<br/>    The overarching project of multi-rate, partitioned methods for multi-physics problems lies at the crossroads where the limitations of analytical technique, computer hardware capabilities and human programmer abilities come together. The first research theme concerns implementation of new turbulence models in legacy codes and increasing their accuracy as knowledge of turbulent flows expands - a central problem in many industrial research groups. The second is to understand and improve the major tool in atmosphere and ocean codes. This is of great importance in global change estimation and in estimation of pollution dispersal. The third is to develop methods for coupled transport of contaminants to and from surface water and groundwater. This is a problem of current interest directly related to control of contaminants and cleanup from industrial and agricultural processes.<br/>"
"1216970","Collaborative Research: Computational Framework for Non-asymptotic Homogenization with Applications to Metamaterials","DMS","COMPUTATIONAL MATHEMATICS","07/15/2012","07/16/2014","Vadim Markel","PA","University of Pennsylvania","Continuing Grant","Leland Jameson","06/30/2015","$148,426.00","","vmarkel@pennmedicine.upenn.edu","3451 WALNUT ST STE 440A","PHILADELPHIA","PA","191046205","2158987293","MPS","1271","9263","$0.00","The project is aimed at developing a non-asymptotic homogenization<br/>theory of Maxwell's equations in artificial periodic composites<br/>(metamaterials). Currently, there is a consensus that sufficiently<br/>large lattice cell sizes are necessary for some nontrivial physical<br/>effects to occur in such structures. (The most intriguing of these<br/>effects is high-frequency magnetism.) Classical homogenization<br/>theories work well in the zero-cell-size limit but are difficult to<br/>apply to large metamaterial cells. In contrast, the proposed theory is<br/>non-asymptotic and does not involve any series expansions with respect<br/>to the cell size. The electromagnetic field in the material is<br/>approximated by a finite set of functions (modes) usually but not<br/>necessarily Trefftz functions such as Bloch waves. The coarse-grained<br/>fields and flux densities are defined via curl-conforming and<br/>div-conforming interpolations, respectively. A linear map between<br/>these interpolants is established and defines an extended material<br/>tensor. In a certain canonical basis, this extended tensor has a<br/>classical block of 36 local parameters and a novel block quantifying<br/>nonlocal effects. From the differential-geometric perspective, this<br/>constitutive relationship can be viewed as a realization of<br/>Bossavit-Hiptmair's discrete Hodge operators (linear maps between<br/>discretized 1-forms that correspond to vector fields and 2-forms that<br/>correspond to fluxes).<br/><br/>Over the last decade, metamaterials have attracted unprecedented<br/>attention due to a variety of potential applications that include<br/>superlensing, electromagnetic cloaking, electromagnetically-induced<br/>transparency, efficient antennas, and more. Experimental<br/>demonstrations of these effects have been limited to proofs of<br/>principle and at optical frequencies have so far been incomplete.<br/>Subwavelength optical imaging has been achieved only in the<br/>quasi-static (near-field) regime, standard for the more conventional<br/>near-field optics; the so-called ""carpet cloak"" conceals surface bumps<br/>rather than 3D objects, and so on. Moreover, applications that do not<br/>depend critically on the effective medium description of metamaterials<br/>appear to be more easily achievable than the ones that do. The latter<br/>group includes, notably, superlensing and cloaking. This suggests<br/>that, to make further progress, theoretical and mathematical issues at<br/>the heart of metamaterial science must be unambiguously resolved. The<br/>main problem can be stated as follows. Given the composition of a<br/>metamaterial cell and the operating frequency, determine whether this<br/>metamaterial can be reasonably described as a continuous medium with<br/>some effective parameters, just like any natural optical material; if<br/>the answer is positive, develop a rigorous methodology for such a<br/>description. The proposed research is aimed at solving this problem in<br/>the most difficult case when the cell size of the composite is an<br/>appreciable fraction of the wavelength of light. The methodology, once<br/>developed, will allow the scientific community to delineate the<br/>possible from the impossible in the field of metamaterials.<br/>The intellectual merit of the proposed research is in the development<br/>of a new paradigm of non-asymptotic homogenization, of new<br/>computational methods related to it, and in the application of the<br/>proposed methodology to electromagnetic metamaterials, allowing one to<br/>gain a much deeper understanding of their properties and limitations.<br/>As a new area of research, non-asymptotic homogenization will also<br/>have a broader technical impact in other areas of applied physics and<br/>engineering, such as acoustics, heat transfer and possibly elasticity."
"1216936","Collaborative Research: New Formulation and Algorithms for Fluid-Structure Interaction, with Application to Tumor Growth","DMS","COMPUTATIONAL MATHEMATICS","09/15/2012","09/14/2012","Jin Wang","VA","Old Dominion University Research Foundation","Standard Grant","Leland Jameson","08/31/2016","$150,002.00","","j3wang@odu.edu","4111 MONARCH WAY","NORFOLK","VA","235082561","7576834293","MPS","1271","9263","$0.00","Fluid-structure interaction (FSI) problems play prominent roles in many scientific and engineering fields, yet an accurate study of such problems remains highly challenging due to the strong nonlinearity and multi-physics involved. Current computational theory and methods for fluid-structure interactions lack sufficient accuracy and realistic material representations, and are limited to relatively simple structural configurations. The goal of this project is to overcome such limitations by establishing a new computational mathematical framework for accurate and efficient numerical investigation of complex FSI problems, particularly for tumor growth modeling and simulation. The PIs will derive new mathematical formulation that allows the study of general FSI problems with sophisticated structural settings, develop efficient numerical algorithms that ensure high accuracy in FSI computations, and apply the proposed mathematical formulation and computational methods to the individual-cell-based modeling and simulation of tumor growth. This proposal builds on the PIs? solid background in computational and applied mathematics and significant work on tumor modeling.<br/><br/>The proposed research will improve the understanding of the nonlinear dynamics in highly complex FSI problems through a combined mathematical and computational framework. Experimental measurements will also be used for validating the numerical results. The success of this project will not only provide a solid knowledge base for advancing the current state of computational FSI study, but also enable important discoveries in the fundamental mechanism of early tumor formation and development. The project experiences and findings will strengthen the research collaboration and curriculum development in computational mathematics and mathematical biology at both Old Dominion University and the College of William and Mary. Due to the close geographical proximity between the two schools, project impacts will be maximized through convenient communication between faculty and students and through joint programs between the two schools. Education and outreach activities will involve graduate and undergraduate students in the theory, methods and application of computational mathematics."
"1217315","Quasiatomistic Method of Solids","DMS","COMPUTATIONAL MATHEMATICS","09/01/2012","09/07/2012","Jingrun Chen","CA","University of California-Santa Barbara","Standard Grant","Leland Jameson","08/31/2016","$238,210.00","Carlos Garcia-Cervera","cjr@math.ucsb.edu","3227 CHEADLE HALL","SANTA BARBARA","CA","931060001","8058934188","MPS","1271","9263","$0.00","The main objective of the present proposal is to develop a new model for multiscale analysis of solids, the quasi-atomistic model, which plays a transitional role between the atomistic and continuum models. In addition, the PIs propose to develop an energy-based procedure to couple fully atomistic descriptions and continuum descriptions in a seamless way, which allows for systematic coarse-graining with controllable error. A second objective is the analysis of the proposed methodology, including consistency, stability and convergence. Inconsistency, known as ghost force in this context, can be systematically removed even in the case of interfaces with corners. Another component of the project is to combine the principles of the multigrid method and multi-resolution analysis for the efficient implementation. This will be done by constructing multilevel grids by multi-resolution analysis and solving nonlinear minimization problems with multigrid methods.<br/><br/>Molecular mechanics is a common approach to modeling the behavior of matter, where atoms are treated as the essential degrees of freedom and a potential function is used to describe the interactive effects between atoms. Equilibrium structures can be computed by minimizing the potential energy with respect to the position of the atoms. Other information about the system, such as the vibrational spectrum, thermodynamic properties, equations of state, and reaction rates, can also be computed. Extensive applications of molecular mechanics modeling can be found in materials science, chemistry and biology. The proposed work will mainly focus on solids, with generalizations to soft matter and biological systems, and conduct mathematical, numerical and applicative studies of the proposed methodology."
"1216433","Inverse Problems in Microstructural Evolution of Polycrystalline Materials","DMS","COMPUTATIONAL MATHEMATICS","08/01/2012","07/18/2012","Shlomo Ta'asan","PA","Carnegie-Mellon University","Standard Grant","Leland Jameson","07/31/2016","$243,820.00","","shlomo@andrew.cmu.edu","5000 FORBES AVE","PITTSBURGH","PA","152133815","4122688746","MPS","1271","9263","$0.00","The vast majority of the solid materials used in engineered systems are polycrystalline. They are composed of many single crystals joined together by a three dimensional network of internal interfaces called grain boundaries.  In many cases, the performance and integrity of a material are determined by the structure of the grain-boundary network. Examples of such materials are nano-twinned copper whose strength is dominated by coherent twin boundaries; fine-scale interconnects in microelectronics whose resistivity is dominated by grain boundaries. While these material present extremely attractive properties, the fundamental mechanisms that underlie them are poorly-understood thus presenting a challenge to further development.  Efforts to meet this challenge have led to new directions of research in experiment, theory, modeling and simulation. The goal of this work is to develop the mathematical tools and its software implementation and to provide a toolbox for extracting these material properties based on experimental data.  The investigator and his colleagues will achieve these goals using inverse problem formulations in conjunction with recently developed experimental technique - The High Energy Diffraction Microscopy (HEDM) - to identify energy and mobility in materials ubiquitously used in applications. Grain boundary energy and mobility, which are defined on a five dimensional space, are the physical parameters that govern the evolution of grain boundaries under thermal loading where the most acceptable model is the Mullins equation. The advent of the HEDM technique opens new possibilities for probing the evolution of polycrystalline materials and will enable us the direct calculation of grain boundary velocities. This in conjunction with inverse problems governed by Mullins equation will lead us to accurate estimates of both energy and mobility. The mathematical techniques that we use in this work include Optimal Transport, Numerical solution of PDEs and Optimization Techniques for solving the inverse problems. <br/><br/> <br/>This work deals with novel mathematical and computational approaches for meeting important challenges in materials science. In particular, understanding  microstructure evolution under mechanical and thermal loading. Microstructure affects materials reliability and failure and is strongly dependent on physical parameters - the energy and mobility. We will develop techniques for accurate identification of these properties in materials of engineering applications. This is pivotal for better design and reliability of electronic, structures and combustion components.  These studies will pave the road to deal with response to thermo-mechanical loading in polycrystalline materials. The applications of these results will have broader impact in essentially all the other branches of engineering where mechanical loads occur (bridges, cars, planes, MEMS devices, prostheses), as well as the study of geological materials."
"1217200","Multiscale Turbulent Reacting Flows and Data-Based Modeling","DMS","COMPUTATIONAL MATHEMATICS","08/15/2012","07/01/2014","Tarek Echekki","NC","North Carolina State University","Continuing Grant","Rosemary Renaut","07/31/2016","$200,000.00","","techekk@ncsu.edu","2601 WOLF VILLAGE WAY","RALEIGH","NC","27607","9195152444","MPS","1271","9263","$0.00","This research project investigates a multiscale flame-embedding approach for the computation of turbulent flames. The model is based on the coupling of large-eddy simulation (LES) for the description of the flow and for flame tracking and embedded 1D stochastic solutions of flamelets based on the one-dimensional turbulence (ODT) model. Important features of the framework include the upscaling of ODT solution to the LES, the downscaling of LES solutions to ODT, and capturing of the flame front. The Lagrangian LES-ODT formulation requires the tracking, spawning, and removal of ODT solutions as they are advected along the flame. The formulation also requires a robust formulation for the filtering of the density from the fine-grained solution of ODT to the LES along with the filtering of transport and source terms for scalars used to track the flame in LES. Wavelet-based methods will be investigated to establish consistency between the LES and ODT velocity fields and their transport. An optimal parameterization of the thermo-chemical scalars using principal component analysis will be used to improve computational efficiency. <br/><br/>This research addresses the prediction of physical processes occurring in the production of energy through combustion. The work aims to develop next-generation modeling tools that can potentially reduce the turn-around time for the design of combustion systems through simulation and to investigate mechanisms to improve combustion efficiency and reduce pollutants."
"1242876","Pacific Northwest Numerical Analysis Seminar 2012","DMS","COMPUTATIONAL MATHEMATICS","08/15/2012","08/08/2012","Donna Calhoun","ID","Boise State University","Standard Grant","Junping Wang","07/31/2013","$8,200.00","Jodi Mead, Grady Wright","donnacalhoun@boisestate.edu","1910 UNIVERSITY DR","BOISE","ID","837250001","2084261574","MPS","1271","7556, 9150, 9263","$0.00","Boise State University will host the 25th Annual Pacific Northwest Numerical Analysis Seminar October 26-27, 2012.  The goal of the meeting is to bring together interdisciplinary researchers from universities, government research labs, and industry from the Pacific Northwest to share expertise in both pure and applied aspects of numerical analysis and computational mathematics. The traditional format of a day-long Saturday session for invited talks will be modified to include a Friday evening poster session for students and postdoctoral fellows to present their work.  This will create a vertically integrated meeting bringing together individuals from undergraduates to distinguished researchers.  The inclusion of participants from national labs and industry will foster new potential research and employment opportunities for a broadened presence of students and postdocs.<br/><br/>Boise State University, which for many years served as an undergraduate teaching institution, has recently been making key investments in faculty, staff, and infrastructure to transition into a research-oriented institution. The Pacific Northwest Numerical Analysis Seminar will be the first conference ever held at Boise State University in this area of mathematics, and will help strengthen the recently developed foundation in computational mathematics that is needed to educate a technological workforce in this underrepresented region of the US.  There will be speakers whose work: (1) interfaces with the biological and mathematical sciences; (2) involves energy sustainability; (3) focuses on the challenges of ?big-data?; and (4) concerns the development of cyberinfrastructure.  Speakers will include senior and junior faculty, women researchers/educators, and graduate students.  In addition to standard communication channels, the seminar will be promoted through the Boise State University student chapters of the Society of Women Engineers, the Society of Hispanic Professional Engineers, and the Pacific Northwest Louis Stokes Alliance for Minority Participation (LSAMP) consortium to broaden participation from underrepresented groups."
"1216923","Development and analysis of fast numerical methods for fractional diffusion and advection-diffusion equations","DMS","COMPUTATIONAL MATHEMATICS","09/01/2012","08/15/2012","Hong Wang","SC","University South Carolina Research Foundation","Standard Grant","Leland Jameson","08/31/2016","$240,000.00","","hwang@math.sc.edu","915 BULL ST","COLUMBIA","SC","292084009","8037777093","MPS","1271","9150, 9263","$0.00","Fractional diffusion equations provide an adequate description of transport processes that exhibit anomalous diffusion, which cannot be modeled properly by classical second-order diffusion equations. However, fractional diffusion equations introduce severe computational, numerical, and mathematical difficulties which have not been encountered in the context of second-order equations: (i) Fractional diffusion equations lead to numerical methods with dense or full coefficient matrices, which makes realistic three-dimensional simulations computationally intractable! (ii) Fractional diffusion operators are non-local and the adjoint of a fractional differential operator is not the negative of itself, which significantly complicates the mathematical analysis. The objectives of this proposal are as follows: (i) Develop fast numerical methods for fractional diffusion equations with significantly improved computational efficiency and memory requirement while retaining the stability and accuracy of standard methods. (ii) Develop efficient preconditioners for the fast numerical methods, so that the convergence of the preconditioned linear system is independent of the mesh size. (iii) Conduct corresponding mathematical and numerical analysis for the proposed fast methods.<br/><br/>Diffusion processes are ubiquitous and occur in nature, sciences, social sciences, and engineering. Sample applications include how water and nutrients travel through membranes in living organisms, how mosquitoes spread malaria, how copiers and laser printers work, and how contaminants in groundwater are transported, as well as the signaling of biological cells, foraging behavior of animals, and finance. Fick first sat up the diffusion equation in 1855. But it was Einstein who derived the diffusion equation from first principle as part of his work on Brownian motion. In last few decades it was found that increasingly more diffusion processes cannot be properly modeled by classical diffusion equations. These discoveries have profound consequences. For example, recent modeling by fractional advection-diffusion equations indicate that remediation of contaminated aquifers may take decades or centuries longer than previously predicted by the classical advection-diffusion equations. Hence, further investigations are crucial. The results of this work will be applicable to a wide range of applications. The proposed research activities will also provide advanced interdisciplinary training to graduate and undergraduate students. All of these activities will have broad and long-lasting impacts and contribute directly to the intellectual infrastructure of the nation."
"1215659","Numerical Improvements, Mesh Adaptation and Parameter Identification for Parallel Finite Element Stokes Ice Sheet Modeling","DMS","COMPUTATIONAL MATHEMATICS, ANS-Arctic Natural Sciences, OPPORTUNITIES FOR RESEARCH CMG","08/01/2012","07/24/2012","Lili Ju","SC","University South Carolina Research Foundation","Standard Grant","Junping Wang","07/31/2015","$157,618.00","","ju@math.sc.edu","915 BULL ST","COLUMBIA","SC","292084009","8037777093","MPS","1271, 5280, 7215","1079, 7215, 9150, 9263","$0.00","The numerical modeling of land ice evolution has been a subject of growing interest because of the crucial role land ice plays in global sea level and other parts of the climate system. Nonlinear 3D Stokes flow is the gold standard among conceptual models for ice sheet dynamics. The current widely-used shallow-ice, shallow-shelf, L1L2, and higher-order approximations are all obtained as reduced forms of the 3D Stokes model by means of scaling analysis, but in many situations, with an attendant loss of fidelity. The PI has closely collaborated with a team of collaborators on the preliminary development of a parallel finite element nonlinear 3D Stokes dynamical core for ice sheet modeling. The goal of the proposed project is to advance the current finite element Stokes ice sheet model by further studying and enhancing its efficiency, accuracy, usability, and robustness. The PI will first investigate some issues related to the finite element Stokes ice sheet dynamics solver, including analysis and implementation of Newton-based fast iterative methods for treating both rheological and basal boundary condition nonlinearities and an adaptive hybrid discretization scheme for enhancing the local conservation properties in our numerical model. In the ice-sheet model we consider, the Stokes ice sheet dynamics equations are fully coupled to the equation for temperature evolution, thus stable and accurate finite element temperature solver with accuracy commensurate with that of the Stokes solver is desired and will also be developed. It is well-known that the adjoint equation approach allows one to directly obtain accurate solutions for the quantity of interests. The PI will also investigate and develop adjoint equation-based methods for adaptive mesh refinement and identification of basal boundary sliding parameter using goal-oriented optimization approaches.<br/><br/>Although numerical ice sheet models have steadily improved in recent years, much work is needed to make them more reliable, efficient and usable at long time and whole ice sheet scales. The enhanced numerical Stokes ice sheet model will achieve high degrees of efficiency and accuracy through the use of high-order accurate adaptive finite element discretization schemes, highly scalable parallel linear and nonlinear system solvers, goal-oriented variable resolution meshing strategies, and effective inverse design for model parameters. The proposed investigation would offer new insights through numerical simulations to the understanding of land ice evolution. The PI will actively disseminate his research results and tested software not only toresearchers in the area but also to much broader communities with interests in numerical methods and computational geophysics through publications, attending meetings, maintaining an informative web-site. The potential impact of the project is very substantial. Direct and transformative innovations resulting from the proposed project will greatly improve computational ice sheet model capabilities in the climate system modeling. In addition, this project will also offer a unique educational opportunity for graduate students with interests in computational and applied mathematics by having them participate in an interdisciplinary research program that combines mathematics, computer science and geological sciences."
"1217161","Collaborative Research: Innovative Integrated Strategies for Nonlinear Parametric Inversion","DMS","COMPUTATIONAL MATHEMATICS","09/15/2012","09/11/2012","Misha Kilmer","MA","Tufts University","Standard Grant","Leland Jameson","08/31/2015","$190,001.00","","misha.kilmer@tufts.edu","169 HOLLAND ST FL 3","SOMERVILLE","MA","021442401","6176273696","MPS","1271","9263","$0.00","The investigators aim to reduce drastically the costs of numerical inversion (as occurs, for example, in medical imaging) by blending new parametric level-set approaches and nonlinear least squares methods together with innovations in linear solvers, preconditioning, and model reduction of parameterized systems. Four strategies are combined to reduce the computation necessary while not degrading accuracy of the solution. First, the dimension of the inverse problem is drastically reduced by developing low-order parametric inversion methods replacing the usual voxel-based inversion. Second, the optimization underlying parametric inversion incorporates novel nonlinear least-squares solvers specifically designed to deal with ill-conditioned Jacobians. Third, the high cost of solving many large forward problems is reduced through new model reduction techniques that are particularly well-suited to the structure of the inverse problems under consideration. Fourth, the high costs of computing reduced models and solving forward problems is reduced by innovations in Krylov subspace recycling and efficient reuse of preconditioners for parameterized linear systems. <br/><br/>The inverse problems studied here involve recovery of images describing how unknown quantities of diagnostic interest (such as electrical conductivity) are distributed throughout a given medium (such as human tissue or soil). These images can reveal the presence or absence of anomalies, such as tumors in human tissue or contaminant plumes in soil. The computational extraction of high quality images from noisy surface measurements in reasonable time is a very difficult task. As rapid advances in technology make it possible to take vastly more measurements, computational bottlenecks become ever more acute, impeding innovation in medical and other areas of imaging. This project aims to combine innovations in diverse fields within computational linear algebra, systems theory, and optimization to create dramatically improved strategies for image extraction."
"1217218","Collaborative Research: Computational Methods for Simulating Complex Coastal Watersheds and Floodplains","DMS","COMPUTATIONAL MATHEMATICS","09/01/2012","08/01/2014","Ethan Kubatko","OH","Ohio State University","Continuing Grant","Rosemary Renaut","08/31/2016","$135,000.00","","kubatko.3@osu.edu","1960 KENNY RD","COLUMBUS","OH","432101016","6146888735","MPS","1271","9263","$0.00","Accurate and efficient computational modeling of rainfall flooding events presents significant challenges. These challenges are primarily due to the complex topology of coastal watersheds and floodplains, and in particular urban environments, which include numerous features relevant to flooding such as small-scale drainage channels, piping networks, etc, that receive stormwater from both the landfall of storm surge and runoff/overland flow due to rainfall.  The primary objective of this project is improve the predictive capability of coastal hydrodynamic models for flooding in complex coastal watersheds and floodplains using a novel multi-physics modeling paradigm. An adaptive multi-physics/multi-dimensional modeling approach will be investigated that can adaptively switch between various models in order to simultaneously optimize physical correctness and computational efficiency. The development of such an approach, along with the supporting concepts and numerical tools that will make its application to full-scale problems possible, is the main goal of the proposed research. This work will be explored in the context of discontinuous Galerkin methods, building and expanding on the PIs' extensive work in the area of shallow water modeling using high-order discontinuous Galerkin methods.<br/><br/>Recent storm events, for example Hurricane Irene, which led to extensive flooding along much of the U.S. East Coast, have demonstrated the severe vulnerability of coastal lowlands and watersheds to storm surge combined with torrential rainfall.  These types of disasters highlight the rising importance of effective emergency management and hazard mitigation, and the need for advanced, physics-based models to better understand their impacts.  The potential for future storms with destructive flooding in low-lying coastal areas due to inland storm surge combined with torrential rainfall is high.  Observations show an increase in hurricane intensity in the North Atlantic since the 1970s and research suggests continued increases in storm intensity and significant potential for heavy rainfall in many regions. The devastating flooding related to these events, along with predicted rapid coastal development, will result in greater coastal risk in the future and poses serious challenges to physical infrastructure, water quality, and sustainability of coastal communities.  The research under this project will have a significant impact on the development of the next generation of coastal hydrodynamic models.  Additional impacts resulting from the proposed activity include 1) a better scientific understanding and ability to predict the complex flooding scenarios due to combined storm surge propagation and torrential rainfall/runoff events, which can lead to more informed decision-making and emergency management planning.  that will help protect the coastal population and infrastructure; 2) the education and training of graduate students and other researchers through courses, seminars, workshops and direct involvement in the research. The project will expose the students to multi-discplinary collaboration in computational mathematics, civil engineering, hydrology, and coastal ocean science; and 3) the transfer of technology and findings to federal agencies such as the National Oceanic and Atmospheric Administration, the U.S. Army Corps of Engineers, various state and local agencies, coastal industries, and other academic institutions."
"1217136","Reduced Basis Element Methods for Thermal Modeling of Integrated Circuits","DMS","COMPUTATIONAL MATHEMATICS","09/15/2012","09/14/2012","Brian Helenbrook","NY","Clarkson University","Standard Grant","Rosemary Renaut","08/31/2016","$150,189.00","Ming-Cheng Cheng","helenbrk@clarkson.edu","8 CLARKSON AVE","POTSDAM","NY","136761401","3152686475","MPS","1271","9263","$0.00","The objective of this project is to develop ""Reduced Basis Element"" techniques for thermal modeling of integrated circuits (ICs).   Typical digital IC's are designed using standard cells from ""technology libraries"", such as NOT, NAND, NOR and XOR gates, flip-flops, adders, multipliers and coders/decoders, etc., each of which may consist of a number of semi-conductor transistors connected   by metal interconnects.   A normal IC will contain millions of these standard   cells and as such it is computationally infeasible to perform detailed thermal simulations of an entire IC.   However, the development of accurate and   efficient thermal models is becoming increasingly important because of the increasing power density of computing systems.  Furthermore, new technologies such as silicon-on-insulator (SOI) and 3D stacking only exacerbate chip-heating problems.  The proposed work will capitalize on the geometric   repetition inherent in an IC to develop accurate and computationally efficient thermal models.  Techniques for dividing and classifying an IC's cells and   interconnects into standard geometry blocks will developed.  Compact reduced order models for these blocks will then be created and these models will be   coupled together to predict the thermal behavior of an entire integrated   circuit.   The reduced order models will be based on proper orthogonal decomposition analysis of detailed simulation data of individual cells.   As such, the reduced order models will not need any ad-hoc modeling assumptions. Coupling procedures will use approaches borrowed from discontinuous Galerkin   finite element methods.  The proposed approach will enable thermal simulations of an IC with accuracy comparable to that of a direct simulation at a computational cost which is affordable with today's computing machinery.    <br/><br/>Current computers pack more power into smaller packages than ever before, which often results in significant internal heating problems.   Computer chip   designers must make compromises based on the temperature distribution in the   integrated circuits and need efficient and accurate thermal models to do this.  Current models are derived using simplifying assumptions about the heat flows   in the integrated circuit and do not provide detailed thermal data.  These   models limit designers from pursuing more advanced designs.  This work aims to develop an efficient, high-fidelity tool that will enable more advanced   designs to be tried while maintaining the short design cycle of the   semiconductor industry.  In addition, the basic framework that will be   developed will be applicable to any problem having repeated geometric features such as stacked-cell batteries, solar cell panels, thermoelectric modules, etc. Thus, this technique could enable first-principles-based high-fidelity simulations in a wide range of fields. These simulations will in turn enable the next generation of advanced designs."
"1216928","Developing reduced basis methods for Galerkin and Collocation framework","DMS","COMPUTATIONAL MATHEMATICS","08/01/2012","07/23/2012","Yanlai Chen","MA","University of Massachusetts, Dartmouth","Standard Grant","Rosemary Renaut","07/31/2016","$161,113.00","","yanlai.chen@umassd.edu","285 OLD WESTPORT RD","NORTH DARTMOUTH","MA","027472356","5089998953","MPS","1271","9263","$0.00","Reduced basis method (RBM) is a model reduction framework for rapid and reliable simulations of input-parametrized partial differential equations.  Many applications require simulations to be repeated tens of thousands of times to study the effect of the parameters on the solution. This repetition can be prohibitive in terms of computational cost. The RBM can provide a surrogate solution in negligible computational time. A similar approach, known as the reduced basis element method (RBEM)  can be employed for computing the surrogate solution on a complicated domain. This method is a combination of domain decomposition and RBM. In this grant proposal, the PI proposes to continue his work in these two areas to design a completely new RBM for the collocation framework and to develop (Galerkin) variants of RBM and RBEM suitable for applications to simulations of scattering problems with large number, wide range of parameters, and rough geometries. The proposed research includes two phases. The first phase aims to build  a solid theoretical foundation that includes study of the new collocation-based RBM, a novel error estimation procedure for RBEM, a RBM algorithm design based on efficient error estimation for a wider range of weak formulations. The second phase of this project is the application of the newly-developed methodologies to acoustic/electromagnetic scattering with rather high-dimensional parameter and uncertainties in the geometry of the scatterer. The intellectual merit of the proposed research lies in their comprehensive coverage of novel algorithm design, solid analysis, and efficient implementation. <br/><br/>The PI's work has far-reaching goals beyond the current proposal because of the methods' broad applicability to problems of significant impact in science and engineering. The real-world application areas include (but are not limited to) national security (fine-tuning of the shape and material for stealth technology), renewable energy (design of solar cells), and non-destructive sensing. The broader impact of this proposal will result from its scientific impact and educational component. The results will be widely disseminated and the codes made  publicly available. The proposed research will incorporate rigorous undergraduate and graduate student training and mentoring. Special attention will be paid to under-represented groups including minorities."
"1216972","Collaborative Research: Advanced Numerical Techniques for the Simulation of Magnetohydrodynamics","DMS","COMPUTATIONAL MATHEMATICS","09/01/2012","08/13/2012","James Adler","MA","Tufts University","Standard Grant","Leland Jameson","08/31/2016","$299,026.00","Scott MacLachlan","jadler3@gmail.com","169 HOLLAND ST FL 3","SOMERVILLE","MA","021442401","6176273696","MPS","1271","9263","$0.00","The overall objective of this research is to develop numerical models and efficient energy-consistent methods for simulation of complex fluid systems and to obtain physically-accurate solutions for magnetohydrodynamic (MHD) systems, in particular. This work focuses on minimizing the computational cost of approximating solutions to these systems in order to develop practical simulations for this type of problem. The bottom line is to further develop discretization and solution algorithms that yield the most accuracy per computational cost. This is achieved by deriving discrete energy laws for MHD systems and proving that they are consistent with the continuous mathematical model. The investigators accomplish this by using the Energetic-Variational Approach (EVA) to further investigate the MHD model itself and determining which ""flavor"" of the MHD equations is the simplest model that captures the relevant physics. One of the main issues with using finite-element methods for solving complex fluid and electromagnetic problems has been the precise preservation of divergence-free solutions. Here, the investigators analyze discretization methods that satisfy these quantities accurately, while remaining amenable to efficient solution.  Finally, the main bottleneck in the discretization methods used so far is the slow convergence of the linear solvers. By further developing multigrid methods for systems of partial differential equations, the investigators create a robust and efficient algorithm for these complex systems.<br/><br/>The development of an efficient simulation framework for MHD systems has a major impact on the study of fusion energy, as this model is used to describe various phenomena that occur in fusion reactors, including tearing mode and sawtooth instabilities. With projects such as the International Thermonuclear Experimental Reactor (ITER) in France and the National Ignition Facility (NIF) at Lawrence Livermore National Lab attempting to obtain sustainable fusion energy, scientific computing in fields related to these projects is critical. In addition, the numerical tools being developed, such as energy-preserving finite-element discretizations and optimal multigrid solvers for systems of PDEs, are applicable to a wide variety of other problems in multi-physics and multi-scale systems.  Finally, the project supports a graduate student, training and exposing them to the latest scientific findings and tools related to modeling, discretization, and solution of problems in the computational modeling of plasma physics and complex fluids."
"1216620","Collaborative Rsch:  Adaptive Hybridized DG Methods for Acoustic and Electromagnetic Scattering","DMS","COMPUTATIONAL MATHEMATICS","08/01/2012","07/18/2012","Peter Monk","DE","University of Delaware","Standard Grant","Leland Jameson","07/31/2016","$167,948.00","","monk@udel.edu","220 HULLIHEN HALL","NEWARK","DE","197160099","3028312136","MPS","1271","9150, 9263","$0.00","In this project, the investigator and his colleagues will develop, analyze, and implement quasi-optimal adaptive hybridized Discontinuous Galerkin methods for acoustic and electromagnetic scattering problems as described by the Helmholtz equation and the time-harmonic Maxwell equation on bounded domains in two and three dimensional domains using general local bases. These methods feature traditional piecewise polynomial bases as well as special purpose wave elements, and multilevel preconditioned iterative solvers on adaptively refined simplicial, quadrilateral, and hexahedral meshes. The adaptive mesh refinement is driven by residual-type a posteriori error estimators. In particular, the team will prove convergence of the adaptive solution process as well as its quasi-optimality in terms of the computational complexity with respect to a properly specified approximation class. High quality software implementations will be used to test the algorithms and inform the analysis.<br/><br/>Advances in the state of the art in numerical methods for performing acoustic and electromagnetic simulations have potentially high impact in several applications. As an example more accurate simulation of acoustic wave propagation can be used to considerably enhance resolution of medical ultra sound scans, and thus expand the reach of non-invasive diagnostics. The emphasis of this project is the development of novel numerical methods that compute provably accurate approximations of physical acoustics and electromagnetics phenomena."
"1216356","Numerical simulation and analysis of transient waves in unbounded domains","DMS","COMPUTATIONAL MATHEMATICS, EPSCoR Co-Funding","09/01/2012","08/14/2012","Francisco Sayas","DE","University of Delaware","Standard Grant","Leland Jameson","08/31/2016","$299,999.00","","fjsayas@math.udel.edu","220 HULLIHEN HALL","NEWARK","DE","197160099","3028312136","MPS","1271, 9150","9150, 9263","$0.00","This project focuses on numerical approximation of wave propagation phenomena in transient cases, with an emphasis on techniques based on the use of boundary integral methods. As a set of physically motivated applications, the investigator will concentrate on different models of scattering of acoustic waves in two and three dimensions and in wave-structure interaction. The proposal includes numerical analysis and implementation of three kinds of schemes: (1) Galerkin and delta-based space semi-discretization with Convolution Quadrature for time domain boundary integral equations; (2) coupling of Finite and Boundary Elements with Convolution Quadrature in time, for models that combine the acoustic wave equation on non-homogeneous media with time domain boundary integral equations; (3) Hybridizable Discontinuous Galerkin methods for complex wave propagation problems, with an emphasis on wave-structure interaction in the time domain. At the analytical level, the investigator and his collaborators will work on the development of new mathematical tools for time domain boundary integral equations, using time domain techniques instead of the usual Laplace domain tools.<br/><br/>Computer simulation is an indispensable part of modern science and technology, often showing the path in design of new devices and predicting the behavior of complicated physical models that are expensive to experiment with. Through deep mathematical understanding, numerical analysis gives not only certainty in the ability of the computational simulations to yield the right answers, but also shows the expected quality of these results, and proposes new techniques to handle problems of increasing difficulty. The investigator and his team will work on the development of algorithmic and mathematical tools to study transient phenomena. The proposed work deals with propagation of sound and the interaction of mechanical vibrations with fluid motion, with potential applications in the simulation of propagation of noise inside vibrating structures (vehicles, for instance). The techniques that the investigator and his team will develop are general in scope and can be potentially applied to other wave propagation problems, including seismic and electromagnetic waves."
"1160392","2012 Finite Element Rodeo Conference","DMS","COMPUTATIONAL MATHEMATICS","04/01/2012","03/22/2012","Beatrice Riviere","TX","William Marsh Rice University","Standard Grant","Junping Wang","03/31/2013","$2,000.00","","Beatrice.Riviere@rice.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","MPS","1271","7556, 9263","$0.00","This workshop project helps support the 2012 Finite Element Rodeo conference that takes place in March 2012 at Rice University.  The workshop has attracted around one hundred participants mostly from the states of Texas and Louisiana. Registration fees for junior participants are waived. Topics covered in the workshop consist of recent advances in the theory and implementation of the general class of finite element methods, including mixed finite element methods, boundary element methods, discontinuous Galerkin methods and finite volume methods.<br/><br/>As scientists attempt to solve more and more complex problems, there is an increasing need for accurate and robust numerical methods. Uncertainty, multiple physics, multiple time and spatial scales are examples of challenges associated with complex problems. Participants of the Finite Element Rodeo address those issues by formulation, rigorous analysis and efficient implementation of state-of-the-art numerical methods. The informal nature of the workshop makes it well-suited for introducing new research ideas. Applications discussed in the workshop cover many engineering fields including energy, environment and biomedicine. Networking and collaboration developing is encouraged among participants. A high number of under-represented groups is to be seen in the workshop participants."
"1217156","Collaborative Research: Innovative Integrative Strategies for Nonlinear Parametric Inversion","DMS","COMPUTATIONAL MATHEMATICS","09/15/2012","09/04/2013","Eric de Sturler","VA","Virginia Polytechnic Institute and State University","Continuing Grant","Leland Jameson","08/31/2015","$359,942.00","Serkan Gugercin, Christopher Beattie","sturler@vt.edu","300 TURNER ST NW","BLACKSBURG","VA","240603359","5402315281","MPS","1271","9263","$0.00","The investigators aim to reduce drastically the costs of numerical inversion (as occurs, for example, in medical imaging) by blending new parametric level-set approaches and nonlinear least squares methods together with innovations in linear solvers, preconditioning, and model reduction of parameterized systems. Four strategies are combined to reduce the computation necessary while not degrading accuracy of the solution. First, the dimension of the inverse problem is drastically reduced by developing low-order parametric inversion methods replacing the usual voxel-based inversion. Second, the optimization underlying parametric inversion incorporates novel nonlinear least-squares solvers specifically designed to deal with ill-conditioned Jacobians. Third, the high cost of solving many large forward problems is reduced through new model reduction techniques that are particularly well-suited to the structure of the inverse problems under consideration. Fourth, the high costs of computing reduced models and solving forward problems is reduced by innovations in Krylov subspace recycling and efficient reuse of preconditioners for parameterized linear systems. <br/><br/>The inverse problems studied here involve recovery of images describing how unknown quantities of diagnostic interest (such as electrical conductivity) are distributed throughout a given medium (such as human tissue or soil). These images can reveal the presence or absence of anomalies, such as tumors in human tissue or contaminant plumes in soil. The computational extraction of high quality images from noisy surface measurements in reasonable time is a very difficult task. As rapid advances in technology make it possible to take vastly more measurements, computational bottlenecks become ever more acute, impeding innovation in medical and other areas of imaging. This project aims to combine innovations in diverse fields within computational linear algebra, systems theory, and optimization to create dramatically improved strategies for image extraction."
"1217080","Space-time Parallelization of Numerical Methods for Partial Differential Equations","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","09/15/2012","08/23/2014","Jingfang Huang","NC","University of North Carolina at Chapel Hill","Standard Grant","Rosemary Renaut","08/31/2016","$338,659.00","","huang@email.unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275995023","9199663411","MPS","1253, 1271","1515, 9263","$0.00","The field of high-performance scientific computing is in the midst of a disruptive paradigm shift brought about by changes in computer architecture. Increased computational through-put is now achieved mainly by increasing concurrency with the number of cores per processor increasing exponentially and plans for the first exascale system suggesting massive cores. In addition, limitations to system power, increased memory hierarchy, and fundamental physical barriers will make memory access and communication relatively more expensive than floating point operations. These changes are necessitating the reconsideration of numerical algorithms of nearly every type in terms of the new efficiency metrics emerging architectures require. Motivated by the challenge of increasing concurrency, this research centers around the analysis, implementation, and application of new algorithms to enable parallelization of numerical methods for partial differential equations in both space and time. His approach builds on the parallel full approximation scheme in space and time (PFASST) algorithm recently developed by the PIs. PFASST combines iterative temporal integration schemes and a hierarchy of spatial and temporal discretizations to allow work on multiple time steps of a PDE to be done concurrently. Preliminary studies of the PFASST algorithm by the PIs have demonstrated temporal parallel efficiencies in excess of fifty percent on a range of representative model PDEs of differing type, however, space-time parallelism to this point is largely unexplored and certainly not widely adopted in the broader community. <br/><br/>This project outlines a program of research necessary to move the use of space-time parallelism from the proof of concept stage to an effective way of increasing computational speed in large scale applications across computational science. Specific major issues addressed in the research include mathematical analysis of the convergence of PFASST in various discretization regimes, load-balancing and optimization of the trade-off between space and time parallelization, adapting PFASST to unstructured grids and particle based simulations, and the use of multiple physical models within the discretization hierarchies. The research has the potential to increase the available computational concurrency in virtually all time-dependent numerical methods. Hence this research project could impact a broad spectrum of fields such as computational chemistry, biology, physics, engineering, and computer science. In the area of education and outreach, the PI includes activities at the graduate and undergraduate level, with a component designed to reach high-school teachers and students."
"1226019","Collaborative Research: Advances in Nonlocal Dielectric Modeling and Free Energy Calculation for Protein in Ionic Solvent","DMS","COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY","09/01/2012","08/22/2012","L. Ridgway Scott","IL","University of Chicago","Standard Grant","Mary Ann Horn","08/31/2016","$169,672.00","","ridg@cs.uchicago.edu","5801 S ELLIS AVE","CHICAGO","IL","606375418","7737028669","MPS","1271, 7334","9263","$0.00","The nonlocal dielectric approach can significantly enhance the classic Poisson dielectric model by considering the polarization correlations among water molecules. However, current studies on the approach are mostly restricted to the water solvent, due to modeling and algorithmic complications that arise in the case of ionic solvents. The current ionic models that do exist fail to incorporate crucial nonlocal dielectric effects. Recent developments also indicate that entropic changes due to protein-ligand association are critical to understanding binding affinity. The computation of entropy, however, remains a very difficult task. Motivated by these challenges, this project aims to develop new nonlocal continuum electrostatic models and new numerical quadratures for the direct calculation of entropy and free energy for protein in ionic solvent. The new nonlocal models will be constructed from a novel combination of the nonlocal dielectric approach with the fundamental measure theory of hard-sphere mixture fluids under the constrained functional optimization protocol. They are expected to significantly improve the accuracy of electrostatic potential calculations in comparison to the classic Poisson-Boltzmann equation, since they reflect both ionic size effects and polarization correlations among water molecules. The new numerical quadratures will be developed by using a special prismatic element interpolation constructed from a prismatic mesh of a bounded state region near a potential energy minimum point. The computing complexity will be further reduced through using a new nonlocal model for computing involved electrostatic potential. Lastly, new fast numerical algorithms and program packages will be developed for solving the new dielectric models and for implementing the new numerical quadratures.  <br/><br/>Calculation of electrostatic potential energy, entropy, and free energy for protein in ionic solvent is a fundamental task in biomolecular simulations. The new nonlocal dielectric models, numerical quadratures for computing entropy and free energy, and the accompanying efficient numerical algorithms and program packages produced from this project will be a considerable contribution to the fields of mathematical biology, computational biochemistry, computational mathematics, and computer science. They will play important roles in ion channel studies, rational drug design, and other bioengineering applications, and will improve our quantitative understanding of critical physiological processes, cellular energetics, and affinity in protein-ligand binding, and of health and disease in general.  The findings from this project are expected to have a significant impact on the development of mathematics, computer science, biochemistry, and bioengineering.  Because there has been substantial interest recently in algorithms for solving high-dimensional problems, any advances made in this project will have broad potential impact in a variety of areas that are related to high-dimensional integrals with integrands that decay exponentially."
"1216318","Extending Sparse Optimization","DMS","COMPUTATIONAL MATHEMATICS, OPERATIONS RESEARCH","08/01/2012","07/24/2012","Stephen Wright","WI","University of Wisconsin-Madison","Standard Grant","Rosemary Renaut","07/31/2016","$240,999.00","","swright@cs.wisc.edu","21 N PARK ST STE 6301","MADISON","WI","537151218","6082623822","MPS","1271, 5514","073E, 9263","$0.00","Rather than solving an optimization problem exactly, sparse optimization seeks approximate solutions that satisfy certain structural properties, such as few nonzeros in the solution vector. Sparse optimization problems and formulations are now recognized across a wide range of applications, and techniques for solving these problems draw on a large variety of algorithmic tools, old and new. This project aims to extend sparse optimization in two respects. First, work is proposed in application areas that can benefit from the sparse optimization perspective: machine learning and data mining at extreme scale, contact dynamics, object packing, medical image reconstruction, and derivative-free optimization. Algorithmic developments will target key problem formulations in these areas, paying particular attention to methods that can exploit parallel computer architectures and specialized hardware. Algorithmic techniques to be considered include stochastic approximation, randomized directions, augmented Lagrangian, and reduced-space search using higher-order information. Second, the project will use general frameworks to analyze such algorithmic ideas as manifold identification, continuation, first-order algorithms, inexactness, and convergence and complexity results. The general nature of these investigations will enable innovations to be spread across a wide range of formulations and applications.  <br/><br/>The field of optimization provides a vital framework for formulating, modeling, and solving problems in many application areas. In sparse optimization, we note that many applications require solutions with a special structure that is easy to specify, but hard to incorporate in traditional algorithms and models. Sparse optimization arises, for example, in reconstruction of signals and images, where we know that the signal should contain only a few frequencies, or that the image should look like a natural image rather than white noise.  Important developments of the past few years have shown that the requirement of structure in solutions, rather than being a hindrance to efficient solution, can actually lead to more efficient formulations and faster methods. Notable successes have been achieved in such areas as compressed sensing and image denoising. This project will build on these successes by developing algorithms that can be leveraged in many new and existing applications of sparse optimization. In keeping with modern optimization research, a bevy of algorithmic techniques will be considered. Theory will be developed to support the use of these techniques in a wide range of contexts."
"1216674","Collaborative Research: Adaptive Hybridized DG Methods for Acoustic and Electromagnetic Scattering","DMS","COMPUTATIONAL MATHEMATICS","08/01/2012","09/14/2015","Adrianna Gillman","TX","William Marsh Rice University","Standard Grant","Leland Jameson","07/31/2016","$157,056.00","Timothy Warburton","adrianna.gillman@colorado.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","MPS","1271","9263","$0.00","In this project, the investigator and his colleagues will develop, analyze, and implement quasi-optimal adaptive hybridized Discontinuous Galerkin methods for acoustic and electromagnetic scattering problems as described by the Helmholtz equation and the time-harmonic Maxwell equation on bounded domains in two and three dimensional domains using general local bases. These methods feature traditional piecewise polynomial bases as well as special purpose wave elements, and multilevel preconditioned iterative solvers on adaptively refined simplicial, quadrilateral, and hexahedral meshes. The adaptive mesh refinement is driven by residual-type a posteriori error estimators. In particular, the team will prove convergence of the adaptive solution process as well as its quasi-optimality in terms of the computational complexity with respect to a properly specified approximation class. High quality software implementations will be used to test the algorithms and inform the analysis.<br/><br/>Advances in the state of the art in numerical methods for performing acoustic and electromagnetic simulations have potentially high impact in several applications. As an example more accurate simulation of acoustic wave propagation can be used to considerably enhance resolution of medical ultra sound scans, and thus expand the reach of non-invasive diagnostics. The emphasis of this project is the development of novel numerical methods that compute provably accurate approximations of physical acoustics and electromagnetics phenomena."
"1217054","Math: Algorithms for Parametric (Comprehensive) Groebner Computations","DMS","COMPUTATIONAL MATHEMATICS, Software & Hardware Foundation","08/01/2012","07/26/2012","Deepak Kapur","NM","University of New Mexico","Standard Grant","Leland Jameson","07/31/2017","$299,481.00","","kapur@cs.unm.edu","1700 LOMAS BLVD NE STE 2200","ALBUQUERQUE","NM","871063837","5052774186","MPS","1271, 7798","7944, 9150, 9263","$0.00","Algorithms for solving multivariate polynomial systems will be investigated with a particular focus on parametric polynomial systems in which indeterminates are classified into two disjoint subsets-- one consisting of parameters and other consisting of variables. Such polynomial systems are used to model or approximate problems generically in many application domains, where a generic problem has parameters such that for every parameter value, the generic problem becomes specific. The objective is to study the structure of solutions for different specializations of parameters. This research project will investigate the use of the framework of Groebner basis computations for this analysis. Particularly, comprehensive Groebner bases and comprehensive Groebner systems are elegant mathematical objects which represent all the solutions of a parametric polynomial system for all possible parameter values. The project will explore theoretical foundations as well as develop efficient and effective algorithms for computing comprehensive Groebner systems and comprehensive Groebner bases for parametric polynomial systems. The concept of a minimal canonical comprehensive Groebner basis will be developed and its significance will be explored for studying problems in polynomial ideal theory and algebraic geometry. An efficient algorithm to compute a minimal canonical comprehensive Groebner basis will be investigated.<br/> <br/>Parametric multivariate polynomial systems are a powerful tool for modeling many problems in various application domains. The problems of (i) determining whether a given polynomial equation system has a common solution, (ii) deriving conditions on symbolic parameters appearing in polynomial equations such that they have a common solution, and (iii) developing an efficient representation of common solutions are of fundamental significance. These problems arise in diverse applications, including engineering design, robotics, inverse kinematics, graphics, solid modeling, CAD-CAM design, geometric construction, drug-design, control theory, and program verification and analysis. Given that many problems in various application domains can be generically modeled using parametric polynomials, fast methods for solving parametric polynomial systems are useful for those applications. The proposed research will lead to the development of theory and algorithms related to comprehensive Groebner computations and investigation of their effective use in many application domains, with a particular focus on geometric design and modeling, as well as  program analysis and verification. The algorithms developed during the research project will be implemented in computer algebra systems including Magma and Singular, and experimented with on a variety of problems arising from different application domains. Heuristics will be developed and analyzed to make these algorithms and their implementations efficient."
"1217066","Fast Spectral Methods and their Applications","DMS","COMPUTATIONAL MATHEMATICS","08/01/2012","05/05/2014","Jie Shen","IN","Purdue University","Continuing Grant","Leland Jameson","07/31/2015","$180,000.00","","shen@math.purdue.edu","2550 NORTHWESTERN AVE STE 1900","WEST LAFAYETTE","IN","479061332","7654941055","MPS","1271","9263","$0.00","The focus of this project is to design accurate, fast and robust spectral methods for solving a large class of partial differential equations, and apply them to investigate several important problems of current interest. More precisely, it is proposed to develop (i)  adaptive sparse spectral methods for solving a class of higher-dimensional problems; (ii) spectrally-accurate schemes in space-time for a class of parabolic type PDEs; (iii) robust and accurate spectral methods for electromagnetic scattering, particularly for layered medium and with higher wave numbers;  and (iv) to  apply the proposed fast and accurate spectral methods  to investigate emerging  problems in fluid dynamics and materials science such as drop formation & filament breakup and ferroelectric & multiferroic nanostructures in advanced materials processing.<br/><br/>It is expected that the proposed numerical simulations will enable us to handle challenging problems having stringent accuracy and/or memory requirements with a reasonable cost in CPU and turn-around time, contribute towards better understandings of the complex physical and mathematical problems, and provide valuable information for the design of advanced materials and on the rheological and hydrodynamic properties of complex fluids. Another important goal of this project is to engage graduate students in learning necessary skills of computational and applied mathematics so that they can pursue a successful career in sciences and engineering."
"1216564","Domain Decomposition Methods: Algorithms and Theory","DMS","COMPUTATIONAL MATHEMATICS","09/01/2012","07/18/2012","Olof Widlund","NY","New York University","Standard Grant","Leland Jameson","08/31/2016","$180,000.00","","widlund@cs.nyu.edu","70 WASHINGTON SQ S","NEW YORK","NY","100121019","2129982121","MPS","1271","9263","$0.00","The development of iterative methods for large algebraic systems is central in the development of efficient codes for computational fluid dynamics, elasticity, and electromagnetics. Many other tasks in such codes parallelize relatively easily. Progress on algebraic system solvers therefore remain very important now that parallel and distributed computing systems, with a substantial number of fast processors, each with a relatively large memory, are becoming widely available. A very desirable feature of domain decomposition algorithms is that they respect the memory hierarchy of modern parallel and distributed computing systems, which is essential for approaching peak floating point performance. This is important since the cost of communication often can dominate for large computer systems. The domain decomposition methods are also relatively easy to implement and they have an increasingly solid theoretical basis, which shows that the rate of convergence can be made independent of the number of subdomains and only deteriorates very slowly with the dimension of the subproblems allocated to individual processors. This research is supported by high quality software systems in particular by  Argonne's PETSc library and by collaborators, who are highly accomplished developers of parallel code. Work will continue on developing several families of domain decomposition methods for increasingly complicated systems of partial differential equations. Domain decomposition algorithms are iterative methods, often of preconditioned conjugate gradient type, for the parallel solution of the large linear, or nonlinear, systems of algebraic equations that arise when partial differential equations are discretized. Much of the work is focused on finite element methods which makes it possible to build on the well developed theory and practice of that field. In each iteration step, local problems representing the restriction of the original problem to a potentially large number of subregions are solved exactly or approximately. The subregions, often allocated to individual processors of a parallel computer, form a decomposition of the entire domain of the problem. In addition, the inclusion of a coarse  component often substantially increases the efficiency of the preconditioner and can dramatically reduce the CPU time. Each class of applications, e.g., elasticity, incompressible fluid flow, and electromagnetics, requires a special consideration and, in particular, the design of an appropriate coarse solver, for the problem at hand, is crucially important. Of important applications, the main focus of this project is now on problems of electromagnetics. Work on almost incompressible elasticity and stationary, incompressible Navier-Stokes will also continue. <br/><br/>This project will combine mathematical analysis with the design and numerical testing of algorithms. New powerful tools for the analysis of these iterative methods are now becoming available, which makes it possible to predict the rate of convergence in terms of geometric properties of the subdomains that are easy to understand even for quite irregular subdomains such as those that result from using standard mesh partitioners. This work will have an impact on graduate education in scientific computing,  outside the narrow research community, by providing new knowledge disseminated through conference and invited talks, tutorials, journal articles, etc. Furthermore, with a focus on widely used methods and through direct contact with computational engineering scientists at the US national laboratories and in academia, the new and improved algorithms will have an impact on the development of important software libraries of these laboratories."
"1201654","Algebraic Geometry for Applications","DMS","ALGEBRA,NUMBER THEORY,AND COM, COMPUTATIONAL MATHEMATICS, Combinatorics","05/01/2012","12/14/2011","Anton Leykin","GA","Georgia Tech Research Corporation","Standard Grant","tara smith","04/30/2013","$22,501.00","Josephine Yu, Grigoriy Blekherman","leykin@math.gatech.edu","926 DALNEY ST NW","ATLANTA","GA","30332","4048944819","MPS","1264, 1271, 7970","7556","$0.00","A three-week long summer graduate program on ""Algebraic Geometry for Applications"" will take place in Georgia Institute of Technology from June 18 to July 6, 2012. The program will focus on Polynomial Optimization and Real Algebraic Geometry, Computer Algebra and Numerical Algebraic Geometry, Tropical Geometry, and their applications. Institute for Mathematics and Applications (IMA) provides funding for IMA participating institutions. The supplemental NSF funding will be used to cover students from non-participating institutions.<br/><br/>Techniques and algorithmic methods from algebraic geometry have been making an impact on applied mathematics and engineering in recent years. With large computations now possible due to the growing power of modern computers and vast availability of computational resources, the applied mathematics community is opening up to the machinery of algebra. This summer program is aimed at preparing the next generation of mathematicians in the area of applied algebraic geometry.<br/><br/>For more information see https://sites.google.com/site/imaaga2012"
"1151297","CAREER: Algorithms and Software for Computational Algebraic Geometry","DMS","ALGEBRA,NUMBER THEORY,AND COM, COMPUTATIONAL MATHEMATICS","08/15/2012","08/13/2012","Anton Leykin","GA","Georgia Tech Research Corporation","Standard Grant","Leland Jameson","07/31/2018","$470,069.00","","leykin@math.gatech.edu","926 DALNEY ST NW","ATLANTA","GA","30332","4048944819","MPS","1264, 1271","1045, 9263","$0.00","In this project the PI will develop symbolic, numerical, and hybrid methods in computational algebraic geometry and implement the resulting algorithms. He expects to advance both heuristic and certified methods in numerical algebraic geometry aimed at solving systems of polynomial equations and extracting exact geometric invariants and combinatorial information from algebraic varieties via approximate numerical methods. The proposed research includes certification of results obtained with numerical homotopy continuation, applications to tropical geometry and Schubert calculus, as well as the development of the numerical algebraic geometry engine of Macaulay2. The proposed multi-level educational program includes a new undergraduate course in algebraic computation, a graduate topics course, and a graduate summer program. <br/> <br/>Polynomial systems are ubiquitous in mathematical models in science and engineering. As engineering community opens up to algebraic methods, applied algebraic geometry is bound to make impact on a multitude of areas. The software produced in this research project will help scientists and engineers confronted with problems algebraic in nature. Certification in homotopy tracking algorithms will bring absolute assurance of the correctness of computation valuable to practitioners and provide a status of proof to the results obtained with homotopy methods important to theoreticians. The educational part of the project will promote algebraic computation in Georgia Tech within and outside the School of Mathematics and is perfectly suited for a large engineering school with a diverse student body."
"1216656","Next-generation integral equation methods for wave scattering and propagation in periodic structures","DMS","COMPUTATIONAL MATHEMATICS","07/15/2012","07/14/2012","Alexander Barnett","NH","Dartmouth College","Standard Grant","Leland Jameson","06/30/2015","$180,000.00","","ahb@math.dartmouth.edu","7 LEBANON ST","HANOVER","NH","037552170","6036463007","MPS","1271","9150, 9263","$0.00","The investigator and supported graduate student will develop new integral equation algorithms to solve the Helmholtz equation in the context of time-harmonic wave scattering from complex periodic structures. These algorithms will be efficient, high-order accurate, mathematically rigorous, and, unlike many existing integral equation solvers, robust for all problem parameters.  Building upon success in two dimensions, the project considers technologically important multilayer media and three dimensional doubly-periodic scatterers. The work includes developing new surface quadrature schemes, and the use of recent fast direct solvers to handle multiple incident angles.<br/><br/>Basic science, engineering progress, and technology is increasingly reliant upon the guidance and control of waves by periodic structures on the scale of the wavelength. Examples include diffraction gratings, filters, photonic crystals and other nano-scale materials, cost-effective solar cells, microwave antennae, radar, sound absorbers, lithography and remote sensing.  The computer algorithms proposed by the investigator will make the modeling and design of such devices more efficient, accurate, and reliable.  Efficiency and robustness are paramount because predicting real-world device performance often requires thousands of solutions at different parameters.  The societal benefits of more rapid modeling and design of such complex devices are many, including faster communication, and cheaper renewable energy. The investigator will release publicly-available software, and also will engage local rural high-school mathematics students with hands-on explorations in music, acoustics, waves, and computer signal analysis."
"1217065","New Sampling Tools, with Applications to Quantum Monte Carlo and Stochastic Control","DMS","COMPUTATIONAL MATHEMATICS","09/01/2012","07/05/2013","Alexandre Chorin","CA","University of California-Berkeley","Continuing Grant","Leland Jameson","08/31/2015","$300,000.00","","chorin@math.berkeley.edu","1608 4TH ST STE 201","BERKELEY","CA","947101749","5106433891","MPS","1271","9263","$0.00","The investigator and his students develop new methods for sampling multidimensional probability densities. The idea is to achieve importance sampling by formulating high-quality proposal densities implicitly. For problems where the variables are continuous the investigator does this by first locating the modes of the density to be sampled, and then sampling by a creating a one-to-one and onto mapping from a convenient reference density onto the given probability space so that the neighborhoods of the modes have a high probability of being sampled. This map is defined implicitly by an efficient solution algorithm for a degenerate algebraic equation. Two successive samples are independent. This idea has been successfully applied by the investigator to problems in Bayesian estimation and in data assimilation, and the investigator proposes to extend it to quantum Monte Carlo and to stochastic control via path integral formulations. For problems where the variables are discrete and the previous algorithm is not applicable and where the probabilities are defined by a Hamiltonian, the investigator proposes to search for high-probability samples by first estimating a sequence of renormalized Hamiltonians via a fast algorithm developed with previous NSF support, and then sampling these Hamiltonians sequentially to find high-probability samples. In a first stage, the investigator expects to apply this second idea to the sampling of spin glasses and simple gauge fields.<br/><br/>The investigator and his students develop efficient algorithms for finding samples of given probability distributions. One can think of the given probability distributions as embodying a (possibly uncertain) theoretical model of a physical system, and the samples as instances of events for which the model is valid; one can then contrast these instances with (possibly uncertain) data and find out what is likely to happen given both the data and the model. This is commonly done in fields such as meteorology and economics. However, finding useful samples is typically difficult and costly in computer resources because the number of possibilities is typical colossal, but most of them turn out to be highly unlikely once data are taken into account. One wants to focus on likely instances, but in general one does not know in advance where these are. This difficulty is a major bottleneck in scientific computing. The investigator has been developing sampling methods that can find the high probability samples, even without prior knowledge, by optimizing the sampling in suitably abstract versions of the problems; he has successfully used these new methods in oceanography and geophysics, and proposes to develop them further for use in robotics, computational chemistry, and nuclear physics."
"1217123","A mixed finite element framework for Biot's consolidation model and its interface problems","DMS","COMPUTATIONAL MATHEMATICS","09/01/2012","08/22/2012","Son-Young Yi","TX","University of Texas at El Paso","Standard Grant","Leland Jameson","08/31/2016","$263,569.00","","syi@utep.edu","500 W UNIVERSITY AVE","EL PASO","TX","799680001","9157475680","MPS","1271","9263","$0.00","This project aims to develop and analyze efficient and robust numerical methods for linear poroelasticity. The theory of poroelasticity addresses the time-dependent coupling between the deformation of porous materials and the fluid flow inside. Modeling the mechanical behavior of fluid-saturated porous media is of great importance in a wide range of science and engineering fields, including reservoir engineering, soil mechanics, environmental engineering, material science, and, more recently, biomechanical engineering. Due to the complicated nature of the governing equations for poroelasticity, analytical solutions have rarely been found; therefore, numerical simulations have played an important role in poroelastic modeling. The PI addresses several important issues in numerical methods for linear poroelasticity; (i) locking effects, (ii) heterogeneity in material properties, and (iii) interaction of a deformable porous medium with other free fluid or mechanical systems. It has been well-known that standard Galerkin finite element methods produce unstable and oscillatory numerical behavior of the fluid pressure, which is known as locking in poroelasticity. Overcoming locking effects in poroelasticity has been a subject of extensive research. Another challenge in numerical modeling of poroelasticity is the effective treatment of interface conditions when heterogeneity is present in porous materials or the poroelastic system is interacting with other flow systems or mechanical systems. The main feature of this proposed project is to develop a mixed finite element framework based on coupling two mixed finite element methods for each of the flow and mechanics problems so that they can efficiently handle the issues addressed above. Various mixed finite element methods are developed and a-priori error estimates are derived. Another important aspect of this project is to develop various coupling techniques for the flow and mechanics problems. The PI investigates several operator-splitting schemes, and analyzes their stability and convergence. The numerical methods developed in this project are implemented and applied to several benchmark problems to demonstrate their accuracy and efficiency. Therefore, this research activity enhances the predictive computational capabilities and understanding of the flow and transport processes in poroelastic materials in various situations.<br/><br/>Developing efficient and robust numerical methods for poroelasticity and the interaction of a poroelastic system with a free fluid or with other mechanical systems has cross-disciplinary implications. For example, the development and management of the nation's energy and natural resources, industrial processing of turbine blades and inkjet printing, waste water treatment, modeling of soft biological tissues such as arterial walls, and development of sound packages for acoustic insulation using multilayered panels heavily rely on predictive computational simulations. Therefore, this project greatly benefits both the computational mathematics and engineering communities. A Ph.D. student is trained to gain knowledge and practical skills in scientific computing and the mathematical analysis of finite element methods in this project."
"1306179","Collaborative Research: Computational Problems in Heterogeneous Nanomaterials","DMS","COMPUTATIONAL MATHEMATICS","08/01/2012","01/28/2013","Vivek Shenoy","PA","University of Pennsylvania","Standard Grant","Junping Wang","07/31/2014","$228,268.00","","vbshenoy1@gmail.com","Research Services","Philadelphia","PA","191046205","2158987293","MPS","1271","0000, 7237, 9263, OTHR","$0.00","In many applications ranging from energy to biomedicine, nanocrystalline materials, such as quantum dots and nanowires, promise to yield revolutionary new technologies. The realization of this promise is hindered by the challenges inherent in reproducibly fabricating nanocrystalline materials with controlled morphologies and compositions. These nanomaterials are typically heterogeneous and consist of alloys with multiple constituents. While there has been much work on formulating conditions under which spatially ordered nanocrystals with nearly uniform shapes and sizes may be produced, a quantitative description of the mechanisms that determine the spatial distribution of the alloy components, which is crucial to device performance, is still poorly understood. The investigators and their collaborators address this issue in this proposal. They study the nonlinear dynamics of heterogeneous, strained strained nanocrystalline materials by (1) developing and applying state-of-the-art adaptive numerical methods to large-scale computation and (2) performing analytical, numerical and modelling studies of important constituent processes. The investigators focus on the dynamic, nonlinear coupling among shape, elastic stress and composition in the context of (i) the dynamics of thin film alloys and quantum dots under far-from-equilibrium processing conditions where there may be bulk and surface transport of the different constituents, as well as phase decomposition; and (ii) the coarsening dynamics and stability of capped nanocrystals. The cap material is needed in applications to provide the confinement potential for charge carriers as well as passivation against the external environment. These problems are characterized by the presence of multiple constitutive components, bulk-surface interactions, complex pattern formation and/or singularities (i.e. spatial complexity). The mathematical models involve high-order spatial derivatives (e.g. up to sixth-order), evolving free boundaries and highly nonlinear interactions that make analysis and simulation difficult, particularly in 3D. The highly nonlinear nature of these problems makes fast, accurate and robust numerical methods essential to their study. <br/><br/>Nanocrystalline alloy materials have physical properties that make them ideally suited for a wide range of potential applications including advanced electronic and magnetic devices as well as biological and chemical sensors. The properties of nanoscale devices are determined both by the spatial composition of the heterogeneous nanocrystal components and the nanocrystal geometry. Recent advances in experimental techniques have enabled the characterization of nanoscale composition variation in nanocrystals. <br/>However, a quantitative understanding of these variations remains elusive and yet is critical to device performance. The investigators and their collaborators address this issue by developing new mathematical models, theory and computational methods that make it possible to characterize and quantify the interactions among nanocrystal shape, elastic stress and composition. The investigators also consider capped nanostructures where the cap material provides protection from the environment that is needed in many applications including the use of nanocrystals in silicon-based electronic circuits. The interaction among the nanocrystalline and capping materials introduces additional complexity. These problems are multidisciplinary and progress requires the combined expertise of the investigators in materials science and applied and computational mathematics. Through this study, the investigators provide guidance in the quantitative interpretation of experimental measurements of composition variation in nanocrystals and suggest optimized processing conditions to achieve desired device shape, composition and performance. The project establishes a new collaboration between two institutions and provides interdisciplinary training of two Ph.D students and one postdoctoral researcher. In addition, the investigators build on their recent success and continue to develop and teach a course on crystal and epitaxial growth for gifted high school students as part of the Calif. State Summer School for Mathematics and Science (COSMOS) at UC Irvine. This course also helps to recruit new math and science majors and enhance the participation of high school students in research."
"1207784","Transformation Optics and Acoustic and Electromagnetic Cloaking","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","08/01/2012","08/03/2012","Hongyu Liu","NC","University of North Carolina at Charlotte","Standard Grant","Michael Steuerwalt","07/31/2015","$105,000.00","","hliu28@uncc.edu","9201 University City Boulevard","CHARLOTTE","NC","282230001","7046871888","MPS","1266, 1271","9263","$0.00","The project aims to study analytically and numerically some central problems arising in the study of invisibility cloaking for acoustic and electromagnetic waves. There has been significant attention in the scientific community in the last few years on invisibility for electromagnetic and other types of waves. The main goal of this project is to develop and analyze practical cloaking schemes under various circumstances, and to understand the cloaking phenomena. The main tools used are analysis and computation. Specifically, the proposed research will be devoted to the following four problems. The first one is to study the regularized approximate cloaking for the full system of Maxwell's equations via the transformation optics approach. Sharp estimates will be derived in assessing cloaking performances under various practical circumstances. The second problem is on the design and analysis of novel cloaking schemes including partial cloaking and on the implementation of isotropic cloaking medium obtained by inverse-homogenization theory. The third problem is to understand the invisibility cloaking from an optimization viewpoint by minimizing the scattering of the waves. This will also gives clues to what is the borderline between visibility and invisibility. The final problem is to develop effective and efficient numerical methods to numerically study cloaking. These problems present interesting challenges from both the analytical and computational points of view.<br/><br/>Research on invisibility cloaking has the potential for many civil and industrial applications, such as in medical surgery, wireless communications, air flight and space exploration etc. However, it presents many challenges both theoretically and in practical implementation due to the singular and unstable structures of the suggested blueprints for cloaking. The solution of the proposed problems would provide theoretical recipes for the construction of practical cloaking devices. Moreover, the mathematical understanding of invisibility cloaking will on the one hand offer a different way than the transformation-optics approach to achieve cloaking, and on the other hand provide important implications for inverse problems involving reconstructing electromagnetic objects. The analytical and computational techniques developed in this project are widely applicable to other electromagnetic phenomena. Some of the ideas developed in this project will be included into a graduate level class. The proposer also plans to advice and train graduate students in this challenging field."
"1216974","Collaborative Research:  Numerical Methods for Shallow Water Equations and Related Models","DMS","COMPUTATIONAL MATHEMATICS","09/01/2012","07/24/2012","Alina Chertock","NC","North Carolina State University","Standard Grant","Leland Jameson","08/31/2016","$200,000.00","","chertock@math.ncsu.edu","2601 Wolf Village Way","Raleigh","NC","276957514","9195152444","MPS","1271","9263","$0.00","The project is aimed at developing accurate, efficient, and robust numerical methods for shallow water equations and related models, with particular reference to problems that admit non-smooth (discontinuous) solutions and to problems that involve highly disparate scales and therefore are difficult to solve numerically. Shallow water and related models are widely used as a mathematical framework to study water flows in rivers and coastal areas as well as to investigate a variety of phenomena in atmospheric sciences and oceanography. These models are systems of time-dependent partial differential equations (PDEs) that are derived using physical properties such as conservation of mass and momentum, and hydrostatic or barotropic approximations. The principal part of the proposed research will be focused on the development of new methods for solving problems involving complicated nonlinear wave phenomena, problems with complex computational domains and moving interfaces. The resulting methods, while based on high-order shock-capturing finite-volume schemes and non-dissipative mesh-free particle methods, will incorporate special numerical techniques such as numerical balancing between the terms that are balanced in the original system of PDEs (development of well-balanced schemes), ensuring positivity of all fluid layers (this is absolutely necessary for both accurate description of dry and near dry states and enforcement of nonlinear stability), accurate and efficient operator splitting, accurate and efficient interface tracking, and others that will be in the focus of the proposed research project. <br/><br/>The proposed project will contribute significantly toward development of computational methods for shallow water and related models. Special attention will be paid to applications arising in oceanography and atmospheric sciences, in which the Coriolis forces (due to the Earth's rotation), thermodynamics, and turbulent effects have to be taken into account. The problems under study include, among others, formation and propagation of atmospheric fronts and ocean currents, propagation of tsunami waves and their on-shore arrival, as well as propagation of pollutants in various environments. The numerical methods under design will provide considerably more powerful tools for studying a variety of internal and surface water waves, including tsunami and rogue waves. These extreme waves, which arise both in deep and shallow water, have a significant impact on the safety of people and infrastructure, and are responsible for damage to ships, oil platforms, coastlines, and sea bottoms and for changes to the biological environment. Thus, understanding the physics of these extreme waves is an important task that may even contribute to saving lives."
"1216801","Collaborative Research:  Modeling and Simulation of Graphene Growth","DMS","COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY","09/01/2012","08/27/2012","Vivek Shenoy","PA","University of Pennsylvania","Standard Grant","Leland Jameson","08/31/2016","$230,000.00","","vbshenoy1@gmail.com","Research Services","Philadelphia","PA","191046205","2158987293","MPS","1271, 7334","9150, 9263","$0.00","Nanoscale materials hold tremendous promise for the miniaturization of devices and components in applications ranging from biomedicine to nanoelectronics. As silicon-based nanodevices reach their natural size limitations, carbon-based materials such as nanotubes and graphene have emerged as exciting alternatives. Because graphene consists of a single 2D planar layer of carbon atoms, and possesses unique physical properties, graphene is thought to be better suited for large-scale circuit design than nanotubes, which typically exhibit large intrinsic resistance in contacts that limits their effectiveness. To realize their promise, large and defect-free graphene sheets must be grown or placed on non-metallic substrates. It is therefore important to understand the mechanisms that govern the growth and morphology of graphene. Indeed, controlling the graphene morphology has proven to be a major challenge, and the kinetics of graphene growth remain poorly understood. The investigators will address these issues here. The main objective of this proposal is to investigate the nonlinear dynamics of the mechanisms that govern the growth and morphology of graphene and develop strategies to control its growth by (1) developing and applying state-of-the-art adaptive numerical methods to large-scale computation and (2) performing analytical, numerical and modelling studies of important constituent processes. More specifically, the investigators will perform fundamental studies of the growth of graphene films from a thermal treatment of a silicon carbide substrate. This process is unique among epitaxial growth mechanisms because there is no deposition flux of carbon. Rather, silicon desorbs from the surface freeing carbon atoms to diffuse on the surface and nucleate first to form a precursor layer and then a graphene layer. A significant challenge is that the structure and morphology of graphene layers is determined both by atomic-scale phenomena and by the elastic interaction of surface features over length scales of hundreds of nanometers. Consequently, no single model is able to describe all the processes involved in the formation of graphene sheets on silicon carbide. The investigators will therefore adopt a multiple-scale approach that includes atomic scale simulations, genetic algorithms for determination of surface structure, and continuum models for shape evolution and patterning. The highly nonlinear nature of these problems makes fast, accurate and robust numerical methods essential to their study.<br/><br/>Nanocrystalline materials have physical properties that make them ideally suited for a wide range of potential applications including areas of Federal strategic interests such as nanotechnology, information technology (via advanced optoelectronic and magnetic storage units), biotechnology, (via biological or chemical sensors), and energy technology (via photovoltaic devices). Because of their unique structural and electronic properties, carbon-based devices, such as defect-free graphene layers, can extend miniaturization beyond the natural limits of their silicon-based counterparts. Recent advances in experimental techniques indicate that the key obstacle in achieving large and uniform graphene layers necessary for device applications is the roughness of the surface on which it grows. However, a quantitative understanding of the interaction among the surface properties and graphene growth processes remains elusive. The investigators will develop new mathematical theory and advance the state-of-the-art in numerical simulation to perform fundamental studies of graphene growth. These studies will provide guidance in the quantitative interpretation of experimental measurements on the dynamics of graphene layer formation and will suggest mechanisms to control graphene growth. The theory and methods developed here will also be useful in the study of other nanoscale materials arrays of semiconductor quantum dots. Two Ph.D. students will receive interdisciplinary training while performing the proposed work. The investigators will develop and teach a course on crystal and epitaxial growth for gifted high school students as part of the Calif. State Summer School for Mathematics and Science (COSMOS) at UC Irvine."
"1216957","Collaborative Research:  Numerical methods for Shallow Water Equations and Related Models","DMS","COMPUTATIONAL MATHEMATICS","09/01/2012","07/24/2012","Alexander Kurganov","LA","Tulane University","Standard Grant","Leland Jameson","08/31/2016","$200,000.00","","kurganov@math.tulane.edu","6823 ST CHARLES AVENUE","NEW ORLEANS","LA","701185698","5048654000","MPS","1271","9150, 9263","$0.00","The project is aimed at developing accurate, efficient, and robust numerical methods for shallow water equations and related models, with particular reference to problems that admit non-smooth (discontinuous) solutions and to problems that involve highly disparate scales and therefore are difficult to solve numerically. Shallow water and related models are widely used as a mathematical framework to study water flows in rivers and coastal areas as well as to investigate a variety of phenomena in atmospheric sciences and oceanography. These models are systems of time-dependent partial differential equations (PDEs) that are derived using physical properties such as conservation of mass and momentum, and hydrostatic or barotropic approximations. The principal part of the proposed research will be focused on the development of new methods for solving problems involving complicated nonlinear wave phenomena, problems with complex computational domains and moving interfaces. The resulting methods, while based on high-order shock-capturing finite-volume schemes and non-dissipative mesh-free particle methods, will incorporate special numerical techniques such as numerical balancing between the terms that are balanced in the original system of PDEs (development of well-balanced schemes), ensuring positivity of all fluid layers (this is absolutely necessary for both accurate description of dry and near dry states and enforcement of nonlinear stability), accurate and efficient operator splitting, accurate and efficient interface tracking, and others that will be in the focus of the proposed research project. <br/><br/>The proposed project will contribute significantly toward development of computational methods for shallow water and related models. Special attention will be paid to applications arising in oceanography and atmospheric sciences, in which the Coriolis forces (due to the Earth's rotation), thermodynamics, and turbulent effects have to be taken into account. The problems under study include, among others, formation and propagation of atmospheric fronts and ocean currents, propagation of tsunami waves and their on-shore arrival, as well as propagation of pollutants in various environments. The numerical methods under design will provide considerably more powerful tools for studying a variety of internal and surface water waves, including tsunami and rogue waves. These extreme waves, which arise both in deep and shallow water, have a significant impact on the safety of people and infrastructure, and are responsible for damage to ships, oil platforms, coastlines, and sea bottoms and for changes to the biological environment. Thus, understanding the physics of these extreme waves is an important task that may even contribute to saving lives."
"1216437","New evolution equations of the joint response-excitation PDF for stochastic modeling: Theory and numerical  methods","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/01/2012","07/09/2014","George Karniadakis","RI","Brown University","Continuing Grant","Rosemary Renaut","08/31/2016","$350,590.00","","George_Karniadakis@brown.edu","BOX 1929","Providence","RI","029129002","4018632777","MPS","1266, 1271","9263","$0.00","New theory and corresponding numerical algorithms are proposed for addressing fundamental open questions in stochastic modeling of physical and biological systems, e.g., the curse-of-dimensionality, the lack of regularity and the long-time integration of stochastic systems. Such problems arise in applications involving processes with small relative correlation length or large number of random parameters, and for time-dependent nonlinear systems subject to uncertainty. The new equations are formulated in terms of the time-evolution of the joint probability density function (PDF) between the system's response and the stochastic excitation. In particular, functional integral methods are employed to determine new types of linear deterministic partial differential equations satisfied by the joint response-excitation PDF associated with the stochastic solution of nonlinear stochastic ordinary and partial differential equations. So far the theory is complete for nonlinear and for quasilinear first-order stochastic PDEs subject to random boundary conditions, random initial conditions or random forcing terms. For higher-order equations, such the stochastic wave equation or the Oberbeck-Boussinesq thermal convection equations, it is proposed  to develop a new PDF method based on differential constraints for the PDF of the solution. It is proposed to investigate the theoretical and numerical effectiveness of this new approach for high-dimensional random systems, such as random flows subject to high-dimensional random boundary or initial conditions in bounded domains.<br/><br/>Stochastic modeling and uncertainty quantification are important new directions in computational mathematics that will enable accurate predictions of physical and biological phenomena,in critical applications such as climate, energy and the design of new products.  The proposed work will have significant and broad impact as it will set new rigorous foundations in uncertainty quantification, data assimilation and sensitivity analysis for many physical and biological systems. It will affect fundamentally the way we design new experiments and the type of questions that we can address, while the interaction between simulation and experiment will become more meaningful and more dynamic. This work will also aid in educating a new cadre of simulation scientists in this metadiscipline at the interface of computational mathematics and probability theory."
"1215987","Tractability of High Dimensional Problems for Quantum and Classical Computers","DMS","COMPUTATIONAL MATHEMATICS","09/01/2012","07/26/2012","Joseph Traub","NY","Columbia University","Standard Grant","Leland Jameson","08/31/2015","$299,861.00","Henryk Wozniakowski, Anargyros Papageorgiou","traub@cs.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","MPS","1271","9263","$0.00","The continuation of the study of algorithms and complexity for the solution of high dimensional continuous problems is proposed. Examples of such problems occur in quantum chemistry, molecular dynamics, and condensed matter physics.Typical continuous mathematical formulations include partial differential equations, continuous optimization, high dimensional integration, and path integration.Dimension measures the size of a continuous problem.Just as in the rest of complexity studies the PIs are interested in solving large problems; that is, problems of high dimension.One cannot enter a function of real or complex variables into a digital computer.One has to discretize it to obtain the computer input.Thus the computer has only partial information about the continuous mathematical input.This permits adversary arguments at the information level pioneered by the PIs and their colleagues which lead to lower bounds on the problem complexity.This may be contrasted with discrete problems where the information is complete, there are often no adversary arguments at the information level, and one has to be content with conjectures that the complexity hierarchy does not collapse.Because of the importance of information-based arguments the study of the complexity of continuous problems is called information-based complexity (IBC).<br/><br/>A central issue is to determine for which settings and spaces a problem is tractable; that is, its complexity is not exponential. There is a huge literature on the computational complexity of d-dimensional problems. Most of these papers and books obtain results which are sharp with respect to 1/E, where E is the error threshold, but have unknown dependence on d.But to determine if a problem is tractable one needs to know the dependence on both 1/E and d.This requires new proof techniques. This is the subject of the monograph ""Tractability of Multivariate Problems"" by E. Novak and H. Wozniakowski.Two volumes of the monograph have been published in 2008 and 2010.These two volumes include 91 open questions. Research will be devoted to trying to answer some of these open questions."
"1245607","5th Annual Graduate Student Mini-conference in Computational Mathematics","DMS","COMPUTATIONAL MATHEMATICS","09/01/2012","08/08/2012","Leo Rebholz","SC","Clemson University","Standard Grant","Junping Wang","08/31/2013","$8,000.00","Hyesuk Lee","rebholz@clemson.edu","230 Kappa Street","CLEMSON","SC","296340001","8646562424","MPS","1271","7556, 9150, 9263","$0.00","This fifth annual ""2013 Graduate Student mini-Conference in Computational Mathematics"" will be held at Clemson University on February 8 and 9, 2013. Topics covered in the conference consist of recent advances in the theory and implementation of numerical methods for partial differential equations, including multiphase flow in porous media, numerical methods for stochastic PDEs, turbulence fluid dynamics, climate simulation and PDE constrained optimization. Aside from one plenary speaker, all talks will be given by graduate students.<br/><br/>Approximately twenty graduate students from Clemson, Virginia Tech, the University of Pittsburgh, Auburn University, the University of Tennessee, Florida State University and Emory University will present scientific research talks involving mathematical modeling in science and engineering, and rigorous analysis and efficient implementation of numerical methods for the modeling equations. The goals of the conference are to give graduate students an opportunity to give a professional scientific talk, and to bring graduate students and researchers together to discuss collaborative research projects and to exchange new ideas in many challenging research areas.  The conference organizers strongly encourage participation of under-represented groups."
"1151308","CAREER:  Direct and Inverse Scattering Problems for Wave Propagation in Complex and Random Environments","DMS","COMPUTATIONAL MATHEMATICS","08/15/2012","06/28/2012","Peijun Li","IN","Purdue University","Standard Grant","Leland Jameson","07/31/2017","$432,250.00","","lipeijun@math.purdue.edu","2550 Northwestern Ave.","West Lafayette","IN","479061332","7654941055","MPS","1271","1045, 9263","$0.00","In scattering theory, due to the complexity of material properties and uncertainty in physical models and parameters, precise modeling and accurate computing present challenging and significant mathematical and computational questions. The PI proposes to develop mathematical models, examine mathematical issues, and design computational methods for new and important classes of direct and inverse problems that arise from the acoustic and electromagnetic wave propagation in complex and random environments. The mathematical modeling techniques and computational methods developed in this project address several key scientific challenges in applied and computational mathematics, which include: (1) multi-scale modeling and computation of the wave propagation in a heterogeneous medium; (2) computational stochastic direct and inverse scattering problems; (3) numerical solution of Maxwell's equations and well-posedness of associated models; (4) global uniqueness, local stability, and numerical solution of the ill-posed inverse scattering problems. The educational plan is to foster greater awareness of the broad and important applications of mathematics so as to attract more students in pursuing a major, a minor, or a graduate degree in mathematics. The proposed education activities include: (1) undergraduate and graduate courses and curriculum development; (2) mentoring of undergraduate, graduate, and postdoc research; (3) organizing summer schools, seminars, and workshops. <br/><br/>The dramatic growth of computational capability and the development of fast algorithms have transformed the methodology for scientific investigation and industrial applications in the field of scattering theory. Reciprocally, the practical applications and scientific developments have driven the need for more sophisticated mathematical models and numerical algorithms to describe the scattering of complicated structures, and to accurately compute acoustic and electromagnetic fields and thus to predict the performance of a given structure, as well as to carry out optimal design of new structures. The proposed computational models and tools are highly promising for qualitative and quantitative study of the complex physical and mathematical problems in optics and electromagnetics, and provide an inexpensive and easily controllable virtual prototype of the structures in the design and fabrication of optical and  electromagnetic devices. The research is multidisciplinary by nature and lies at the interface of mathematics, physics, engineering, and materials sciences. In addition, it has significant potential to advance the frontiers of applied and computational mathematics, and even to have impact on other branches of science."
"1247539","A Conference on New Frontiers in Numerical Analysis and Scientific Computing","DMS","COMPUTATIONAL MATHEMATICS","09/01/2012","09/01/2012","Jing Li","OH","Kent State University","Standard Grant","Junping Wang","08/31/2013","$23,000.00","Richard Varga","li@math.kent.edu","OFFICE OF THE COMPTROLLER","KENT","OH","442420001","3306722070","MPS","1271","7556, 9263","$0.00","The PI proposes to organize a two-day conference in frontiers of numerical analysis and scientific computing in Kent State University in April 2013. The topics of this conference include (1) fast iterative solutions of large systems of linear and nonlinear equations, (2) iterative solutions of ill-posed problems, (3) solutions of inverse problems, (4) large-scale eigenvalue and singular value problems, structured problems in linear algebra, and (5) mathematics for liquid crystal, and applications to biology. The conference topics center around the recent developments of tools in numerical analysis and scientific computing. <br/><br/>In recent years, there have been new and important developments in the field of numerical analysis and scientific computing. Advances in the design of new computational algorithms and their theoretical analysis and applications to different branches of sciences, have generated many new frontiers in this field. An important tool, inherent in most numerical solution approaches, is the use of iterative methods. Any breakthrough in the algorithm and theory of iterative methods will have a huge impact on solving many important problems in different disciplines. On the other hand, the applications from different fields provide a great platform for the advance of algorithmic designs and analytical theories of iterative methods. The PI proposes to organize a conference to address the fast development in these frontiers. The focus of this conference includes: fast iterative solutions of large systems of linear and nonlinear equations, iterative solutions of ill-posed problems, solutions of inverse problems, large-scale eigenvalue and singular value problems, structured problems in linear algebra, orthogonal polynomials, quadratures, mathematics for liquid crystal, and applications to biology. This conference covers computational subjects which are crucial for solving complicated problems in a wide range of scientific, engineering, industrial, and economic disciplines, with applications in areas such as medical and biological image processing, cancer diagnosis, liquid crystal display, mobile tablet, information technology, aircraft design, radar technology, petroleum and natural gas reservoir, and natural disaster prediction, etc."
"1217073","RUI: Uncertainty reduction through better nonlinear particle filters","DMS","COMPUTATIONAL MATHEMATICS","08/15/2012","07/01/2014","Haiyan Cheng","OR","Willamette University","Continuing Grant","Rosemary Renaut","07/31/2016","$132,169.00","","hcheng@willamette.edu","900 State Street","Salem","OR","973013930","5033706049","MPS","1271","9178, 9229, 9251, 9263","$0.00","The objective of this project is to create and implement new methods for improving the performance of filtering, or data assimilation techniques, applied to non-linear, non-Gaussian systems. Many problems in computational statistics, artificial intelligence, and geophysics involve such systems, and utilize specialized Monte Carlo sampling methods, called particle filters, for data analysis and forecasting, and for better understanding of the underlying phenomena. The principal investigator studies variational data assimilation methods to demonstrate that targeted ensemble generation using those methods delivers more effective filter performance, and that dynamic adaptation of the size of the particle ensemble improves the computational efficiency of the filter.<br/><br/>Statistical computations are an essential tool for the solution of problems in such diverse areas as artificial intelligence, industrial and consumer electronics, robotics, weather systems, climate change, ocean ecosystems, and land surface processes.  The proposed research improves statistical computations required for the analysis, estimation, and forecasting of information that arrives over time, and contributes to a better combination of theoretical models with observational data.  In addition, the project involves the training of undergraduate students in applied scientific research.   <br/>"
"1216551","The development and analysis of sweeping preconditioners for scattering problems","DMS","COMPUTATIONAL MATHEMATICS","08/01/2012","07/16/2012","Joseph Pasciak","TX","Texas A&M University","Standard Grant","Leland Jameson","07/31/2016","$235,405.00","Hakan Bagci","pasciak@math.tamu.edu","400 Harvey Mitchell Pkwy South","College Station","TX","778454375","9798626777","MPS","1271","9263","$0.00","The main objective of this research is the development of efficient iterative methods for computing numerical approximations to the solutions  of acoustic and electromagnetic scattering problems. A fundamental issue in any finite element approximation to a scattering problem is the efficient implementation of the far field boundary condition. In this research, this condition  will be approximated using either finite elements with a ``Perfectly Matched Layer'' (PML) far field approximation or finite element boundary integral formulations. The research will develop innovative new preconditioning techniques for the solution of the algebraic systems resulting from the above-mentioned approximation techniques.  The preconditioners are constructed using H-matrix approximation combined with a sweeping algorithm.   <br/> <br/>Electromagnetic scattering problems play an important role in the development of new technologies with applications in, for example, antenna and microwave engineering, remote sensing, stealth vehicle design, electromagnetic and plasmonic cloaking, biomedical engineering, and electromagnetic and seismic subsurface imaging, and are especially indispensable in locating and monitoring gas and oil reservoirs.  Simulations capable of efficiently solving acoustic and electromagnetic scattering problems involve complicated geometry, often, with fine scale inhomegenities. It is the goal of this research to significantly reduce the computational costs associated with solving above problems, thus enabling more realistic and robust computer design technology for systems involving electromagnetic scattering."
"1216454","Development of high-order accurate numerical methods for the shallow-water equations and other hyperbolic conversation laws with source terms","DMS","COMPUTATIONAL MATHEMATICS","08/01/2012","07/24/2012","Yulong Xing","TN","University of Tennessee Knoxville","Standard Grant","Junping Wang","05/31/2016","$166,178.00","","xing.205@osu.edu","1331 CIR PARK DR","Knoxville","TN","379163801","8659743466","MPS","1271","9150, 9263","$0.00","The objective of the proposed project is to provide a class of novel high-order accurate and efficient well-balanced discontinuous Galerkin (DG) and Weighted Essentially Non-Oscillatory (WENO) schemes for the shallow-water equations and other hyperbolic conservation laws with source terms. The proposed activity includes a comprehensive coverage of new algorithm development, theoretical numerical analysis, numerical implementation issues and practical applications. The investigator proposes to provide a detailed study of highly efficient high-order well-balanced methods in the following directions: 1. Development of well-balanced methods: Very accurate well-balanced numerical methods will be developed for several equations arising in different areas; 2.  Shallow-water equations: Positivity-preserving well-balanced methods for the shallow-water equations will be developed. Then, the investigator will investigate their performance, including efficiency, scalability, etc., and study their potential application in the coastal ocean modeling; 3.  Euler equations under a gravitational field: Hydrodynamical evolution in a gravitational field arises in most astrophysical problems. The investigator will develop well-balanced methods for such system; 4. Nonlinear water wave equations: Conservative DG methods will be developed for nonlinear dispersive wave equations.<br/><br/>The proposed project will provide more efficient and accurate numerical approaches to solve the shallow-water equations, and other conservation laws with source term. It will have a direct impact in many application problems arising from hydraulic engineering and atmospheric modeling, and is suitable for other source-term problems in chemistry, biology, fluid dynamics, astrophysics, and meteorology. Due to its multi-disciplinary nature, the proposed research will initiate and serve as a solid foundation for collaborative research work with applied mathematicians, hydraulic engineers and astrophysicists, and promote interdisciplinary research between Oak Ridge National Laboratory and the University of Tennessee. The proposed project will also provide training and education opportunities for both graduate and undergraduate students interested in computational mathematics.<br/>"
"1217081","Efficient, Reliable, and Robust A Posteriori Error Estimators of Recovery Type","DMS","COMPUTATIONAL MATHEMATICS","09/01/2012","09/01/2012","Zhiqiang Cai","IN","Purdue University","Standard Grant","Leland Jameson","08/31/2016","$180,000.00","","zcai@math.purdue.edu","2550 Northwestern Ave.","West Lafayette","IN","479061332","7654941055","MPS","1271","9263","$0.00","The main aim of this proposed research is to design, analyze, and test efficient, reliable, and robust a posteriori error estimators for various finite element approximations to computationally challenging problems; that is, those problems having the following phenomena: interface singularities, discontinuities (in the form of shock-like fronts, and of interior and boundary layers), and/or oscillations of various scales (multiscale phenomena). Estimators to be developed in this project do not use a priori knowledge of locations and characteristics of these phenomena; they may then be applied more readily to highly nonlinear problems and have potential to be applied to complex systems arising in applications. Estimators to be investigated in this project are of the recovery type; recovery estimators possess a number of attractive features that have led to their widespread adoption in engineering practice and to the subject of mathematical study. However, existing recovery estimators have several major drawbacks for more challenging problems. The investigator and his colleagues overcome those obstacles by introducing an innovative recovery procedure and developing a methodology on how to design efficient, reliable, and robust recovery estimators for complex systems. The methodology is applied to various problems arising from continuum mechanics to design robust estimators that will be studied theoretically and numerically.<br/><br/>Self-adaptive numerical methods provide a powerful and automatic approach in scientific computing. In particular, Adaptive Mesh Refinement (AMR) algorithms have been widely used in computational science and engineering and have become a necessary tool in computer simulations of complex natural and engineering problems. As identified by the US National Research Council, AMR is one of two necessary tools (AMR and Parallel Computer) for computationally grand challenging problems. The key ingredient for success of AMR algorithms are a posteriori error estimates that are able to accurately locate sources of global and local error in the current approximation. Success in this project will empower the ability of AMR algorithms for automatically locating physical interfaces, detecting layers and discontinuities, and resolving oscillations of various scales. The methodology developed in the project will shed light on how to design estimators for indefinite problems such as convection-dominant diffusion problems on relatively coarse meshes. Research on those indefinite problems is completely open and requires major breakthrough not only technically but also conceptually."
"1216889","Algorithms, analyses, and model reductions for  a class of  parametrized systems","DMS","COMPUTATIONAL MATHEMATICS","07/15/2012","03/26/2014","Mahadevan Ganesh","CO","Colorado School of Mines","Continuing Grant","Leland Jameson","06/30/2015","$210,000.00","","mganesh@mines.edu","1500 Illinois","Golden","CO","804011887","3032733000","MPS","1271","9263","$0.00","The main aim of the project is to develop, implement, and analyze innovative fast and highly accurate  algorithms for simulation, model reduction,  and quantification of interactions and  radiation induced by parametrized configurations comprising a large number of three dimensional particles. The focus is specifically on large systems with hundreds or even thousands of particles in  multiscale configurations that arise in atmospheric and biological sciences applications. Even for a fixed set of parameters describing a large configuration,standard iterative algorithms (and acceleration techniques) suffer from computational complexity (and slow convergence). The innovative preconditioned and accelerated   iterative  algorithms  and analyses in this project facilitate a practical approach to efficiently simulate scattering and absorption by (and interactions of) large numbers of  particles  occurring in atmospheric and biological sciences. Development of very efficient algorithms for electromagnetic scattering and absorption by a single three dimensional particle is essential to simulate interactions in large configurations.<br/><br/>Atmospheric aerosols affect Earth's energy budget directly by scattering and absorbing radiation, and indirectly by modifying the amount of cloud and the radiative properties of clouds. One of the highest priority tasks  is to advance the ability to model aerosol-cloud-precipitation interaction in climate models. The key to quantifying and  reducing uncertainty about the impact of aerosols is to understand  the scattering, absorption, and interaction properties of large configurations of particles well enough to accurately replicate them in the full climate models. A technically related problem arises in medical diagnostics where a high priority task is to understand how a laser beam interacts with a large number of red blood cells (erythrocytes). The focus of  the project is to implement  the computational mathematics component of these high priority recommendations. The project includes training of graduate and undergraduate students."
"1217122","Convergent Data-Based Algorithms for Model Reduction and Feedback Control of PDEs","DMS","COMPUTATIONAL MATHEMATICS","08/01/2012","07/24/2012","John Singler","MO","Missouri University of Science and Technology","Standard Grant","Rosemary Renaut","07/31/2016","$269,956.00","Belinda Batten","singlerj@mst.edu","300 W 12th Street","Rolla","MO","654096506","5733414134","MPS","1271","9150, 9263","$0.00","In complex applications such as design and feedback control of energy efficient buildings, and  wave or wind energy arrays, existing codes are often available for simulation but these codes are  not always suitable for purposes such as model reduction or feedback control design. The  outcome of this research is a suite of computationally efficient and provably convergent algorithms  for grand challenge problems in PDE model reduction and feedback control.  The proposed work  focuses on two fundamental problem classes: (1) computing approximate solutions of infinite  dimensional Lyapunov and Riccati equations used in feedback control design, and (2) algorithms  for PDE balanced model reduction. This work utilizes specific solution data from PDE systems to  produce provably convergent approximations for PDE model reduction and feedback control  problems. Since the algorithms are data-based, the methods may use existing simulation codes  with specialized discretization schemes and tools such as adaptive solvers, parallel algorithms, and  multigrid methods to increase computational efficiency and accuracy. Since the algorithms can  exploit such advanced simulation techniques, the algorithms can scale to treat highly complex  grand challenge problems.  <br/><br/>The accurate solution of model reduction problems for partial differential equation systems is  important for many applications including fast simulations, tractable optimization, feedback control  design, and real time control implementation. Feedback control of PDEs has potential applications  in many areas.  For example, feedback control of air flow in commercial buildings could lead to  dramatic reduction in energy consumption. In another area, feedback control of fluid-structure  interactions in wave energy converters could lead to effective ocean wave energy extraction. The  proposed work primarily considers the development and analysis of model reduction and  feedback control algorithms for linear PDE systems, as extensions of these reduced models and  feedback laws can be used to treat problems involving nonlinear PDEs. The algorithms can exploit  advanced existing simulation codes, and therefore the completion of the proposed work will open  the door for large advances in computational feedback control to challenging nonlinear PDE  systems."
"1216742","Closest Point Methods for Eigenvalue Problems from Inhomogeneous Structures","DMS","COMPUTATIONAL MATHEMATICS","08/01/2012","07/24/2012","Chiu-Yen Kao","OH","Ohio State University","Standard Grant","Junping Wang","04/30/2013","$225,866.00","","ckao@cmc.edu","Office of Sponsored Programs","Columbus","OH","432101016","6146888735","MPS","1271","9263","$0.00","The goal of this project is to develop forward eigenvalue solver based on closest point  method and efficient algorithms for shape optimization for inhomogeneous structure with (1)  general constrains and boundary conditions, (2) fourth order equations (e.g. BiLaplace Operator)  and integro-differential equations, and (3) general surfaces. The closest point method is a new  numerical technique to solve PDEs on a surface based on standard Cartesian grid discretization  via the closest point extension. It will be extended to solve general eigenvalue problems. The approach for extremum eigenvalue is based on Rayleigh formulation and an efficient  rearrangement algorithm to achieve optimal configuration. Two types of rearrangement  approaches will be investigated: full rearrangement and partial rearrangement. The full rearrangement approach looks for the optimal rearrangement at each iteration while the partial rearrangement approach takes moderate changes to have the satisfactory result. The approaches based on shape derivatives and topological derivatives are examples of partial rearrangement. To demonstrate the capability and efficiency of the numerical approach, it will be applied to problems from inhomogeneous materials and population dynamics.         <br/><br/>The broader impact of the work arises from its wide ranges of applications. The PI will  apply the numerical approaches to problems including (1) identifying of composite strings and  membranes with frequency control, (2) finding composite materials with optimal conductivity,  (3) designing composite plates with desired extremum frequency, and (4) investigating eigenvalue optimization in population biology and shape identification in images from different  modalities including magnetic resonance images and optical coherence images. Moreover, the techniques will open a new door to compute spectral information on general surfaces without meshes on surfaces and provide an improved understanding of shape optimization on general surfaces. Software developed as part of this work will be incorporated into numerical courses in graduate study and will be freely available to the public. In the coming three years, the PI will organize mini symposiums on closest point method and shape optimization in the coming SIAM and international conferences to interest more scientists and invite more speakers in the underrepresented groups to broaden the field."
"1217262","High-order approximation techniques for nonlinear hyperbolic PDEs","DMS","COMPUTATIONAL MATHEMATICS","09/15/2012","07/24/2014","Bojan Popov","TX","Texas A&M University","Continuing Grant","Leland Jameson","08/31/2016","$300,000.00","Jean-Luc Guermond","popov@math.tamu.edu","400 Harvey Mitchell Pkwy South","College Station","TX","778454375","9798626777","MPS","1271","9263","$0.00","Many applications are based on nonlinear partial differential equations in which stability is not a result of an energy estimate. This is the case in nonlinear conservation laws, convection-dominated or multiphase flows, and free-boundary problems, where shocks fronts and discontinuities are important  features and pose significant difficulties for numerical methods. The natural setting for these problems involves the physical notion of entropy and requires the positivity of quantities like mass, temperature or density. The investigators propose to continue the development of a new nonlinear approximation technique for solving the above class of differential equations. This new approach consists of computing the so-called entropy residual and use it to design a stabilization mechanism to the Galerkin formulation of the problem at hand. This is a different point of view than that of standard stabilization techniques. The investigators  propose to design a nonlinear viscosity based on the second principle of thermodynamics and respect positivity/boundedness of the relevant quantities at the same time.  Even though the nonlinear algorithms are more complicated and difficult to analyze, they yield great benefits when working with rough solutions, complicated geometry, and strong nonlinearities. <br/><br/>In the past several decades, a large amount of work has been dedicated to the development of robust numerical methods modeling nonlinear phenomena.  Significant advances have been made in many areas, but the current state of the art is far from providing accurate and faithful numerical representations of the complex physical processes. For instance, accurate approximation of interfaces,  sharp fronts, and shock formations is still an enormous challenge. The proposed project has a broad impact in many fields. In mechanical and aerospace engineering, the proposed method improves on numerical models for simulating high velocity gas dynamics, nonlinear elasticity  and phase transition problems. In petroleum engineering the new set of methods is beneficial for more accurate simulation of multiphase flows in reservoirs with complicated geometry.  Moreover, the project will also have significant impact in other fields such as geophysics, nanotechnology, and environmental problems where reliable simulations for resolving shocks, sharp interfaces, and other nonlinear phenomena are needed."
"1217000","Collab. Research: Instability analysis of the split-step method on spatially-varying  backgrounds, with applications to optical telecommunications and Bose-Einstein condensation","DMS","COMPUTATIONAL MATHEMATICS","09/15/2012","09/12/2012","Yanzhi Zhang","MO","Missouri University of Science and Technology","Standard Grant","Rosemary Renaut","08/31/2016","$124,898.00","Taras Lakoba","zhangyanz@mst.edu","300 W 12th Street","Rolla","MO","654096506","5733414134","MPS","1271","9150, 9263","$0.00","The operator-splitting, or split-step, method (SSM) is widely used to numerically solve time-dependent partial differential equations arising in diverse applications, from hydrodynamics to quantum mechanics. To minimize the computational time, one needs to select the time step as large as possible. On the other hand, the upper bound on the time step is often set by the requirement that the numerical scheme be stable. The von Neumann analysis is used to obtain such upper bounds for model problems where the coefficients are constant. However, solutions of practically interesting equations are typically not constant in space. To justify the use of the von Neumann analysis for such problems, one often approximates non-constant coefficients by constant ones. However, for the SSM, this approach fails. Recently, the PIs proposed an alternative approach to analyze the instability of the SSM when this method is used to simulate a solution close to the soliton (i.e., a bell-shaped solution) of the nonlinear Schroedinger equation. In this project, the PIs will extend that analysis to more practically relevant settings that involve two applications: fiber optical telecommunications and Bose-Einstein condensates. This will provide an understanding of the development of the numerical instability in problems with essentially non-constant coefficients. They will then use this information to propose modifications of the SSM with relaxed stability requirements. Clearly, this will reduce the computational time.<br/><br/>This project will develop a systematic approach to studying a fundamental property - stability - of a widely used numerical method, the SSM. A numerical method must be stable in order to accurately model the physical process of interest. The current approach to the stability analysis consists in approximating the simulated processes by some constant values. The PIs will not use this approximation, as they have demonstrated that it leads to incorrect predictions regarding the performance of the SSM. Their alternative approach will rely on a combination of techniques from numerical analysis and the theory of linear differential equations. It will provide an understanding of the performance limitations of the SSM. This, in turn, will allow them to propose more efficient and reliable modifications of this numerical method. The applications considered in this project will directly impact the modeling of fiber-optic communication systems and low-temperature atomic condensates. However, their approach will affect other applications of the SSM, which include environmental modeling, hydrology, heat conduction, and reacting flows. Moreover, the approach can be extended to related numerical methods, which are used in other applications such as the modeling of the interaction among molecules and chemical species through reactions and random motion (diffusion)."
"1217239","Functional Analysis and Computational Methods in Imaging, Materials, and Atmospheric Sciences","DMS","COMPUTATIONAL MATHEMATICS","08/01/2012","09/02/2014","Luminita Vese","CA","University of California-Los Angeles","Continuing Grant","Leland Jameson","07/31/2016","$240,000.00","John Garnett, Igor Yanovsky","lvese@math.ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","MPS","1271","9263","$0.00","The investigators, their students and collaborators study mathematical formulations and efficient computational techniques for applications arising in image analysis, materials science, and atmospheric and climate modeling. This multidisciplinary research combines areas of computational mathematics, inverse problems, image analysis, interfaces and free boundaries, and atmospheric sciences. They study image restoration using cartoon and texture decompositions, restoration of images in the presence of a stochastic point spread function, implicit open curve evolution and applications to free boundary problems in materials sciences, and variational data fusion of atmospheric records acquired by multiple instruments. The research team develops novel variational approaches, iterative and numerical analysis techniques for solving these inverse problems.<br/><br/>The proposed activity provides the link between efficient mathematical formulations, imaging approaches, and applications in climate and materials sciences, where similar approaches have not yet been attempted. In particular, capability for merging data acquired by multiple sensors is a key part to our understanding of the Earth's climate system, and therefore, is of importance when making projections about climate change and climate impacts. Current atmospheric data fusion methods are largely ad hoc and establishing a firm mathematical foundation and computational methods for combining important records enhances their scientific credibility and further a wide range of scientific analyses. The investigators promote multidisciplinary teaching, training and learning. Mathematics students are exposed to a broad range of topics and techniques: (i) in applied and computational mathematics, image processing and analysis; and (ii) topics outside mathematics, including materials and atmospheric sciences."
"1217277","Collaborative Research: Reactive instabilities, colloids, and interfacial flows: experiments, modeling and numerics","DMS","COMPUTATIONAL MATHEMATICS","12/15/2012","12/04/2012","Shuwang Li","IL","Illinois Institute of Technology","Standard Grant","Leland Jameson","11/30/2015","$149,999.00","","sli15@iit.edu","10 West 35th Street","Chicago","IL","606163717","3125673035","MPS","1271","9263","$0.00","The investigators and their colleagues study novel instabilities in fluids driven by material complexity occurring only at interfaces. For instance, when two reacting micellar liquids are brought into contact, the reaction may produce a growing gel-like phase at the interface, which significantly stiffens the boundary between the fluids.  Another example arises from the presence of nanoscale colloidal particles which accumulate at interfaces. Intercolloid forces also endow the interface with stiffness, and may even jam the interface at sufficiently high volume fraction. The goal of this proposal is to develop comprehensive, physically appropriate models and simulations for these very difficult problems. The highly nonlinear nature of these problems makes fast, accurate and robust numerical methods essential to their study. The research team plans to investigate the nonlinear dynamics of interfaces endowed with complex physical properties and to develop strategies to control their pattern forming abilities by (1) developing and applying state-of-the-art adaptive numerical methods to large-scale computation; (2) performing analytical, numerical and modeling studies of important constituent processes; and (3) performing experiments to calibrate and validate the mathematical models, to test the model predictions, and to help elucidate the underlying physical processes.<br/><br/>Interfacial instabilities occur when driving forces compete with resistive forces with a consequence being the formation of complex patterns. Examples occur in diverse systems such as including filamentary microorganisms, growing biofilms, smoldering flame fronts, and lava flows. The goal of this project is to develop comprehensive, physically appropriate models and efficient numerical methods for solving such problems. Experiments will be performed to validate the models and test the model predictions, and to help elucidate the underlying physical processes. The research will focus on flows with complex interfacial physics such as reactions and nanoscale particles at interfaces. The research activities will provide new integrated theoretical, numerical and experimental results that can be used to (1) further explore these pattern forming systems that are driven out of equilibrium; (2)develop guidelines for controlling the evolving morphologies. While specific and novel applications are investigated here, the new mathematical and adaptive numerical techniques are expected have application beyond the present context.  In addition, this project will provide valuable interdisciplinary training opportunities for young researchers, and outreach programs are planned for middle school and undergraduate students (Penn State), high school students (UC Irvine) and undergraduate students (Ill. Inst. Techn.)."
"1209251","Direct Transcription Solution of Optimal Control Problems with Delays","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/01/2012","06/28/2012","Stephen Campbell","NC","North Carolina State University","Standard Grant","Lora Billings","08/31/2016","$284,817.00","","slc@math.ncsu.edu","2601 Wolf Village Way","Raleigh","NC","276957514","9195152444","MPS","1266, 1271","9263","$0.00","In a wide variety of important areas of modern technology  from the control of aerospace systems to guiding vehicles to determining drug therapies to producing industrial products it is desired to find the optimal or best way to perform different tasks.   The goal is improved efficiency and performance and lower cost.  The physical system can be  described mathematically.  This project will develop numerical algorithms, computer software, and supporting mathematics that will enable scientists and engineers to take these mathematical descriptions and solve a number of  optimal control problems that they currently have great difficulty in solving. This will contribute to a number of areas of national need including more efficient industrial processes.  The initial areas of application of this research will be chemical processes, aerospace applications, and biomedical problems since those collaborations are already under way.  The long term impact is even wider than these areas since the need for increased efficiency and better performance is a driving need throughout science and technology.<br/> <br/><br/>Mathematical descriptions often involve differential equations.  Frequently there are physical or operational constraints on either the physical process or the means being used to control this process.  One of the more successful numerical approaches that is often used for complex optimal control problems is direct transcription where the problem is converted to a discrete problem  by various  programing techniques, and then iteratively solved on specially chosen refined grids until a high quality solution is found.  Direct transcription is a popular technique in industry.  Many challenging problems also have delays in either the state dynamics or the controls or both.  Delays can occur for several reasons including transmission delays, physical processes,  actuator delays, or human  operator induced delays.   State dependent delays are common in the chemical industry, for example.   These delays, to date, have posed challenges that have hindered the development of industrial grade direct transcription algorithms for the computation of the optimal solution of state and control constrained nonlinear systems with delays.  This  project will address this difficulty.  It is proposed to develop algorithms, efficient implementations, and supporting mathematical analysis for the direct transcription solution of state and control constrained optimal control problems with delays.  The proposed research will result in new algorithms and new theoretical understanding of numerical methods.  These types of algorithms tend to be very sophisticated.  Theory backed guidelines will be developed for both users and developers of these types of algorithms.  The proposed project will result in substantial advancement on a number of important problems in optimal control, the training of the next generation of researchers to work on these problems, and contributions to several areas of national need. Among the broad impacts are the  capability to more widely use constrained   mathematical descriptions  with delays which will permit easier simulation and optimization of a wide variety of physical systems resulting in reduced time needed for design and improved performance.  The implementation of the projects results into an industrial grade code will greatly hasten and broaden their impact across a number of industries."
"1216866","Collaborative Research: Sparse spectral-tau methods for binary neutron star initial data","DMS","COMPUTATIONAL MATHEMATICS","09/15/2012","09/11/2012","Stephen Lau","NM","University of New Mexico","Standard Grant","Rosemary Renaut","08/31/2016","$131,490.00","","lau@math.unm.edu","1700 Lomas Blvd. NE, Suite 2200","Albuquerque","NM","871310001","5052774186","MPS","1271","9150, 9263","$0.00","Binary neutron star inspiral is the most certain source of gravitational waves detectable by Earth-based observatories like the US LIGO project, and simulations of such binaries should facilitate eventual detections. These simulations require initial conditions: solutions to the initial value problem of general relativity for the coupled gravity-matter system. The conformal thin sandwich method is an excellent approach for solving the initial value problem; however, although not an intrinsic assumption of the method, in practice the approach has assumed conformal flatness (as have other valuable approaches). Conformal flatness yields unphysical junk radiation. By numerically constructing helically symmetric solutions to the Einstein equations, the PI will extract initial data (or conformal thin sandwich trial data) which does not rely on conformal flatness, and therefore contains the correct initial gravitational wave content. The mixed PDEs arising from the helical reduction of the Einstein equations (or their approximation in the post-Minkowski formalism) will be solved with innovative techniques: sparse modal spectral-tau methods with new preconditioning strategies. In part, these strategies may rely on randomized algorithms for the interpolative decomposition. Spectral methods deliver superb accuracy for smooth problems(neutron star spacetimes are smooth almost everywhere), and sparsity affords a fast matrix-vector multiply when using a Krylov-subspace method to iteratively solve a linear system. Whereas the preconditioning of nodal (collocation) spectral methods is well studied, less is known about modal preconditioning. Our techniques have been successfully applied to models of the binary neutron star problem. Moreover, the problem's physical structure has already been explored with different, but limited, techniques. <br/><br/>This project is to combine two sets of techniques (each already developed) and further develop the first set (spectral-tau methods), in order to obtain new results for a leading problem in gravitational wave physics. The PI will develop these mathematical methods by applying them to the specific neutron star problem described above. This strategy of specificity is often used in the development of techniques, which then prove to be more general. Because the scientific problem is of great interest, much is known about it, and results therefore exist withwhich comparisons can be made. These comparisons facilitate the development of mathematical algorithms. Conversely, new mathematical methods deliver more and/or better solutions which enhances scientific understanding."
"1214282","A data-driven Bayesian framework for the solution of SPDEs on random heterogeneous media","DMS","COMPUTATIONAL MATHEMATICS","08/15/2012","08/14/2012","Nicholas Zabaras","NY","Cornell University","Standard Grant","Leland Jameson","07/31/2015","$200,000.00","","nzabaras@nd.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","MPS","1271","9263","$0.00","The PI and his colleagues study the solution of Stochastic Partial Differential Equations (SPDEs) with emphasis on modeling processes in random heterogeneous media.  A holistic mathematical view of the problem is adopted in which the stochastic input is explicitly modeled from experimental data and uncertainty is propagated via a deterministic solver. The key aspects of the proposed work are as follows: (A) Data-driven stochastic input modeling. This includes the development of reduced-order representations of experimentally observed input fields, construction of the mapping from the reduced input space to the high dimensional input space and estimating the probability density of the reduced input space as induced by the observations. (B) Uncertainty propagation. This includes the construction of a hierarchical, local, Bayesian surrogate of the deterministic code made efficient by the informative selection of deterministic runs using active learning, the sequential refining of the discretization of the solver, the explicit treatment of output correlations and/or output dimensionality reduction and analytical/ numerical integration of the surrogate for the calculation of the response statistics as well as error bars. <br/> <br/>The work performed in this project allows better appreciation for the need to account for variabilities in the analysis and design of engineered and natural systems. It is such thinking that will contribute towards re-usable multifunctional design of components and systems in an environment prone to natural and manufacturing uncertainties. In particular, this research systematically addresses key problems that arise in modeling random heterogeneous media (existing, very expensive deterministic multiscale solvers, few experimental input realizations, non-isotropy of the response, high-dimensionality of input/output) and poses concrete mathematical questions for their resolution. It serves as a paradigm of a successful combination of seemingly diverse ideas of applied mathematics and computational statistics in order to answer realistic engineering questions.   Informative (data-driven) stochastic simulations would improve safety and greatly benefit the design and optimization process for a wide array of industries while at the same time reducing costs. The student that participates in this research is trained in the interface of computational mathematics and Bayesian statistics. The research activity and courses organized benefit many diverse communities that have interests in predictive science and design in the presence of uncertainties. The algorithms, data and software developed are disseminated to the community through the web.    <br/>"
"1214188","A Smoothed Finite Element Method (SFEM) for Fluid-Structural Interaction Problems","DMS","COMPUTATIONAL MATHEMATICS","09/15/2012","09/12/2012","Gui-Rong Liu","OH","University of Cincinnati Main Campus","Standard Grant","Rosemary Renaut","08/31/2016","$180,000.00","","liugr@uc.edu","University Hall, Suite 530","Cincinnati","OH","452210222","5135564358","MPS","1271","9263","$0.00","Systems in nature and manmade often involves both fluids and solid structures. The behavior and characteristics of such a system are often affected by the interactions between the fluid flows and solid structures. Study of the fluid-structural interaction is of great importance to understand, design and control such systems, and also presents big technical challenges, due to the complexity in geometry of the systems and the coupling of multiple physics (nonlinear solid mechanics, and Navier-Stokes flows). This project aims to develop a Smoothed Finite Element Method (SFEM) for solving general fluid-structural interaction problems with complicated geometry for both fluid media and nonlinear solids undergoing large deformation. This is achieved by developing a set of techniques and properly designed combinations of these techniques based on essentially the weakened weak formulation that allows the use of a much more general functions for field approximation, including a certain class of discontinuous functions (in a proper G space). The formulations for both fluid flows and solid structures will be unified in the some framework of SFEM. The developed computational technique consists largely of 1) an SFEM-Solid solver for modeling the nonlinear and dynamic behavior of solids and structures; 2) an SFEM-Fluid solver for dynamic behavior of fluids; and 3) SFEM-FSI solver for dealing with effectively the coupling at the interfaces of the moving solids in the flowing fluid. The developed SFEM-FSI model is expected to have important ""softening"" effects so that it can work well with triangular/tetrahedral mesh that can be generated automatically, enabling automation in computation for complicated systems.  For the interaction between the fluids and solids, ideas of the immersed boundary/finite element methods will be employed and modified for effectively dealing with the overlaid areas near the interfaces of the fluid media and solids, without re-meshing to generate the body-fitted mesh. <br/><br/>The proposed project is multidiscipline in nature across computational mathematics, fluid dynamics, structure mechanics, and biomechanics. The computational techniques developed in this project are expected to have a significant impact to all these related areas. In particular, the SFEM formulations for the fluid-structural interaction problems are expected to offer a profound new approach in solving complicated problems with coupled multi-physics. Once developed, the SFEM-FSI will be applicable in the modeling and simulation of a wide class of problems in science and engineering, such as flapping wings for special purpose aircrafts (quite, low speed, flapping wings) such as micro air vehicles (MAV), design of large span and flexible membrane structural systems, modeling blood flows in human hearts and vascular systems, etc. Because the SFEM-FSI allows the use of triangular/tetrahedral mesh, it enables automation-in-computation, and thus is expected to have a pervasive impact in significantly saving resources for manual operations in the meshing and re-meshing process. It is anticipated to change significantly the capability and applicability of the existing modeling and simulation software packages largely written in the past half a century based on the standard weak formulations. In addition, through this project students will be well-trained in the related STEM (science, technology, engineering and mathematics) area important for the long-term and sustainable development of knowledge-based economy in the United States."
"1217153","New Active-Set Methods for Optimization and Complementarity Problems","DMS","COMPUTATIONAL MATHEMATICS","08/01/2012","07/01/2014","Daniel Robinson","MD","Johns Hopkins University","Continuing Grant","Junping Wang","07/31/2015","$210,000.00","","dpr219@lehigh.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","MPS","1271","9263","$0.00","The principal investigator and his student consider the design, analysis, implementation, and validation of a new class of active-set algorithms for solving large-scale optimization and complementarity problems.  In the first part of the project they introduce a new class of rapidly adapting active-set methods in the context of solving large-scale convex quadratic problems. These algorithms benefit if a good initial guess is available and allow for rapid updates to the active-set, which are essential for handling large-scale problems.  Consequently, this algorithm not only solves stand-alone quadratic programs, but may allow other methods, e.g., sequential quadratic programming methods, to handle problems that are larger than is currently possible.  In the second part of the proposal, they introduce the concept of an acceleration phase, which improves upon existing subspace phases.  Subspace phases have been used with great success to enhance basic algorithms for solving various complementarity, variational inequality, quadratic, and nonlinear problems, as well as applications in machine learning and compressed sensing.  This success, however, has masked a prevailing weakness: all iterates generated must remain in the subspace.  An acceleration phase has the added flexibility of selectively enlarging the subspace, when deemed necessary.  In the final part of the project, they consider a new fast and robust active-set algorithm for solving complementarity problems.  Efficiency and reliability are acquired by (i) utilizing a special property of the Newton-like direction that holds in this setting to formulate an improved search procedure; and (ii) suggesting a simple framework that allows for acceleration phases to be incorporated naturally.<br/><br/>The new active-set framework, convergence results, and freely available software will have a large sphere of influence by aiding in solving challenging problems arising in the design of large complex systems.  In particular, they will serve as useful tools for the future design and development of new highly-efficient algorithms for solving large-scale real-world problems related to energy transmission, trajectory optimization, optimal control, contact problems in computational mechanics, regularized machine learning problems, and various equilibrium problems associated with traffic flow, optimal design, and the pricing of energy.  For example, their work will help answer questions such as ""How can we plan for energy transmission infrastructure that accounts for uncertainties such as the location and type of future energy generation, technology, policy, and economic development?""  The improved optimization tools provided by the principal investigator and his student will aid regulators and regional transmission organizations to develop more robust investment plans that may save the consumers millions of dollars every year."
"1217053","Collaborative Research: Sparse spectral-tau methods for binary neutron star initial data","DMS","COMPUTATIONAL MATHEMATICS","09/15/2012","09/11/2012","Richard Price","TX","The University of Texas at Brownsville","Standard Grant","Junping Wang","10/31/2015","$78,927.00","","rprice.physics@gmail.com","One West University Blvd","Brownsville","TX","785204956","9568827849","MPS","1271","9263","$0.00","Binary neutron star inspiral is the most certain source of gravitational waves detectable by Earth-based observatories like the US LIGO project, and simulations of such binaries should facilitate eventual detections. These simulations require initial conditions: solutions to the initial value problem of general relativity for the coupled gravity-matter system. The conformal thin sandwich method is an excellent approach for solving the initial value problem; however, although not an intrinsic assumption of the method, in practice the approach has assumed conformal flatness (as have other valuable approaches). Conformal flatness yields unphysical junk radiation. By numerically constructing helically symmetric solutions to the Einstein equations, the PI will extract initial data (or conformal thin sandwich trial data) which does not rely on conformal flatness, and therefore contains the correct initial gravitational wave content. The mixed PDEs arising from the helical reduction of the Einstein equations (or their approximation in the post-Minkowski formalism) will be solved with innovative techniques: sparse modal spectral-tau methods with new preconditioning strategies. In part, these strategies may rely on randomized algorithms for the interpolative decomposition. Spectral methods deliver superb accuracy for smooth problems(neutron star spacetimes are smooth almost everywhere), and sparsity affords a fast matrix-vector multiply when using a Krylov-subspace method to iteratively solve a linear system. Whereas the preconditioning of nodal (collocation) spectral methods is well studied, less is known about modal preconditioning. Our techniques have been successfully applied to models of the binary neutron star problem. Moreover, the problem's physical structure has already been explored with different, but limited, techniques. <br/><br/>This project is to combine two sets of techniques (each already developed) and further develop the first set (spectral-tau methods), in order to obtain new results for a leading problem in gravitational wave physics. The PI will develop these mathematical methods by applying them to the specific neutron star problem described above. This strategy of specificity is often used in the development of techniques, which then prove to be more general. Because the scientific problem is of great interest, much is known about it, and results therefore exist withwhich comparisons can be made. These comparisons facilitate the development of mathematical algorithms. Conversely, new mathematical methods deliver more and/or better solutions which enhances scientific understanding."
