"AwardNumber","Title","NSFOrganization","Program(s)","StartDate","LastAmendmentDate","PrincipalInvestigator","State","Organization","AwardInstrument","ProgramManager","EndDate","AwardedAmountToDate","Co-PIName(s)","PIEmailAddress","OrganizationStreet","OrganizationCity","OrganizationState","OrganizationZip","OrganizationPhone","NSFDirectorate","ProgramElementCode(s)","ProgramReferenceCode(s)","ARRAAmount","Abstract"
"1265390","Collaborative Research: Speical session on Numerical Modeling of Fluids and Structures","DMS","COMPUTATIONAL MATHEMATICS","06/01/2013","04/10/2013","Xiaozhe Hu","PA","Pennsylvania State Univ University Park","Standard Grant","Leland Jameson","11/30/2013","$10,000.00","Ludmil Zikatanov","hu_x@math.psu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271","7556, 9263","$0.00","Numerical Modeling of Fluids and Structures at the 9th International Conference on Large-Scale Scientific Computations (LSSC) in Sozopol, Bulgaria from June 3-7, 2013.<br/><br/>The investigators and his colleagues are organizing a special session on Numerical Modeling of Fluids and Structures at the 9th International Conference on Large-Scale Scientific Computations (LSSC) in Sozopol, Bulgaria from June 3-7, 2013. This minisymposium focuses on developing, investigating, and applying fundamental mathematical theories and advanced modeling and simulation techniques to various multiphysics and multiscale problems, especially fluid-structure interactions.  Key scientific questions addressed in this session have a wide range of applications, including magnetorheological fluids, aerodynamics, biomedical applications, micro-electro-mechanical systems, and ground water modeling.<br/><br/>This special session supports participation of students, postdocs, and junior researchers from the United States, who are working in areas related to the modeling and simulation of fluids, structures, and their interactions. The workshop environment promotes contacts  between researchers from the United States and other countries, including theorists and experimentalists from applied mathematics, computational science and engineering. Mutually beneficial discussions between junior and senior researchers and mathematicians and engineers are expected.  The special session is mainly organized by junior researchers and, along with other young participants, makes their research highly visible to the rest of the scientific community, providing them the access to various application fields for which they can contribute many advancements."
"1255416","CAREER: Structured Matrix Computations: Foundations, Methods, and Applications","DMS","COMPUTATIONAL MATHEMATICS, Division Co-Funding: CAREER","08/01/2013","07/09/2014","Jianlin Xia","IN","Purdue University","Continuing Grant","Leland Jameson","07/31/2018","$413,894.00","","xiaj@purdue.edu","2550 NORTHWESTERN AVE STE 1900","WEST LAFAYETTE","IN","479061332","7654941055","MPS","1271, 8048","1045, 9263","$0.00","The proposed research is concerned with innovative and systematic structured matrix computations. Large-scale matrices arise frequently in mathematical computations and engineering simulations. By exploiting the inherent structures, one can often develop new fast and reliable matrix methods. This work is especially interested in rank structures and data-sparse matrices, as well as innovative ideas of using them in the solutions of practical numerical problems (especially high dimensional discretized problems). The PI proposes to enhance both the flexibility and the applicability of structured methods. Systematic analysis for the structures and the methods will be included. The following aspects will be studied: (1) theoretical foundations of rank properties and new nested hierarchical structures; (2) new perspectives for exploring matrix structures, such as matrix-free structured sparse factorization, factorization update, and nested localization and sparsification; (3) efficient rank structured matrix algorithms, their analysis, and their use in fast solutions of large linear systems, least squares problems, eigenvalue problems, discretized PDEs, and numerous engineering applications.<br/><br/>Matrix computations lie at the heart of most scientific computation tasks. This research will systematically extend classical dense and sparse matrix computations to data-sparse ones, and will introduce new structured matrix theories and techniques into scientific and engineering computations. The project will result in practical ways to reveal and use structures, which will further yield fast and reliable algorithms such as stable direct three dimensional PDE solvers with nearly linear complexity. Understanding the structures will also provide new perspectives to classical challenges in numerical solutions, such as large fill-in, ill conditioning, lack of explicit matrices, and repeated solutions with highly varying parameters. The proposed algorithms can be used (say, as kernel solvers) in many complex numerical problems such as PDE solution, seismic imaging, signal processing, nanostructure modeling, and VLSI circuit simulation. The work will provide a multidisciplinary opportunity for researchers in different areas to participate. The project will result in freely available open source packages for practical applications, as well as courses ad tutorial and test materials for educational outreach programs that can stimulate the interest and achievement of students from diverse backgrounds."
"1319172","Finite Element Methods for Higher Order Variational Inequalities","DMS","COMPUTATIONAL MATHEMATICS","07/15/2013","07/08/2013","Susanne Brenner","LA","Louisiana State University","Standard Grant","matthias gobbert","06/30/2017","$244,770.00","Li-yeng Sung","brenner@math.lsu.edu","202 HIMES HALL","BATON ROUGE","LA","708030001","2255782760","MPS","1271","9150, 9263","$0.00","Elliptic variational inequalities are fundamental mathematical tools for modeling phenomena that  involve elliptic partial differential operators and constrained optimization. This project will develop and  analyze finite element methods for fourth and higher order elliptic variational inequalities, which arise  naturally for example in mechanics and elliptic optimal control problems.  A recent theoretical advance  by the PIs demonstrates that, for the displacement obstacle problems of Kirchhoff plates, the heart of  the error analysis involves only problems at the continuous level and therefore any finite element  method that works for fourth order boundary value problems can also be adapted for obstacle problems.   This new approach will be extended to other fourth and higher order variational inequalities with  different types of constraints, which will bring well-developed finite element methodologies for  boundary value problems (conforming and nonconforming methods, discontinuous Galerkin methods,  generalized finite element methods, isoparametric finite element methods, local mesh refinement,  singular function method, etc.) into the study of numerical solution of higher order variational  inequalities. Fast solvers for higher order variational inequalities, such as multigrid methods, domain  decomposition methods and adaptive methods, will also be developed.  In particular this project will  lead to new algorithms for second order elliptic distributed optimal control problems with pointwise  state and/or control constraints that are fundamentally different from existing algorithms.  <br/><br/>The results from this  project will provide new insights to the numerical solution of higher order  variational inequalities, an area that is becoming increasingly important as more and more complex  phenomena in science, engineering and finance are being modeled by higher order differential  equations. The outcomes of this project will impact diverse areas that require reliable and efficient  numerical algorithms for the solution of such inequalities."
"1320608","Algebraic multigrid methods for solving the Dirac equation in Lattice Quantum Chromodynamics","DMS","COMPUTATIONAL MATHEMATICS","08/01/2013","07/09/2013","James Brannick","PA","Pennsylvania State Univ University Park","Standard Grant","Leland Jameson","07/31/2017","$180,000.00","","brannick@psu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271","9263","$0.00","The goal of this research project is to combine ideas from the finite element and multigrid  methodologies in order to develop an adaptive algebraic multigrid algorithmic framework with  the potential to make an appreciable and broad impact on computational Quantum Chromodynamics  (QCD). The proposed research is driven by three specific interrelated research goals: (1) To render the Galerkin adaptive algebraic multigrid methods currently being used to solve  the Wilson-Dirac system more robust and more efficient; (2) To design and analyze new Petrov-Galerkin  multigrid methods for solving the domain wall fermion system; (3) To discover and analyze  relationships between lattice field theory and the rich theory that researchers have developed for  the finite element method.  This research encompasses a broad range of fundamental research  in algebraic multigrid methods, including the design and analysis of new multigrid smoothers based on  greedy (randomized) subspace correction methods, randomized methods for range approximation, adaptive  multigrid methods for solving non-hermitian problems, and multilevel methods for computing eigenpairs  and singular value triplets.<br/><br/>The intellectual merit of this project derives from its potential to make several distinct  mathematical advances and to integrate those advances into multilevel algorithms and software  for large-scale QCD applications.  These advances are expected to significantly reduce the  errors that arise in lattice calculations and, in turn, to make it possible to use simulations  to test the full non-linearities of QCD and confront experimental data with ab initio predictions.   The project's potential to make a broader impact will be realized by applying  the proposed algorithmic solutions to a wide range of problems in areas beyond the primary focus  on fundamental investigations into particle physics, such as lattice field theories of graphene,  models involving Maxwell's equations, e.g., magnetohydrodynamics, large-scale  graph applications, e.g., Markov chains as arise in various Stochastic models, and partial differential  equations with random coefficients, as arise, for example, in uncertainty quantification for groundwater flow. Graduate students involved in the project will engage in interdisciplinary research led by the  PI and have opportunities to visit and work with multiple collaborators from the US and Europe,  such that they will receive advanced training in both the theory and practice of advanced mathematical  algorithms and high-end scientific computing."
"1319462","Computational and theoretical study of parameter scaling in particle systems","DMS","COMPUTATIONAL MATHEMATICS","08/01/2013","07/30/2017","Alethea Barbaro","OH","Case Western Reserve University","Standard Grant","Yuliya Gorb","07/31/2018","$142,420.00","","abb71@case.edu","10900 EUCLID AVE","CLEVELAND","OH","441061712","2163684510","MPS","1271","9263","$0.00","Agent-based models are used to simulate the behavior of many interacting agents, such as insects, fish, robots, or humans. Generally, agents are taken to have common interaction rules.  With these agent-based models, there is always the question of how to choose parameters in order to best predict the behavior of the population being modeled. Some models, such as the Czirok-Vicsek model, are originally formulated in discrete time, while others, such as the Cucker-Smale model, are formulated in continuous time. Many agent-based models in biology and the social sciences use the Forward Euler Method to simulate the model.  Hence, even if the model is originally formulated in continuous time, the choice of timestep often becomes a parameter in the simulations.  In addition to the timestep, the number of agents, particle density, and any applicable ranges of interaction must be chosen.  But what happens as these parameters are changed? Should the other parameters change as the particle density changes in order to maintain the same dynamics? The goal of this project is to understand how the parameters in discrete-time agent-based models, including the number of particles, the timestep, and parameters such as the interaction range, should scale with one another in order exhibit the same large-scale dynamics with different parameter values.  Another question of interest is what happens in the continuum limit, i.e. when the timestep is taken to zero and the number of agents is taken to infinity.  How do such limits affect the dynamics of the model? A further goal of this project, if time permits, is to explore the impacts of this investigation on applications of these models and on the derivation of associated PDE models.<br/><br/>This research stands to have a broad impact on many research areas which currently employ agent-based models.  These models are often applied in biology, physics, and social science.  In these fields, the system being modeled generally includes a prohibitively large number of organisms, such as people, fish, insects, birds, or robots, interacting among themselves.  As such, it is often necessary to approximate the behavior of the population by an agent-based model where each agent represents a group of individuals, even though rules of interaction are derived with interactions among individual organisms in mind.  Thus, the question of how to scale the parameters as the number of agents in the simulation changes is central to the successful application of these models. Furthermore, where these agent-based models are being applied, discrete-time versions are often employed in place of continuous dynamical systems, and it is easy to ignore the question of how the timestep should scale with other parameters. Hence, it is imperative that the effect of these scalings be understood and disseminated, since they can significantly change the dynamics of the model.  In this way, mathematics, physics, biology, and social science all stand to gain essential information from the investigations of the PI and her collaborators."
"1254794","The Eighth IMACS International Conference on Nonlinear Evolution Equations and Wave Phenomena: Computation and Theory","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","01/15/2013","01/14/2013","Thiab Taha","GA","University of Georgia Research Foundation Inc","Standard Grant","Victor Roytburd","06/30/2015","$18,000.00","Jerry Bona","thiab@cs.uga.edu","310 E CAMPUS RD RM 409","ATHENS","GA","306021589","7065425939","MPS","1266, 1271","7556","$0.00","The Eighth IMACS International Conference on Nonlinear Evolution Equations and Wave Phenomena: Computation and Theory will be held at the <br/>University of Georgia from March 25 to March 28, 2013. More information is available on the conference website: waves.uga.edu<br/><br/>The proposed conference will focus on the derivation, theory, numerical simulation and application of nonlinear wave equations. Despite several decades of intense activity, this general area shows no sign of abating nor of calcification. Indeed, two of the recent Fields medalists are cited for their work in this area, and major new forays into geophysical modeling and high-speed communication have made use of nonlinear wave equations. The conferences in this series are well known for bringing together researchers in theoretical and computational mathematics, the applied sciences and engineering.<br/><br/>The conference will feature  several invited, one-hour presentations on some of the most topical aspects of the area and an estimated 180 shorter talks, most of which will be in a focused session format. Past experience suggests that well over 200 participants will attend. At the most recent conference in 2011, 229 research papers were presented. In addition to 161 participants from the USA, there were 68 international scientists and students from 36 countries. We had 41 graduate and undergraduate students, 3 junior faculty and 27 women who attended the conference. This conference we will have 20 organized sessions, 3 keynote speakers, and two tutorials for students and young faculty. The requested support is for the expenses of the invited speakers and to defray the costs of younger participants, with special attention paid to students, women, minorities, persons with disabilities, postdocs and junior faculty. As of mid-November, 2012, more than 50 applications were received from students, women, underrepresented groups, and young faculty requesting financial support to attend the conference."
"1318186","Developing Energy-Conserving Deterministic Solvers for Kinetic Electromagnetic Plasma Simulations","DMS","COMPUTATIONAL MATHEMATICS","07/01/2013","06/25/2013","Yingda Cheng","MI","Michigan State University","Standard Grant","Leland Jameson","06/30/2016","$142,650.00","","ycheng@math.msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1271","9263","$0.00","In this proposal, the investigator plans to develop and analyze a class of energy-conserving deterministic solvers for kinetic electromagnetic plasma simulations. The proposed methods have several features that overcome the difficulties of many traditional solvers: it conserves the total particle number and energy of the system; it has a systematic way to incorporate explicit or implicit time stepping depending on the stiffness of the equations; and it is designed for implementations on unstructured grids for complex geometries in the physical space. To achieve the objective, the research topics include a range of analytical and computational subjects. The investigator proposes to design a new energy-conserving splitting for the coupled Vlasov-Maxwell system, so that the splitted equations still maintain energy conservation and can be computed in reduced dimensions. The investigator plans to set up a general framework to incorporate various type of energy-conserving temporal and spatial discretizations. Methods to further improve computational efficiency by using various local basis, local time stepping and hybrid solvers will be explored. Issues on how to enforce charge continuity and positivity will be addressed. Analytical aspects such as the numerical dispersion relation, stability and error estimates will be considered.<br/><br/>The proposed activity lies between algorithm development, analysis and applications. The resulting numerical schemes can be applied to a wide range of plasma simulations.  The theoretical studies will provide foundation and guidance to the design of such numerical methods. The broader impacts of the proposed activity will be its interdisciplinary outreach and educational components. The proposed research is multidisciplinary in its nature. The investigator actively interacts and consults with faculty members in physics, electrical engineering departments. Training opportunities for students and postdocs will be provided. Computational math curriculum development will be incorporated."
"1319356","Randomized Models for Nonlinear Optimization:  Theoretical Foundations and Practical Numerical Methods","DMS","COMPUTATIONAL MATHEMATICS, OPERATIONS RESEARCH","09/15/2013","09/06/2013","Katya Scheinberg","PA","Lehigh University","Standard Grant","Leland Jameson","08/31/2017","$200,000.00","Frank Curtis","katyas@cornell.edu","526 BRODHEAD AVE","BETHLEHEM","PA","180153008","6107583021","MPS","1271, 5514","073E, 9263","$0.00","This project involves the design, analysis, and implementation of numerical algorithms for the mathematical optimization of large-scale, complex systems.  In particular, the novel feature of the proposed algorithms is the use of random sampling of objective function information in the context of solving deterministic (i.e., non-random) problems.  Despite the success of randomization in, e.g., stochastic gradient techniques for machine learning, it has yet to be used actively in other settings as it has been deemed too expensive in sequential computing environments.  However, with parallel computing becoming increasingly common, and with new advancements and convergence theory for randomized algorithms, these methods have great promise.  The research in this project will focus on the use of ``accurate'' randomized models, broadening of convergence theory, and implementation of effective software.  The novelty of the approach lies in achieving a middle ground between deterministic models that have to be accurate at each algorithmic step, and stochastic models that are accurate only in expectation, by exploiting random models that need to be accurate only with sufficiently high probability. The proposed strategies will balance per-iteration cost of the optimization routine with convergence speed while utilizing parallel computation.  The priority in the project on developing practical, general-purpose numerical methods based on theoretically sound methodologies solidifies the merits of the proposed work.<br/><br/>This project focuses on the development of novel numerical algorithms, and their analysis, for solving problems in two related realms of engineering design.  In the first, the aim is to minimize a quantity---e.g., cost, energy, or the discrepancy between expected and observed data---that can only be determined via a computer simulation. These ""black-box"" optimization problems arise in important areas such as molecular geometry optimization, circuit design, and groundwater modeling.  The second area represents those applications in which a given design needs to be robust under various input conditions, which includes problems in, e.g., medical image registration and the optimization of control systems.  The project promises to advance the study of algorithms for solving all of these types of problems via the common thread of exploiting randomization and parallel computation.The impact of this work will clearly be cross-disciplinary, and will benefit users of optimization methods and software in academia, governmental research laboratories, and private industry.  It will also promote the use of rigorous, classical algorithms in combination with randomized models for solving cutting-edge scientific problems.Finally, the educational plan will expose undergraduate and graduate students to modern efforts and challenges in computational mathematics, improve the educational opportunities for students interested in scientific research, and encourage  faculty interaction in area schools."
"1317919","Practical Filtering Methods with Model Errors","DMS","COMPUTATIONAL MATHEMATICS","12/15/2013","12/03/2013","John Harlim","PA","Pennsylvania State Univ University Park","Standard Grant","Leland Jameson","11/30/2017","$249,421.00","","jharlim@psu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271","9263","$0.00","The projects in this proposal are part of the PI's long-term career goal to deliver a class of practically scalable data assimilation (or filtering) schemes with solid theoretical foundations for state estimation of geophysical fluid dynamics. This proposal is an outgrowth of the PI's recent successful effort in designing accurate, reduced filtering methods with cheap stochastic models as alternatives to expensive models. Four projects are proposed: 1. Design computationally faster stochastic filters to assimilate atmospheric infrared sounder (AIRS) in the presence of multiple cloud types in the tropics. 2. Develop stable linear autoregressive (AR) filters for nonlinear, weakly chaotic dynamical systems. This project involves designing a novel parameterization scheme for AR models that avoids utilizing a long time series as in classical regression strategy, yet respects the sufficient conditions for optimal AR filtering, established in the PI's recent work. 3. Study the role of higher order terms of the singular perturbation expansion when a reduced model from classical averaging theory is used in filtering multi-scale interaction between modes of turbulent signals with moderate separation of scales. This study involves formal asymptotic expansion and rigorous error estimation. The PI will show that the higher order terms are important to avoid covariance underestimation in the presence of model errors. 4. Develop a fast filtering framework to assimilate multi-scale dynamical systems with ""superparameterization"", a fast numerical scheme to resolve interaction of cloud-scale dynamics and large-scale tropical convecting atmosphere. The new algorithm will include an online small-scale estimation scheme that imposes statistical consistency between the large and small-scale variables.<br/> <br/>Fundamental issues in real-time weather prediction are model errors. This problem is attributed to incomplete understanding of the physics and our lack of computational resources to resolve physical processes in various time and length scales. Modern operational weather models poorly reproduce the tropical observational records even after resolving 10 billion variables. This long-standing issue prevents the global weather model forecasting skill to improve from weekly to monthly, as reported in a recent article in the World Meteorological Organization bulletin. The results from this proposal will transform the future design of computational methods for various prediction related problems in the presence of model errors, in particular numerical weather prediction. This proposal supports an interdisciplinary research training environment for a graduate student, involving mathematical analysis, statistical modeling, and scientific computing. The PI, who is jointly appointed as a faculty in the mathematics and meteorology departments at PSU, will develop an interdisciplinary graduate course with emphasis on PDE and waves for atmospheric and ocean modeling."
"1318763","Fluid-structure interaction with multi-layered structures: a new class of partitioned schemes","DMS","COMPUTATIONAL MATHEMATICS","08/15/2013","04/17/2018","Suncica Canic","TX","University of Houston","Standard Grant","Leland Jameson","07/31/2019","$280,858.00","Martina Bukac","canics@berkeley.edu","4300 MARTIN LUTHER KING BLVD","HOUSTON","TX","772043067","7137435773","MPS","1271","9263","$0.00","Fluid-structure interaction (FSI) problems arise in many applications. They include  multi-physics problems in engineering such as aeroelasticity and propeller turbines, as well as biofluidic application such as self-propulsion organisms, fluid-cell interactions, and the interaction between blood flow and cardiovascular tissue.  A comprehensive study of these problems remains to be a challenge due to their strong nonlinearity and multi-physics nature. To make things worse, in many biological applications the structure is composed of several layers, each with different mechanical characteristics. This is, for example, the case with arterial walls. A FSI solver that simulates the interaction between an incompressible, viscous fluid and a multi-layered structure would be an indispensable tool for the computational studies of this class of problems. To date, there are no such FSI solvers for hemodynamics, and the work proposed here makes a first step in this direction. The investigators are developing a set of stable loosely-coupled partitioned schemes for solving a class of nonlinear moving boundary, fluid-multi-structure interaction problems. The proposed schemes are based on a novel  implementation of the  Lie operator splitting, which is designed in such a way that the energy of the discretized problem mimics the energy of the continuous problem.  The proposed program opens up a new field within the area of FSI problems, bringing to light several new features that have not been studied before, such as the study of the regularizing effects of fluid-structure interfaces with mass. The proposed class of schemes will be implemented and optimized for high performance computing using an open source library of solvers called LifeV. This will make the products of this research accessible to a large set of users involving a broad range of applications.<br/><br/>This is an exciting, novel study requiring the development of original mathematical and computational techniques motivated by important applications in cardiovascular flow. The investigators are developing a computational software that will, for the first time, capture the interaction between different layers of the human arterial walls as they interact with pulsating blood flow. This study is motivated by the most recent advances in ultrasound speckle tracking methods, which reveal that in high adrenaline situations, there is significant strain between different layers within arterial walls. It has been noted that the role of this phenomenon in the development of cardiovascular disease has not been explored yet. The computational models developed in this study will provide an indispensable tool for the study of the influence of this phenomenon on the physiology and pathophysiology of the human cardiovascular system. The results from this research will have impact across different scientific disciplines through an open source code, which will be freely available to users. The work proposed here promises to develop a strong partnership between the University of Houston, the University of Pittsburgh, Emory University, and the Texas Medical Center in Houston. The broader impacts will be further achieved through student education, mentoring of students and junior faculty, and organization of interdisciplinary conferences/workshops. Both investigators are women with a track record in education and mentoring women and minorities, and this practice will continue throughout this project."
"1319054","Hybrid Hermite-Discontinous Galerkin Methods with Applications to Elastic and Electromagnetic Waves","DMS","COMPUTATIONAL MATHEMATICS","09/15/2013","09/08/2013","Daniel Appelo","NM","University of New Mexico","Standard Grant","Leland Jameson","08/31/2017","$258,196.00","","appelo@vt.edu","1700 LOMAS BLVD NE STE 2200","ALBUQUERQUE","NM","871063837","5052774186","MPS","1271","9150, 9263","$0.00","The Principal Investigator proposes to carry out an interdisciplinary comprehensive research program combining the development, analysis and optimization of a new class of numerical methods, with their application to problems in seismology and electromagnetics. The novel methods hybridizes arbitrary-order Hermite approximations with arbitrary-order discontinuous Galerkin methods. The combination of these two methods will result in a new class of hybrid methods able to handle complex geometries and with unprecedented computational efficiency through large time steps and high-resolution. The methods have very large computation to communication ratio and are well suited for implementation on current and emerging supercomputer systems, enabling the solution of complex, multiple-scale evolutionary systems. The proposed unified analysis of discontinuous Galerkin methods and Hermite methods will require new tools and theories to be developed and will lead to a new theoretical framework for the analysis of hybrid methods. The proposal will consider methods for both first and second order formulations of the governing equations of elasticity and electromagnetics.   <br/><br/>The research will have broader impacts in technology and science, as well as in the training of the next generation of computational scientists. As recent events in Japan have shown, earthquakes are a societal problem throughout the world. To better mitigate seismic hazard, effective prevention and prediction is needed. Careful assessment of seismic hazards through accurate computational predictions can lead to appropriate building codes. This can be of enormous impact for human life and societal welfare in the case of a large seismic event in a densely populated area as the greater Los Angeles or the San Francisco bay. The broader impacts of the proposed activities also include education. The project will involve graduate students who will gain experience in state-of-the-art computational science. The research will be performed at the University of New Mexico, a Hispanic serving institution that also serves a large body of native Americans, allowing active recruitment and education of students from underrepresented groups."
"1320919","Novel Algorithms for Separated Representations in Functional Form for the Adaptive Solution of Quantum Chemistry Problems and Other Applications","DMS","COMPUTATIONAL MATHEMATICS","09/15/2013","09/17/2013","Gregory Beylkin","CO","University of Colorado at Boulder","Standard Grant","Rosemary Renaut","08/31/2016","$330,000.00","Lucas Monzon","gregory.beylkin@colorado.edu","3100 MARINE ST","BOULDER","CO","803090001","3034926221","MPS","1271","9263","$0.00","This proposal develops a new approach for solving partial  differential and integral equations based on novel algorithms for  separated representations in functional form. Separated  representations, a natural extension of separation of variables,  is a nonlinear method to approximate multidimensional functions  as sums of separable functions. In this representation functions  in a high-dimensional space are described with a small number of  parameters, making possible to bypass the so-called curse of  dimensionality, that is, to avoid the exponential growth of  computational cost in the underlying dimension of the problem.  The term in functional form refers to the handling of the  components of separated representations in each dimension; they  are obtained via a nonlinear approximation rather than via a  representation through bases. This approach not only provides a  greater efficiency by reducing the number of parameters but also  expands the current paradigm for solving equations. By seeking  solutions via a self-correcting iterative process, a new  efficient algorithm keeps a manageable number of terms in the  representation while maintaining the functional form of the  components and the desired accuracy. The goal of this project is  to design, test and implement such a reduction algorithm and  apply it to solve several multidimensional problems that cannot  be addressed by current methods. Many problems in modern science  require computing multivariate solutions and a major challenge is  to develop representations and algorithms to obtain them while  avoiding the curse of dimensionality. The proposed effort  develops a functional calculus for solving high dimensional  problems via a self-correcting iterative process based on a  combination of three types of novel algorithms: (1) Separated representations in functional form as a tool to circumvent the curse of dimensionality; (2) Highly efficient nonlinear approximations of univariate functions to achieve adaptivity of the components of the separated representations; (3) Randomized projections to reduce the number of terms in the separated representation while maintaining the functional form of the components and the desired accuracy. These adaptive algorithms should yield accurate solutions with  guaranteed error bounds while requiring a computational time that scales linearly in the dimension of the problem. A particular emphasis of this proposal is on a fundamental problem of Quantum Chemistry to accurately compute the electronic structure of molecules.   <br/><br/>Accurate modeling in modern science and engineering requires  computations with multivariate functions and any progress toward  making such computations feasible will either significantly  accelerate existing numerical methods or lead to the solution of  many problems that are currently out of reach. Scientific areas  to benefit from proposed algorithms are not limited to Quantum  Chemistry and material sciences where the ability to understand  chemical reactions and properties of materials relies heavily on  efficient numerical algorithms, but also include robotics and the  design of multicomponent structures, just to name a few. This  proposal provides numerical tools to address the multivariate  nature of many challenging scientific problems. As a result, topics of the proposal are expected to give raise to  interdisciplinary collaborations as well as  become part of  graduate dissertations."
"1320652","Collaborative Research: Scalable and accurate direct solvers for integral equations on surfaces","DMS","COMPUTATIONAL MATHEMATICS","08/01/2013","07/14/2013","Per-Gunnar Martinsson","CO","University of Colorado at Boulder","Standard Grant","Rosemary Renaut","07/31/2016","$219,187.00","","pgm@ices.utexas.edu","3100 MARINE ST","BOULDER","CO","803090001","3034926221","MPS","1271","9263","$0.00","The goal of the proposed research is to develop faster and more accurate algorithms for computing approximate solutions to a broad class of equations  that  model physical phenomena such as heat transport, deformation of elastic bodies, scattering of electromagnetic waves, and many others. The task of solving such equations is frequently the most time consuming part of computational simulations, and is the part that determines which problems can be modeled computationally, and which cannot. Dealing with complicated shapes (e.g.  scattering from complex geometry or flow through channels of complicated shape) adds difficulty to the computational task.<br/><br/>Technically speaking, most existing large-scale numerical algorithms for solving partial differential and integral equations on complex geometries are based on so called ""iterative methods"" which construct a sequence of approximate solutions that gradually approach the exact solution. The proposed research seeks to develop ""direct methods"" for solving  equations. A ""direct method"" computes the unknown data from the given data in one shot.  When available, direct methods are often preferred to iterative ones since they are more robust, and  can be used in a ""black-box"" way.  As a result these are  more suitable for incorporation in general purpose software, and in many cases work for important problems that cannot be solved with existing iterative methods. The reason that they are today typically not used is that existing direct methods for many problems are often prohibitively expensive. However, recent results by the PIs and other researchers have proven that it is possible to construct direct methods that are competitive in terms of speed with the very fastest existing iterative solvers. The new algorithms will be applied to the simulation of fluid flows and biomolecular simulations, and their performance will be demonstrated by the execution of simulations on complex geometries."
"1318633","Accurate and Efficient Algorithms for Computing Exponentials of Large Matrices with Applications","DMS","COMPUTATIONAL MATHEMATICS","07/15/2013","07/02/2013","Qiang Ye","KY","University of Kentucky Research Foundation","Standard Grant","Leland Jameson","06/30/2017","$189,971.00","","qye3@uky.edu","500 S LIMESTONE","LEXINGTON","KY","405260001","8592579420","MPS","1271","9150, 9263","$0.00","Matrix exponential is an important linear algebra tool that has a wide range of applications. Its efficient computation is a classical numerical linear algebra problem that is of considerable importance to many fields. This research project is concerned with numerical algorithms for computing exponentials of large matrices. The main objectives are: (1) to develop efficient preconditioning techniques for computing the product of the exponential of a matrix with a vector, and (2) to develop accurate and efficient algorithms to compute some selected entries of the exponential of an essentially nonnegative matrix. The proposed research will advance theory and algorithms for matrix exponentials in the setting of iterative methods for large scale problems. It will systemically address the problems of preconditioning and entrywise relative accuracy that are critically important in certain applications. The resulting algorithms will improve the existing ones in computational efficiency and/or accuracy. At the conclusion of this project, robust MATLAB implementations of the algorithms developed will be made publicly available.<br/><br/>The algorithms proposed in this project will provide new computational tools that are sufficiently efficient and/or accurate to meet the challenges posed by many large scale application problems. A fully developed efficient preconditioning technique would significantly advance the state of the art in solving large scale initial value problems, which are used to model and solve a large number of practical problems in science and engineering. The proposed algorithms for accurately computing selected entries of the exponential of a large essentially nonnegative matrix would remove the numerical accuracy issue that may present a significant challenge to the traditional algorithms. The need for entrywise accurate computations arise in continuous-time Markov chain models, where the entries represent transition probabilities, and in large complex networks, where the entries define various network properties such as connectivity. Thus, the new algorithms will be applicable to a wide range of problems that involves continuous-time Markov chains or complex networks. They include problems from genetics, sociology, neurology, biological networks, social networks and homeland security, telecommunication networks, and computer networks."
"1318652","Problems in mathematical foundations of adaptive finite element methods","DMS","COMPUTATIONAL MATHEMATICS","09/01/2013","07/08/2013","Alan Demlow","KY","University of Kentucky Research Foundation","Standard Grant","Junping Wang","04/30/2015","$179,995.00","","demlow@math.tamu.edu","500 S LIMESTONE","LEXINGTON","KY","405260001","8592579420","MPS","1271","9150, 9263","$0.00","A posteriori error estimates and adaptive finite element methods (AFEM) are widely-used tools for solving partial differential equations (PDEs) arising in science and engineering applications.  A posteriori estimates provide computable bounds on discretization errors, while AFEM are efficient solution techniques which accurately reflect solution properties via automatic local mesh grading.  The goals of this project are to better understand the mathematical underpinnings of AFEM and to provide new a posteriori error estimates and adaptive algorithms in several specific application areas.  A major part of the project is devoted to development and analysis of a posteriori error estimates and AFEM for PDEs on surfaces.  Specific projects concern Eulerian formulations of parabolic PDEs on evolving surfaces, solution of elliptic PDEs on surfaces for which the only available information is a discrete approximation, and elliptic eigenvalue problems.  Another emphasis is fine properties of FEM, in particular the development of a priori and a posteriori error estimates in nonstandard norms.  The PI will develop new a priori error estimates in such norms on the types of highly graded meshes typically seen in practice, prove new a posteriori maximum-norm bounds for elliptic interface problems, and integrate similar error analysis into his study of surface eigenvalue problems. <br/><br/>A wide variety of applications in science and engineering give rise to partial differential equations (PDEs) which must be solved in order to obtain accurate predictions about the physical world.  PDEs are typically solved approximately on computers in modern applications, and there is a tradeoff between the quality of the approximate solution and the investment of computational resources.  The PI will study the mathematical underpinnings of adaptive algorithms which automatically generate more accurate solutions while efficiently employing the computing power at hand.  Part of the project is aimed at enriching mathematical understanding of existing algorithms, and part to developing new and mathematically well-justified adaptive algorithms for various applications."
"1303442","Workshop on Multilevel Computational Methods and Optimization","DMS","COMPUTATIONAL MATHEMATICS","05/15/2013","05/13/2013","James Brannick","PA","Pennsylvania State Univ University Park","Standard Grant","Junping Wang","04/30/2014","$20,000.00","","brannick@psu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271","7556, 9263","$0.00","This grant supports travel of US researchers to attend the workshop on ""Mutilevel methods and Optimization"" from April 29 to May 2, 2013, at the Weizmann Institute of Science in Rehovot, Israel. The planned talks and panel discussions will cover classical problems such as partial differential equations, together with modern tasks such as web search and data mining.  Speakers and participants in the workshop come from a variety of disciplines, including physics, biology, chemistry, economics, environment and earth sciences, computer science and engineering. A special two-hour panel ""Challenges in Multilevel Computation: where should we be directing our efforts and our graduate students?"" is planned for the second day.  <br/><br/>Multilevel solution methods for simulation and optimization problems over very large number of variables is central and important to virtually all disciplines in the sciences and engineering. These methodologies are very powerful because they exploit the fact that most computational problems have multiple scales. This notion of multiple scales may take on many different guises, including time and space, pixels, particles, proteins, or web-pages. This multiplicity and disparity of scales is an essential source of computational complexity. The multilevel algorithms address the problem under consideration at a hierarchy of scales, typically treating each with a method that is local to that particular scale.  The proposed workshop will bring together junior researchers and world-class experts, mainly from North America, Western Europe, and Israel, to exhibit and discuss their recent research on multilevel computational methods for simulation and optimization in a wide variety of topics and applications.  Together, the diverse backgrounds of the participants in the workshop and the planned activities are expected to expose new research directions in multilevel computational methods and to identify the most pressing challenges in this diverse field."
"1308365","Modeling the Effects of Species Range Shifts","DMS","COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY","09/01/2013","06/22/2015","Mark Kot","WA","University of Washington","Continuing Grant","Junping Wang","07/31/2017","$284,856.00","","mkot@uw.edu","4333 BROOKLYN AVE NE","SEATTLE","WA","981950001","2065434043","MPS","1271, 7334","9263","$0.00","Climate change is having a profound effect on many organisms.  The purpose of this project is to develop, analyze, and use a new class of mechanistic models, integrodifference equations, that include growth, dispersal, and climate-driven range shifts in order to study and predict the effects of climate change on animal and plant populations.  Integrodifference equations reduce the problem of determining the persistence of a population in a changing environment to a simple eigenvalue problem.  Researchers will analyze the effects of climate-driven range shifts on age- and stage-structured populations with complex life histories, perform analyses of two-dimensional range-shift models on realistic geometries, build and analyze models with explicit habitat quality functions, and build and analyze range-shift models that contain interspecific interactions.  Sensitivity analyses will be performed in order to determine which demographic stages have the strongest influence on persistence in a changing environment.<br/><br/>The Earth is getting warmer.  In response to this warming, many species have shifted their ranges poleward in latitude or upward in elevation.  The purpose of this project is to develop mathematical models and tools that will help us determine which species can continue to keep pace with climate-driven habitat shifts and which species are at risk.  Researchers will start with models that include growth and demography, dispersal, and climate-driven spatial shifts and extend these models to include age and stage structure, complicated life histories, population interactions, habitat quality, and realistic geometries.  These extensions will help us more accurately assess the effects of climate change on animal and plant populations."
"1312636","Recovery of high frequency wave fields, kinetic theory of photons and entropy satisfying methods","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/01/2013","08/29/2013","Hailiang Liu","IA","Iowa State University","Standard Grant","Victor Roytburd","08/31/2017","$225,185.00","","hliu@iastate.edu","1350 BEARDSHEAR HALL","AMES","IA","500112103","5152945225","MPS","1266, 1271","9150, 9263","$0.00","This research project develops mathematical tools and numerical algorithms to study multiscale problems governed by a selected set of partial differential equations arising in diverse applications. The proposed work consists of three projects:  recovery of high frequency wave fields governed by a variety of wave equations, including hyperbolic equations such as the acoustic wave equation, dispersive equations such as the Schroedinger equation, and the time independent Helmholtz equation; development of kinetic theory of photons in the transport of energy;  and design of entropy satisfying discontinuous Galerkin methods for kinetic Fokker-Planck equations, with emphasis on kinetic models arising in polymeric fluids and collective motions in biology. <br/><br/>Each of the proposed projects has the potential to have a significant impact on problems that are both fundamental and technologically important. Recovery of high frequency wave fields is a fundamental problem in high frequency wave propagation, the study of which can provide a deeper understanding of high frequency wave dynamics occurring in various applications. The study of condensation of photons would result in methods which may potentially be suitable for designing novel light sources. Entropy satisfying methods are important in capturing the right physics in long time numerical simulations. The design of such methods has the potential to elucidate many aspects of the physical process. The theory will be applied to and driven by identified practical applications."
"1314406","Workshop on Numerical Linear Algebra and Optimization","DMS","COMPUTATIONAL MATHEMATICS","07/01/2013","05/13/2013","Ioana Dumitriu","WA","University of Washington","Standard Grant","Junping Wang","06/30/2014","$23,900.00","","idumitriu@ucsd.edu","4333 BROOKLYN AVE NE","SEATTLE","WA","981950001","2065434043","MPS","1271","7556, 9263","$0.00","This grant provides travel support for US scientists to a three-day ""Workshop on Numerical Linear Algebra and Optimization"", to be held August 8-10, 2013 at the University of British Columbia, Vancouver, Canada. The workshop has the following three objectives: (1) to bring together the community of linear algebra and optimization in order to foster interaction and explore the rich area at the intersection of these two research fields; (2) to seek application of these problems in fields like machine learning and control; and (3) to promote and discuss the issue of actively using large-scale numerical linear algebra tools in scientific and industrial optimization. One of the main areas the workshop will focus on is eigenvalue optimization, which has received a lot of attention recently and which is studied by the two communities from different perspectives.<br/><br/>Optimization is a large field of research, with applications ranging from economics and engineering to national security, energy, and climate understanding. Examples of problems that can be solved with the help of optimization include maximizing profit or minimizing waste when manufacturing a variety of goods under raw material constraints; computer-based learning to classify objects (e.g., distinguishing tanks from trees); designing stronger buildings subject to volume and environmental constraints; and making planes safer by avoiding certain undesirable vibration frequencies. Solutions to such optimization problems need to make use of linear algebra quantities (like eigenvalues), and extensive calculations of such quantities must be done with care and in the most efficient way. This is a central task in numerical linear algebra, the tools of which have been adopted and adapted by various optimization communities to suit their needs. There is a very rich area of research at the interface between these two fields of optimization and numerical linear algebra, and the organizers of this workshop aim to see both communities work together toward addressing the important problems that arise in industry."
"1320910","Sparse 3D-Data Representations from Compactly Supported Atoms for Rigid Motion Invariant Classification with Applications to Neuroscience Imaging","DMS","COMPUTATIONAL MATHEMATICS","08/01/2013","09/10/2015","Emanuel Papadakis","TX","University of Houston","Continuing Grant","Rosemary Renaut","05/31/2017","$229,993.00","Ioannis Kakadiaris, Demetrio Labate","mpapadak@math.uh.edu","4300 MARTIN LUTHER KING BLVD","HOUSTON","TX","772043067","7137435773","MPS","1271","9263","$0.00","The quantitative characterization of neuronal morphology is currently among the most fundamental objectives in neuroscience, as it is essential to precisely correlate structure, activity and neuronal communication at the cellular level. It has been long established that neurons respond to external stimuli through significant structural changes. Hence, the ability to quantitatively capture and track these changes is fundamental for understanding the cell-level biology of brain functions.  Dendritic spines, in particular, are are sub-cellular structures, which play a key-role in how neurons talk to each other; these structural changes are referred to as synaptic plasticity. Although, this type of microanatomical plasticity has been associated with drug addiction or even with autism, the change in the morphology and density of spines in addiction, autism and in neurodegenerative diseases is still unclear. Recent developments of high-resolution confocal single photon and multi-photon microscopy, together with the ability to mark subcellular structures, provide a new window for the observation of live single or small groups of neurons which never existed before. However, extracting useful information using this novel imaging is a challenging task. In particular, observing the variations of spine populations, which are in the order of several thousands for even a single neuron, categorizing them in different types and maintaining the timeline of changes are largely laborious manual tasks that are subject to the inevitable inaccuracies native to repetitive and tedious manual work.<br/><br/>Our project aims to develop the algorithmic foundations for a new generation of software tools for extracting global spine morphometric characteristics and population dynamics from high-resolution confocal single photon and multi-photon microscopy images with minimal human intervention. Such tools will have a transformative effect in the logistics of spine studies, because they slash the required labor cost. To achieve our goal, we will make contributions to both mathematical analysis and computer vision. We aim to develop robust methods for the detection, identification of type and estimation of volume regardless of the position and spatial orientation of spines in a 3D image of a neuron acquired with the said microscopes. Finally, our project offers educational opportunities to graduate students in a blend of abstract and computational mathematics and computer vision. We also plan to continue our outreach activities to local high schools located in disadvantaged areas of Houston, offering to top students sneak peeks of the life of the mathematician, the computer scientist and the biologist researcher."
"1265097","South Central Conference on Advanced Numerical Methods and Applications","DMS","COMPUTATIONAL MATHEMATICS","01/15/2013","01/07/2013","Yanqiu Wang","OK","Oklahoma State University","Standard Grant","Amnon J Meir","12/31/2013","$25,457.00","","yqwang@math.okstate.edu","401 WHITEHURST HALL","STILLWATER","OK","740781031","4057449995","MPS","1271","7556, 9150, 9263","$0.00","The South Central Conference on Advanced Numerical Methods and Applications will be held in April 5-7,  2013 at the University of Arkansas at Little Rock (UALR).   The conference will bring together researchers of all career stages, working on various aspects of numerical analysis and scientific computing, from the south central region and other surrounding states. It will cover a wide range of topics on Numerical Analysis and Scientific Computing, including but not limited to the following list: finite element methods, finite volume methods, spectral methods, discontinuous Galerkin methods, numerical linear algebra, preconditioning techniques, multiscale methods, parallel computing, numerical methods for solid mechanics, fluid mechanics, image processing.<br/><br/>The conference will serve as a forum for researchers to distribute newest ideas, foster interaction and collaboration between different groups, advocate the numerical analysis community in the south central region, and help envision future research and education agendas.<br/><br/>In addition to promoting group interaction and collaboration, this conference will influence and invigorate the educational developments among colleges, universities and research institutes.  Graduate students, postdocs, and junior researchers will benefit greatly from attending the conference and communicating with peers. Special effort will be made to encourage the attendance of woman, minorities, and other under-represented groups.  More information can be found on the conference webpage: http://www.math.okstate.edu/~yqwang/south-central-conf/"
"1318916","Discontinuous Petrov Galerkin Methods and Applications","DMS","COMPUTATIONAL MATHEMATICS","07/15/2013","07/02/2013","Jay Gopalakrishnan","OR","Portland State University","Standard Grant","Leland Jameson","06/30/2017","$302,000.00","","gjay@pdx.edu","1600 SW 4TH AVE","PORTLAND","OR","972015522","5037259900","MPS","1271","9263","$0.00","Computer simulation of many natural and technological processes relies on robust and efficient algorithms for solution of partial differential equations. In the continuing pursuit of such algorithms, a class of new Discontinuous Petrov-Galerkin (DPG) methods emerged as hybrid methods with a least-squares character. Their unusual stability and localization properties have the potential to expand the research frontiers in high performance computing. This project extends, improves, and identifies new applications for these DPG methods. These methods use a number of local operations, implementable on heterogenous computational clusters, to guarantee stability. Building on the method's known stability properties, the following five projects are proposed: (i) an explicit space-time extension of DPG methods providing a new way to simulate evolution of Friedrichs systems (ii) analysis and incorporation of adaptivity into DPG schemes thereby allowing computational resources to be allocated where they are needed most (iii) understanding DPG methods for harmonic wave phenomena in acoustics, elasticity, and electromagnetics, (iv) design of efficient preconditioners and other fast solution strategies for DPG methods, and (v) new tailor-made computational techniques to simulate biological pattern formation via chemotactic feedback.<br/><br/>The proposed research is on a new method to solve partial differential equations, the Discoutinuous Petrov-Galerkin method. Impacts of development of the new method will apply to several areas, including propagation of acoustic, electromagnetic, and seismic waves in heterogenous media, and potential contributions in computational fluid dynamics applied to wind energy. The research component on biological patterns is inspired by questions of immediate relevance in health sciences, including a model for simulating tumor invasion, and simulation of chemotactic cancer cell movement, both intimately related to cells aggregating to form patterns. Finally, trained workforce additions will be accomplished by integrating graduate student involvement into the proposed research."
"1414365","Investigation of Auxiliary Subspace Techniques as a  General Tool for A Posteriori Error Estimation","DMS","COMPUTATIONAL MATHEMATICS","10/01/2013","08/18/2014","Jeffrey Ovall","OR","Portland State University","Continuing Grant","Rosemary Renaut","08/31/2016","$143,860.00","","jovall@pdx.edu","1600 SW 4TH AVE","PORTLAND","OR","972015522","5037259900","MPS","1271","9150, 9263","$0.00","A posteriori error estimation is an essential component of high-performance finite element computations.  Such estimates are used in practice not only to reliably determine when an approximate solution is accurate enough, but also to (efficiently) adaptively improve the approximation. This proposal considers auxiliary subspace error estimates, which are derived from computing an approximate error function in an auxiliary space. Such an approximate error function provides great flexibility, in principle, in how it may be used for adaptive finite, and we are here concerned estimation of and adaptivity with respect to: error in a variety of norms, higher-order derivatives in a variety norms, functional error for general classes of linear functionals, and error in eigenvalue and invariant subspace computations. The robustness of hierarchical error estimates of energy-norm error is well-established both in theory and in practice for low-order finite elements and second-order linear elliptic boundary value problems in two dimensions. This proposal aims to significantly extend both theory and practice not only to include the various error measures mentioned above, but also higher-order elements in two and three dimensions (p- and hp-adaptivity), as well as to different types of operators and finite elements, including systems of partial differential equations.  Additionally, an adaptive convergence theory would also be developed, where possible. A key component of the proposed research is the development of a basic framework in which clear guidance concerning an appropriate choice of auxiliary space for computing the approximate error function is provided by considering a few basic properties of the underlying problem and the space which was used for the approximate solution.<br/><br/>The ability to automatically detect and adapt to relevant fine and coarse-scale features in the modeling of composite materials is often indispensable as an aid for design of such materials, as well as for remote sensing in the presence of complex media (e.g. non-destructive exploration for natural resources).  This proposal concerns the development of a general and very flexible approach to error estimation and adaptive improvement of approximations in a variety of contexts, providing careful development of specific cases of interest, such as those mentioned above.  A clear theoretical framework for error estimation and adaptivity, together with several important practical realizations, will not only aid practitioners in making appropriate choices in their particular contexts, but will also make it easier to train students to be able to develop such tools for problem where little (if any) are available.  The various projects in the proposal include both national and international collaboration,as well as the education and involvement of graduate students.  Additionally, much of the software developed in conjunction with this proposal will be made freely available by the proposer from his website."
"1317730","Algorithms for Multiple Phases","DMS","COMPUTATIONAL MATHEMATICS","07/15/2013","09/10/2015","Selim Esedoglu","MI","Regents of the University of Michigan - Ann Arbor","Continuing Grant","Leland Jameson","06/30/2017","$301,942.00","","esedoglu@umich.edu","1109 GEDDES AVE, SUITE 3300","ANN ARBOR","MI","481091079","7347636438","MPS","1271","9251, 9263","$0.00","This project will develop rigorously understood, highly efficient and accurate computational tools (algorithms and their software implementation, based on a solid theoretical foundation) for simulating the motion of networks of surfaces under geometric motions such as motion by weighted mean curvature and motion by surface diffusion. The approach is based on a new, variational formulation of threshold dynamics (also known as diffusion generated motion) of Merriman, Bence, and Osher that makes it possible to correctly extend the original algorithm to e.g. weighted mean curvature flow of multiple phases with unequal and anisotropic surface tensions.<br/><br/>The geometric motions that will be studied in this project play a central role in materials science, where they describe the microstructural evolution of polycrystalline materials under common industrial processes such as annealing (heat treatment). Polycrystalline materials are very common: most metals and ceramics belong to this category. They are composed of tiny single-crystal pieces, known as grains, that are joined together along their faces. The physical properties of these materials, such as conductivity and yield strength, depend intimately on their microstructure (the shapes and sizes of the grains that make up the material). This project will advance our ability to simulate how the microstructure of these materials change, which is important for computational design of materials, where computer simulations rather than costly experiments would identify the most favorable processing parameters for achieving desired characteristics."
"1318586","Algorithms and Computation for Rare Events in Complex Systems","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, DYNAMICAL SYSTEMS","09/01/2013","08/29/2013","Qiang Du","PA","Pennsylvania State Univ University Park","Standard Grant","Junping Wang","09/30/2015","$250,000.00","","qd2125@columbia.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1266, 1271, 7478","9263","$0.00","The project is concerned with mathematical and computational issues related to the simulation and analysis of equilibria, metastable and transition states and  minimum energy paths for complex energy landscapes of practical interests, and associated stochastic dynamics. The research to be carried out is closely motivated by applications in a number of areas of federal strategic interests: the development of effective algorithms and codes is a crucial part of high-performance computing, and numerical methods and software tools to be developed may be potentially useful for effective computational  materials and drug design.<br/> <br/>The principal investigator will carry out interdisciplinary research that encompassing subjects like computational mathematics, physics, information, materials and biological sciences. He will focus on new algorithmic development and analysis which have the potential to significantly improve the usual practice on the modeling and simulation of rare events. He will consider some specific and important applications, including systems of interacting particles and interfaces in geometrically confined and frustrated configurations or deformable geometry which arise in many areas of physics, chemistry and biology (such as formation of nano-clusters, bimolecular conformation, vesicle mediated interactions, and critical nucleation in solid state transformations). He will attempt to draw strong connections with some of the algorithms developed by practitioners implemented in existing software codes such as those for first principle calculation and computational chemistry.  Most of the problems involved in the research project are associated with either infinite dimensional spaces such as deterministic or stochastic partial differential equations or finite dimensional spaces with high dimensions (discretization of differential equations or particle systems involving a large number of particles), which lead to many computational challenges. Various mathematical and numerical issues will be studied, ranging from efficient local saddle point search and its robust numerical implementation to rigorous analysis and effective multiscale simulations of relevant dynamics and rare events. It is expected that the progress made during the project will have a broad impact on the community interested in the study of rare events. The project will also contribute to education and training as it will provide students valuable training ground and research experience in an interdisciplinary environment. Much effort will be devoted to promoting active engagement of student participation at all levels and integrating research findings into teaching and training."
"1312644","Computional Analysis of Inverse problems","DMS","COMPUTATIONAL MATHEMATICS","05/15/2013","05/14/2013","Yuanwei Qi","FL","The University of Central Florida Board of Trustees","Standard Grant","Junping Wang","08/31/2014","$26,290.00","Qiyu Sun, Jiongmin Yong, Alexandru Tamasan","yuanwei.qi@ucf.edu","4000 CENTRAL FLORIDA BLVD","ORLANDO","FL","328168005","4078230387","MPS","1271","7556, 9263","$0.00","This grant supports an international conference on ""Computational Analysis of Inverse Problem,"" to be held in May 16-18, 2013 at the University of Central Florida (UCF) in Orlando, Florida. The theme of the conference is on computation and analysis of inverse problems. Inverse problems have wide range of applications in medical imaging, remote sensing, tomography and nondestructive testing, machine learning, geophysics and statistical inference. In the past 20 years, there have been major advances in inverse problems and its foundational aspects, where methods of functional analysis, partial differential equations and applied harmonic analysis have played pivotal roles in guiding the computational methods. The aim of the conference is to bring together top international experts to facilitate collaboration and communication among researchers under the common theme of inverse problems. There will be 20 invited speakers from USA, Europe and Asia Pacific, 15 of them from USA. Funds from NSF shall provide support for graduate students and recent PhDs and cover partial expenses of some domestic senior researchers.<br/><br/>Inverse problems have wide range of applications including medical and other imaging techniques, location of oil and other mineral deposits underneath the earth's surface through remote sensing, creation of astrophysical images from telescope. In addition to the traditional application in medical imaging, which plays a big role in improving national health care, the theory and computational methods developed to study inverse problems have demonstrated a big impact on energy independence through more effective drilling of oil and natural gas. They also help us to deep our understanding of climate change through creation of astrophysical images. The conference will serve the purpose of encouraging communication and collaboration between researchers not only in different scientific disciplines and industries, but also across international boundaries. The conference is expected to attract many young researchers and graduate students to participate in conference activities, in particular women and other under-represented minorities. The participation of graduate students and young researchers from USA and other countries will give arise to a good opportunity for mentoring activities for these groups."
"1338314","Southeastern-Atlantic Regional Conference on Differential Equations 2013","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, ANALYSIS PROGRAM","08/01/2013","08/05/2013","Suzanne Lenhart","TN","University of Tennessee Knoxville","Standard Grant","Pedro Embid","04/30/2014","$21,938.00","Tuoc Phan, Steven Wise","slenhart@utk.edu","201 ANDY HOLT TOWER","KNOXVILLE","TN","379960001","8659743466","MPS","1266, 1271, 1281","7556, 9150","$0.00","The Southeastern-Atlantic Regional Conference on Differential Equations (SEARCDE) has met annually since 1981. It was initiated by members of the Department of Mathematics at the Virginia Polytechnic Institute and State University and has since then rotated among various research institutions in the Southeast. This year, the 33rd SEARCDE conference will be held at the University of Tennessee, Knoxville (UTK), September 21 and 22, 2013. Continuing SEARCDE's tradition, the conference is a forum to discuss, exchange recent advances in both theoretical and applied areas of differential equations. Besides four invited plenary talks, there will be many contributed talks with a wide range of topics organized in parallel sessions. Young researchers are encouraged to give talks, will receive helpful feedback, and can benefit from interactions with a diverse group of plenary lecturers. The invited plenary lectures will broaden the participants' knowledge about current researchand techniques in differential equations and its applications. Many contributed talks and the networking opportunities will contribute to the exchange of research ideas and the formation of new collaborations. Information about the conference can be found at the meeting website. http://www.math.utk.edu/SEARCDE2013.<br/><br/>The principal objective of SEARCDE conference is to promote research and education in the field of differential equations by bringing together established and beginning researchers, including advanced undergraduate and graduates students as well as recent PhD's.  The meeting provides a platform to exchange ideas and to discuss recent developments in the field, both in applied and theoretical differential equations.  SEARCDE particularly encourages the participation of beginning researchers, for whom the opportunities offered by regional conferences are important, especially those from traditionally under-represented groups. Indeed, it is often the case that a researcher in the field will have presented her research findings for the first time at a meeting like SEARCDE. NSF funding will ensure that many talented young researchers will have the opportunity to participate in SEARCDE 2013."
"1318716","Computation with Finitely Presented Groups","DMS","COMPUTATIONAL MATHEMATICS","09/15/2013","09/08/2013","Robert Gilman","NJ","Stevens Institute of Technology","Standard Grant","Rosemary Renaut","08/31/2016","$269,538.00","Mark Sapir, Alexei Miasnikov, Alexander Ushakov, Alexey Myasnikov","rgilman@stevens.edu","1 CASTLEPOINT ON HUDSON","HOBOKEN","NJ","07030","2012168762","MPS","1271","9263","$0.00","Intractable computational problems, in particular recursively unsolvable problems, occur naturally in combinatorial group theory and have been studied in that context for over a hundred years. This project is devoted to finding better algorithms and partial algorithms for these problems, both for well-known ones and also for new ones which have arisen, for example, in group-based cryptography. Using techniques developed in their previous work, the investigators will perform computer experiments to discover and test new computational procedures and also to gather information on the distribution of hard instances in specific problems.  <br/><br/>An algorithm for a computational problem may be useful even though it sometimes fails, if its failures are rare. A well known example is the simplex algorithm for linear optimization. This algorithm (which is used hundreds or thousands of times every day) can take a very long time for certain carefully constructed cases but never does so in practice. In other words the difficult cases are extremely rare. Although there are many other algorithms which behave the same way, this phenomenon is not well understood. The broader significance of this project is that it seeks a better understanding through investigation of an appropriate class of computational problems."
"1309312","Conference on Advanced Statistical Methods for Underground Seismic Event Monitoring and Verification","DMS","STATISTICS, COMPUTATIONAL MATHEMATICS","02/15/2013","01/31/2013","Minge Xie","NJ","Rutgers University New Brunswick","Standard Grant","Gabor Szekely","01/31/2015","$31,040.00","Rong Chen","mxie@stat.rutgers.edu","3 RUTGERS PLZ","NEW BRUNSWICK","NJ","089018559","8489320150","MPS","1269, 1271","7556, 9263","$0.00","The Conference on Advanced Statistical Methods for Underground Seismic Event Monitoring and Verification will be held March 7-8, 2013 in Washington DC area. The ability of monitoring and verification of underground seismic events is vital to national security and disaster preparation and prevention. The research and development of monitoring and verification technology have been extensive. Significant advances have been made in sensor development and also in the development of seismic signal processing methodologies that have the ability to verify any underground seismic events as well as distinguish signals generated from different mechanisms with sensors placed a vast distance away from the event site. The research and development is highly interdisciplinary, involving geophysics, sensor development, signal processing, and statistics. To further enhance the collaboration between statisticians and other scientists in the field and to investigate the potential approaches of combining state-of-art statistical methods with advanced sensor technology, we propose to organize a conference on advanced statistical methods for underground seismic event monitoring and verification. The conference will bring statisticians and the other experts in the field together to discuss the current status of field, to exchange ideas, and to brainstorm novel approaches. The conference will also serve a venue to generate new interests among statisticians to this field, to enlist statisticians to bring in their new statistical ideas and approaches to deal with this important problem.<br/><br/>The conference will be collaboration between academics and federal agencies. The experts in the federal agencies will share their vision and experience and also any urgent specific problems. The conference will consists of general sessions where plenary speakers and discussants present their research findings and proposals of future research, with floor discussion encouraged, and a study group session where participants are separated into several groups and discuss and deliberate specific topics. At the end, the conference organizer will produce a report to be shared with federal agencies and participants, and be published in scientific community newsletters such as ASA news to generate interests in the larger community. The conference will attract, engage, educate and train students and next generation scientists to work in the area of research and development of underground seismic event detection technology using advanced statistical and mathematical tools. Such exposure and training is essential for them to become statisticians capable of collaborating effectively with scientists and researchers in the field and to generate new innovative approaches to real problems that have been difficult to tackle in underground event detection and related fields."
"1318465","Modeling and Simulations of Complex Fluids and Atomistic Strain","DMS","COMPUTATIONAL MATHEMATICS","07/01/2013","06/25/2013","Young-Ju Lee","NJ","Rutgers University New Brunswick","Standard Grant","Leland Jameson","10/31/2013","$144,816.00","","y_l39@txstate.edu","3 RUTGERS PLZ","NEW BRUNSWICK","NJ","089018559","8489320150","MPS","1271","9263","$0.00","The main objectives of the project is to build an integrated mathematical and computational research program that includes coherently interconnected mathematical disciplines, targeting, but not limited to, some challenge applications in modeling and simulation of complex fluids and atomic strain. The major goal in the project is to understand the flow instabilities in worm-like micellar fluids such as the oscillating falling sphere and jumping bubbles. Using the three species model that takes into account long and short micelles and the shear-induced structure, the conjectured relation between the flow instability and the shear-induced structures will be investigated. The project will introduce the regularization techniques in the complex-fluid models for robust and stable simulations and will integrate them with a fast multigrid solver in the framework of massively parallel computing techniques. Such integrated modeling and computational method is anticipated to make a rheological modeling software. The project is also aimed at developing the new strain modeling and simulation of nano-crystalline materials. The atomic strain model will be developed by applying the finite element methodology for the continuum linear elasticity. Unlike the conventional strain models developed by using the finite difference approximations, the newly proposed model will mirror and take into account the real atomic structures such as the diamond and zinc structures. The model developed in this project will then be used to investigate a sample strain-related nano-structure formation as its application. <br/><br/>Complex fluids are ubiquitous in nature and industry and they are used in many important areas, including the pharmaceutical, food, military, bio-materials, printing, and oil industry, just to name a few. Strain in nano-crystalline materials is central in materials science research and understanding the strain is critical to provide guidance for the real-life device design applications such as light emitting diodes, injection lasers and solar cells. Yet, the modeling and simulation of complex fluids and strain in nano-crystalline materials remain formidable and grand challenges, even with modern supercomputers. Among others, the inherent deficiency of existing mathematical models and the inefficiency of conventional numerical techniques are the major bottlenecks, which defeat scientists' attempt to understand and design materials. It is anticipated that the modeling and computation methods developed in this research will remedy both the deficiency in the models and the inefficiency in the computation, thereby drastically eliminating the mathematical and computational bottlenecks and eventually providing valuable guiding tools for scientists to better understand the materials of interest within the scope of this project as well as in a number of other neighboring areas of research where the technologies developed in this project can be applied."
"1318172","Computational Intersection Theory for Infinite Dimensional Dynamical Systems","DMS","COMPUTATIONAL MATHEMATICS","07/01/2013","06/27/2013","Jason Mireles James","NJ","Rutgers University New Brunswick","Standard Grant","Junping Wang","02/28/2015","$103,429.00","","jmireles@math.rutgers.edu","3 RUTGERS PLZ","NEW BRUNSWICK","NJ","089018559","8489320150","MPS","1271","9263","$0.00","The purpose of this research is to develop mathematically rigorous computational methods for studying intersections of stable and unstable manifolds of infinite dimensional dynamical systems.  The problem splits naturally into two distinct technical challenges.  First it is necessary to extend existing methods of computational intersection theory to higher dimensions than currently accessible.  This problem will be addressed via reductions to lower dimensional slow stable invariant manifolds.  In order to study connecting dynamics it is also important to compute the linear bundles of these reduced manifolds. This requires an extension of classical Floquet theory into the slow manifold setting. The second major challenge is to develop a-posteriori techniques for proving the existence of connecting orbits in infinite dimensions. The question is: can we conclude the existence of connecting orbits in the infinite dimensional system once the existence of corresponding connections have been established in a projection of high enough finite dimension? Answering this question requires extending existing methods for studying infinite dimensional equilibria and periodic orbits to the setting of the boundary value problems which describe connecting orbits. The project will also consider the plausibility of computer assisted techniques for studying continuation with respect to parameter, as well as bifurcations of connecting orbits.<br/><br/>This research will yield new methods for insuring the correctness of scientific computations.  The focus of the project is on infinite dimensional models of applied mathematics such as partial differential equations, delay equations, and renormalization operators.  In addition to providing mathematically rigorous error bounds for approximate numerical solutions of these problems, the techniques of computer assisted proof resulting from this work are able to provide answers to theoretical questions about the global dynamics of nonlinear systems.  For example by establishing the existence of some transverse connecting orbits it is possible to prove the existence of turbulence, spatiotemporal chaos, or positive topological entropy in the phase space of a partial differential equation. Other theoretical problems which might be approached computationally once the techniques of this project become available include studying the combinatorial dynamics of renormalization operators, as well as some problems in nonlinear analysis involving the application of Floer's Homology theory. A central theme of this project is that at each stage of advancement the theoretical and computational tools developed will be applied to established problems of applied mathematics and dynamical systems theory."
"1320317","Enhancing the robustness of the immersed interface method for flow simulation","DMS","COMPUTATIONAL MATHEMATICS","08/15/2013","07/29/2013","Sheng Xu","TX","Southern Methodist University","Standard Grant","Leland Jameson","07/31/2017","$194,174.00","","sxu@smu.edu","6425 BOAZ LANE","DALLAS","TX","75205","2147684708","MPS","1271","9263","$0.00","The immersed interface method employs fixed grids and associated fast solvers to efficiently solve a variety of PDEs involving interfaces. It accurately captures the effects of interfaces by incorporating interface-induced jump conditions into numerical schemes. The main objective of this research is to enhance the robustness of this method to tackle 3-D large-size multi-scale flow problems. The PI proposes: (1) to derive and implement jump conditions for the method with a triangular mesh representation of a 3-D fluid-solid interface, (2) to handle solid collisions in a flow by incorporating into the method the lubrication theory, (3) to extend boundary condition capturing in the method from rigid solids to deformable solids, and (4) to use the domain decomposition and master-slave techniques for distributed-memory parallelization of the method for fluid-solid interaction and two-fluid flows. The PI and his students apply the enhanced method to investigate the dynamics of a collection of solid particles falling in a fluid and the aerodynamic control strategies in insect flight.<br/><br/>The proposed research is to push a computational method, the immersed interface method, so that it can be used to compute various interesting and important 3-D flow problems that are of large sizes and multiple scales. In particular, the PI and his students apply the method to study the dynamics of a collection of solid particles falling in a fluid and the aerodynamic control strategies in insect flight. A wide range of biological and physical systems involve the collective dynamics of objects, for example, schooling, microorganism colony, and particle suspension and sedimentation. The proposed study in this area will help understand, model, and design such systems. Winged insects are nature's answer to perfect small-scale flying machines. Understanding insect aerodynamics is of great interest to engineers in designing flapping-wing micro air vehicles, which can be employed in military surveillance, biological warfare detection, and reconnaissance in confined spaces. The PI plans to disseminate on his web page a user-friendly software and the associated tutorials on the immersed interface method to benefit undergraduate and graduate students who want to use the method for their research. Other educational impact of this research includes the support of an under-represented graduate student and the involvement of undergraduate students in computational research."
"1318377","Data-Driven Time-Frequency Analysis via Nonlinear Optimization","DMS","COMPUTATIONAL MATHEMATICS","12/01/2013","11/27/2013","Thomas Hou","CA","California Institute of Technology","Standard Grant","Leland Jameson","11/30/2017","$300,000.00","","hou@acm.caltech.edu","1200 E CALIFORNIA BLVD","PASADENA","CA","911250001","6263956219","MPS","1271","9263","$0.00","This investigator proposes to develop a new data-driven time-frequency analysis method to study nonlinear and non-stationary data. The key idea is to look for the sparsest time-frequency representation of a signal over the largest possible dictionary using nonlinear optimization. Such a method is motivated by physical applications and the need to extract instantaneous frequency and trend from multiscale data arising from many scientific and engineering applications. Although several methods have been introduced to extract instantaneous frequency from a multiscale signal, these methods suffer from various limitations and do not have a solid mathematical foundation. The data-driven time-frequency analysis method developed by this investigator and his colleagues provides a mathematically rigorous definition of instantaneous frequency. This investigator and his colleagues have developed an efficient nonlinear matching pursuit method based on L1-regularized nonlinear least squares to decompose the signal. This method can be used to extract physically meaningful information of the signal such as instantaneous frequency and trend. The preliminary results show that this method can decompose a wide range of physical signals accurately and efficiently. Applications of this method to some real world data from geo-science and biomedical applications have led to some new discoveries. One of the main objectives of this proposal is to carry out a rigorous convergence study of this method and apply it to solve some challenging real world problems in biomedical and geo-science applications.<br/> <br/>Developing effective data analysis methods is an important path to understand some hidden patterns such as trend and cycles from the massive amount of data. So far, most data analysis methods use a predetermined basis to process data. Most of these methods can handle only linear and stationary data. To better understand the physical mechanisms hidden in data, one needs to develop effective methods that can handle the non-stationarity and nonlinearity of the data. Such methods require the use of a data-driven basis that is adaptive to the data instead of being determined a priori. The data-driven time-frequency method developed by this investigator and his colleagues has a solid mathematical foundation and uses a novel nonlinear optimization technique. Application of this method to the 9 year AMSU data over tropical oceans has led to the discovery of a new near-annual trend. This method has been applied to analyze blood pressure wave data, leading to a completely new way of diagnosing patients with cardiovascular diseases. The proposed method could provide a completely new way to analyze real world data. The proposed research will help train students and postdocs in this emerging research area. The knowledge, techniques and tools developed in this project will be disseminated through publishing in the open literature, and making available as open-source the software tools that are developed."
"1319276","Efficient Algorithms for Complex Multiphase Physics","DMS","COMPUTATIONAL MATHEMATICS","07/01/2013","06/25/2013","James Sethian","CA","University of California-Berkeley","Standard Grant","Leland Jameson","06/30/2017","$400,000.00","","sethian@math.berkeley.edu","1608 4TH ST STE 201","BERKELEY","CA","947101749","5106433891","MPS","1271","9263","$0.00","Many problems involve multiply-connected moving interfaces, including liquid and solid foams, coarsening in materials, complex mixing in fluids, and evolving cell structures in biology. These problems have multiple domains which share common walls meeting in multiple junctions.  Boundaries move under forces which depend on both local and global geometric properties, such as surface tension and volume constraints, as well long-range physical forces, including incompressible flow, membrane permeability, and elastic forces.<br/><br/>This proposal is aimed toward developing, implementing, and applying new numerical methods for propagating multiphase interfaces in a complex physical settings. One of the central computational tools will be the recently developed Voronoi Implicit Interface Methods, which is a mathematical perspective and associated numerical methodology for tracking interfaces in general multiphase problems. These methods offer accurate, consistent, and efficient schemes for multi-dimensional coupled multiphase, which handle complex triple joints/junction, topological change, and naturally couple to complex physics.  The investigator and his colleagues will develop new algorithmic tools for multiphase coupled transport problems, and will apply these techniques to computing solid and liquid foams, as well as manufacturing techniques for new materials, providing new methods to compute, refine, and optimize the design and performance cf complex materials."
"1315993","An Eulerian finite element method for partial differential equations posed on surfaces","DMS","COMPUTATIONAL MATHEMATICS","07/01/2013","05/01/2015","Maxim Olshanskiy","TX","University of Houston","Continuing Grant","Rosemary Renaut","06/30/2016","$221,637.00","","molshan@math.uh.edu","4300 MARTIN LUTHER KING BLVD","HOUSTON","TX","772043067","7137435773","MPS","1271","9263","$0.00","The goal of this research project is the development and analysis of a new Eulerian finite element method for solving elliptic and parabolic partial differential equations defined on hypersurfaces. The method uses traces of volume finite element space functions on a surface to discretize equations posed on that surface. This project aims at extending the method, its analysis and applications in several directions: (i) The extension and the analysis of the method for the case of an evolving surface; This is done in the framework of space-time finite element methods; (ii) The development of a higher order surface finite element method; This involves the analysis of the properties of traces of higher order finite element spaces on hypersurfaces; (iii) An error analysis for a class of coupled bulk domain - surface problems, discretized with volume and surface finite element methods; This includes numerical analysis and experiments for the problem of equilibrium two-phase incompressible viscous flow with surface active agents (surfactants).<br/><br/>Partial differential equations posed on surfaces arise in mathematical models for many natural phenomena: diffusion along grain boundaries, lipid interactions in biomembranes, pattern formation, and transport of surfactants on multiphase flow interfaces to mention a few.  Numerical simulations play an important role in a better understanding and prediction of processes involving these or other surface phenomena. Although, the study of numerical methods for equations on surfaces is a rapidly growing research area, computational technique for evolving and implicitly defined surfaces is largely in its infant stage. Numerical methods developed in the project are based on the Eulerian description of the motion of continuous medium. This choice of the Eulerian instead of the Lagrangian description is fundamental. It leads to serious algorithmic and analysis challenges, but it is consistent with most of approaches in computational mechanics and  so enables an integration of the method in many existing software packages for scientific computing. One example of a specific application the project aims is the transport of surface active agents on the interface in two-phase incompressible flow problems. In this application, the surface (interface between two different fluids, such as water and oil) evolves driven by a bulk fluid flow. To account for variable surface tension phenomena, such as Marangoni forces, one has to solve transport-diffusion equations for surfactant concentration on the evolving surface. Reliable computational tools for simulation processes on fluidic interfaces are crucial for a rigorous understanding of the behaviour of such very complex two-phase flow problems."
"1318161","A Novel Probabilistic-Based Approach to the Simulation of Disperse Two-Phase Flows with Application to Atmospheric Science","DMS","COMPUTATIONAL MATHEMATICS","07/15/2013","07/31/2015","Carlos Pantano-Rubino","IL","University of Illinois at Urbana-Champaign","Continuing Grant","Leland Jameson","06/30/2017","$300,604.00","","pantanor@usc.edu","506 S WRIGHT ST","URBANA","IL","618013620","2173332187","MPS","1271","9263","$0.00","The investigator will develop and study a new computational approach for the simulation of turbulent droplet-laden flows rooted in the probabilistic-based description of particle transport. This requires the determination of the evolution of the particle-density function in space and time, coupled with the turbulent flow of the carrier phase (gas or liquid). Knowledge of this function enables consistent coupling with the flow through mass, momentum, and energy sources in the governing equations of the carrier gas flow. The main mathematical difficulty that has prevented this approach from progressing in the past is the high dimensionality of the space of independent variables of the distribution function, which renders traditional computational techniques ineffective with current or foreseeable computational resources. The main idea of the research is the use of a new non-linear global basis function projection approach that condenses several of the extra dimensions of the problem. The transformative nature of the proposal is in (i) devising a methodology for integrating the transport equation for the distribution function that is computationally amenable, (ii) implementing the numerical methodology in an efficient predictive and modular tool, and (iii) extending the knowledge of the currently inaccessible aspects of the microphysics interaction with the carrier gas in atmospheric cloud simulations.  Furthermore, collaboration with a team at Max-Planck Institute for Meteorology will ensure the effective transfer and dissemination of the technology that is proposed to the area of physical meteorology. <br/><br/>The prediction of multi-phase flows, particularly solid or liquid particles dispersed in a host-gas, is challenging  and computationally onerous. These flows arise in natural phenomena; encompassing cloud dynamics, dust storms and grassland fires; and industrial applications such as food and chemical processing as well as chemical synthesis and propulsion. The interactions between a highly turbulent flow and the extremely large number of particles (millions-to-billions and beyond) of different shape and size, moving in different directions with different velocities, that undergo phase transformation and/or chemical reactions, lead to a complex mathematical problem. The proposed research will make a significant impact in the understanding of a wide range of science and engineering phenomena involving flows with dispersed particles that are currently inaccessible. The research will enable high-fidelity computations that incorporate phenomena at the small and large scales consistently. Enhancement in the prediction of these flows has numerous scientific and societal benefits; e.g., because atmospheric flows are critical to improve weather prediction and to better understand the global energy balance of our planet."
"1317330","Linear Response Eigenvalue Problem: New Minimization Principles and Efficient Algorithms","DMS","COMPUTATIONAL MATHEMATICS","09/01/2013","09/11/2013","Ren-Cang Li","TX","University of Texas at Arlington","Standard Grant","Leland Jameson","08/31/2017","$214,458.00","","rcli@uta.edu","701 S. NEDDERMAN DR","ARLINGTON","TX","760199800","8172722105","MPS","1271","9263","$0.00","The linear response eigenvalue problem, also known as the random phase approximation eigenvalue problem, arises from computing excitation states (energies) of physical systems. Such an eigenvalue problem is usually of large scale -- the matrix dimensions for a molecule of reasonable size can easily get up to tens of millions. It is considered much more difficult than the symmetric eigenvalue problem because it is non-Hermitian in nature. But it has internal symmetric structures in each of the submatrix blocks, which previously have been largely unexploited. This project involves the development of new theory and advanced computational methods through fully exploiting the internal symmetric structures. A systematic study will be thoroughly conducted to uncover new min/maximization principles. These principles should mirror those for the symmetric eigenvalue problem, and will make it possible and guide the investigator to transform some of existing and successful techniques for the symmetric eigenvalue problem for use in the linear response eigenvalue problem research, It is highly expected that new efficient algorithms that are capable of computing several smallest positive eigenvalues simultaneously will emerge as the result of this project. In addition to advancing research in the linear response  eigenvalue problem, the investigator will recruit and train graduate students in computational mathematics and interdisciplinary studies.  <br/><br/>The linear response eigenvalue problem is a major tool in computing energy excitation states of electrons and molecules. This project will critically advance current understanding and solution techniques for the eigenvalue problem in the context of mathematical theory, computational methods, and software. With the successful completion of the project, a significant contribution will be made to the state-of-the-art physical excitation energy computations via random phase approximations, a proven technique that is widely used in computational quantum chemistry and physics."
"1319640","Mixed Finite Elements, Monge-Ampere equation and Optimal Transportation","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/15/2013","08/30/2013","Gerard Awanou","IL","University of Illinois at Chicago","Standard Grant","Rosemary Renaut","08/31/2016","$150,000.00","","awanou@uic.edu","809 S MARSHFIELD AVE M/C 551","CHICAGO","IL","606124305","3129962862","MPS","1266, 1271","9263","$0.00","The goal of the proposal is to study efficient mixed finite element methods for the computation of transport maps in optimal transportation problems. The focus is on problems in which the cost of transport is a quadratic function of the distance. They lead to Monge-Ampere equations. The first part of the project consists in clarifying the applicability of finite element type methods to weak solutions of the equation. The key approach here is approximation by smooth functions. In the second part, techniques of mixed finite element analysis are adapted to the approximation of smooth solutions of the equation.<br/><br/>Optimal transportation has a growing application in various fields ranging from theoretical ones such as geometry and analysis to applied fields such as biology, pattern recognition, image processing, fluid mechanics, geophysics, meteorology, optics, oceanography and cosmology. This has created the critical need for efficient and robust numerical methods backed up theoretically to solve optimal transportation problems. The efficient and reliable methods developed from this project could be used to solve optimal transportation problems which appear in many other applications e.g. weather forecasting, traffic congestion, economics, mesh equidistribution, texture mapping, etc. The proposal studies the Monge-Ampere equation of optimal transportation with the goal of clarifying theoretically the use of the efficient mixed finite element methods. It advances knowledge towards the resolution of some open problems in analysis and geometry involving Monge-Ampere type equations."
"1255408","CAREER: Numerical Methods for Stochastic Reaction Diffusion Equations","DMS","Cellular Dynamics and Function, COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY, Division Co-Funding: CAREER","07/01/2013","06/13/2013","Samuel Isaacson","MA","Trustees of Boston University","Standard Grant","Leland Jameson","06/30/2019","$434,043.00","","isaacson@math.bu.edu","1 SILBER WAY","BOSTON","MA","022151703","6173534365","MPS","1114, 1271, 7334, 8048","1045, 9263","$0.00","A challenge facing numerical analysis, biophysics, computational biology, and biochemistry today is to accurately compute the stochastic behavior of tens to hundreds of thousands of interacting and diffusing molecules within a realistic three dimensional model of a eukaryotic cell. In order to contribute to the solution of this problem, this project will develop accurate, convergent, and efficient numerical methods for approximating the solutions to stochastic reaction-diffusion models of biochemical systems within the complicated geometries that come from sub-cellular imaging data. This will be done by creating new convergent reaction-diffusion master equation approximations to high dimensional coupled systems of partial integro-differential equations. These equations model the stochastic reactions and diffusion of tens of thousands of molecules within a cell containing detailed sub-cellular structures derived from high resolution soft X-ray tomography imaging data.<br/><br/>To better comprehend how organisms function, respond to environmental stimuli, and to aid in treating disease, it is necessary to understand, predict, and control the behavior of individual cells. Each cell contains numerous complex dynamical processes involving proteins undergoing biochemical reactions that play a major role in cell to cell communication, in cell growth and division, in immune system function, and in the development and progression of cancer. Understanding how proteins move about and interact within cells is critical to being able to predict and control these dynamical processes. This project will develop new mathematical equations and computational methods that can be used to study how proteins move about and interact within cells. These methods are designed to facilitate the computer simulation of cellular processes within realistic models of the interior of cells derived from high resolution experimental imaging data.  This project integrates the theoretical work with an educational program designed to improve the training of computational mathematical biologists. This interdisciplinary field requires a synthesis of skills that the project will provide to students in an integrated manner. These skills include the ability to develop mathematical models of biological systems; the ability to understand, and choose, appropriate numerical methods with which to solve these models; and the ability to implement these methods in a manner that takes advantage of existing numerical libraries on large scale computing platforms. Thus the planned research studies are complemented by an educational program designed to address the need to train scientists and engineers in the computational sciences, with an emphasis on computational mathematical biology."
"1320849","Numerical solution of the chemical master equation in cell biology","DMS","COMPUTATIONAL MATHEMATICS, MSPA-INTERDISCIPLINARY, Physiol Mechs & Biomechanics","08/01/2013","07/09/2013","Roger Sidje","AL","University of Alabama Tuscaloosa","Standard Grant","Leland Jameson","07/31/2017","$193,748.00","","roger.b.sidje@ua.edu","301 ROSE ADMIN BLDG","TUSCALOOSA","AL","354870001","2053485152","MPS","1271, 7454, 7658","8007, 9150, 9263","$0.00","The number of computations needed to solve the chemical master equation tends to explode because of the high number of potential states of the system and this fact motivates the need to develop sophisticated computational techniques to address this so-called ""curse of dimensionality."" This project seeks to address the problem using a combination of techniques such as model reduction techniques, efficient embedded techniques for the reduced problem, and inexact or relaxed function evaluations in the integration schemes.<br/><br/>The chemical master equation arises when mathematical modeling is used to represent the biochemical reactions that regulate the metabolism within the cells. Models of cellular processes allow experimentalists to avoid costly trial-and-error laboratory experiments in live cells . This sort of modeling poses a challenging problem because some key regulatory molecules are so small in number that the cellular processes associated with them seem random or stochastic and cells can change through a myriad of pathways that are difficult to track even on the fastest supercomputers. Thus the ability to use mathematical modeling to accurately mimic key molecules and to apply computational methods to efficiently code the simulations have important applications for  fields of molecular biology and medicine because there is a significant need to accurately simulate biochemical reactions inside a cell in real time.<br/>"
"1319731","Hybrid Computational Models and Robust Numerical Methods for Electrostatic Interactions in Biomolecules","DMS","Cellular Dynamics and Function, COMPUTATIONAL MATHEMATICS, MSPA-INTERDISCIPLINARY","09/01/2013","08/29/2013","Bo Li","CA","University of California-San Diego","Standard Grant","Leland Jameson","08/31/2017","$280,000.00","Li-Tien Cheng","bli@math.ucsd.edu","9500 GILMAN DRIVE","LA JOLLA","CA","920930021","8585344896","MPS","1114, 1271, 7454","8007, 9263","$0.00","This project develops hybrid computational models and robust numerical methods for electrostatic interactions in biomolecular systems. The computational models are constructed at different levels. They include variational mean-field models with atomistic details, particularly ionic size effects, and Monte Carlo simulation models for treating individual ions. These models are coupled with an advanced, variational approach to the solvation of biomolecules.  A robust numerical method for solving the related elliptic interface problem and calculating the dielectric boundary force is designed and analyzed. Special interface algebraic multigrid methods and the GPU (Graphics Processing Unit) implementation are developed to accelerate the related large-scale computations. Numerical analysis focuses on the accuracy of the proposed schemes, particularly that of the boundary force approximation.<br/><br/>Biomolecules such as proteins and DNA are assemblies of atoms of which a significant portion are charged. Charged biomolecules polarize the solvent (water or salted water) and produce ions that are mobile charged particles in the solution.  The electrostatic or charge-charge interaction gives rise to strong forces that determine the structure, dynamics, and function of underlying biological systems. For instance, the electrostatic interaction affects how a drug molecule binds to a target molecule, which in turn determines how effective the drug is in the process of curing a disease. Through the development of modern mathematical theories and computational tools, this project aims at understanding the fundamental principles of biological systems at the molecular level and advancing the research of computational mathematics. The success of this project can potentially help reduce the high cost often needed for experiments and speed up the process of drug discovery. In addition, this highly interdisciplinary research brings opportunities for students at different levels to receive training at the interface of computational mathematics and molecular biological science. Such training is critical to keeping our strength in scientific research in an competitive international environment."
"1318480","Methods and Applications for Optimization with Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","07/15/2013","07/02/2013","Philip Gill","CA","University of California-San Diego","Standard Grant","Leland Jameson","06/30/2018","$370,000.00","Randolph Bank, Michael Holst","pgill@ucsd.edu","9500 GILMAN DRIVE","LA JOLLA","CA","920930021","8585344896","MPS","1271","9263","$0.00","The  demand for  advanced  optimization software  tools is  increasing sharply as the importance  of optimization methodology in engineering, basic  science,  finance and  data  science  is becoming  more  widely recognized.  The  dramatic  increase   in  computing  power,  and  the improvements in supporting technologies such as modeling languages and automatic   differentiation  are   fueling  demand   for  optimization algorithms  that  solve  more  and  more  computationally  challenging problems, including nonlinear  optimization problems with differential equation constraints and/or discrete  variables.  This project focuses on several  fundamental computational issues involved  in the parallel implicit solution of optimization  problems with differential equation constraints.  Such problems arise in  many contexts in engineering and scientific  computation, since  physical  reality  is often  expressed through models involving ordinary  and partial differential equations. Accurate discretizations of differential  equation constraints lead to very large structured constrained optimization problems, where much of the  structure reflects  the discretization.  A specific  goal is  the development   of   modern   algorithms   that   are   well-suited   to implementation  on advanced  computing platforms  (such as  those with multicore and GPU  architectures), interoperable with high-performance software  in  related areas  (such  as  linear algebra),  and  readily customizable for  particular important applications.  A  major part of the project involves the development of software and its dissemination within  the  manufacturing,   engineering  and  scientific  community. Software developed  as part of  the project will provide  an effective method  of  technology   transfer  and  will  extend   the  scope  and effectiveness of the  existing codes PLTMG, MC and  SNOPT developed by the investigators.  <br/><br/>Differential equations conveniently characterize  the physical laws of many complex systems  occurring in science and  engineering. They also lie  at the  heart of  the mathematical  models used  to simulate  and predict  the behavior  of these  systems.   The need  to optimize  the performance  of  such  systems  is the  common  feature  of  practical applications that range over such diverse areas as the design of large neurobiological   network   models,    the   numerical   modeling   of gravitational  waves,  and  trajectory  planning  for  spacecraft  and unmanned  autonomous vehicles  (UAVs).  Software  developed under  the auspices of  this project will  provide engineers and  scientists with instant  access  to  state-of-the-art  methods for  the  modeling  and optimization  of  complex   systems  involving  differential  equation constraints.  The  resulting improvements in the  efficiency, accuracy and robustness of these models will have a substantial impact in areas of  manufacturing  and  engineering  that   are  vital  to  US  global competitiveness."
"1318975","A novel boundary integral formulation for dynamic implicit interfaces","DMS","COMPUTATIONAL MATHEMATICS","09/01/2013","09/11/2013","Yen-Hsi Tsai","TX","University of Texas at Austin","Standard Grant","Leland Jameson","08/31/2017","$209,945.00","","ytsai@math.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271","9263","$0.00","This project involves a novel formulation for constructing boundary integral methods to solve boundary value problems involving linear partial differential equations on domains with oriented, piecewise smooth boundaries defined implicitly by the corresponding signed distance functions. The proposed framework will facilitate computations in a wide class of computational problems that involve, e.g., the solutions of Poisson's equation or Helmholtz equation defined on time dependent domains with irregular boundaries. Such computational problems are found in multiphase viscous fluid flows, inverse scattering, shape optimization problems, and gradient flows of surface energies modeling e.g. solidification process of a fluid. The aim of our new formulation is to lift the overhead of remeshing that is needed in finite element methods, and to avoid delicate and possibly complicated formulas found in finite difference based methods that depend on how surfaces ""cut"" through the underlying grids. The formulation is based on averaging a one parameter family of parameterizations of an integral equation defined on the boundary of the domain. By application of the coarea formula, a novel boundary integral equation without any explicit parameterization of the boundaries is derived. The resulting numerical algorithm is simple and is applicable to a variety of meshing or grids. The proposed research program consists of a systematic study of such new type of boundary integral formulation, encompassing (a) numerical integration methods (quadratures) for singular integrals, (b) analytical and numerical treatment of corners and higher co-dimensional manifolds, (c) applications to nonlinear interface dynamics and shape optimizations.  <br/><br/>The proposed research will contribute directly to a crucial mathematical and computational part of many important applications in science and engineering, from multiphase fluids, seismic imaging in petroleum engineering, inverse scattering in wave propagation, high order nonlinear interface evolution found in the study of solidification of fluids, to bio-mechanical applications. The training of students and post-doctoral researchers provided by the proposed research program will allow them to conduct research in highly inter-disciplinary projects and bring state-of-the-art numerical analysis and computational algorithms to the related areas."
"1321018","Computational Algorithms for Imaging, Design and Inverse Problems of Particle Propagation in Heterogeneous Media","DMS","COMPUTATIONAL MATHEMATICS","07/15/2013","07/08/2013","Kui Ren","TX","University of Texas at Austin","Standard Grant","Leland Jameson","06/30/2017","$259,565.00","","kr2002@columbia.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271","9263","$0.00","This project is concerned with the computational study of some imaging, optimal design and inverse problems related to systems of kinetic equations that model the propagation of particles in complex heterogeneous media. The objective is to develop fast and robust numerical algorithms by intelligently utilizing information on the structures of both the model equations and the inverse problems that we obtained through computational and mathematical studies of them, sometimes in simplified settings. Precisely, the proposed research include (i) to develop fast forward and inversion algorithms by preconditioning the computation with computationally less expensive models; (ii) to develop efficient computational strategies for uncertainty quantification and variance reduction in the imaging and inverse problems involve randomness; and (iii) to develop and validate direct non-iterative methods for imaging in extended targets in heterogeneous media. <br/><br/>The main motivation for the study is the application of the problems in (i) optimizing the delivery of radiation therapy to caner patients; (ii) designing efficient nano-scale semiconductor devices; and (iii) imaging extended targets in highly-scattering random environments. The proposed research is expected to have long-term impacts in the practices of intensity-modulated radiation treatment planning for cancer treatment, semiconductor solar cell design for energy harvesting, and imaging in heterogeneous environment for homeland security applications. The project involves a significant education component that aims at training both undergraduate and graduate students. The ideas and techniques developed in this project will be incorporated into a graduate level class on numerical methods for imaging and inverse problems which will benefit graduates who are interested in applying advanced mathematical and computational techniques to solve real-world problems. The lecture notes for this graduate class will be made accessible to the general public through the PI's webpage hosted by the PI's institution."
"1319078","Numerical Study of Electrokinetic Bioparticle Transport Through Fluid-Structure-Electric Interaction","DMS","COMPUTATIONAL MATHEMATICS","09/01/2013","09/03/2013","Yan Peng","VA","Old Dominion University Research Foundation","Standard Grant","Leland Jameson","08/31/2018","$213,901.00","Jin Wang","ypeng@odu.edu","4111 MONARCH WAY","NORFOLK","VA","235082561","7576834293","MPS","1271","9263","$0.00","This proposal aims to develop a new computational framework to simulate electrokinetic bioparticle transport in microfluidics devices involving complex fluid-structure-electric interactions. Due to the complicated nature of multi-physics and multi-scale phenomena, several important numerical issues have to be addressed: (1) Numerical stiffness and convergence challenges due to the strong fluid-structure interactions; (2) Resolution of unsteady phenomena such as wakes, separation and vortices induced by interactions of flows with deformable moving boundaries; (3) Convergence and accuracy challenges imposed by the strong electric-structure interactions. The investigator and her team propose to use the lattice Boltzmann equation (LBE) for the fluid motion because of its accuracy (low dissipation/low dispersion and better isotropy) and computational advantages including its excellent parallel scalability, absence of the need to solve a time consuming elliptic Poisson-type equation for the pressure field, and ease of representation of complex boundaries on Cartesian grids. The immersed boundary method (IBM) is chosen to track the deformable moving boundaries for its ease of implementation without re-meshing to generate the body-fitted mesh. Relaxation and multigrid methods are used to solve the electric field represented by Laplace equation. A central theme of this proposal is to advance the capability of LBE, IBM and multigrid techniques through a more rigorous mathematical formulation of these methods combined with their numerical analysis, as well as through the application of existing numerical algorithms in conjunction with the development of novel efficient numerical techniques.<br/><br/>One of the main motivations for this study comes from the Lab-on-a-chip (LoC) application, important for bio-medical, pharmaceutical, and environmental industries. Well-controlled manipulations of bio-particle transport are the basis of the working principle of LoC. For instance, electrical cell separation by deformability in a microfluidic reservoir can be demonstrated using the proposed numerical framework, which will benefit inexpensive point-of-care diagnostics of pathogens that affect the biomechanical properties of human cells such as parasite-infected red blood cells in malaria. The project will complement and advance the current knowledge of particle electrokinetics in microfluidic devices, and build the fluid mechanics foundation for the design and electric control of future bioparticle manipulation microdevices. In addition, this proposed research will be intimately integrated with undergraduate and graduate education programs."
"1328230","CAREER: Fast Algorithms for Oscillatory Integrals","DMS","COMPUTATIONAL MATHEMATICS","01/01/2013","02/21/2013","Lexing Ying","CA","Stanford University","Standard Grant","Junping Wang","08/31/2015","$216,550.00","","lexing@math.stanford.edu","450 JANE STANFORD WAY","STANFORD","CA","943052004","6507232300","MPS","1271","0000, 1045, 9263, OTHR","$0.00","Many challenging computational problems related to high frequency wave phenomena can be formulated mathematically as integral equations and transforms with oscillatory kernels. The PI proposes to leverage the ideas of multidirectionality and butterfly computation to develop fast and accurate algorithms for oscillatory integral equations and transforms, with targeted applications in acoustic and electromagnetic scattering, numerical wave propagation, and reflection seismology. The proposed research activities include: (1) fast and parallel algorithms for the $N$-body problems and the boundary integral equations of high frequency acoustic and electromagnetic scattering, (2) an optimal complexity algorithm for computing Fourier integral operators with applications in high frequency wave propagation and seismic migration, (3) an optimal complexity algorithm for sparse Fourier transform where the spatial and Fourier samples are supported only on a low dimensional manifold, and (4) an optimal complexity algorithm for partial Fourier transform where the frequency summation is restricted to a spatial dependent domain. The education part of includes the following components (1) mentoring students and postdocs through participating the proposed research activities, (2) curriculum development through developing a new course that focuses on the fast algorithms in multiscale and multidirectional computation and publishing survey papers on these topics, and (3) organizing summer schools and lecture series that aim to present students with recent developments in computational mathematics.<br/><br/>Through developing robust and accurate numerical algorithms with optimal complexity, this research will significantly improve our ability of understanding large scale physical problems of oscillatory nature. The algorithms to be developed in the proposed research activities will have direct applications in acoustic and electromagnetic scattering, reflection seismology, and medical imaging. The PI will also work closely with researchers from industrial and government laboratories to disseminate ideas and deliver operational softwares for realistic challenging applications. The development of a new generation of numerical algorithms and softwares requires researchers to understand different aspects of computational mathematics. The research and educational components will integrate together to (1) help train a new generation of researchers who master algorithmic design, mathematical analysis, and software development, and (2) promote the awareness and interests in computational mathematics among undergraduates and underrepresented groups (female and minority students).<br/>"
"1320158","Collaborative Research: Optimal Monte Carlo Estimation via Randomized Multilevel Methods","DMS","COMPUTATIONAL MATHEMATICS","08/01/2013","08/03/2015","Peter Glynn","CA","Stanford University","Continuing Grant","Leland Jameson","07/31/2017","$209,999.00","","glynn@stanford.edu","450 JANE STANFORD WAY","STANFORD","CA","943052004","6507232300","MPS","1271","9263","$0.00","This research project will investigate a comprehensive set of tools to enable efficient and unbiased Monte Carlo methods in a wide range of settings such as: steady-state computations and stochastic differential equations (SDEs). The PIs extend the applicability and power of a recently introduced technique called multilevel Monte Carlo (MLMC), which has rapidly grown in popularity and has shown to be highly successful, particularly in the context of numerical solutions to SDEs. The PIs strategy rests on two basic ingredients. First, they abstract the main ideas of MLMC. This abstraction makes it clear that MLMC can be applied to many problem settings (beyond the SDE context), for example in problems such as: estimating steady-state expectations of Markov random fields, and solving distributional fixed point equations. Second, the PIs introduce a simple, yet powerful, extra randomization step. This randomization step will permit to not only completely delete the bias, which so far is present in every single application of the multilevel method, but it will also permit to more easily optimize parameters (often user-defined) that arise in classical multilevel applications. At the core of our abstraction of the MLMC method lies the construction of a suitable sequence of strong (almost sure) approximations under some metric. The freedom that is implicit in constructing such approximations yields a rich research program that touches upon many of the elements of modern probability, including random matrices, Markov random fields, mean field fixed point equations and Lyapunov stability.<br/>    <br/>    The PIs will investigate a methodology that enables high-performance computing in the context of simulation of stochastic systems. The PIs methodology will substantially extend a recently developed approach, called Multilevel Monte Carlo (MLMC), which has typically been applied only to compute numerical solutions of stochastic differential equations (SDEs). More generally, this research project addresses a wide range of problems that lie at the center of modern scientific computing, beyond the important setting of SDEs which arise in virtually all areas of modeling in engineering and science. For example, the PIs will generalize the MLMC approach to accurately perform so-called steady-state simulation for Markov chains indexed by trees. These computational problems arise very often in statistical inference applications, ranging from imaging to classification problems. The PIs research also improves upon the classical MLMC technique by optimizing its design and allowing the study of, for example, steady-state analysis of SDEs (i.e. combining traditional areas of study with new methodological applications). The PIs will in particular apply these optimized computational techniques to solve problems in service and manufacturing engineering. The PIs plan to develop a new jointly designed course, on the topic of this proposal, and the course material will be made available online to increase the dissemination and the potential applicability of the project's findings. The PIs will attempt to recruit high-quality personnel from under-represented groups and will disseminate the scientific output of the research via open access sites, in addition to the standard vehicles such as conferences and journal publications."
"1301611","2013 International Conference on Mathematical Modeling and Computation","DMS","COMPUTATIONAL MATHEMATICS","02/15/2013","02/04/2013","Xiu Ye","AR","University of Arkansas Little Rock","Standard Grant","Leland Jameson","06/30/2014","$22,000.00","","xxye@ualr.edu","2801 S UNIVERSITY AVE","LITTLE ROCK","AR","722041000","5015698474","MPS","1271","7556, 9150, 9263","$0.00","The 2013 International Conference on Mathematical Modeling and Computation will be held on May 16-19, 2013 at Wuhan University, China.   The conference will serve as a platform to showcase recent advances in computational mathematics and mathematical modeling, to provide a forum for exchanging ideas and disseminating results in computational/applied mathematics, to foster the interaction and collaboration between mathematicians and scientists from other disciplines,   to introduce computational/applied mathematics to graduate students, postdocs and junior faculty members, and to enhance the participation of women, underrepresented minorities and persons with disabilities in computational/applied mathematics.  <br/><br/>Recently, applied and computational mathematics has emerged as a major driving force for interdisciplinary researches. Currently, the boundaries between traditional disciplines, such as mathematics, physics, chemistry, biology and engineering are evolving, redefining and coalescing. New challenges in science and engineering require collaborative and synergic efforts from mathematical, physical, and engineering scientists. Meanwhile, the applied and computational mathematics has preserved and enhanced its core value that defines the community. This conference will cover a wide range of topics in computational mathematics and mathematical modeling. The main themes of the conference include, but are not limited to numerical methods for scientific computing, optimization, and high performance computing, modeling and computation of condense matter materials, soft matter and complex fluids, modeling and computation of nano-fluidic systems and nano-electronic devices, modeling and computation of complex systems in biological and biomedical sciences, and multiscale and stochastic methods for science and engineering. Special efforts will be made to ensure a broad participation by students, junior researchers, college faculties, especially, women, under-represented minorities and persons with disabilities.  The results of the conference, including abstracts, presentations, and preprints, will be published online at http://math.msu.edu/?wei/ICMMC/index.html."
"1318898","Matched alternating direction implicit (ADI) schemes for solving the nonlinear Poisson-Boltzmann equation with complex dielectric interfaces","DMS","COMPUTATIONAL MATHEMATICS","09/15/2013","09/18/2013","Shan Zhao","AL","University of Alabama Tuscaloosa","Standard Grant","Leland Jameson","08/31/2017","$250,000.00","Weihua Geng","szhao@ua.edu","301 ROSE ADMIN BLDG","TUSCALOOSA","AL","354870001","2053485152","MPS","1271","9150, 9263","$0.00","The goal of the proposed project is to develop second order interface methods embedded in the alternating direction implicit (ADI) framework for solving the 3D nonlinear Poisson-Boltzmann (PB) equation with complex dielectric interfaces. Efficiency and accuracy are known to be the two major difficulties for solving the nonlinear PB equation numerically. The efficiency concern stems from the needs for solving the PB equation in demanding applications, such as one-time solution to systems with large spatial degrees of freedom, and/or million-time solutions in dynamical simulations. The accuracy concern is due to various challenging features of the PB model, including piecewisely-defined dielectric constants, a strong nonlinearity, singular point charges, and complex dielectric interfaces. Without addressing these features, fine meshes have to be used for a reliable simulation, which in turn impairs efficiency. In this project, a new pseudo-transient continuation formulation will be constructed based on a suitable regularization setting so that the singular charges are represented analytically. The nonlinear term of the PB equation will be integrated exactly with time splitting techniques. To deal with piecewise dielectric constants, a tensor product decomposition of 3D interface conditions will be carried out to derive essentially 1D jump conditions so that the dielectric interface can be accommodated along each Cartesian direction in an alternating manner. Fast algebraic solvers will be developed for solving matrices of each Cartesian direction. Consequently, the proposed matched ADI approaches not only maintain both the simplicity of Cartesian grids and the efficiency of the Thomas algorithm, but also achieve spatially second order accuracy in resolving complex dielectric interfaces.<br/><br/>The electrostatic interactions are vital not only for the study of biological and chemical systems and processes at the molecular level, but also for the design of semiconductor devices at the nanoscale. The PB model, in which the electrostatic interactions are computed implicitly via a mean force approach, can surprisingly well describe the electrostatics of a charged system. This model finds broad applications in science and engineering, such as modeling the charged polymers and surfactants in interface and colloid science, studying transistors on very large scale integration (VLSI) semiconductor devices in nanotechnology, and analyzing structure, function, and dynamics of solvated biomolecules including proteins and DNAs in molecular biology. The proposed mathematical modeling, algorithm development, and numerical computations will address key scientific challenges in interdisciplinary fields involving computational mathematics, chemistry, biology, and electrical engineering. The planned research activities will bring new advances to computational mathematics and lead to reliable simulation tools for the electrostatic analysis of various physical, chemical, and biological systems/devices. In addition, this project will provide interdisciplinary research and training opportunities for students pursing careers in science and engineering."
"1320655","Structured Dictionary Models and Learning for High Resolution Images","DMS","COMPUTATIONAL MATHEMATICS","08/01/2013","07/15/2013","Mauro Maggioni","NC","Duke University","Standard Grant","Rosemary Renaut","02/28/2017","$240,001.00","Elizabeth Honig, Eric Monson, Ingrid Daubechies","mauro.maggioni@jhu.edu","2200 W MAIN ST","DURHAM","NC","277054640","9196843030","MPS","1271","9263","$0.00","We will develop novel techniques for the multi-resolution analysis of high-resolution images, to obtain novel efficient and information representations. These representations will take into account natural invariances in images, and will lead to novel dictionary learning constructions and algorithms for images and in signal processing in general. These representations will then be used to analyze, search, and recognize similar objects or features in collections of (scans of) paintings, in particular a large collection by the baroque artist Jan Brueghel. The distances between images and portions thereof, the features learned by the extensions of dictionary learning we will construct, and the associated statistical similarities, together with labels provided by experts to be used to train classifiers and algorithms that learn similarities among items to match those provided by expert, will enable us to enrich the current set of capabilities in building these large networks of paintings, to search through them more easily and with more general search patterns, and to visualize them according to different metrics by using dimensionality reduction techniques.<br/><br/>The automatic learning of templates and patterns, and their statistical relationships, in images and signals in general is crucial in a wide variety of applications, such as automating object recognition, and in defining visually meaningful similarities between images, needed to enable searches in large image databases. We will both develop novel techniques for automatically learning good templates for images, that incorporate natural invariances such as translations and scalings, and novel ways of exploiting these templates for analyzing large collections images, measuring the similarities  between then, and finding and characterizing recurrent patterns in them. These novel techniques will be applied to the data on the Jan Brueghel Research site, that allows scholars to investigate and conceptualize a very different notion of old master pictures. Instead of creating absolute categories of genuine and not-genuine, the team will be drawing a map of interconnections between the thousands of paintings produced in the workshops of early modern Antwerp. These pictures were made over several generations, in the shops of masters ranging from world-famous (Pieter Brueghel, Rubens) to utterly obscure. The website will chart how ideas were generated, exchanged, reused and retooled by different artists, mapping networks of creation and production well beyond those traceable through archival documents."
"1318486","Novel Discontinuous Galerkin Finite Element Methods for Second Order Fully Nonlinear Equations and High Frequency Wave Equations","DMS","COMPUTATIONAL MATHEMATICS","08/15/2013","07/29/2013","Xiaobing Feng","TN","University of Tennessee Knoxville","Standard Grant","Leland Jameson","07/31/2017","$260,000.00","","xfeng@utk.edu","201 ANDY HOLT TOWER","KNOXVILLE","TN","379960001","8659743466","MPS","1271","9150, 9263","$0.00","The PI proposes to carry out a comprehensive study for two of most difficult numerical partial differential equation (PDE) problems using discontinuous Galerkin (DG) methods. The first main goal of the award is to develop convergent direct DG discretization methods for approximating viscosity solutions of general second order fully nonlinear PDEs, which builds upon the PI's previous successful research on developing indirect numerical methods for these PDEs. The objectives of this part of the research project are: (i) to extend the direct nonstandard DG methods to high-dimensional Monge-Ampere and Bellman equations; (ii) to establish a general convergent theory for the proposed DG methods; (iii) to develop efficient non-Newtonian nonlinear solvers for solving the resulting nonlinear systems; (iv) to apply the resulting DG methods to fully nonlinear PDE application problems including the optimal mass transport problem, the semigeostrophic flow problem, and stochastic optimal control problems; (v) to further develop the DG finite element differential calculus theory resulted from the proposed research project. The second main goal of the award is to develop absolutely stable, solver-friendly, and coercivity-preserving DG discretization methods and two-level Schwarz fast solvers for high frequency acoustic, elastic and electromagnetic wave equations. To resolve highly oscillatory waves, sufficiently fine mesh must be used, which in turn results in huge algebraic systems to solve. It is the sheer amount of computations coupled with the strong indefiniteness and the extremely ill-conditioned nature of high frequency wave problems that makes them intractable even on today's high performance computers if the brute force approach is adopted. The ultimate solution to overcome the challenge must be sought at the algorithmic level. The objectives of this part of the research project are: (i) to design, analyze and implement novel absolutely stable, solver-friendly, and coercivity-preserving DG discretization methods for the three types of high frequency wave equations; (ii) to develop, analyze and test novel parallelizable two-level Schwarz solution methods for solving the resulting large algebraic systems.<br/><br/>The completion of the proposed research will have a significant theoretical and practical impact on the emerging field of numerical fully nonlinear PDEs and the thriving field of high frequency wave computation. The anticipated new enabling numerical capabilities can be used to solve various fully nonlinear PDE problems and wave scattering problems arising from differential geometry, antenna design, astrophysics, geophysical fluid dynamics, image processing, optimal control and optimal mass transport, petroleum engineering, geoscience, medical science, defense and telecommunication as well as financial industries. The education component of this research project is train graduate students in developing necessary applied and computational mathematics knowledge and skills so that they can pursue a successful career in either academia or industry in the near future."
"1262735","Graduate Student Support for the 2013 Gene Golub SIAM Summer School in China","DMS","COMPUTATIONAL MATHEMATICS","05/15/2013","05/13/2013","Zhaojun Bai","CA","University of California-Davis","Standard Grant","Junping Wang","04/30/2014","$30,000.00","Michele Benzi","bai@cs.ucdavis.edu","1850 RESEARCH PARK DR, STE 300","DAVIS","CA","956186153","5307547700","MPS","1271","7556, 9263","$0.00","This award provides support for US-based Ph.D. student participation in the Gene Golub SIAM Summer School, which will coincide with the International Summer School on Numerical Linear Algebra (ISSNLA) on July 22 - August 2, 2013 at Fudan University in Shanghai, China. The conference encourages and financially supports participation by members of groups underrepresented in mathematics. <br/><br/>The meeting includes invited lectures on topics of current research interest in computatonal mathematics. The conference brings together workers in a variety of different areas of research in numerical linear algebra, with emphasis on preparing Ph.D. students for useful and engaging research careers. Allocation of the funds will be based on scientific merit, financial need, and diversity, with an emphasis on participation by members of underrepresented groups.<br/><br/>Conference web site: http://g2s3.cs.ucdavis.edu"
"1319110","Robust Multilevel Preconditioning Techniques for Elliptic PDE with Variable Coefficients","DMS","COMPUTATIONAL MATHEMATICS","09/01/2013","08/29/2013","Yunrong Zhu","ID","Idaho State University","Standard Grant","Leland Jameson","08/31/2017","$85,646.00","","zhuyunr@isu.edu","921 S 8TH AVE","POCATELLO","ID","832015377","2082822592","MPS","1271","9150, 9263","$0.00","The proposed research is to design robust preconditioners for solving the finite element discretization of second order elliptic PDEs with variable coefficients and then apply these preconditioners in developing efficient iterative solvers for Maxwell's equations and H(div) equations. The PI shall develop, analyze and implement nearly optimal iterative solvers for elliptic PDE with variable coefficients, especially multiscale elliptic PDEs. Based on several successful preliminary investigations, the PI will design robust multilevel preconditioners for various types of finite element discretization, such as conforming, nonconforming,  discontinuous Galerkin discretization and mixed formulation of second order elliptic PDEs with general variable coefficients on both structured and unstructured bisection grids. The approach will be based on the auxiliary space preconditioning framework. This technique will be proved to be robust with respect to both the variations in the coefficients and the grid size for solving general multiscale elliptic PDEs. The research will allow one to choose different coarse grid problems other than the standard variational coarse grid problems in the preconditioners. Upon obtaining robust preconditioners for various finite element discretizations, the PI will then use these preconditioners to develop robust iterative solvers for Maxwell's equations and H(div) equations with variable coefficients using the auxiliary space preconditioning techniques. The algorithms will be implemented as open source software packages which will be used in collaborations with domain-specific scientists. <br/><br/>This project has broad impact in education and other areas of mathematics, engineering, and physics through software development. The methods to be developed will contribute to the advancement of numerical methods for both linear and nonlinear systems. The research results will provide powerful tools for the exploration of important models such as reservoir simulations and electromagnetic computation. The project enriches the graduate program in the Department of Mathematics at ISU, especially in the area of partial differential equations and numerical analysis. The research shall involve undergraduate and graduate students, and excellent mentoring shall be provided by the PI."
"1308241","Computational Methods and Function Theory Conference, 2013","DMS","COMPUTATIONAL MATHEMATICS, ANALYSIS PROGRAM","03/01/2013","02/19/2013","Edward Saff","TN","Vanderbilt University","Standard Grant","Bruce P. Palka","02/28/2015","$18,500.00","","edward.b.saff@vanderbilt.edu","110 21ST AVE S","NASHVILLE","TN","372032416","6153222631","MPS","1271, 1281","7556, 9150","$0.00","The award provides funding to help defray the expenses of U.S. participants in the ""Computational Methods and Function Theory Conference, 2013"" that will be held June 10-14, 2013, at Shantou University in Shantou, Guangdong, China.<br/><br/>This event, which is the seventh in a series of quadrennial international meetings devoted to the theme of interactions between complex analysis and scientific computing, will host a formal delegation of thirteen individuals from the U.S.  The delegation will comprise ten junior mathematicians (i.e., recent Ph.D.'s and graduate students) and three plenary speakers (Olga Holtz, Don Marshall, Joel Shapiro). Function theory, as one of the fundamental disciplines of mathematics, has widespread applications in many areas of the sciences and technology. Its methodology, for example, is a fundamental tool in developing computer algorithms for problems in systems theory and control. Conversely, some of the basic research problems in function theory have recently become more manageable through the use of the vast power modern computers provide. Thus there is a synergistic relationship between function theory and computational methods that greatly benefits both areas and that this conference will serve to highlight. The conference program provides ample opportunity for graduate students, postdocs, and other young scientists to present their work."
"1315259","Algorithms and modeling for nonlocal models of diffusion and mechanics and for plasmas","DMS","COMPUTATIONAL MATHEMATICS","07/15/2013","07/24/2015","Max Gunzburger","FL","Florida State University","Continuing Grant","Leland Jameson","06/30/2017","$360,000.00","","gunzburg@fsu.edu","874 TRADITIONS WAY","TALLAHASSEE","FL","323060001","8506445260","MPS","1271","9263","$0.00","The project involves the modeling, analysis, algorithmic invention, and numerical analysis of novel models for three physical systems, namely diffusion, solid mechanics, and plasmas. In the first system, the PI considers a nonlocal, integral model for non-Fickian (or anomalous) diffusion. The model has as  special cases fractional Laplacian and fractional derivative models but generalizes these models in several ways such as allowing for spatial heterogeneity and anisotropy, less smooth solution behavior, and a simple means for treating problems posed on bounded domains. The project addresses several issues that are crucial to the efficient, robust, and accurate approximation of the nonlocal diffusion model. In particular, the effects of truncating kernels and data so that computations can be done on finite domains are analyzed, combined finite element/domain and data truncation error estimates are obtained, and a goal oriented, adjoint equation-based grid adaptation methodology is developed, analyzed, and tested. In the second system, the PI considers the nonlocal, spatial derivative free peridynamics model for solid mechanics. The model allows for discontinuous solutions so it is especially well suited for modeling defects. As such, its efficacy has been demonstrated in several sophisticated applications, including the fracture and failure of composites, crack instability, fracture of polycrystals, and nanofiber networks. The project involves the development of a computational methodology that takes full advantage of the multiscale properties inherent in peridynamics and which results from the phenomenological horizon parameter that limits the extent of interactions. In the third system, both the Vlasov-Poisson and cold-ion systems for modeling the expansion of ions from high to low-density regions are considered. The project includes the development of a new cold-ion model that remains valid beyond the time of singularity creation, showing that solutions of the new model remain the limit (as the ion temperature tends to zero) of solutions of the Vlasov-Poisson system, studying analytically and computationally the transition that occurs as the density ratio decreases from solutions having no singularities to ones that do, treating problems with multiple species of ions, and developing efficient numerical methods for two and three-dimensional settings.<br/><br/>The project addresses fundamental issues that arise in the mathematical and computational treatment of three physical systems that are of huge importance in a wide variety of applications. These include but are not limited to the nucleation and propagation of defects, (cracks, delaminations, etc.) in solid bodies (airplane wings, nuclear reactor containment vessels, etc.); anomalous diffusive behavior observed in subsurface water, oil, and gas flows, in animal foraging behaviors, in polymeric flows, in exotic materials, etc.; and in ionized flows in lasers, space propulsion systems, supernovae, etc. Obtaining useful information about such complex systems requires massive computational efforts which can be greatly aided by improvements in mathematical models, qualitative theoretical information about solutions of those models, and, most of all, by better, more efficient and more accurate computational algorithms. Because of the wide-ranging settings that the project impacts, the results obtained will be of great interest to scientists, engineers, and policy makers involved in, among other things, the theoretical study of physical phenomena, in the design and manufacture of new devices, and in the assessment of risks and design of remediations."
"1318108","Topics in the analysis of finite elements","DMS","COMPUTATIONAL MATHEMATICS","07/01/2013","07/14/2015","Johnny Guzman","RI","Brown University","Continuing Grant","Leland Jameson","06/30/2017","$210,000.00","","Johnny_Guzman@brown.edu","1 PROSPECT ST","PROVIDENCE","RI","029129127","4018632777","MPS","1271","9263","$0.00","Three distinct projects that study the behavior of finite element methods (FEM) will be considered. The  first project is studying the pollution effects of immersed boundaries in the immersed boundary finite  element method. A sharp error analysis will be given that measures how far one has to be from the  immersed boundary to obtain optimal convergence. The second project will involve adaptive  Discontinuous Galerkin (DG) methods. Contraction properties of weakly penalized DG methods will be  proved. The final project is max-norm stability analysis of inf-sup stable finite element methods for the  Stokes problem. A Fortin projection that is exponentially decaying will be constructed for the lowest-order  Taylor-Hood element in three dimensions. Exponentially decaying projections will be an important tool to  prove max-norm stability estimates.    <br/><br/>FEM are widely used to simulate a variety of problems in engineering and science. Users of these  methods rely on theoretical results that give them some guarantee of their reliability. The P.I. will use  mathematical analysis to describe the behavior of FEM for three important FE methods. In particular, the  P.I. will mathematically study the behavior of the immeresed boundary FEM which is a method especially  suited for fluid-solid interactions. For example, these methods have been used to simulate blood flow and  animal locomotion, to name a few. The results of this investigation will give users theoretical guidance on  where to put more computational effort which in turn will make their simulations more accurate for  imporant applications."
"1318348","High Order in Time and Space Numerical Methods for Solving the Miscible Displacement Problem","DMS","COMPUTATIONAL MATHEMATICS","07/01/2013","06/24/2015","Beatrice Riviere","TX","William Marsh Rice University","Continuing Grant","Leland Jameson","06/30/2017","$229,830.00","","Beatrice.Riviere@rice.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","MPS","1271","9263","$0.00","High order numerical methods in time and space are proposed to solve the incompressible miscible displacement problem in heterogeneous porous media. A mixture of solvent and resident fluids moves as a single phase with a velocity that follows Darcy's law. The solvent concentration satisfies a convection-dominated parabolic problem, with a diffusion-dispersion matrix that depends on the fluid velocity in a non-linear fashion.  The fluid pressure equation is coupled with the concentration equation.  Under certain conditions, the miscible displacement becomes physically unstable and the phenomenon of viscous fingering occurs.  Accurate prediction of the number and location of the viscous fingers is important in the development of a numerical model. Additional numerical challenges include the nonlinear coupling between the pressure and concentration equations, and the unboundedness of the diffusion-dispersion matrix.  The investigator and her team propose to use a discontinuous Galerkin method for the time integration.  For the spatial discretizations, locally mass conservative methods such as mixed finite element methods and interior penalty discontinuous Galerkin methods are utilized. Several algorithms, based on solving the pressure and concentration equations consecutively,  are formulated. Their cost and accuracy are compared. Convergence of the numerical solution is obtained under low  regularity assumptions on the data and exact solution using a new  generalization of the Aubin-Lions compactness theorem. The effects of randomness in the permeability  of the porous media are taken into account by sampling the coefficients and combining the Monte Carlo technique with temporal and spatial discretizations.  The algorithms developed in this project are also used to predict the onset and growth of viscous fingers.  Two factors contributing to fingering are investigated: the increase of the ratio of the displaced fluid viscosity to the solvent fluid viscosity, and the variation of longitudinal and transverse dispersions.<br/><br/>The miscible displacement problem occurs in several applications, including environment and energy.  For instance, a large amount of the oil reserve  in the U.S. is deemed unrecoverable by current technology. Enhanced Oil Recovery (EOR), by changing the properties of the reservoir and the hydrocarbons,  will help produce some of this trapped oil. Miscible displacement is one important technique used in EOR.  The main goal of this project is to provide accurate and robust numerical solutions to the miscible displacement problem for incompressible fluids.  In  EOR, this numerical approximation can be used to efficiently harvest the remaining trapped oil. This project advances discovery and understanding while promoting learning through the  training of at least one Ph.D. student and two undergraduate students. In addition, the principal investigator organizes a Summer program in which participating   high school students  learn about computational mathematics and its applications to complex flow and transport in porous media."
"1317684","Multiscale Approaches for the Dynamics and Rheology of Magnetic Fluids","DMS","COMPUTATIONAL MATHEMATICS","07/01/2013","06/19/2013","Hector Ceniceros","CA","University of California-Santa Barbara","Standard Grant","Leland Jameson","06/30/2017","$405,151.00","","hdc@math.ucsb.edu","3227 CHEADLE HALL","SANTA BARBARA","CA","931060001","8058934188","MPS","1271","9263","$0.00","The Principal Investigator proposes to carry out an integrated, comprehensive research program which combines theory and innovative numerical methods with state of the art experimental work for the investigation of two-phase systems with a magnetic fluid component.   This project  aims at developing  effective, predictive computational tools as well as to advancing the understanding  of these two-phase, complex (non-Newtonian) flows. While magnetic fluids are technologically important  on their own they also constitute an excellent model system (due to their low  dimensional configuration space)  for scientific study of  complex fluids as well as for active suspensions. Consequently, the proposed research can have a wider impact in the multiscale modeling and computation of more general two-phase flows with a complex fluid component.  The specific objectives of the proposed work can be summarized as follows: 1) to develop innovative, effective micro-macro numerical approaches for magnetic fluids and two phase flows with a magnetic fluid component in 2D and 3D and to apply them for the prediction and investigation of the dynamics and rheology of these complex fluid systems,  2)  to use specifically targeted experimental work to validate the new computational approaches as well as to provide a feedback mechanism to the theory,  3)  to formulate simplified models based on the an increased understanding of the rheology of magnetic fluid systems obtained by a combination of numerical and experimental work,  and 4) to advance a fundamental understanding of the microphysical mechanisms that influence the (macro)rheology of magnetic fluid droplets and emulsions under the presence of a magnetic field.<br/><br/>Magnetic fluids, also known as ferrofluids, are manmade colloidal suspensions of magnetic nano-particles in a liquid carrier. Emulsions consisting of suspended magnetic fluid droplets surrounded by a continuous phase offer a high potential for technologically important applications such as the design of new smart materials and drug targeting.  To this end, as in other applications such as polymer and advanced material processing, it is necessary to predict or manipulate the dynamics of their droplet microstructure.  This can be done with a combination of mathematical modeling, computer simulation, and experimental work which the investigator proposes to develop and integrate as part of this project.  The broader impacts of the proposed activities also include education,  the integration of people from underrepresented groups, and potential industrial relevance. The proposed research will play a central role in the education and training of a new cadre of computational math students who will learn to work in an interdisciplinary, international team."
"1254618","CAREER: Explicit Adaptive Methods for Coupled Problems","DMS","COMPUTATIONAL MATHEMATICS, Physiol Mechs & Biomechanics, Division Co-Funding: CAREER","09/01/2013","06/30/2014","Andrea Bonito","TX","Texas A&M University","Continuing Grant","Leland Jameson","08/31/2018","$405,412.00","","bonito@math.tamu.edu","400 HARVEY MITCHELL PKY S STE 30","COLLEGE STATION","TX","778454375","9798626777","MPS","1271, 7658, 8048","1045, 8007, 9263","$0.00","The design of adaptive algorithms with provable optimal error decay rates on elliptic problems are well understood, encouraging results are available for parabolic equations while few results are derived in hyperbolic regimes.  Although coupled problems are ubiquitous in science and engineering, their adaptive treatment is in its infancy. In fact, ad hoc adaptivity without rigorous justification is very popular but its efficiency suffers from solid mathematical grounding. Yet, the increasingly amount of resources involved in coupled systems makes adaptive algorithms even more essential. The aim of the proposed research is to design, analyze and implement adaptive algorithms tailored to coupled problems. The following objectives are put forward: (i) develop a systematic framework for the design of explicit adaptive algorithms iterating between the resolution of each quantity of interest; (ii) study a new concept of approximation able to describe the nonlinear interactions between each component of the coupled systems; (iii) derive optimal convergence decay rates in the context of elliptic problems, saddle point systems, and time dependent problems; (iv) challenge the new algorithms in the context of living cell motility where numerical methods must confront the complexity of the numerous phenomena involved and their interactions with the cell geometry.  <br/> <br/>Modern algorithms are able to optimize and balance the computational effort to capture small details without over-resolving the quantity of interest. However, when several processes interacting with each other need to be approximated, the established theory fails to apply due to two major obstructions: (i) the algorithm is required to make decisions without complete knowledge of all interacting quantities; (ii) the abilities to approximate each component of the system are tangled together in a highly nonlinear fashion. We propose to initiate a systematic study of couple problems with special emphasis to physical models related to living cell motility.  The difficulty of modeling cell locomotion is to overcome the inherent great computational expense when considering multi-scale, multi-dimensional and multi-component phenomena. Efficient and flexible algorithms are thus critical in this context. The understanding of cell locomotion has impact on several areas of bio-physics such as in embryonic development,  tissue regeneration, immune response and wound healing in multi-cellular organisms. In addition, the proposed study will actually benefit strategic departments such as energy (oil recovery and carbon dioxide sequestration), environment (groundwater contamination) and  material science (cloaking and filter design)."
"1320051","Infinite-dimensional relaxations of mixed-integer optimization problems","DMS","COMPUTATIONAL MATHEMATICS","08/15/2013","06/24/2015","Matthias Koeppe","CA","University of California-Davis","Continuing Grant","Leland Jameson","07/31/2017","$219,850.00","","mkoeppe@ucdavis.edu","1850 RESEARCH PARK DR, STE 300","DAVIS","CA","956186153","5307547700","MPS","1271","9263","$0.00","Mixed-integer linear optimization is a mature discipline of mathematical optimization and a key technology of Operations Research and Mathematical Analytics.  Key ingredients of the state-of-the-art solver technology are so-called cutting planes.  Strong cutting planes for combinatorial optimization problems (e.g., the TSP) arise from sophisticated studies of the polyhedral combinatorics of convex hulls. In contrast, the state-of-the-art solvers for mixed-integer optimization problems use cuts such as the Gomory's mixed-integer cut, which are derived by integer rounding principles from a single row of the simplex tableau.  The performance of cutting planes has stagnated since the computational breakthroughs of the late 1990s, early 2000s. To meet the challenges of ever more demanding applications, it is desired to make use of information from several rows of the tableau. Finding such ""effective multi-row cuts"" is the most important open question in mixed-integer linear optimization.  The PI proposes to study Gomory Johnson's (1972) k-row infinite group problem.  This problem is infinite-dimensional; its convex geometry is notoriously hard to study.  Finding a characterization of extreme functions corresponding to facet-defining inequalities of polyhedral combinatorics) even for k = 1 had eluded researchers for the past four decades.  The methods used in the breakthrough algorithmic classification by the PI and coauthors of the 1-row rational piecewise linear extreme functions show a route for further work: The arithmetic aspect of the problem (neglected in the literature) leads to the study of reflection groups and their action. The arithmetic interacts closely with the discrete geometry of the problem, where certain periodic polyhedral complexes arise. On the analytic side of the problem, one needs to consider solutions to functional equations of several variables that generalize the one studied by Cauchy and its generalizations by Aczel, Baker, Chung. On the computational side, besides the development of new numerically stable cutting plane procedures, computer-based search will be employed.<br/><br/>The revival of industrial manufacturing in America is closely tied to the field of Analytics, which is the science of making the best decisions in manufacturing and business processes, on the basis of the ever-growing amounts of available data.  Mathematical Optimization is one of the key hard sciences of Analytics.  It provides powerful computational technologies (optimization algorithms and software). One such technology are so-called ""mixed-integer linear optimization solvers,"" which are used by thousands of Analytics experts in all of our industries, including manufacturing, biotechnology, and sustainable infrastructure.  However, one key component in today's mixed-integer linear optimization software has not kept up with the demand to use more and more data in order to come to better decisions, and thus to increase the dimension of the optimization problem: Today's mixed-integer ""cutting plane separators"" still only look at one row of an array of data called the ""simplex tableau"" at a time. As the number of rows grows, this technique is becoming weaker and weaker. Researchers have long sought to find effective ""multi-row cutting plane separators"".  The PI proposes to study an innovative approach, using the ""k-row infinite group problem,"" which will extend his recent breakthrough work on this topic with students and collaborators. This will lead to new mathematical insights, more efficient algorithms and new, more powerful optimization software. This project also has a strong educational impact.  The PI plans to train several undergraduate and graduate students in this research area.  One component of the training will be to create new course material on the topics of this proposal, and to use it for new classes for undergraduate and graduate students.  The second component of the training consists of direct involvement of students in this research project, involving theoretical work, computer experimentation, and software implementation, all of which lead to undergraduate and graduate theses.  All of this will prepare the students for far-reaching careers as experts in Mathematical Analytics, who are able to use the most cutting edge optimization technology."
"1319720","Efficient Methods for Electromagnetic and Acoustic Problems","DMS","COMPUTATIONAL MATHEMATICS","07/15/2013","07/08/2013","Yassine Boubendir","NJ","New Jersey Institute of Technology","Standard Grant","Leland Jameson","06/30/2017","$214,568.00","","boubendi@njit.edu","323 DR MARTIN LUTHER KING JR BLV","NEWARK","NJ","071021824","9735965275","MPS","1271","9263","$0.00","The investigator proposes a family of new algorithms to respond to the increasing demand for computational efficiency and/or accuracy for  acoustic and electromagnetic problems.  The main  idea of this project consists in adequately  combining  several numerical techniques such as finite  elements, integral equations, and domain decomposition methods. The investigator plans to  develop a quasi-optimal non-overlapping domain decomposition method for Maxwell's equations  using an  appropriate approximation of the Dirirchlet to Neumann operator. In the case of partially coated dielectric objects, the following are proposed: (1) design well-conditioned  integral equations; and (2) use these new integral formulations to introduce a novel robust  domain decomposition method, where the iteration  operator is only defined on the aperture  interface. It is also proposed to explore  hybrid algorithms for large and complex bodies such as aircraft and satellites. In particular, the investigator plans to couple finite elements, localization techniques of the Dirirchlet to Neumann map, and substructuring methods to deal with scatterers with large platforms where dielectric  objects and deep cavities are attached. Parallel computing and mathematical analysis will be used  to help achieve these goals.           <br/><br/>The proposed project is concerned with the improvement of computational tools required to face rapidly increasing engineering and industrial needs.  Indeed, the computation of acoustic and electromagnetic waves is a vast area of research. This is largely due to breadth of applications, many of which have imposed technological requirements in systems, such as noise  reduction, oceanic scattering, optical fibers, stealth technology, radar design, remote sensing, and  many others.  In developing modern aircraft, which consist of many very different components, engineers use high performance computing  and innovative mathematical algorithms to enhance performance and optimize passenger safety. This procedure reduces the cost of the design, and allows to rapid response to new technological advances as well as minimization energy  consumption. The results obtained through this research plan will be made readily available to engineers and scientists in the aerospace industry, which will contribute to enhancing U.S  leadership in this field. In addition, this work can be used in the areas of  underground water flow in hydrology, oil recovery in petroleum engineering and fluid flow through body tissues.  Several aspects in this project will benefit the education of both undergraduate and graduate students, and will train them in state-of-art scientific computing and mathematical analysis. This will reinforce their preparation to face future challenges in science and technology."
"1320621","Collaborative Research: Scalable and accurate direct solvers for integral equations on surfaces","DMS","COMPUTATIONAL MATHEMATICS","08/01/2013","07/14/2013","Denis Zorin","NY","New York University","Standard Grant","Rosemary Renaut","07/31/2016","$219,999.00","","dzorin@mrl.nyu.edu","70 WASHINGTON SQ S","NEW YORK","NY","100121019","2129982121","MPS","1271","9263","$0.00","The goal of the proposed research is to develop faster and more accurate algorithms for computing approximate solutions to a broad class of equations  that  model physical phenomena such as heat transport, deformation of elastic bodies, scattering of electromagnetic waves, and many others. The task of solving such equations is frequently the most time consuming part of computational simulations, and is the part that determines which problems can be modeled computationally, and which cannot. Dealing with complicated shapes (e.g.  scattering from complex geometry or flow through channels of complicated shape) adds difficulty to the computational task.<br/><br/>Technically speaking, most existing large-scale numerical algorithms for solving partial differential and integral equations on complex geometries are based on so called ""iterative methods"" which construct a sequence of approximate solutions that gradually approach the exact solution. The proposed research seeks to develop ""direct methods"" for solving  equations. A ""direct method"" computes the unknown data from the given data in one shot.  When available, direct methods are often preferred to iterative ones since they are more robust, and  can be used in a ""black-box"" way.  As a result these are  more suitable for incorporation in general purpose software, and in many cases work for important problems that cannot be solved with existing iterative methods. The reason that they are today typically not used is that existing direct methods for many problems are often prohibitively expensive. However, recent results by the PIs and other researchers have proven that it is possible to construct direct methods that are competitive in terms of speed with the very fastest existing iterative solvers. The new algorithms will be applied to the simulation of fluid flows and biomolecular simulations, and their performance will be demonstrated by the execution of simulations on complex geometries."
"1320829","RUI: New Applications of Curvature in Image Processing","DMS","COMPUTATIONAL MATHEMATICS","07/01/2013","06/26/2013","Stacey Levine","PA","Duquesne University","Standard Grant","Leland Jameson","06/30/2017","$185,240.00","","sel@mathcs.duq.edu","600 FORBES AVENUE","PITTSBURGH","PA","152820001","4123961537","MPS","1271","9229, 9263","$0.00","The investigator, students, and collaborators will develop and establish the mathematical foundations of new models for image processing, implement, test and compare these new models with existing ones, and directly apply these models to problems in image fusion, medical imaging, and video processing. The proposed work has several over-arching goals. The first is the development and mathematical analyses of a new framework for image denoising that exploits the rich information of the curvature of an image in a new and effective way. The second is a better understanding of how to model geometric features in learned, structured, and overcomplete dictionaries for processing and fusing degraded data. The new models proposed in this work will be formulated in both the variational and patch-based frameworks, and will mainly address data that have been compromised by noise and linear degradations.<br/><br/>Digital images are now used in almost every area of science and technology. The models developed in this project will be used to solve real world problems, including problems in image fusion, video processing, and medical imaging. However, the models will be formulated in enough generality to potentially be applied to a wide array of applications in the sciences. Software developed under the auspices of this grant will be made publicly available. This project will also support undergraduate researchers who will implement, test and compare new and existing image processing models, determine appropriate numerical schemes, work directly with scientists to apply these models to real world problems, and present their results at local and national meetings. The investigator regularly teaches courses on image processing, and leads workshops on image processing for middle school students and high school women and minorities. Thus this work will be applied to problems in the sciences, be accessible for others working in directly and indirectly related fields, promote the training of young scientists, and provide educational opportunities for underrepresented groups."
"1319050","Accelerated Algorithms for a Class of Saddle Point problems and Variational Inequalities","DMS","COMPUTATIONAL MATHEMATICS","09/01/2013","07/08/2013","Yunmei Chen","FL","University of Florida","Standard Grant","Leland Jameson","08/31/2017","$160,000.00","Guanghui Lan","yun@math.ufl.edu","1523 UNION RD RM 207","GAINESVILLE","FL","326111941","3523923516","MPS","1271","9263","$0.00","This project will develop novel theories and optimal numerical methods for solving certain classes of deterministic and stochastic saddle point and variational inequality problems arising from large-scale data analysis in various disciplines. The proposed accelerated primal-dual (APD) algorithm is based on the integration of a multi-step acceleration scheme with the primal-dual method, and expected to exhibit an optimal rate of convergence as the one obtained by Nesterov for a different scheme. The proposed stochastic APD algorithm is also expected to possess an optimal rate of convergence for solving stochastic saddle point problems, while no stochastic primal-dual algorithms have been developed in the literature. Moreover, the research will be extended to the development of optimal methods for solving a class of composite variational inequalities (VI) that includes the class of the saddle point problems to be studied as a special case. This study provides some important insights on the decomposition of a general VI problem to potentially accelerate its solution. Furthermore, the theoretical analysis on optimal convergence rate, and optimal estimation of the bound for duality gap, especially, the dependence on the distance between the initial and saddle points (or the diameter of the feasible set, if they are bounded), of all the proposed algorithms will be investigated. The project will investigate and develop backtracking strategies for the proposed algorithms to enhance their practical performance.  The new methods will be applied to several image reconstruction and machine learning problems. <br/><br/>The class of the deterministic and stochastic saddle point and variational inequality problems studied in this proposal has been considered as a framework of ill-posed inverse problems regularized by a non-smooth functional in many data analysis problems, such as image reconstruction, compressed sensing and machine learning.  The success of the proposed research will significantly advance non-smooth convex optimization solvers by enriching solver's abilities in accelerating computation with good theoretical performance guaranteed. Therefore, this project is expected to greatly increase the applicability of many emerging technologies, such as partially parallel imaging and dynamic multi-tracer PET. Those imaging methods can significantly reduce scan time and improve image quality. However, their clinical applications have been hindered by our incapability to efficiently solve the large-scale ill-posed and ill-conditioned inverse image reconstruction problems. Moreover, the development of stochastic APD algorithms will greatly enhance learning power. For instance, these optimal methods will enable researchers to build high-level, class specific feature detectors from massive datasets. The new methods to be developed have a wide range of applications in large-scale data analysis problems from various disciplines. Therefore, the research will contribute to the research communities and industry with mutual interest. The algorithms developed during the research will be made freely available on the World Wide Web. The graduate students of the PIs will be involved in all aspects of the research, both theoretical analysis as well as practical implementation of algorithms. The research will be made accessible to more graduate and senior undergraduate students through seminars and course developments. The PIs intend to teach courses based on the proposed research."
"1319893","Computational Methods for Discrete Conic Optimization","DMS","COMPUTATIONAL MATHEMATICS, OPERATIONS RESEARCH","09/01/2013","09/11/2013","Theodore Ralphs","PA","Lehigh University","Standard Grant","Leland Jameson","08/31/2017","$300,000.00","","tkr2@lehigh.edu","526 BRODHEAD AVE","BETHLEHEM","PA","180153008","6107583021","MPS","1271, 5514","073E, 9263","$0.00","This project's goal is to develop and implement methodology for solving mixed integer conic linear optimization problems (MICLPs), which are to minimize a linear function subject to both conic and linear constraints, as well as integrality constraints on a subset of the variables. The primary focus of this work is on computational methods for solving MICLPs involving so-called second order cones, which form the basis for the most tractable class of conic optimization problems. Although both discrete and conic optimization models have been the subject of intense study, their integration is a challenging task; only recently have the two areas gained enough maturity to make the development of efficient solution methodologies for MICLPs realistic. The PI proposes a new paradigm,  called branch and constrain, that generalizes the disjunctive methods so successfully applied in the case of discrete linear models. The work involves study of the geometric structure of the feasible regions of these models and the disjunctive sets that arise, as well as the development of methodology to exploit this knowledge in a general computational framework.  <br/><br/>An optimization problem is that of choosing values for a set of variables that minimize the value a given objective function (function of the variables) subject to the restriction that the values of a set of constraint functions (also functions of the variables) are constrained to be between given bounds. One may also require the variables to take values from a certain restricted set (such as the integers). The most tractable optimization problems are those involving linear functions and for which the variables may take any real value. The addition of nonlinear functions or variables whose values must be taken from a discrete set significantly impacts the efficiency with which the model can be solved. Among nonlinear constraints, conic constraints are the easiest to accommodate, so the development of methods for solving discrete conic optimization problems is the first natural step in developing approaches to more general models that have both discrete and nonlinear structure. Many real-world applications involve a combination of these two modeling paradigms. For example, financial optimization models often involve constraints on the level of risk, which can be expressed using conic constraints. In supply chain logistics, bounds on the distance between two geospatial locations can also be expressed using conic constraints. In both of these classes, applications naturally arise in which there are also discrete choices to be made. For example, in portfolio optimization, one often wants to restrict the number of investments in a given portfolio. In facility location models, one wants to restrict the choice of locations to a given list of candidates. Models of maximizing returns subject to risk bounds or minimizing costs subject to geospatial constraints are examples of the kinds of models whole solution this work will enable."
"1318427","Computation of crowded geodesics on the universal Teichmueller space for planar shape matching in computer vision","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","08/01/2013","05/30/2014","Akil Narayan","MA","University of Massachusetts, Dartmouth","Continuing Grant","Leland Jameson","10/31/2015","$198,300.00","Alfa Heryudono","akil@sci.utah.edu","285 OLD WESTPORT RD","NORTH DARTMOUTH","MA","027472356","5089998953","MPS","1266, 1271","9263","$0.00","Quantifying the (dis)similarity between two shapes is a central problem in computer vision. One distance metric on the space of planar shapes is realized by identifying this space as a subset of the Universal Teichmueller Space, and equipping it with the Weil-Petersson metric. This results in a metric that is scale- and translation-invariant on shapes, and has unique geodesic flow between two shape endpoints. The work of this proposal develops robust computational methods for the computation of metric distances and geodesics between shapes on this space. The major difficulty lies in computations involving ""crowded"" shapes, i.e., those with elongated, winding, or extended protrusions. Such shapes stymie finite-precision computations because direct algorithms suffer from severe roundoff error. The major thrusts of this proposal develop algorithmic methodologies to address roundoff error and related issues: The Zipper conformal mapping algorithm will be augmented to produce accurate conformal maps for crowded shapes. The velocity field representation on a geodesic will be rewritten into a form that is resistant to roundoff error. The geodesic equation will be transformed into a expression that takes advantage of the aforementioned velocity field transformation, and can effectively flow between crowded shapes. The final phase of this project will demonstrate accurate geodesic flow and distance computations between crowded shapes. The methods developed under this project can be applied to several related problems in scientific computing: solutions to differential equations on irregular geometries through conformal mapping, conservative integration methods with ill-conditioned particle systems, and moving-mesh kernel approximations.<br/><br/>The work of this project can contribute to far-reaching applications in scientific and computer vision problems: automated object recognition (e.g. projectile identification), outline classification (determination of an animal's species), medical imaging (usage of MRI to diagnose dementia and related diseases), and artificial intelligence (visual recognition and interpretation) to name a few. All computational deliverables (computer code, example simulations, documentation) will be made publicly available. Through the engagement of students in related research tasks, this project will contribute to the educational development of future engineers, mathematicians, and computer scientists."
"1265401","Collaborative:  Special Session on Numerical Modeling of Fluids and  Structures","DMS","COMPUTATIONAL MATHEMATICS","06/01/2013","04/10/2013","James Adler","MA","Tufts University","Standard Grant","Leland Jameson","11/30/2013","$15,000.00","","jadler3@gmail.com","169 HOLLAND ST FL 3","SOMERVILLE","MA","021442401","6176273696","MPS","1271","7556, 9263","$0.00","Numerical Modeling of Fluids and Structures at the 9th International Conference on Large-Scale Scientific Computations (LSSC) in Sozopol, Bulgaria from June 3-7, 2013.<br/><br/>The investigators and his colleagues are organizing a special session on Numerical Modeling of Fluids and Structures at the 9th International Conference on Large-Scale Scientific Computations (LSSC) in Sozopol, Bulgaria from June 3-7, 2013. This minisymposium focuses on developing, investigating, and applying fundamental mathematical theories and advanced modeling and simulation techniques to various multiphysics and multiscale problems, especially fluid-structure interactions.  Key scientific questions addressed in this session have a wide range of applications, including magnetorheological fluids, aerodynamics, biomedical applications, micro-electro-mechanical systems, and ground water modeling.<br/><br/>This special session supports participation of students, postdocs, and junior researchers from the United States, who are working in areas related to the modeling and simulation of fluids, structures, and their interactions. The workshop environment promotes contacts  between researchers from the United States and other countries, including theorists and experimentalists from applied mathematics, computational science and engineering. Mutually beneficial discussions between junior and senior researchers and mathematicians and engineers are expected.  The special session is mainly organized by junior researchers and, along with other young participants, makes their research highly visible to the rest of the scientific community, providing them the access to various application fields for which they can contribute many advancements."
"1244041","Syzygies in Berlin","DMS","ALGEBRA,NUMBER THEORY,AND COM, COMPUTATIONAL MATHEMATICS","05/01/2013","11/20/2012","Henry Schenck","IL","University of Illinois at Urbana-Champaign","Standard Grant","Tie Luo","04/30/2015","$21,405.00","","hks0015@auburn.edu","506 S WRIGHT ST","URBANA","IL","618013620","2173332187","MPS","1264, 1271","7556","$0.00","The workshop ""Syzygies in Berlin"" will take place in Berlin, Germany on May 27-31, 2013 and will bring together early-stage and senior mathematicians to study classical results and open problems surrounding free resolutions, regularity, and syzygies. This classical area has undergone a renaissance in the past decade, aided in large part by computer algebra calculations, especially with the NSF funded computer algebra package Macaulay2. The workshop's will center around a trio of short courses, led by D. Eisenbud (Berkeley), H. Schenck  (Urbana-Champaign), and F.-O. Schreyer (Saarlandes). These leading experts are also well known for their enthusiasm and effectiveness as teachers. In addition to the short courses above, three invited lectures will highlight recent developments in the field. Potential speakers for these lectures are: Christine Berkesch (Duke University), Diane Maclagan (Warwick University, England), and Irena Peeva (Cornell University).<br/><br/>This workshop will bring together young researchers and senior leaders in the field of algebraic geometry. Algebraic geometry is a field which studies the interplay between polynomial equations and the geometric objects which constitute the solutions to the equations: a familiar example might be the equation y=x^2, whose set of solutions forms a parabola in the plane. The field of algebraic geometry plays a prominent role in both pure and applied mathematics, appearing in problems ranging from the purely theoretical (string theory) to applied (signal processing, geometric modeling and computer aided design). The NSF funding for the proposal matches support provided by the German Mathematical Association, and provides travel support for ten Ph.D. students and postdocs, as well as support for lodging for fifteen participants, as well as travel and lodging support for two of the invited lecturers.  Additional information can be found on the conference website: http://syzygies.math.fu-berlin.de"
"1320550","Collaborative Research:   Optimal Monte Carlo Estimation via Randomized Multilevel Methods","DMS","COMPUTATIONAL MATHEMATICS","08/01/2013","07/31/2015","Jose Blanchet","NY","Columbia University","Continuing Grant","Leland Jameson","07/31/2017","$209,993.00","","jose.blanchet@stanford.edu","202 LOW LIBRARY 535 W 116 ST MC","NEW YORK","NY","10027","2128546851","MPS","1271","9263","$0.00","This research project will investigate a comprehensive set of tools to enable efficient and unbiased Monte Carlo methods in a wide range of settings such as: steady-state computations and stochastic differential equations (SDEs). The PIs extend the applicability and power of a recently introduced technique called multilevel Monte Carlo (MLMC), which has rapidly grown in popularity and has shown to be highly successful, particularly in the context of numerical solutions to SDEs. The PIs strategy rests on two basic ingredients. First, they abstract the main ideas of MLMC. This abstraction makes it clear that MLMC can be applied to many problem settings (beyond the SDE context), for example in problems such as: estimating steady-state expectations of Markov random fields, and solving distributional fixed point equations. Second, the PIs introduce a simple, yet powerful, extra randomization step. This randomization step will permit to not only completely delete the bias, which so far is present in every single application of the multilevel method, but it will also permit to more easily optimize parameters (often user-defined) that arise in classical multilevel applications. At the core of our abstraction of the MLMC method lies the construction of a suitable sequence of strong (almost sure) approximations under some metric. The freedom that is implicit in constructing such approximations yields a rich research program that touches upon many of the elements of modern probability, including random matrices, Markov random fields, mean field fixed point equations and Lyapunov stability.<br/>    <br/>    The PIs will investigate a methodology that enables high-performance computing in the context of simulation of stochastic systems. The PIs methodology will substantially extend a recently developed approach, called Multilevel Monte Carlo (MLMC), which has typically been applied only to compute numerical solutions of stochastic differential equations (SDEs). More generally, this research project addresses a wide range of problems that lie at the center of modern scientific computing, beyond the important setting of SDEs which arise in virtually all areas of modeling in engineering and science. For example, the PIs will generalize the MLMC approach to accurately perform so-called steady-state simulation for Markov chains indexed by trees. These computational problems arise very often in statistical inference applications, ranging from imaging to classification problems. The PIs research also improves upon the classical MLMC technique by optimizing its design and allowing the study of, for example, steady-state analysis of SDEs (i.e. combining traditional areas of study with new methodological applications). The PIs will in particular apply these optimized computational techniques to solve problems in service and manufacturing engineering. The PIs plan to develop a new jointly designed course, on the topic of this proposal, and the course material will be made available online to increase the dissemination and the potential applicability of the project's findings. The PIs will attempt to recruit high-quality personnel from under-represented groups and will disseminate the scientific output of the research via open access sites, in addition to the standard vehicles such as conferences and journal publications."
"1255203","CAREER: Super-Resolution and Subwavelength Imaging","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, Division Co-Funding: CAREER","07/15/2013","09/15/2017","Laurent Demanet","MA","Massachusetts Institute of Technology","Continuing Grant","Pedro Embid","06/30/2018","$480,000.00","","laurent@math.mit.edu","77 MASSACHUSETTS AVE","CAMBRIDGE","MA","021394301","6172531000","MPS","1266, 1271, 8048","1045","$0.00","Demanet<br/>1255203<br/><br/>     The investigator aims to put the super-resolution phenomenon of signal estimation on a quantitative footing, and to explore the consequences of reliable super-resolution in tomographic imaging.  The estimation of a signal from the knowledge of its Fourier transform in a band qualifies as super-resolved when the fine structure of the signal is recovered on a length scale smaller than the inverse of the band's width --- the so-called Shannon-Nyquist scaling.  It is a poorly understood, yet real and decidedly nonlinear numerical phenomenon.  Sparsity has been suggested as a principle according to which super-resolution reliably occurs.  However, recent insights from analysis of convex programs indicate that a second principle, sign compatibility, is needed in tandem with sparsity to unlock positive results.  Building on this, the investigator seeks quantitative guarantees of a new kind for successful signal recovery up to the ideal resolution level that no method can beat.  Such results would generalize the theory of compressed sensing in the regime of very coherent dictionaries, where no restricted isometry-type property can be expected to hold.  The investigator also studies algorithms based on translation-invariance such as the matrix pencil method, modified matching pursuits, precorrective filtering, and generalizations to higher dimensions.  He explores implications, both positive and negative, for tomographic imaging modalities such as seismic and synthetic aperture radar in the subwavelength regime. <br/><br/>     The project aims to design advanced, nonlinear processing methods to deliver higher image resolution and interpretation levels in situations where the data come with poor frequency content, such as in the case of a blurring.  A methodical understanding of the possibilities offered by super-resolution could eventually transform the methods by which information is extracted from data in a host of inverse problems, ranging from medical imaging (MRI, fluorescence microscopy) to geophysical imaging (exploration seismology) and defense applications.  The project also offers an opportunity for students to acquire strong interdisciplinary training at the intersection of computational mathematics, modern data processing, and tomographic imaging.  Graduate curricula typically fall short of covering this evolving material in a satisfactory way, even though there is a great demand in industry for quantitative-minded specialists who can operate as experts on all these fronts.  The investigator is involved in several initiatives to introduce this new research area widely, through the organization of graduate summer schools, the administration of an internship program geared toward minorities, and remote teaching via MIT's online educational platforms OCW and EdX."
"1318894","Robust reconstruction techniques for nonuniformly sampled data","DMS","COMPUTATIONAL MATHEMATICS","08/01/2013","07/02/2014","Benjamin Adcock","IN","Purdue University","Standard Grant","Leland Jameson","07/31/2017","$289,998.00","Benjamin Adcock","adcock@purdue.edu","2550 NORTHWESTERN AVE STE 1900","WEST LAFAYETTE","IN","479061332","7654941055","MPS","1271","9263","$0.00","In this research the PI develops and analyzes mathematical and numerical frameworks for robust reconstructions from nonuniformly-acquired, multidimensional data.  A particular focus of this work is on wavelet-based, sparsity-exploiting algorithms based on infinite-dimensional (i.e. analog/continuous) signal and image models.  Research objectives include (i) introducing a comprehensive mathematical sampling theory for stable, realizable reconstructions in arbitrary bases and frames from nonuniform data, (ii) extending compressed sensing theory and techniques to nonuniform and nonideal data, as well as continuing the development of compressed sensing to the infinite-dimensional setting, (iii) implementing and analyzing efficient algorithms for reconstruction based on numerical linear algebra, and (iv) establishing new fundamental barriers for stable reconstructions from uniform and nonuniform data.  The research will provide thorough mathematical analysis, in particular as regards the key issues of accuracy and stability.<br/><br/>In many different areas, including medical imaging, tomography, seismic imaging, radar, and astronomy, data is collected nonuniformly.  In medical imaging, for example, nonuniform sampling geometries allow for fast, higher-resolution scans with lower susceptibility to noise and artifacts.  However, standard algorithms used for image reconstruction from such data often have critical shortcomings, especially as regards accuracy and robustness to noise and other errors.  This can lead to incorrect image registration and, in medical imaging, misdiagnosis.  This project introduces new and improved algorithms for non-standard and nonuniformly sampled data, with a particular emphasis on sparsity-exploiting methods, and addresses the fundamental mathematical analysis of image reconstruction from such data.  The benefits of this work include (i) the development of a more realistic theory of sampling and compressed sensing that is closer to and more representative of the practitioner's needs, and (ii) the introduction of reconstruction algorithms with superior reconstruction quality, lower data acquisition times and improved robustness in the presence of noise and perturbations."
"1317205","Spectral Value Sets: Theory, Algorithms and Applications","DMS","COMPUTATIONAL MATHEMATICS, NUM, SYMBOL, & ALGEBRA COMPUT","08/01/2013","07/09/2013","Michael Overton","NY","New York University","Standard Grant","Rosemary Renaut","07/31/2016","$431,745.00","","overton@cs.nyu.edu","70 WASHINGTON SQ S","NEW YORK","NY","100121019","2129982121","MPS","1271, 7933","9263","$0.00","Spectral value sets arise in the modeling of linear dynamical systems with uncertain feedback.  They are important because they model uncertainty inherent in the feedback which is assumed to depend linearly on the output.  They are parametrized by a parameter E which bounds the norm of the uncertainty in question. Theoretical aspects of the project include analysis of properties of specific extremal points of spectral value sets for a given value of E and at points of coalescence of the spectral value set components for critical values of E, both in terms of local geometry and algebraic measures. Algorithmic aspects include the development and analysis of fast methods to compute (1) maximizers of the real part or modulus over a given spectral value set for fixed E and (2) the complex stability radius (or its reciprocal, the H-infinity norm) defined as the largest value of E such that the associated spectral value set lies inside the stability region (the left half-plane or the unit disk).  They also include developing methods to design controllers for open-loop plants that result in closed-loop systems with desired stability and optimality properties, such as locally maximizing the stability radius (minimizing the H-infinity norm). Since these functions are not concave or convex and their optimizers are typically at points where they are not differentiable, methods for nonsmooth, nonconvex minimization are needed, including methods that can handle constraints efficiently.<br/><br/>The mathematical properties of spectral value sets and associated algorithms to compute their extremal values have both theoretical and practical importance. The broader goal of the project is to bring the tools of algorithms for optimization over spectral value sets and related problems to a wide community of scientists and engineers, for use in many different kinds of applications.  The investigator's open-source software is already in use in a variety of applications, including  the design of aircraft controllers, a proton exchange membrane fuel cell system, power systems, observer-based fault detection and minimally invasive surgery. All of these systems require controllers to work effectively: a complex system such as an airplane or a power plant requires automatic controllers to function safely and effectively, in addition to skilled operators who know how to use such systems.  However, current methods are limited to small or moderate-sized systems, which cannot model real physical systems accurately.  The new methods will allow the design of controllers for much larger systems than was previously possible, including control of discretized systems of partial differential equations, which have applications throughout the natural sciences and engineering."
"1303565","UNCG Summer School in Computational Number Theory","DMS","ALGEBRA,NUMBER THEORY,AND COM, COMPUTATIONAL MATHEMATICS","04/01/2013","04/30/2015","Dan Yasaki","NC","University of North Carolina Greensboro","Continuing Grant","Andrew Pollington","03/31/2016","$53,748.00","Sebastian Pauli, Brett Tangedal, Filip Saidak","d_yasaki@uncg.edu","1000 SPRING GARDEN STREET","GREENSBORO","NC","274125068","3363345878","MPS","1264, 1271","7556, 9263","$0.00","A one-week summer school in Computational Number Theory will be held at the University of North Carolina Greensboro in May of 2013, 2014, and 2015.  The first summer school is scheduled for May 20-24, 2013. The subjects for each of the upcoming summer schools to be held at the University of North Carolina Greensboro are the following:<br/>- May 2013: Computational Algebraic Number Theory <br/>- May 2014: Geometry and Modular Forms <br/>- May 2015: Computational aspects of Hilbert's 12th Problem<br/>The aim of the one-week summer school is to complement the traditional training that graduate students receive by exposing them to a constructive and computational approach to many objects in number theory. This will further their knowledge and give the students additional tools for their research. Furthermore, the school will allow the students to have the opportunity to work closely with experts in the field. <br/><br/>The summer school will help create research communities. By meeting and working with other graduate students in their field the students will lay the foundation for future collaboration. In the years after the summer school they will meet again at one of the regional conferences: Palmetto Number Theory Series or South Eastern Meeting on Numbers. The PIs will encourage student participation in these conferences, which will be valuable for their careers as researchers and in their post-doctoral lives. By introducing the students to a computational approach to number theory, this project will enhance the next generation of mathematicians by increasing their ability to use computing technology in their research. More information can be found at the website for the summer school:<br/>http://www.uncg.edu/math/numbertheory/summerschool/"
"1316662","High Order Maximum Principle Preserving Finite Difference Schemes for Hyperbolic Conservation Laws","DMS","COMPUTATIONAL MATHEMATICS","09/01/2013","09/03/2013","Zhengfu Xu","MI","Michigan Technological University","Standard Grant","Leland Jameson","05/31/2017","$226,349.00","","Zhengfux@mtu.edu","1400 Townsend Drive","Houghton","MI","499311295","9064871885","MPS","1271","9263","$0.00","The main focus of this proposal is to develop and to analyze a novel parametrized maximum principle preserving flux limiter technique for high order numerical schemes applied to hyperbolic conservation laws. A flux limiting technique will also be designed to obtain high order positivity preserving schemes. Numerical schemes that preserve the maximum principle and positivity are desirable because physically relevant solutions have those properties. The development is based on finite difference methods, which have the advantage of producing accurate approximations with low computational cost especially in multi-dimensional simulations. Within the proposed framework, conservative maximum principle preserving high order finite difference, finite volume and discontinuous Galerkin schemes can be designed that allow for significantly large CFL number, and therefore more efficient computational simulation. Some important applications investigated in this proposal include compressible Euler equations, magneto hydrodynamics equations and Vlasov-Maxwell equations.<br/><br/>The investigator is developing new computational techniques that can be applied to difficult and very important problems in science and engineering. These techniques address shortcomings in existing methods and should allow more efficient, robust, and accurate computer simulations in a number of critical applications. One such application is the supersonic flow problem, which is of great importance in designing astrophysical jets and also in the simulation of reentry vehicle for space flight modeling. Another application is the study of the magneto hydrodynamic systems, which arises in space weather modeling, in modeling electric propulsion sources, and in systems involving plasma (such as plasma-opening switches, flight control via plasma, plasma assisted combustion). These problems are strategically important for the design of the next generation devices of great industrial and commercial value."
"1318820","Joint Diagonalization-Based Spectral Element Approach","DMS","COMPUTATIONAL MATHEMATICS","07/01/2013","06/23/2015","Suchuan Dong","IN","Purdue University","Continuing Grant","Leland Jameson","06/30/2017","$189,019.00","","sdong@purdue.edu","2550 Northwestern Ave.","West Lafayette","IN","479061332","7654941055","MPS","1271","9263","$0.00","This project aims to develop algorithmically scalable high-order numerical techniques. The essential components consist of numerically-constructed one-dimensional basis functions, which correspond to a set of optimal bases in the function space in some sense. Expansion bases for higher dimensions are then developed from such functions. Methods employing these new bases exhibit superior properties in terms of numerical efficiency and algorithmic scalability.<br/><br/>The investigator develops techniques that make computer simulations of physical processes both very accurate and very fast. These computer simulations permeate essentially every aspect of modern life. They are indispensable and critical to, for example, the design of airplanes and spacecrafts, discovery and design of new materials, understanding and prediction of severe weather conditions such as tornadoes and hurricanes, understanding and prevention of oil spills. The significance of the project lies in that the techniques developed herein can significantly reduce the time to acquire the solutions in simulations, and simultaneously substantially increase the simulation accuracy."
"1321473","CONFERENCE: Tutorials in Applicable Algebraic Geometry","DMS","COMPUTATIONAL MATHEMATICS","09/01/2013","09/05/2013","Daniel Bates","CO","Colorado State University","Standard Grant","Junping Wang","08/31/2014","$15,520.00","","bates@math.colostate.edu","601 S Howes St","Fort Collins","CO","805232002","9704916355","MPS","1271","7556, 9263","$0.00","There has recently been a significant increase in the application of the methods of algebraic geometry to problems outside of mathematics.  The resulting interdisciplinary work necessarily entails much interaction between experts in algebraic geometry and those from other disciplines.  The PI will run a workshop July 29-31, 2013 focused on introducing non-experts to two fundamental tools rooted in algebraic geometry:  numerical algebraic geometry and toric geometry.  Authors of recent books in these two areas will give lectures:  Frank Sottile and Jonathan Hauenstein for numerical algebraic geometry, John Little and Hal Schenck for toric geometry.  These lectures will serve as a rapid introduction to the methods and software from these two areas, focused on the value for problems coming from applications. This meeting will take place at the Pingree Park mountain campus of Colorado State University.<br/><br/>Mathematical problems in application areas can sometimes be converted into a certain type of problem, the polynomial system.  For years, there was no efficient way to solve polynomial systems, so researchers had to find different, sometimes less desirable, formulations for their problems.  However, with recent developments in numerical algebraic geometry and toric geometry, it is now reasonable to solve relatively large polynomial systems directly.  These new computational tools open the door to study problems that were previously too difficult to consider.  For example, in kinematics, the introduction of numerical algebraic geometry has already resulted in the ability to solve long-standing problems and to discover new mechanisms with special properties.  The workshop supported by this award will help to expedite the use of these powerful new tools by the researchers who need them."
"1358953","Modeling and Simulations of Complex Fluids and Atomistic Strain","DMS","COMPUTATIONAL MATHEMATICS","07/01/2013","05/05/2017","Young-Ju Lee","TX","Texas State University - San Marcos","Standard Grant","Leland Jameson","08/31/2018","$144,816.00","","y_l39@txstate.edu","601 University Drive","San Marcos","TX","786664616","5122452314","MPS","1271","9263","$0.00","The main objectives of the project is to build an integrated mathematical and computational research program that includes coherently interconnected mathematical disciplines, targeting, but not limited to, some challenge applications in modeling and simulation of complex fluids and atomic strain. The major goal in the project is to understand the flow instabilities in worm-like micellar fluids such as the oscillating falling sphere and jumping bubbles. Using the three species model that takes into account long and short micelles and the shear-induced structure, the conjectured relation between the flow instability and the shear-induced structures will be investigated. The project will introduce the regularization techniques in the complex-fluid models for robust and stable simulations and will integrate them with a fast multigrid solver in the framework of massively parallel computing techniques. Such integrated modeling and computational method is anticipated to make a rheological modeling software. The project is also aimed at developing the new strain modeling and simulation of nano-crystalline materials. The atomic strain model will be developed by applying the finite element methodology for the continuum linear elasticity. Unlike the conventional strain models developed by using the finite difference approximations, the newly proposed model will mirror and take into account the real atomic structures such as the diamond and zinc structures. The model developed in this project will then be used to investigate a sample strain-related nano-structure formation as its application. <br/><br/>Complex fluids are ubiquitous in nature and industry and they are used in many important areas, including the pharmaceutical, food, military, bio-materials, printing, and oil industry, just to name a few. Strain in nano-crystalline materials is central in materials science research and understanding the strain is critical to provide guidance for the real-life device design applications such as light emitting diodes, injection lasers and solar cells. Yet, the modeling and simulation of complex fluids and strain in nano-crystalline materials remain formidable and grand challenges, even with modern supercomputers. Among others, the inherent deficiency of existing mathematical models and the inefficiency of conventional numerical techniques are the major bottlenecks, which defeat scientists' attempt to understand and design materials. It is anticipated that the modeling and computation methods developed in this research will remedy both the deficiency in the models and the inefficiency in the computation, thereby drastically eliminating the mathematical and computational bottlenecks and eventually providing valuable guiding tools for scientists to better understand the materials of interest within the scope of this project as well as in a number of other neighboring areas of research where the technologies developed in this project can be applied."
"1312424","Computational Model-based Statistical Methods in Biomedicine","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","08/15/2013","08/19/2013","Erkki Somersalo","OH","Case Western Reserve University","Standard Grant","Victor Roytburd","07/31/2018","$254,018.00","","ejs49@case.edu","Nord Hall, Suite 615","CLEVELAND","OH","441064901","2163684510","MPS","1266, 1271","","$0.00","This project concerns the mathematical modeling and analysis of biomedical applications in which the objective is to retrieve pertinent information of the structure or functioning of a biological system from indirect and minimally invasive measurements. The applications include electroencephalography (EEG) and magnetoencephalography (MEG), electrical impedance tomography (EIT), electric neurography (ENG), and dynamical PET imaging. Characteristic for all these problems is the high complexity of the mathematical model describing the system, significant level of noise in the signals, and severe ill-posedness of the inverse problem of recovering the information of interest from the data. Well-planned model reduction methods help to simplify the model, but at the same time a significant modeling error is introduced, as the simplified model can no longer capture all the features of the data. The aim in the project is to develop computational statistical methods to overcome these problems. Unknown quantities are modeled as random variables, making it possible to analyze in statistical terms the model reduction errors. In the MEG/EEG application, stochastic modeling is used to analyze and filter out the complex noise due to normal brain activity that easily masks the signal coming from an abnormal activity such as the onset of focal epileptic seizure. Well-planned prior models for the unknown quantities help to reduce the ill-posedness of the inverse problems, and lead to efficient numerical methods for both estimating the unknowns of interest as well as to quantify the uncertainty in the estimate. Novel time-dependent filtering methods are investigated to deal with noisy signals.<br/><br/>The mathematical and computational methodology aims at improving the performance of different diagnostic processes: In the impedance tomography application, the goal is to be able to discern benign and malignant lesions seen in a mammography image without the need of breast biopsy, by injecting weak electric currents through contact electrodes in the breast and measuring the corresponding electric voltages, and by further computing the electric response of the tissue of interest. It is known that cancer tissue is characterized by an abnormal electric response.  The main target in EEG and MEG research is to help localizing epileptic foci in the brain by measuring the electric and magnetic fields outside the patient's head. This information helps greatly the brain surgery planning for patients with severe epilepsy that does not respond to medication. Dynamic PET imaging is used in the studies of brain functioning, e.g., under severe liver conditions that change the ammonium level in the blood. Electric neurography aims at reading the electric signals inside a peripheral nerve in a minimally invasive manner using contact microelectrodes. This data can be used to give a patient control of a prosthetic robotic arm mounted on an amputated limb, as if the arm would be a real arm responding to neuronal commands. Another exciting application being investigated is the possibility to control chronic pain."
"1318409","High order methods for some kinetic models","DMS","COMPUTATIONAL MATHEMATICS","09/15/2013","06/29/2015","Fengyan Li","NY","Rensselaer Polytechnic Institute","Standard Grant","Leland Jameson","08/31/2017","$273,594.00","","lif@rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","MPS","1271","9251, 9263","$0.00","The objective of this proposal is to develop, analyze, and numerically evaluate highly accurate asymptotic preserving numerical methods for robust simulations of collisional kinetic models in different regimes, and accurate and efficient numerical methods which preserve important physically relevant properties for the collisionless kinetic model including Vlasov-Maxwell equations. High order methods are widely used for their computational efficiency to achieve expected accuracy, the excellent performance over long time, and their capability of capturing features with small scales or phenomena involving multiple scales. <br/><br/>Kinetic theory and its related numerical simulations play an increasingly important role in a broad range of applications, such as rarefied gas dynamics, plasma physics, traffic networking, and swarming. Accurate, robust and efficient simulations of kinetic models are of fundamental significance. The numerical challenges lie in the high dimensionality of most kinetic models, small scales, multiple scales in both time and space, nonlinear coupling, nonlinear or singular collision operators with multi-fold integrals, and important conservation properties of the solutions. Through the proposed projects, both numerical and analytical techniques will be advanced which either directly or have potential to address some of the challenges mentioned above. Computer simulation tools, especially those being highly accurate and cost efficient, preserving key physical properties, and capable of handling both spatial and temporal multiscales, will be greatly enriched."
"1315128","A parallel Poisson/Helmholtz solver using local boundary integral equation and random walk methods","DMS","COMPUTATIONAL MATHEMATICS","09/01/2013","09/11/2013","Wei Cai","NC","University of North Carolina at Charlotte","Standard Grant","Junping Wang","08/31/2015","$140,000.00","","cai@smu.edu","9201 University City Boulevard","CHARLOTTE","NC","282230001","7046871888","MPS","1271","9263","$0.00","The objective of this project is to develop a new type of scalable elliptic solvers with high parallel scalability, and a  fundamentally new approach in solving Poisson or modified Helmholtz equations in 3-D is proposed. The solution  of these equations constitutes a major computational cost for many computational engineer problems such as  incompressible flows by projection methods, electrostatic potential problems in molecular biology, and enforcing  divergence free constraints of magnetic field in plasma MHD simulations, etc. The approach proposed is based on  combining deterministic local boundary integral equation methods and random Brownian walk probabilistic  representations of PDE solutions, resulting in straightforward parallel non-iterative solvers for the Dirichlet-to  Neumann mappings of the elliptic PDEs, thus the complete solutions of the PDEs with the help of the FMM.  <br/><br/>The high performance computers nowadays use many cores in the order of hundreds of thousands designed for  parallel implementations. The challenging for algorithms designers is to develop highly scalable and parallel  methods to solve the mathematical equations coming from the representations of real world science and engineering  problems. The development of the proposed algorithm in this project is a step toward to achieving such a degree of  scalability and parallelism for problems, such as flow-structure interactions and electrostatics in computational  biology and plasmas. The idea of using both random and deterministic methods in the proposed method is  fundamentally different from traditional purely deterministic methods such as multi-grid and domain decomposition  methods, and has the potential to produce high impact in the field of scientific and engineering computing at  extreme scale."
"1320037","A new computational method for viscoelastic two-phase flows","DMS","COMPUTATIONAL MATHEMATICS","09/01/2013","09/03/2013","Shahriar Afkhami","NJ","New Jersey Institute of Technology","Standard Grant","Leland Jameson","08/31/2016","$252,527.00","","shahriar.afkhami@njit.edu","University Heights","Newark","NJ","071021982","9735965275","MPS","1271","9263","$0.00","The investigator proposes to develop novel computational schemes for the study of flows of viscoelastic liquids in three spatial dimensions. A new formulation that transforms the constitutive equation for viscoelastic stress into a conservative form is proposed. This new formulation is amenable to the use of a state-of-the-art adaptive mesh refinement method on octree finite-volume meshes. The goal of this proposal is to develop discretization and solution algorithms that are designed to not only maintain the higher order accuracy, but also guarantee that the discrete set of algebraic equations possess particular characteristics that are contained in the differential form of the constitutive equations. Different constitutive models for viscoelastic liquids are incorporated into the computational framework, allowing the investigation of the effects of constitutive laws on improved fitting to the experimental measurements, especially in flows which contain stress singularities. Parallelized algorithms combined with adaptive mesh refinement and GPU optimization are expected to significantly improve the efficiency of the direct simulations.<br/><br/>The numerical methodologies constructed in this proposed research, while focusing on addressing two-phase viscoelastic flows, will be broadly-useful in simulating and investigating a number of different complex flow applications such as polymer processing, biological flows in microfluidic devices, and emulsion flows in polymer blending. In nano/microscale geometries, flows of two immiscible liquids are often dominated by surface tension. Moreover, the interface of two liquids may undergo large deformation rates as it moves in networks of nano/microchannels. While the surface tension force discretization proposed in this work overcomes the former, the improvements proposed for discretizing the viscoelastic constitutive equations allow practical direct simulation of viscoelastic flows with strong elasticity."
"1318364","Closest Point Methods for Eigenvalue Problems from Inhomogeneous Structures","DMS","COMPUTATIONAL MATHEMATICS","01/01/2013","03/12/2013","Chiu-Yen Kao","CA","Claremont McKenna College","Standard Grant","Rosemary Renaut","07/31/2016","$219,276.00","","ckao@cmc.edu","500 E. Ninth St.","Claremont","CA","917115929","9096077085","MPS","1271","9263","$0.00","The goal of this project is to develop forward eigenvalue solver based on closest point  method and efficient algorithms for shape optimization for inhomogeneous structure with (1)  general constrains and boundary conditions, (2) fourth order equations (e.g. BiLaplace Operator)  and integro-differential equations, and (3) general surfaces. The closest point method is a new  numerical technique to solve PDEs on a surface based on standard Cartesian grid discretization  via the closest point extension. It will be extended to solve general eigenvalue problems. The approach for extremum eigenvalue is based on Rayleigh formulation and an efficient  rearrangement algorithm to achieve optimal configuration. Two types of rearrangement  approaches will be investigated: full rearrangement and partial rearrangement. The full rearrangement approach looks for the optimal rearrangement at each iteration while the partial rearrangement approach takes moderate changes to have the satisfactory result. The approaches based on shape derivatives and topological derivatives are examples of partial rearrangement. To demonstrate the capability and efficiency of the numerical approach, it will be applied to problems from inhomogeneous materials and population dynamics.         <br/><br/>The broader impact of the work arises from its wide ranges of applications. The PI will  apply the numerical approaches to problems including (1) identifying of composite strings and  membranes with frequency control, (2) finding composite materials with optimal conductivity,  (3) designing composite plates with desired extremum frequency, and (4) investigating eigenvalue optimization in population biology and shape identification in images from different  modalities including magnetic resonance images and optical coherence images. Moreover, the techniques will open a new door to compute spectral information on general surfaces without meshes on surfaces and provide an improved understanding of shape optimization on general surfaces. Software developed as part of this work will be incorporated into numerical courses in graduate study and will be freely available to the public. In the coming three years, the PI will organize mini symposiums on closest point method and shape optimization in the coming SIAM and international conferences to interest more scientists and invite more speakers in the underrepresented groups to broaden the field."
"1319052","Uniqueness and Reconstructions Methods for Inverse Problems","DMS","COMPUTATIONAL MATHEMATICS","07/15/2013","02/11/2016","William Rundell","TX","Texas A&M University","Standard Grant","Leland Jameson","06/30/2017","$280,000.00","Bangti Jin","Rundell@math.tamu.edu","400 Harvey Mitchell Pkwy South","College Station","TX","778454375","9798626777","MPS","1271","9263","$0.00","Specific problems addressed in this proposal include the recovery of the location and shape of interior objects from surface measurements or the determination of obstacles from acoustic or electromagnetic scattering data. In particular, we concentrate on developing extremely fast algorithms designed to detect significant features utilizing only minimal data. One central feature of this proposal is the investigation of inverse problems for so-called anomalous diffusion models. Classical diffusion is based on Brownian motion and has its roots in 19th century physics. Here a very localised disturbance spreads with the characteristic shape of a bell curve and, further, the state of the process at a given time step depends only on the state at the previous time step. While this serves well for a wide range of models, it fails for those that exhibit a ""history"" or ""memory"" effect.  This includes many materials that been developed over the last twenty years as well as economic forecasting such as stock and commodity market modeling. It turns out that degree of ill-conditioning in anomolous diffusion inverse problems can be very different from those of the classical case suggesting that indeed fundamental new physics is involved. From a mathematical and computational standpoint this comes at a price; the resulting analysis is considerably more complex and challenging.<br/><br/>Many objects of physical interest cannot be studied directly. Examples include, imaging the interior of the body, the determination of cracks within solid objects, and material parameters such as the conductivity of inaccessible objects. When these problems are translated into mathematical terms they take the form of partial differential equations, the Lingua Franca of the mathematical sciences. However, since we have additional unknowns in the model, these introduce unknown parameters in the equations that have to be additionally resolved by means of further measurements. In this proposal we deal with the practical aspects of such ""inverse problems"" from a mathematical and computational perspective. We are interested in when a unique determination can be made from a given amount of data, but these inverse problems are characterized by often severe ""ill-conditioning"", meaning that even when there is only one solution to the problem, two very different objects may produce data sets that are infinitesimally close. This aspect makes designing and analyzing algorithms for the efficient numerical recovery of the unknowns extremely challenging. Inverse problems can have multiple scales of complexity. Some, such as earthquake modeling require large scale computational resources and amassing considerable amounts of data. Others rely on obtaining extremely fast computations with minimal data collection; developing algorithms that enable a hand-held scanner to locate flaws in structural materials or portable machines to detect tumors in a noninvasive way. The proposal also has a significant educational component in the training of undergraduate students. Many of the distinct features of inverse problems can be seen from considering applications in vibration, heat conduction and acoustic scattering, and can have a significant hands-on component. The experimental equipment is readily available and cheap. Metal plates make conductive 2D media, a saw cuts an insulating inclusion and cheap thermistors can be used to measure data. Loudspeakers make incident waves, microphones make receivers, the software to go between analogue signals and digital data is on most laptops.  The mystery of the ""hidden"" object can be added by black, light opaque, acoustically transparent speaker cloth. We have amassed much of this equipment already, some of it quite well used in previous undergraduate research experiences."
"1316779","Numerical Algorithms as Dynamcal Systems - Structure Preservation, Convergence Theory, and Rediscretization","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/15/2013","09/06/2013","Moody Chu","NC","North Carolina State University","Standard Grant","Leland Jameson","08/31/2017","$250,000.00","","chu@math.ncsu.edu","2601 Wolf Village Way","Raleigh","NC","276957514","9195152444","MPS","1266, 1271","9263","$0.00","The focus of the project is to improve iterative algorithms in numerical analysis by linking them to particular systems of differential equations. Thirty years ago, it was realized that the QR algorithm for calculating eigenvalues can be considered as a time-T map of the Toda lattice. This opens up the possibility of bringing the qualitative methods of dynamical systems to bear on the algorithm, and to potentially speed up the algorithm by more efficient discretizations. The crucial aspect of the Toda lattice is that it is a continuous conjugation that preserves upper Hessenberg form and therefore the eigenvalues. In recent research, the PI has achieved similar results with the calculation of the singular value decomposition by developing a Lotka-Volterra system that preserves bidiagonal structures, which has led to advances in computing the SVD. This project investigates other dynamical systems preserving symplectic and Hamiltonian structure, which are pivotal in many areas of applications. The ultimate goal is to investigate the connection between their geometric structures and existing numerical algorithms, to establish a rigorous mathematical theory on dynamical behaviors, and to develop possible structure-preserving re-discretizations to improve robustness, speed, and accuracy of iterations in numerical analysis. <br/><br/>Structure-preserving dynamical systems are natural and ubiquitous. Conservation laws in the physical world and constrained mechanics in engineered systems are just two examples. Structure preservation is also imperative in computation because it makes possible more efficient algorithms, improves physical feasibility and interpretability, and is more robust in long-term behavior. The proposed research recasts numerical algorithms as differential systems that mimic the structure-preserving properties of the corresponding iterative schemes. Understanding the overall dynamics of the continuum system can shed light on the convergence properties of the related discrete counterparts, and can also contribute to the re-discretization of the continuum system into a new algorithm with better numerical properties. A wide range of applications stands to benefit from the study of properties and geometric structure of these systems, which essentially include all disciplines that entail structure preservation, including classical and quantum mechanics, model reduction, reversible systems, and molecular dynamics."
"1318641","A computational framework for atherosclerotic plaque growth simulations","DMS","COMPUTATIONAL MATHEMATICS","07/01/2013","09/03/2015","Benjamin Seibold","PA","Temple University","Continuing Grant","Leland Jameson","06/30/2016","$86,277.00","Sunnie Joshi","seibold@temple.edu","1801 N. Broad Street","Philadelphia","PA","191226003","2157077547","MPS","1271","9263","$0.00","The investigators develop a computational framework for the growth of atherosclerotic plaques in large arteries. Specific emphasis is placed on the nonlinear constitutive models for the arterial wall, including residual stresses, and on the bridging of the highly separated time scales that govern this process. This study focuses on the incompressible Navier-Stokes equations that describe the blood flow, coupled with nonlinear elasticity equations that govern the response of the diseased arterial walls. The actual plaque growth process exhibits a large separation of time scales between the growth of the plaque, which takes place over a course of years, and the heart rate, which is in the order of seconds. The investigators develop a methodology to couple a growth model with the fluid-structure interaction problem in a way that the fundamental challenges incurred by the separation of time scales are resolved. In addition, the computational framework allows for the incorporation of variable behavioral factors, such as physical activity and cholesterol concentration in the blood.<br/><br/>While it is known that the rupturing of an atherosclerotic plaque can cause a heart attack, the actual growth process of plaques in arteries is far from well understood. In this project, a computational framework is developed that bridges the highly separated time scales between the plaque growth and the heart rate, and that allows for the incorporation of accurate models for the elastic arterial walls. This new framework can yield fundamental insights into the long-term causes of atherosclerosis, and the dependence of the disease on behavioral factors such as physical activity, cholesterol intake, and tobacco use. In addition, the methodologies developed in this project can find applications in the modeling of damage in elastic materials, other diseases that develop over a large time span such as abdominal aortic aneurysms and intimal hyperplasia, and biological phenomena such as the growth and transport of algae in channel flows and the growth of biofilms. This project involves a collaboration with engineers who measure residual stresses in arteries experimentally."
"1318942","Collaborative Research: Gradient-augmented level set methods and jet schemes","DMS","COMPUTATIONAL MATHEMATICS","07/01/2013","09/03/2015","Rodolfo Rosales","MA","Massachusetts Institute of Technology","Continuing Grant","Leland Jameson","06/30/2017","$176,768.00","","rrr@math.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","MPS","1271","9263","$0.00","This project focuses on high-order generalizations of semi-Lagrangian approaches, called jet schemes (in the context of the transport of field quantities), and the gradient-augmented level set method (GALSM, in the context of interface tracking). These numerical methods achieve high-order of accuracy by tracking certain derivatives of the solution along characteristics. They are optimally local, in the sense that the data used to update the solution at a grid point is located only in a single grid cell, independent of the scheme's order. Moreover, the use of cell-based Hermite interpolations yields a certain level of subgrid resolution, which allows the GALSM to capture structures smaller than the grid resolution. The research in this project focuses on the numerical analysis and parallel performance of the new approaches, as well as their combination with adaptive mesh refinement and with Lagrangian particles. In addition, jet schemes are applied to kinetic equations, and the GALSM is applied to Hamilton-Jacobi equations. The latter results in the introduction of limiters, and provides a path to gradient-augmented re-initialization.<br/><br/>The accurate detection, tracking, and computation of interfaces (curves and surfaces) is an important problem in many areas of science and technology, such as: gas-liquid interfaces in computational fluid dynamics, phase transitions in materials, weather fronts, the motion of biological membranes, edge detection in medical imaging, flame fronts, and shock fronts in supersonic flows. The methods developed in this project allow the computational tracking of interfaces, as well as the evolution of field quantities, with high accuracy. At the same time, they are computationally efficient and very modular. Moreover, they are advantageous for the capture of small structures. This project involves an international collaboration, as well as the training of graduate and undergraduate students."
"1318866","Multiscale Computational Methods with Applications in Materials Science and Tissue Engineering","DMS","COMPUTATIONAL MATHEMATICS, EPSCoR Co-Funding","09/01/2013","08/27/2013","Yi Sun","SC","University of South Carolina at Columbia","Standard Grant","Leland Jameson","08/31/2017","$158,038.00","","yisun@math.sc.edu","Sponsored Awards Management","COLUMBIA","SC","292080001","8037777093","MPS","1271, 9150","9150, 9263","$0.00","In this project the investigator will develop new computational multiscale methods to model and simulate (a) epitaxial growth in materials science; (b) cellular aggregate fusion in organ biofabrication and tissue engineering. Even though the two problems arise from distinct disciplines, they all involve complex phenomena on multiple spatio-temporal scales across several orders of magnitude. Numerically solving these problems directly at the finest scale with standard algorithms inevitably leads to an enormous computational cost. Therefore, it is necessary to develop multiscale methods that share the efficiency of the macroscopic models while achieving the accuracy of the microscopic models. In our methods, the microscale dynamics is described by a lattice model based on the kinetic Monte Carlo algorithm, while ordinary/partial differential equations are used for modeling the macroscale dynamics on continuum level. There are several challenging issues to be addressed in the research: (1) a detailed understanding of the relation between the physical or biological models at different scale levels; (2) how to apply suitable boundary conditions and constraints for microscopic models; (3) systematic and accurate procedures of coarse-graining. Once these issues are addressed, the investigator will extend the ideas produced in this research to a broad range of relevant multiscale problems. This computational approach will also set up a paradigm for investigating (a) both homoepitaxial and heteroepitaxial growth using various material species; (b) cell fusion and tissue/organ fabrication in general by incrementally incorporating additional chemically significant protein dynamics.<br/><br/>This research has the potential to significantly and positively impact relevant applications in materials science, tissue engineering, and cell biology. It can help us to (a) understand the physical and mechanical processes during epitaxial growth, which is an affordable method of high-quality crystal growth for many semiconductor materials and is important in nanotechnology and in semiconductor fabrication; (b) understand the origin of intercellular forces due to cellular responses in cells as well as tissue fusion and quantitatively characterize the mechanochemical process during tissue morphogenesis, accurately predict and optimize postprinting structure formation in organ biofabrication, and intelligently develop approaches in drug design and tissue engineering.  Through collaborating with scientists and engineers from these disciplines, the investigator will develop a suitable computational multiscale framework for solving these problems to better understand complex phenomena in these systems. Educational impact includes interdisciplinary training of graduate and undergraduate students interested in computational mathematics. Special attention will be paid to underrepresented groups including minorities."
"1349855","CAREER: Optimizations for Sparse Solutions and Applications","DMS","COMPUTATIONAL MATHEMATICS","07/01/2013","11/25/2013","Wotao Yin","CA","University of California-Los Angeles","Continuing Grant","Junping Wang","04/30/2014","$61,419.00","","wotaoyin@math.ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","MPS","1271","0000, 1045, 9263, OTHR","$0.00","In many areas such as signal processing, control, statistics, learning, inverse problems, and management, ""large"" data sets are often processed to find ""small"" solutions, those depending ultimately upon a small number of factors. Since these solutions tend to be sparse in a way, it is possible for methods that pick out the sparse solutions to find them from a reduced number of indirect measurements compared to what are usually considered necessary. This is the emerging technology of compressed sensing (CS). In this research, the PI proposes to study a broad range of issues and techniques to advance CS. His proposed reseach includes the introduction of new methodolgies for exploiting solution sparsity to accelerate CS computation, the development of algorithms that utilize operations requiring low storage and maintain robustness to noise and errors in data, and the discovery of efficient methods for minimizing the l1-norms of wide classes of functions such as first and higher-order differences. This project will include an integrated educational program involving a new course, one Ph.D. student, and the participation in the Rice-Houston AGEP program in producing competitive women and minority graduate students.<br/><br/><br/>The new emerging technology of ""compressed sensing"" is a complement to traditional data compression. While the traditional technology encodes digital data using fewer bits in order to save storage and transmission time, the new technology can significantly reduce the time, energy, and cost associated with the acquisition of digital data. This is achieved by acquiring digit information of an object of interest from a reduced number of obervations than what is usually necessary. For example, the life of an aeriel such as a space telescope can be greatly extended due to a lower sampling rate (and thus a lower power demand). Hyperspectral and infrared imaging devices can produce the same images with smaller sensors, or if with the same sensors, images at higher resolution. As such, the new technology can lead to breakthroughs for applications where the bottleneck lies in the high cost of data acquisition.<br/>"
"1318709","Collaborative Research: Gradient-augmented level set methods and jet schemes","DMS","COMPUTATIONAL MATHEMATICS","07/01/2013","07/31/2015","Benjamin Seibold","PA","Temple University","Continuing Grant","Leland Jameson","06/30/2016","$235,310.00","","seibold@temple.edu","1801 N. Broad Street","Philadelphia","PA","191226003","2157077547","MPS","1271","9263","$0.00","This project focuses on high-order generalizations of semi-Lagrangian approaches, called jet schemes (in the context of the transport of field quantities), and the gradient-augmented level set method (GALSM, in the context of interface tracking). These numerical methods achieve high-order of accuracy by tracking certain derivatives of the solution along characteristics. They are optimally local, in the sense that the data used to update the solution at a grid point is located only in a single grid cell, independent of the scheme's order. Moreover, the use of cell-based Hermite interpolations yields a certain level of subgrid resolution, which allows the GALSM to capture structures smaller than the grid resolution. The research in this project focuses on the numerical analysis and parallel performance of the new approaches, as well as their combination with adaptive mesh refinement and with Lagrangian particles. In addition, jet schemes are applied to kinetic equations, and the GALSM is applied to Hamilton-Jacobi equations. The latter results in the introduction of limiters, and provides a path to gradient-augmented re-initialization.<br/><br/>The accurate detection, tracking, and computation of interfaces (curves and surfaces) is an important problem in many areas of science and technology, such as: gas-liquid interfaces in computational fluid dynamics, phase transitions in materials, weather fronts, the motion of biological membranes, edge detection in medical imaging, flame fronts, and shock fronts in supersonic flows. The methods developed in this project allow the computational tracking of interfaces, as well as the evolution of field quantities, with high accuracy. At the same time, they are computationally efficient and very modular. Moreover, they are advantageous for the capture of small structures. This project involves an international collaboration, as well as the training of graduate and undergraduate students."
"1321391","Numerical Methods for Transmission Eigenvalues","DMS","COMPUTATIONAL MATHEMATICS","02/01/2013","06/19/2013","Jiguang Sun","MI","Michigan Technological University","Standard Grant","Junping Wang","07/31/2015","$71,211.00","","jiguangs@mtu.edu","1400 Townsend Drive","Houghton","MI","499311295","9064871885","MPS","1271","6863, 9150, 9263","$0.00","The transmission eigenvalue problem has attracted many researchers in the <br/>scattering and inverse scattering communities recently. Although simply <br/>stated, the problem is not covered by any standard theory of partial <br/>differential equations. Numerical treatment of transmission eigenvalues is <br/>very limited to date. Effective numerical methods will enhance the <br/>understanding of the problem and provide tools for mathematicians and <br/>engineers to compute transmission eigenvalues. This proposal aims at robust <br/>numerical methods for transmission eigenvalues for the Helmholtz equation and <br/>the Maxwell's equations. In particular, the following research topics will be <br/>carried out. 1) Iterative methods for the Helmholtz equation. Based on a <br/>fourth order reformulation, an associated generalized eigenvalue problem will <br/>be solved by the finite element method. Then iterative methods will be applied <br/>to search roots of a related algebraic function which turn out to be the <br/>transmission eigenvalues. 2) Continuous finite element method for the <br/>Maxwell's equations. The transmission eigenvalue problem of the Maxwell's equations will be written in a suitable weak form first. Then the curl conforming edge elements will be used to compute the transmission eigenvalues. 3) Iterative methods for the anisotropic Maxwell's equations. This approach is again based on a forth order reformulation of the transmission eigenvalue  problem of the anisotropic Maxwell's equations. An associated generalized Maxwell's eigenvalue problem will be used to set up an algebraic equation whose roots are the transmission eigenvalues. Then iterative methods can be applied to search the roots of the algebraic equation. It is an extension of the iterative methods for the Helmholtz equation. However, the case for the Maxwell's equations is much more difficult and require additional technical treatment.<br/><br/>The proposed research will be a pioneer numerical study on transmission <br/>eigenvalues for the Helmholtz equation and the Maxwell's equations. The <br/>results are important for the development of mathematical theory for <br/>transmission eigenvalues and can be used to compare various estimates in <br/>inverse scattering theory.  The proposed research will provide mathematicians <br/>and engineers reliable tools to compute transmission eigenvalues. It will lead <br/>to new methods for studying the inverse scattering problems such as inverse <br/>electromagnetic scattering problem for anisotropic media. Since transmission <br/>eigenvalues can be used to estimate material properties of the scattering <br/>object, the proposed research has potential usage in non-destructive testing, <br/>geophysical applications, medical imaging, etc. For example, it is possible to <br/>detect the presence of cavities in the dielectric from the location of the <br/>transmission eigenvalues. The numerical results will be disseminated to <br/>mathematician for analytical study of transmission eigenvalues and engineers <br/>for detection and reconstruction of unknown objects. In addition, successful accomplishment of the proposed project will enhance the research capacity of the university and provide graduate students valuable research opportunities."
"1318832","Computational methods for stochastic models of biochemical reaction systems","DMS","Cellular Dynamics and Function, COMPUTATIONAL MATHEMATICS, MSPA-INTERDISCIPLINARY","08/15/2013","06/24/2014","David Anderson","WI","University of Wisconsin-Madison","Continuing Grant","Leland Jameson","07/31/2017","$249,999.00","","anderson@math.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","MPS","1114, 1271, 7454","8007, 9263","$0.00","The objective of this research project is to develop and analyze next generation stochastic simulation methods for the models found in biochemistry.   Such  models include gene regulatory networks, neural networks, and models of viral infection and growth.  Specifically, the two main research topics considered are the efficient computation of expectations and the efficient computation of parametric sensitivities.  The mathematical focus of the project will the development of Monte Carlo estimators that are unbiased, yet orders of magnitude more efficient than the current state of the art.  To achieve such efficiency, novel coupling procedures, sometimes used in conjunction with the multi-level Monte Carlo framework, will be employed in both project areas.   <br/><br/>Due in part to the appearance of new technologies, most notably fluorescent proteins, there is now a large literature demonstrating that the fluctuations arising from the effective randomness of molecular interactions can have significant consequences, including a randomization of phenotypic outcomes and non-genetic population heterogeneity.  In such cases, stochastic models, combined with both analytical and computational tools, are essential if they are to be well understood.  The problems that will be addressed in this project often form the bottleneck in computational experiments in systems biology.  Hence, the research will make possible many realistic modeling and simulation scenarios that are beyond the range of existing techniques.  As the relevant models include those for both gene networks and viral growth, this project plays a role in improving long-term human health by greatly improving the predictive power of such models."
