"AwardNumber","Title","NSFOrganization","Program(s)","StartDate","LastAmendmentDate","PrincipalInvestigator","State","Organization","AwardInstrument","ProgramManager","EndDate","AwardedAmountToDate","Co-PIName(s)","PIEmailAddress","OrganizationStreet","OrganizationCity","OrganizationState","OrganizationZip","OrganizationPhone","NSFDirectorate","ProgramElementCode(s)","ProgramReferenceCode(s)","ARRAAmount","Abstract"
"1912646","Superconvergent Approximations by Galerkin Methods for Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","06/15/2019","06/14/2019","Bernardo Cockburn","MN","University of Minnesota-Twin Cities","Standard Grant","Yuliya Gorb","05/31/2023","$350,002.00","","cockburn@math.umn.edu","200 OAK ST SE","MINNEAPOLIS","MN","554552009","6126245599","MPS","1271","9263","$0.00","The computer simulation of physical phenomena is a highly valued tool of practical interest in  a wide variety of applications in Engineering and Physics. The investigator will study two new, promising techniques of carrying out these simulations with highly accurate and more efficient algorithms for a wide range of problems of practical interest. They include many applications to Aerospace and Mechanics (heat flow, incompressible fluid flow, subsonic and supersonic flow) as well as to Civil and Mechanical Engineering (seismic wave propagation and elastodynamics of solid structures).<br/><br/>The investigator proposes to continue to develop a recently uncovered adjoint-recovery method which can reduce the cost of computing  approximations of linear and nonlinear functionals by Galerkin methods by several orders of magnitude. The incorporation of adaptivity techniques, to deal with the varying degree of regularity of the solution, and the extension of this approach to the computation of nonlinear functionals, like the eigenvalues of a differential operator,  will render the method of great practical value. The investigator will also develop new discretization techniques for partial differential equations with Hamiltonian structure. They combine superconvergent discontinuous Galerkin space discretizations with symplectic time-marching schemes and result in methods with an energy which does not drift. Such methods  are important in many applications including seismic wave propagation and elastodynamics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913093","Lubricated Immersed Boundary Method: Numerical Analysis, Benchmarking, and Applications","DMS","COMPUTATIONAL MATHEMATICS","06/15/2019","06/03/2019","Thomas Fai","MA","Brandeis University","Standard Grant","Yuliya Gorb","05/31/2023","$226,102.00","","tfai@brandeis.edu","415 SOUTH ST","WALTHAM","MA","024532728","7817362121","MPS","1271","9263","$0.00","Fluid-structure interaction is common in biological problems and engineering applications. In many cases of interest, such as red blood cell motion through the microcirculation and the opening and closing of the heart valves, small-scale fluid flows between structures in near-contact are important for the overall behavior. The presence of multiple scales in these problems poses challenges for both modeling and simulation. Whereas existing methods such as adaptive mesh refinement use algorithmic techniques to bridge these scales and incur significant computational costs, here the research develops an alternative method in which the governing equations are replaced at small scales by a much simpler asymptotic limit.<br/><br/>The goal of this project is to develop an improved version of the immersed boundary method that uses lubrication theory to model fluid flows between structures in near contact. The immersed boundary method is a widely used approach for modeling fluid-structure interaction. A longstanding limitation of this method is that structures that are in near contact tend to stick together, so that they require unphysically large forces to separate. The lubricated immersed boundary method uses lubrication theory as a subgrid model to overcome this difficulty of the classical method. Because lubrication theory is exact in the limit that the spacing between two structures goes to zero, the accuracy of the subgrid model improves as structures come closer together. This research analyzes and benchmarks the lubricated immersed boundary method. Specific aims include performing a multiscale numerical analysis, developing efficient implementations in three dimensions, and investigating higher-order accurate extensions based on the immersed interface method.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1847770","CAREER: A Multiscale Framework for Crystalline Defects in 2-Dimensional Materials","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","05/30/2023","Xingjie Li","NC","University of North Carolina at Charlotte","Continuing Grant","Yuliya Gorb","06/30/2024","$400,000.00","","xli47@uncc.edu","9201 UNIVERSITY CITY BLVD","CHARLOTTE","NC","282230001","7046871888","MPS","1271","1045, 9263","$0.00","Two-dimensional (2D) materials such as graphene are structures that have thickness on the atomic scale (one atom thick in the case of graphene) which have revolutionized many fields in materials science and nanotechnology. Currently, little is known about the mathematical formulation to systematically study these 2D few-layered structures, or about multiscale modeling to reliably quantify how defects affect materials properties. The overarching goal of this project is to develop constitutive mathematical models and computational tools to provide a fundamental understanding of defect mechanisms and their influence on mechanical and electronic properties and to help the control and design of defects inside 2D materials. This research lies at the intersection of multiple disciplines, and the purpose of the project is to bridge the computational and theoretical gaps to meet the modeling demands. The educational goal of this project is to motivate next generation of students to participate in STEM study and to seek a STEM career.<br/><br/>This project focuses on the development of a new and quantitative coupling framework for defective 2D systems in the following specific directions: (1) introduce computational schemes to cross the length scales for thin structures, employ mathematical tools to identify sharp coupling conditions, and establish comprehensive error estimates which allow defects in the analyses, (2) develop new interface absorbing conditions to minimize wave reflection for modeling fracture propagation, establish a posteriori error analysis for the adaptivity of computation, (3) investigate time-accelerated schemes to study thermally-activated defects, and (4) develop constitutive mathematical models and computational tools to study the essential impacts of defects on the electronic properties. The computational tools and the developed methodology can also be applied to a wide range of physical and science problems. Computational open-source software will be developed to contribute to the advancement of nanomaterial research and technology. For the educational component, this project will provide a research and outreach platform to prepare and train students for interdisciplinary research and to disseminate knowledge of a range of educational levels from K-12 students to young postgraduate researchers and to the general public in the U.S. Successful completion of this project will also greatly facilitate the mission and goals of encouraging students from middle school student to graduate to pursue a STEM career by a variety of outreaching activities.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1848508","CAREER: Optimal Approximation Algorithms in High Dimensions","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","08/16/2023","Akil Narayan","UT","University of Utah","Continuing Grant","Yuliya Gorb","07/31/2024","$400,000.00","","akil@sci.utah.edu","201 PRESIDENTS CIR","SALT LAKE CITY","UT","841129049","8015816903","MPS","1271","1045, 9263","$0.00","The increasing power of modern computational hardware has enabled computer-based simulation of sophisticated mathematical models that resolve important physical phenomena in great detail. With the advent of these computational abilities has come an increased demand to include more complex physical interactions in the models, and thus an increased strain on computational resources. Modern engineering design utilizes such models, and these design problems typically involve (1) numerous tunable parameters that affect reliability, cost, and failure, (2) uncertainty about external influences manifesting as randomness in the model, and (3) epistemic ignorance involving model form uncertainty. In realistic applications, the collection of these effects leads to predictions that depend on a cumulatively high-dimensional parameter. This project focuses on development and deployment of novel, near-optimal experimental design and sampling algorithms for the accurate and efficient simulation of physical models parameterized by high-dimensional inputs. The work of this project involves the application of recently developed approximation theory results in the computational arena, targeted advances that extend theoretical mathematics for computational purposes, and the development and implementation of algorithms for large-scale computations.<br/><br/>The technical aspects of this project are designed to provide feasible computational algorithms and concrete mathematical guarantees for tasks in high-dimensional approximation. The three major core components for the completion of this task involve the design, implementation, and analysis of algorithms that leverage optimality characteristics of (1) random and deterministic experimental and sampling design, (2) computational algorithms for identifying efficient sampling schemes, and (3) strategies and techniques for emerging approximation paradigms such as sparse approximation and dimension reduction. A crosscutting theme is application of these methods to problems of modern interest in scientific computing. This project involves fundamental contributions to the fields of applied approximation theory and computational approximation methods through the development of applications-oriented sampling designs with provable near-optimality. Theoretical investigations of this project connect classical techniques in approximation and linear algebra with emerging algorithms in data reduction and reduced order modeling. The implementation of these algorithms will significantly enhance theoretical understanding and computational feasibility for goal-oriented design, parameter study and reduction, sparse and compressive representations, model verification and calibration, and data-driven simulations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912938","Modeling with Constraints and Phase Transitions in Porous Media","DMS","COMPUTATIONAL MATHEMATICS","07/15/2019","05/14/2019","Malgorzata Peszynska","OR","Oregon State University","Standard Grant","Yuliya Gorb","06/30/2024","$224,402.00","","mpesz@math.oregonstate.edu","1500 SW JEFFERSON ST","CORVALLIS","OR","973318655","5417374933","MPS","1271","9263","$0.00","The changes in sea temperatures and those in permafrost regions have influence on hydrological, climate, and human systems on the time scale of years and decades. The freezing and thawing of permafrost leads to subsidence and development of hills and depressions; these alter the direction of surface waters, and challenge the stability of construction. Warming of permafrost causes decay of biomass as well as release and transport of methane gas from hydrate and other stores underneath the frozen layers. Methane gas is a major contributor to greenhouse gas balances, and its presence, transport, and evolution, as well as that of  methane hydrate, an ice-like substance, are of great interest in geophysics, climate studies, and energy engineering. Methane hydrate can dissociate to gas, and is a potential unconventional energy source, drilling hazard, and contributor to sub-sea slope instability.  The realistic scenarios and case studies motivating this work include the melting of ice to water and dissociation of methane hydrate into gas in response to increased temperature or mechanical disturbance, with the liquid and gas phases traveling through the sediment. Models of similar nature also apply to bubble and steam transport, e.g., due to microbial activity, or in geysers. In this project the principal investigator will develop new mathematical results as well as those useful for geophysics, and continue interdisciplinary modeling efforts across the many fields. <br/> <br/>This project addresses mathematical and computational challenges arising in the  models of phase change in porous media such as permafrost or sub-sea sediments, and the evolution and migration of the resident liquid and the dissociated gas phase. For these coupled processes of  energy and  mass transport, data and some nonlinear model systems of PDEs at the spatial and temporal (Darcy) scale of the reservoir are available. However, the new dynamics in the Earth's environment calls for further insights into the processes across the several interlinked spatial and temporal scales including the pore-scale.The models at the pore-scale  bridge the physics between the interface and Darcy scales, account for confinement within the porous walls and complex geometries, and can be upscaled to Darcy scale.  While x-ray micro-tomography can deliver unprecedented insight into pore-scale processes, at present, this data is rather sparse for conditions near phase transitions. These challenge the current knowledge and motivate the project. The research will advance the understanding of the  micro-scale (pore-scale and interface scale) processes which inform the Darcy scale models.  The project will develop and analyze algorithms for relevant models; many techniques and results are of independent interest.  The evolution models the principal investigator will consider are complex and delicate, and involve pointwise constraints on the solutions in and out of the equilibrium.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1845406","CAREER: Fast and Accurate Algorithms for Uncertainty Quantification in Large-Scale Inverse Problems","DMS","COMPUTATIONAL MATHEMATICS","09/01/2019","07/25/2023","Arvind Saibaba","NC","North Carolina State University","Continuing Grant","Yuliya Gorb","08/31/2024","$400,000.00","","asaibab@ncsu.edu","2601 WOLF VILLAGE WAY","RALEIGH","NC","27607","9195152444","MPS","1271","1045, 9263","$0.00","The need to visualize regions that are impossible to see with the naked eye is pervasive in everyday life. For example, in medicine, accurate visualization of tissue is needed to diagnose and treat tumors. A key step in imaging technologies requires one to solve an inverse problem in order to transform measured data into detailed image reconstructions of the quantities of interest. However, image reconstruction is inherently uncertain, in part, due to noisy measurements from sensors. Ignoring the uncertainty in the imaging process can lead to undesirable outcomes, such as misjudging the location and spread of a suspected tumor. Uncertainty Quantification (UQ) in imaging is in its infancy and hence, the potential for impact in research contributions is high. UQ for imaging is computationally challenging since thousands of inversions are needed beyond the initial inversion to generate accurate statistics of the uncertainty. Current approaches for UQ are inadequate because they either fail to deliver solutions in a reasonable computational time or they lack the applicability across a broad range of imaging technologies.<br/><br/><br/>The project is on the development of fast algorithms for UQ in large-scale inverse problems that are applicable to a broad range of imaging technologies. These algorithms are expected to bring down the computational cost by at least an order of magnitude while maintaining the accuracy of the solutions. More specifically, the project will (1) Advance image reconstruction and UQ techniques for incorporating prior information based on fractional partial differential equation (PDE) and Bayesian level set approaches; and (2) Develop new algorithms and analysis for data-driven dimensionality techniques for UQ in Bayesian inverse problems, using randomized and Krylov subspace methods. The algorithms developed here will be rigorously analyzed and validated on several model problems and applications, including diffuse optical and photoacoustic tomography (in biomedicine) and hydraulic tomography and satellite data fusion (in geoscience). The algorithms developed here are also applicable to other imaging-based inverse problems in biomedicine, geophysics, materials science, etc. Outside of imaging applications, these mathematical advances will be of interest to scientists working in many areas of computational science, for example, fractional partial differential equations (PDEs), model reduction, tensor decompositions, and principal component analysis. Lastly, the PI's education and outreach activities will make UQ and imaging technologies more modular, accessible, and easier to understand for pre-service and early career K-12 educators, undergraduate students, and graduate students. Specifically, the educational program of this project will: (1) Strengthen STEM education through teacher training workshops and practical research experiences for pre-service and early career K-12 teachers, which will result in reproducible teaching modules for use in K-12 education; and (2) Enhance undergraduate and graduate curriculum at North Carolina State University by creating accessible seminar talks and new course content.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912715","Modeling and Hybridizable Discontinuous Galerkin Methods for Two-phase Flows in Karstic Geometry","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","07/30/2019","Daozhi Han","MO","Missouri University of Science and Technology","Standard Grant","Yuliya Gorb","07/31/2022","$99,951.00","","daozhiha@buffalo.edu","300 W 12TH ST","ROLLA","MO","654096506","5733414134","MPS","1271","9150, 9263","$0.00","A prime example of multi-phase flow in karstic geometry is flow in natural karst aquifers. Karst aquifers supply  about 40 percent of the drinking water in the United States, and are susceptible to contamination. During flooding seasons, the water pressure in the conduits is larger than that in the adjacent porous media so that conduit-borne contaminants are driven into the porous media. Likewise during dry seasons, contaminants sequestered in the porous media are released into flow in the conduits due to the pressure reversal,  and exit through springs and wells into surface water systems. This exchange of flow between conduits and porous media poses an environmental issue in that sequestered contaminants may influence the quality of underground water sources and thus significantly decrease water availability.  Besides applications in environmental science, multi-phase flows in karstic geometry are also important in oil recovery in petroleum engineering, in Polymer Electrolyte Membrane fuel cell technology, as well as in cardiovascular modeling and simulation in biomedical sciences. In these applications multi-phase flows in conduits and in porous media interact with each other, and therefore have to be considered together. Geometric configurations that consist of both conduits and porous media are termed as karstic geometry. Despite the importance of the subject, little work has been done in this direction, due to the nature of deforming boundary of the problem, the complex geometry, the coupling of different dynamics via domain interface, the vast disparity of spatial and temporal scales and so on.<br/><br/>The investigator will examine modeling and the design of hybridizable discontinuous Galerkin (HDG) methods for two-phase flows in karstic geometry. Based on the phase field formalism and Onsager's variational principle, the PI will derive a degenerate Cahn-Hilliard-Stokes-Darcy model for two-phase flow of arbitrary density and viscosity contrast in karstic geometry. The derivation seeks to overcome a number of obstacles in modeling of multiphase flows in karstic geometry, including maintaining a divergence-free velocity, deriving an explicit degenerate mobility function, and incorporating multiphysics such as wetting and solute. The PI then will introduce and analyze superconvergent HDG methods for solving the diffuse interface model by exploiting approximation via polynomials of mixed orders and by carefully stabilizing the nonlinear advection in the presence of high-order diffusion. Finally, the PI and his collaborators will develop scalable HDG multigrid solvers for diffuse interface fluid models. The practical solvers will further address the lack of efficient iterative solvers in the HDG community. Graduate students will participate in the work of this project.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913364","Improving Numerical Methods for Large Eigenvalue Problems","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","07/22/2019","Zhaojun Bai","CA","University of California-Davis","Standard Grant","Yuliya Gorb","07/31/2023","$250,000.00","","bai@cs.ucdavis.edu","1850 RESEARCH PARK DR, STE 300","DAVIS","CA","956186153","5307547700","MPS","1271","9263","$0.00","Eigenvalue problems are the cornerstones of computational science and engineering. They arise in applications ranging from electronic structure calculations in physics and chemistry, dynamic of supramolecular systems in biology to structural and vibration in civil and mechanical engineering. Emerging applications include the investigation and design of new materials such as Lithium-ion electrolyte and graphene and the study of dynamics of viral capsids of supramolecular systems such as Zika and West Nile viruses. These applications require large number of eigenvalues. The capability of being able to efficiently compute large number of eigenvalues will not just be appealing, but also mandatory for the next generation of eigensolvers. In this project, we will undertake synergistic efforts to develop mathematical theory and numerical methods for large eigenvalue problems. The outcome of this project will provide mathematical theory and computational tools for scientists and engineers to obtain more precise simulation outputs in much less time, and to allow them to pursue more productive simulation strategies. This project will integrate research activities into interdisciplinary teaching, education and training of graduate students in the forefront of computational mathematics.  One graduate student will be funded by this award.<br/><br/>To address challenging issues of existing algorithms and software for large linear eigenvalue problems, we will focus on two core techniques. One is an explicit external deflation for reliably moving away the computed eigenpairs to prevent the algorithm from computing over again those quantities. The second technique is a communication-avoiding matrix powers kernel for fast sparse-plus-low-rank matrix-vector products in Krylov subspace solvers with the explicit external deflation. For large nonlinear eigenvalue problems, we develop mathematical theory and algorithm templates for guiding the design and implementation of approximation based nonlinear eigensolvers. In addition, we will explore an emerging formulation of large nonlinear eigenvalue problems where underlying nonlinear matrix-valued functions are not explicitly available.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1854299","FRG: Collaborative Research: Non-Smooth Geometry, Spectral Theory, and Data: Learning and Representing Projections of Complex Systems","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","06/21/2019","John Harlim","PA","Pennsylvania State Univ University Park","Standard Grant","Yuliya Gorb","06/30/2023","$343,426.00","","jharlim@psu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271","079Z, 1616, 9263","$0.00","Complex, time-evolving systems are ubiquitous in nature and society, with examples ranging from the Earth's weather and climate, to the function and dynamics of biomolecules, and the behavior of markets and economies. Despite their apparent complexity, many such systems exhibit a form of underlying organized structure (``building blocks''), whose discovery would enhance our ability to understand and predict a wide range of phenomena. The goal of this project is to develop the next generation of mathematical and algorithmic tools that can harness the information content of large datasets acquired from experiments and observations to create coherent representations of complex systems, and use these representations to perform prediction, and ultimately, control. These objectives will be addressed through a novel combination of mathematical techniques, bridging dynamical systems theory and differential geometry with machine learning and data science. The newly developed techniques will be tested and applied in real-world problems through collaboration with domain experts in the areas of climate dynamics, space physics, and condensed matter physics. The project will also contribute to STEM workforce and curricular development through training of students and postdoctoral researchers, and design of multi-disciplinary lecture courses. In particular, this project will support one graduate student at each of the three universities involved.<br/><br/>The modern scientific method is undergoing an evolutionary change wherein large data sets and machine learning algorithms have the potential to outperform classical first-principles approaches for certain complex phenomena.  For these tools to be accepted by the scientific community, a rigorous mathematical framework is required to match the verifiability and quantifiability of the classical modeling approach.  Recently, a new tool called the diffusion forecast has been developed based on provably consistent estimators, which learn the unknown structure of a large class of stochastic dynamical systems on manifolds.  Moreover, the results of many published numerical experiments indicate that this framework can be applied far beyond the restricted context of the current theory.  In particular, the evidence suggests that the consistency proofs can be extended to non-autonomous projections of complex systems, deterministic chaotic systems represented by non-compact operators, non-smooth domains such as fractal attractors, and even generalized tensors on metric-measure spaces. This project will undertake a rigorous mathematical unification of these problems, leading to transformative advances in our ability to model and describe complex systems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913291","GOALI: Numerical Methods for Multiphase Flows in Porous Media","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","08/01/2019","07/29/2019","Beatrice Riviere","TX","William Marsh Rice University","Standard Grant","Yuliya Gorb","07/31/2023","$305,397.00","Michael Sekachev","Beatrice.Riviere@rice.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","MPS","1253, 1271","1504, 9263","$0.00","This collaborative project with the oil and gas industry aims to result in improved models of oil production from reservoirs. While there has been extensive work in academia on modeling subsurface fluid flows, many of the methods fall short in delivering accuracy and robustness on real reservoirs. Indeed, there are industrial constraints on the reservoir data, which this project will address by a close collaboration between university and industry partners. The project focuses on two-phase flow, for instance the flow of oil and water. Many of the techniques under development can be applied to black-oil (three-phase flow) or compositional models. One anticipated outcome of this project is an accelerated transfer of technology from academia to industry. Another impact is the training of students on industrial problems. State-of-the-art algorithms developed by faculty and students will be applied to solve challenging problems relevant to the industry. This could have the potential of transforming the current computational tools used by the industrial partner and beyond. <br/><br/>This project has two main goals. First, a multi-numerics approach will be developed to produce fast and accurate numerical simulations of two-phase flow in complex reservoirs. The numerical model couples finite volume methods with discontinuous Galerkin methods on non-overlapping domains, and it utilizes optimal coupling conditions between the subdomains. The popularity of finite volume methods combined with the accuracy and flexibility of discontinuous Galerkin methods are key positive features of the coupled method. A second goal of the project is a new finite element scheme that employs physical unknowns, such as phase pressure and phase saturation. Using a compactness argument, the numerical approximations of the phase pressure and saturation are shown to converge strongly to the weak solution, even in the case of degenerate relative permeability coefficients. The convergence analysis is based on deriving bounds for the gradient of the phase pressure, using intermediate variables like global pressure. This new scheme is motivated by the industry constraints of using physical primary unknowns in reservoir simulations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913039","Collaborative Research: Sparse Optimization in Large Scale Data Processing: A Multiscale Proximity Approach","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","06/11/2019","Lixin Shen","NY","Syracuse University","Standard Grant","Yuliya Gorb","06/30/2023","$125,000.00","","lshen03@syr.edu","900 S CROUSE AVE","SYRACUSE","NY","132440001","3154432807","MPS","1271","9263","$0.00","There is an emergent demand in areas of national strategic interest such as information technology, nanotechnology, biotechnology, civil infrastructure and environment for abstracting useful knowledge for decision making or uncovering truth from large-scale data acquired via various means such as sensors and internet. A core issue of these areas is to develop accurate mathematical models, which govern the abstraction process, and to design efficient algorithms that solve the underlying optimization problems for the models. A challenge of the tasks comes from the large-scale nature of given data. This nature requires determining a large number of model parameters and it is computationally expensive. To address this challenge, this project will take advantage of certain intrinsic multiscale structure of given data in modeling so that the resulting models have significantly fewer parameters to be determined. It is also crucial to introduce efficient algorithms for solving the resulting optimization problems for the models, which have intrinsic multiscale structures. The second goal of this proposed research is to provide rigorous training of young mathematicians and computational scientists so that they have the skill sets needed to face the challenges of the big data era through this proposed research and its associated educational components. Outcomes of the proposed research and its educational component will certainly contribute to the Federal strategic interest areas.<br/><br/>This research project addresses several critical issues of processing large-scale data, such as high dimensionality and high noise, through properly choosing structured sparsity promoting non-convex functions in modeling and through synthesizing the multiscale representation of data and using fixed-point equations/inclusions involved the proximity operator in solving the resulting optimization problem. Structured non-convex sparsity promoting functions are proposed to overcome drawbacks of the existing modeling of large-scale data, leading to the design of efficient single-scale proximity algorithms. Multiscale analysis has been developed to efficiently represent data, while how multiscale representation of data is used to improve convergence of the fixed-point proximity algorithm remains unsolved. The proposed multiscale proximity method avoids iterations on the full large-scale of the fixed-point equation/inclusion. Instead, when data are represented in a multiscale analysis, iterations of the multiscale proximity algorithm are conducted only on a (small-scale) lower frequency component of the equation/inclusion (based on a single-scale algorithm), and only one functional evaluation on a (large-scale) high frequency component is required. The multiscale algorithm will preserve accuracy of the single-scale algorithm while accelerating its convergence significantly. This leads to a fast algorithm for solving the fixed-point equation/inclusion involved the proximity operator.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912716","High Order Numerical Methods for Gravitational Wave Computations","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","06/20/2019","Scott Field","MA","University of Massachusetts, Dartmouth","Standard Grant","Yuliya Gorb","09/30/2023","$275,000.00","Sigal Gottlieb, Gaurav Khanna","sfield@umassd.edu","285 OLD WESTPORT RD","NORTH DARTMOUTH","MA","027472356","5089998953","MPS","1271","9263","$0.00","The research area of black hole astrophysics has experienced a major transformation as a result of multiple recent breakthroughs -- a Nobel Prize-winning discovery of gravitational waves from black hole and neutron star binary systems by the US LIGO detectors, and the first-ever image of the horizon of a black hole by the Event Horizon Telescope. Gravitational waves were predicted by Einstein himself a century ago and had never been directly observed before. Ongoing observations of these waves from compact binary systems will be used to obtain additional information about exotic astrophysical objects in the universe like black holes and neutron stars. LIGO has also generated significant spin-off technologies and strongly drawn public attention towards STEM disciplines. This proposed project aids in the development of advanced computational models that will play a very critical role in the future success of LIGO and upcoming space-borne missions like LISA. The main objective of the proposed project is to develop new computational techniques to meet the high-accuracy and high-efficiency requirements set by the LIGO and LISA data-analysis effort. This project includes support for students (including women and minorities) and therefore directly contributes to student mentorship, traineeship, and retention in an important STEM area. The computational skills that the students develop are broadly applicable, and therefore would allow them access to a variety of career options, including in areas of great national need. Previous research projects by the PIs have been discussed in the general media, and this work also has great potential at being successful for outreach to the general public.<br/><br/>The proposed work addresses the ""Windows on the Universe"" challenge by developing and adapting spatial and time-evolution methods for use in gravitational wave simulations. Specifically, Aim 1 will develop a one dimensional discontinuous Galerkin method to solve the Teukolsky equations. This method tracks the particle and keeps it at the domain interfaces while computing the derivatives of the Dirac delta functions as matching conditions at the boundary of the domain. This approach simulates the in-spiral phase to extremely high accuracy. However, for an accurate simulation of the plunge and ring-down phase we require a shock capturing scheme that can handle derivatives of the Dirac delta function and provide highly efficient and accurate multi-dimensional numerical results. For this, Aim 2 will develop a very high order WENO solver that will include the ability to handle up to third derivatives of the Dirac delta function and be made highly efficient in the regions away from the discontinuity. Finally, efficient and accurate time evolution approaches must be tailored to the spatial schemes in Aims 1 and 2. For this, Aim 3 will develop stable and efficient time-discretizations tailored for the spatial schemes in Aims 1 and 2. For each spatial discretization, time-discretization approaches such as Runge-Kutta and multi-step Runge-Kutta methods will be tailored such that the methods are low storage, computationally efficient, have small dispersion errors, small error constants, and stability regions that are tailored to the spatial discretization, and (for WENO) optimal SSP time-steps. The proposed developments in both spatial and temporal discretizations will lead to more efficient methods that can accurately and efficiently handle long time-integration and the presence of Dirac delta functions and its derivatives. Furthermore, the development of an accurate, efficient numerical solver capable of generating waveforms over sizable portions of the parameter space is a major advance in the computation of gravitational waves, and will thus have a major impact on the field of gravitational wave science.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913120","Novel High Order Accurate Finite Difference Schemes Constructed via Superconvergence of Finite Element Methods","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","06/20/2019","Xiangxiong Zhang","IN","Purdue University","Standard Grant","Yuliya Gorb","06/30/2023","$175,000.00","","zhan1966@purdue.edu","2550 NORTHWESTERN AVE STE 1900","WEST LAFAYETTE","IN","479061332","7654941055","MPS","1271","9263","$0.00","The research on novel computational tools will benefit both computational mathematics and interdisciplinary computational disciplines with not only deeper mathematical understanding of advanced simulation technology but also further development of existing popular scientific computing software. The study on novel finite difference schemes will provide rigorous justification and robustness guarantee on simplified implementation of high order accurate numerical methods for simulating physical phenomenon such as wave propagation and convection diffusion process with wide applications including gas dynamics, plasma dynamics, inertial confinement fusion, etc. Progress in novel and efficient high order accurate methods will impact on simulation technology in such applications.  <br/> <br/>Among other popular numerical methods, the finite element method has been the most successful one thanks to its rich analysis theories and flexibility for complex geometries. On the other hand, many real world applications are given on or can be transformed to a rectangular domain, on which finite difference (FD) type schemes are preferred due to their simple data structure and easy implementation. The PI proposes to explore construction of novel finite difference type schemes based on superconvergence of finite element method to obtain simpler construction of high order accurate numerical schemes, e.g., a fourth order accurate finite difference scheme can be constructed by using only quadratic polynomials. One major advantage of this approach is the simpler algebra in high order schemes since lower order polynomials are involved. Moreover, simple algebraic representation makes it easier to analyze discrete properties of high order schemes, such as the discrete maximum principle for variable coefficient diffusion operators.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1902214","Mathematics - Opportunities in Research and Education (MORE)","DMS","INFRASTRUCTURE PROGRAM, ALGEBRA,NUMBER THEORY,AND COM, COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY, Combinatorics","08/01/2019","01/20/2023","Gretchen Matthews","VA","Virginia Polytechnic Institute and State University","Standard Grant","Yuliya Gorb","07/31/2024","$29,320.00","Julianne Chung, Lauren Childs, Michael Robert","gmatthews@vt.edu","300 TURNER ST NW","BLACKSBURG","VA","240603359","5402315281","MPS","1260, 1264, 1271, 7334, 7970","7556, 9263","$0.00","The participation of underrepresented students in mathematical sciences doctoral programs is an issue of national concern. MORE: Mathematics - Opportunities in Research and Education is a new, annual workshop designed to increase the number of these students who pursue graduate degrees in mathematics; develop a peer network for support in continuing education and career goals; and equip participants with strategies to increase retention among those who enter graduate programs in the mathematical sciences. This is achieved through a unique active workshop format engaging students in highly relevant mathematics tied to applications that address societal needs. MORE specifically targets and prioritizes the participation of female, minoritized, and/or first-generation college students, involves them mathematics via experiential learning in a collaborative setting, establishes a peer/mentor community, and provides them with insight on and support for mathematical graduate experiences. The MORE workshop gives participants strength in numbers in ways that mobile their collective promise in mathematics, thus leading to a better qualified and more diverse workforce.<br/><br/>The MORE: Mathematics - Opportunities in Research and Education conference serves as an early professional development and community-building opportunity for undergraduate mathematical sciences majors.  The target audience for the workshop includes women, first-generation college students, and students traditionally under-represented in the mathematical sciences. In addition to helping students build a peer mentoring network, the workshop will introduce students to current research questions introduced by two topical plenary speakers.  These presentations will be followed by working group sessions, where students advance the research question through guided discussion and exploration led by graduate students. Topics are selected for their timeliness and accessibility. Panels and other activities are arranged to demystify the graduate school experience. Graduate students assisting in cooperative breakout sessions will receive mentor training, providing them with translational skills. MORE also provides materials to a larger audience through its Get MORE page, which highlights upcoming opportunities of interest, and the SEGS: Success and Enrichment in Graduate School page, which focuses on topics that are tied to documented barriers to success for the target group of participants.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913050","RUI: Efficient Numerical Methods for Axisymmetric Problems","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","06/21/2019","Minah Oh","VA","James Madison University","Standard Grant","Yuliya Gorb","06/30/2023","$100,000.00","","ohmx@jmu.edu","800 S MAIN ST","HARRISONBURG","VA","228013104","5405686872","MPS","1271","9229, 9263","$0.00","An axisymmetric problem is a problem defined on a three-dimensional (3D) domain that is symmetric with respect to an axis. These problems arise in various applications in the field of biomedical engineering, electromagnetism, and optics. An axisymmetric problem can be reduced to a sequence of two-dimensional (2D) problems by using cylindrical coordinates and a Fourier series decomposition. A discrete problem corresponding to a 2D problem is significantly smaller than a discrete problem corresponding to a 3D one, so such dimension reduction is an attractive feature considering computation time. The resulting 2D problem, however, is posed in weighted function spaces and is mathematically quite different from the analogous ""standard"" 2D problems, so special care is required when developing numerical methods that are well-fit for these weighted 2D problems. In this project, we will study efficient numerical techniques with solid mathematical support that can be applied to axisymmetric problems including those that arise in the treatment of various cancer treatments.  <br/> <br/>The first goal of this project is to perform multigrid analysis for axisymmetric H(curl) and H(div) problems with general data including the axisymmetric time harmonic Maxwell equations. Multigrid for axisymmetric H(curl) and H(div) problems have been studied previously under the assumption that the data is independent of the rotational variable, which is not the case for most applications. Therefore, this project will bring new results for general axisymmetric problems with meaningful applications in Hepatic Microwave Ablation, an alternate treatment to liver, breast, bone, and lung cancer. Undergraduate students will be a part of evaluating the performance of multigrid in designing efficient antennas that can be used for these cancer treatments. Furthermore, this project will provide new mathematical tools to study axisymmetric problems with general data as well.  The second goal of this project is to study axisymmetric state-constrained elliptic optimal control problems with axisymmetric data by using P1 finite element methods. There are very few studies done on axisymmetric optimal control problems, so this will be new and significant. The PI will also run a ""Numerical Analysis Day"" for local high school students with her undergraduate students from the James Madison University Association for Women in Mathematics Student Chapter.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912906","Collaborative Research: Data-driven Path Metrics for Machine Learning","DMS","COMPUTATIONAL MATHEMATICS","07/15/2019","07/12/2019","Anna Little","MI","Michigan State University","Standard Grant","Yuliya Gorb","06/30/2021","$150,000.00","Matthew Hirn, Yuying Xie","little@math.utah.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1271","075Z, 079Z, 9263","$0.00","The era of big data has introduced unprecedented computational and mathematical challenges. Traditional machine learning algorithms often lack scalable computational complexity, while modern approaches lack solid mathematical foundations. Moreover, high data dimensionality creates challenges for traditional methods of data analysis. The principal investigators (PIs) propose to combine classic dimension reduction methods with data-driven distances, so that both the distance and embedding procedure are data dependent. This novel approach allows for greater flexibility in balancing the density-based and geometric features of the data, achieves a density-based simplification of geometry, and insightfully represents the data in a small number of dimensions. In contrast to black box methods such as deep learning, the developed methodology can be rigorously analyzed to derive strong theoretical guarantees for several statistical and machine learning tasks. This research will contribute computational tools for cancer immunogenomics and the investigators will consult with the Rogel Cancer Center at the University of Michigan for scientific questions related to tumor immunology and T-cell biology. In addition, new data analysis tools will be made publicly available in an open source software package. <br/><br/>The investigators' approach is driven by the analysis of a family of data-dependent path metrics. These metrics are both density-sensitive and geometry-preserving, with the balance governed by the choice of a single parameter p. By utilizing the space of paths through data, the PIs will obtain density based metrics and embeddings while avoiding the explicit computation of a density estimator, which may be unreliable in a large number of dimensions. The PIs will propose a simple yet highly flexible data model which does not assume the data is sampled from a manifold or collection of manifolds, and investigate the continuous limit of these metrics and an associated graph Laplacian operator. By continuously varying the parameter p, the PIs will propose to create data videos which represent the data from multiple perspectives. The PIs will investigate both multidimensional scaling and graph Laplacian embeddings as mechanisms for obtaining path-based low dimensional representations, and will explore fast algorithms with scalable computational complexity for approximating these metrics. The PIs will contextualize path metrics in the larger frame work of data-driven metrics and focus specifically on the analysis of biological data.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1845856","CAREER: Understanding Invariant Convolutional Neural Networks through Many Particle Physics","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","12/12/2022","Matthew Hirn","MI","Michigan State University","Continuing Grant","Yuliya Gorb","08/31/2022","$311,850.00","","mhirn@msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1271","079Z, 1045, 9263","$0.00","Large scale computing in engineering and the physical sciences, in addition to new experimental methods, are generating massive amounts of high dimensional distributed data, and interpreting, analyzing, and using this data is a fundamental problem facing science. Machine learning algorithms extract, interpolate, and extrapolate information from these data sets. However, the complexity of modern data requires new algorithmic paradigms that are capable of parsing intricate and subtle patterns across numerous scales. This CAREER award will make significant strides in developing these new machine learning paradigms, focusing on multiscale systems of interacting bodies that are used to model molecules, materials, and drugs, amongst others.<br/><br/>More specifically, this CAREER award will facilitate an integrated scientific and educational program at the interface of mathematics, deep learning, many particle physics and data science. Scientifically, it will develop a mathematical theory of invariant convolutional neural networks based upon (wavelet) scattering transforms, and seek to interpret the mathematical properties of these scattering transforms through the lens of many particle systems. The research will facilitate fast simulations of quantum many particle systems, thus opening new research avenues in quantum chemistry, materials science and drug discovery. Intertwined with these research efforts is a plan to increase the participation of under-represented students in data science. The centerpiece of this part of the project is a data science themed ""alternate spring break,"" meant to introduce undergraduate students to data science research, which will be integrated with existing programs at Michigan State University to maximize impact.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912183","Implicit Multi-Scale Plasma Simulations Using Low Cost Matrix-Free Methods for Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","07/30/2019","Andrew Christlieb","MI","Michigan State University","Standard Grant","Yuliya Gorb","07/31/2023","$250,000.00","","christli@msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1271","9263","$0.00","The Carrington event of 1859 was a massive solar flair that hit the earth and left large amounts of charged particles trapped in the earth's magnetic field.  These charged particles created large currents that coupled to the telegraph wires via an inductive coupling, as what happens in transformers.   The currents that were pushed through the telegraph wires were so large they caused the telegraph machines to explode.  If this were to happen today, unless we know to turn off and disconnect the power grid, such an event would destroy modern power infrastructure. Yet solar flairs happen all the time, we can't simply turn off the power grid every time one happens.   From the time of detection, it takes 3 days for a solar flair to travel the distance to the earth.  Predicting if a solar flair will hit the earth is currently done with low resolution models, which are not particular good at predicting these events.  Increasing the accuracy to include more physics in the calculation leads to bigger calculations that simply can't be done in three days, even on modern super computers with state of the art methods.  This project centers on creating a new class of methods that could make these calculations possible.      <br/><br/>One way to begin to address the issues of simulating problems with a significant number of time scales is to use implicit solvers.   These typically lead to large systems of implicitly coupled equations.  The main bottleneck in scalable solvers for such systems is in the communication and large number of interactions that are needed to solve these systems.  In this project we are pursuing a new paradigm that solves coupled systems of non-linear PDEs, it is important to note that the pieces of the operators are typically linear.  We have developed a strategy of expanding these pieces of the operators as global convolutions that give unconditional stability when combined with explicit time stepping methods, but can be cheaply evaluated with three term recurrence relations and avoids iteration.  This approach has led to unconditionally stable solvers for problems such as degenerate advection diffusion or the Hamilton Jacobi equations.  Here we are working to extend these methods to systems of PDEs.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912706","Fast and Robust Algorithms for Signal Recovery from Underdetermined Measurements:  Generalized Sparse Fourier Transforms, Inverse Problems, and Density Estimation","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","05/30/2019","Mark Iwen","MI","Michigan State University","Standard Grant","Yuliya Gorb","06/30/2023","$200,000.00","","markiwen@math.msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1271","9263","$0.00","This project aims to develop computational methods capable of quickly generating best-possible simple solutions for several difficult computational problems of wide interest.  As an example, the developed computational methods will include an algorithm for rapidly finding the best possible simple approximation of a given function of many variables from just a few function evaluations.  If, e.g., the function one cares about is the probability of having an extreme rain event in Florida in two weeks as a function of current ocean temperatures, wind speeds, atmospheric pressures, etc. then such a method could help to provide a generic framework for quickly building up simple models to help predict such extreme rain events based on a reduced number of costly weather observations and climate simulations.  A second example of the numerical methods to be developed as part of this project include provably accurate methods for producing correct pictures of, e.g., microscopic material features from realistic ptychographic imaging data.  Such methods can help guarantee that the images one can obtain using well-planned ptychographic scans of microscopic object features (that are too small to see with the naked eye) actually look like the true object one scanned as opposed to, e.g., a distorted, fake, or even disguised version of the true object which just so happens to produce similar scan results.  <br/><br/><br/>More generally, this project will develop fast computational methods, supported by rigorous theoretical guarantees, for several problems that involve learning extremely large and high dimensional signals from severely underdetermined measurements. The developed numerical methods will include: (i) improved and generalized sublinear-time Sparse Fourier Transform (SFT) algorithms capable of rapidly approximating any function of many variables that exhibits sparsity in any given bounded orthonormal product basis, (ii) FFT-time and provably accurate lifted phase retrieval algorithms for approximately recovering compactly supported functions (up to a global phase factor) from their spectrogram measurements as well as new and even faster SFT-based compressive phase retrieval methods which run in only sublinear-time, and (iii) the development of new, fast, low-memory, and highly-parallel distributed density estimation algorithms for large multimodal datasets and tensors. A common difficulty in developing all three sets of algorithms for the problems above stems from the shear size of the memory and/or processing power required by their standard solution approaches, which limits both their applicability as well as one's ability to obtain fully determined sets of signal measurements for their use in many settings. In all three cases, new and computationally tractable algorithms will be developed that take advantage of hidden simplifying structure in each application above (e.g., generalized Fourier sparsity in the first case, intrinsically low rank data in the second case, and intrinsic low-dimensional geometric structure in the third) thereby providing numerical approaches capable of solving several types of large problems whose numerical solution currently lies beyond our collective capabilities.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912821","Inverse Problems with Internal Data","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","06/13/2019","John Schotland","MI","Regents of the University of Michigan - Ann Arbor","Standard Grant","Yuliya Gorb","09/30/2020","$393,705.00","","john.schotland@yale.edu","1109 GEDDES AVE, SUITE 3300","ANN ARBOR","MI","481091079","7347636438","MPS","1271","9263","$0.00","Advances in imaging technologies such as computed tomography (CT), magnetic resonance imaging (MRI) and super resolution microscopy have transformed the practice of clinical medicine and basic biomedical research. Although the development of such technologies is well known to depend upon progress in physics and engineering, it is less well known that applied and computational mathematics has also played an essential role. This research project studies mathematical questions that arise in new medical biomedical imaging modalities in which new novel measurements play a key role. The research will study novel mathematical algorithms that will lead to improvements in optical imaging both with respect to resolution (visualizing structures at smaller scales) and computational speed. In particular, the project aims to devise robust and accurate image reconstruction algorithms that may lead to the detection and characterization of disease at much earlier stages than is currently possible. The principal investigator has research interests in applied mathematics and theoretical physics. He is also a physician. Graduate students will be trained to function in this interdisciplinary environment.<br/><br/>The objective of this project is to investigate inverse problems with internal data that arise in biomedical optical imaging. Two classes of problems will be considered. (i) Teh PI will develop mathematically-justified methods for imaging below the diffraction limit of resolution, also known as superresolution imaging. The proposed work includes both analysis of the inverse scattering problem with internal sources and the development of reconstruction algorithms. The algorithms will be tested and characterized using data from physically realistic numerical simulations. (ii) The PI will study inverse problems that arise in acousto-optic imaging. The research will focus on the regime of coherent multiple scattering which leads to considerable mathematical simplifications compared to incoherent imaging. In particular, the PI will develop reconstruction methods for recovering the absorption and scattering coefficients of the radiative transport equation from coherent acousto-optic measurements. Finally, the role of improvements in modeling of the acousto-optic effect on image reconstruction will be investigated.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913146","Hybrid Multiscale Methods with Applications in Biomaterials and Bioengineering","DMS","COMPUTATIONAL MATHEMATICS, MSPA-INTERDISCIPLINARY","08/15/2019","07/21/2023","Yi Sun","SC","University of South Carolina at Columbia","Standard Grant","Yuliya Gorb","07/31/2024","$179,133.00","","yisun@math.sc.edu","1600 HAMPTON ST # 414","COLUMBIA","SC","292083403","8037777093","MPS","1271, 7454","068Z, 9150, 9263","$0.00","On the research side, this project aims to develop experimentally guided, hybrid multiscale models and methods to study complex biological systems and problems arising in biomaterials and bioengineering (a) sprouting angiogenesis during vascularization; (b) bacterial swarming during biofilm formation. This research will have many benefits to multiscale problems and relevant applications in biomaterials, tissue regeneration and biomedical engineering, which include bioprinting technology for fabricating tissues and organs, study of cell motions, drug design and ultimately regenerative medicine. These methods can be used as hypothesis generating and testing tools for biologists and bioengineers. Through collaboration with experimentalists, the PI will develop a hybrid multiscale approach to better understand complex mechanisms in the vascularization and the biofilm growth.  On the educational side, this project will not only provide multidisciplinary research training to graduate and undergraduate students, but also promote awareness and interest in computational mathematics and mathematical biology among underrepresented minority groups.<br/><br/><br/>For the thrust (a), motivated by new findings in sprouting angiogenesis in bioprinting technology, the PI will integrate models for angiogenic signaling pathways with that for the mechanical motion. In particular, we employ typically coarse-grained continuum models (reaction-diffusion (RD) systems) to describe the dynamics of vascular-endothelial-growth-factor (VEGF) and nutrients/oxygen, a mechanical model for the extra-cellular matrix (ECM) based on the finite element method (FEM), and couple a discrete multicellular lattice model based on the kinetic Monte Carlo (KMC) algorithm to describe the cellular dynamics. Communication between the microscale model and the continuum ones is carried out via a suite of multiscale protocols. For the thrust (b), the PI will study several mechanisms responsible for bacterial swarming during biofilm formation, such as bacterial chemotaxis, interaction between bacteria, bacterial shapes, etc. In the proposed hybrid agent-based model, bacteria are characterized by self-propelled particles (SPP) or self-propelled rods (SPR) and the dynamics of extracellular polymeric substances (EPS) in the environment is described by continuously changing fields. The multiscale model is described by a system of ordinary and partial differential equations. The research outcomes consist of a set of hybrid multiscale models, detailed implementation of the models, and accompanying in silico analysis tools for simulating tissue formation and ultimately 3D biofabrication involving angiogenesis and vascularization. The tools can provide efficient ways to systematically test the influence of individual cellular features under a spectrum of environmental conditions and to study the collective behavior of bacterial colonies.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913035","Novel Finite Element Methods for Elliptic Distributed Optimal Control Problems","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","06/21/2019","Susanne Brenner","LA","Louisiana State University","Standard Grant","Yuliya Gorb","06/30/2023","$262,254.00","Li-yeng Sung","brenner@math.lsu.edu","202 HIMES HALL","BATON ROUGE","LA","708030001","2255782760","MPS","1271","9150, 9263","$0.00","Optimal control problems with elliptic partial differential equation constraints appear in many optimal design processes in engineering and science.  In these problems the state (output) is connected to the control (input) through an elliptic partial differential equation, and the objective is to find the control that will produce a desired state in an optimal fashion.  The proposed research is on the design, analysis and efficient implementation of novel numerical methods for such problems, with applications to mechanical engineering, electrical engineering and materials science.<br/><br/>Traditional numerical approaches for these optimal control problems treat the control as the primary unknown. The resulting finite element methods only involve low order elements.  The convergence analysis, where the error estimates for the control, the state and the adjoint state are intertwined, is substantially more complicated than the convergence analysis for elliptic boundary value problems. In contrast, the approach in the proposed research treats the state as the primary unknown by reformulating the optimal control problems as variational inequalities for the state. A new analytical framework developed recently by the PI and the Co-PI shows that the convergence analysis for these elliptic variational inequalities can be obtained by using the same tools for the convergence analysis for elliptic boundary value problems.  Consequently many finite element methods originally intended for elliptic boundary value problems can also be applied to the optimal control problems constrained by elliptic partial differential equations. The goal of the proposed research is to apply this new insight to design novel finite element methods for optimal control problems with general cost functionals, problems with semi-linear second order and fourth order elliptic partial differential equation constraints,  problems for electromagnetics and problems  with  rough coefficients that appear in materials science.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912802","Collaborative Research: Machine Learning and Inverse Problems in Discrete and Continuous Settings","DMS","COMPUTATIONAL MATHEMATICS","06/15/2019","06/11/2019","Nicolas Garcia Trillos","WI","University of Wisconsin-Madison","Standard Grant","Yuliya Gorb","08/31/2020","$65,212.00","","garciatrillo@wisc.edu","21 N PARK ST STE 6301","MADISON","WI","537151218","6082623822","MPS","1271","079Z, 9263","$0.00","The goal of this project is to push forward the principled use of data in science and applications. By means of rigorous mathematical analysis, the PIs intend to uncover the hidden unity of seemingly unrelated learning problems and methodologies, facilitating the transfer of theoretical and computational developments and unifying the growing applied literature. The proposed work intends to partially satisfy the societal and scientific need to build paradigms that combine data and complex mathematical models to obtain more accurate predictions while accounting for uncertainty quantification.<br/><br/>The PIs intend to address some of the new challenges that the increasing complexity of models and the growing size of data sets have brought to the foundations of optimization and Bayesian approaches to machine learning and inverse problems. This project will emphasize the connection between statistical consistency and algorithmic scalability: consistent problems are often computationally tractable, and a key principle for the design of scalable algorithms is to exploit statistical consistency wherever present. The specific research projects that will be pursued have five overarching themes: <br/>i) The analysis of continuum limits of discrete objects defined on random data.<br/>ii) The study of new regularization techniques. <br/>iii) The design and analysis of scalable sampling algorithms. <br/>iv) The use of discrete approximations of complex models. <br/>v) The quantification of uncertainty in the solutions. <br/>Contributing in a substantial manner to this wide range of themes will require close collaboration between the PIs.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912735","Implicit Weighted Essentially Non-Oscillatory (WENO) Schemes for Advection-Diffusion-Reaction Systems","DMS","COMPUTATIONAL MATHEMATICS","09/01/2019","05/24/2019","Todd Arbogast","TX","University of Texas at Austin","Standard Grant","Yuliya Gorb","08/31/2023","$250,000.00","","arbogast@ices.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271","9263","$0.00","Computational modeling is used in science and engineering to simulate how physical and biological systems work, so that we can better understand them and how they may be modified for societal benefit.  Many of these systems mix advective (or transport), diffusive, and reactive processes. We have good numerical techniques for simulating a single such process, but only a few of these can handle multiple processes at once.  This project concerns theoretical and algorithmic development of an alternate category of numerical techniques for simulation of systems of nonlinear advection-diffusion-reaction equations.  These new numerical techniques show great promise, and they are likely to lead to better accuracy and computational efficiency.  Applications to geoscience problems important to energy production and environmental protection will be pursued. Assessment, design, and monitoring of human activities involving reservoirs and aquifers in the Earth's subsurface require large-scale simulation of advective, diffusive, and reactive processes over long time periods. There is a potential societal benefit in energy production and environmental protection. The project may also have an impact on broad areas of science and engineering that use models consisting of nonlinear, coupled advection-diffusion-reaction equations. The project is expected to have an impact on the STEM workforce and its diversity through the education and training of two Ph.D. graduate students (both female, one a native citizen).  Such students are in high demand in industrial and governmental labs, as well as in academia.<br/><br/>The mathematical structure of physical or biological models governed by nonlinear advection-diffusion-reaction partial differential equations is often poorly understood, and solutions can develop shocks or very steep fronts. This project concerns theoretical and algorithmic development of high order, implicit, weighted essentially non-oscillatory (iWENO) schemes for numerical approximation of systems of such equations, because this type of scheme has the potential to handle all three processes well. The development will including finite volume and finite difference schemes, Eulerian-Lagrangian approaches, and a multi-moment variant. The objectives are to (1) develop a suitable smoothness indicator and time integrator for the problem; (2) develop a general procedure to handle possibly degenerate diffusive processes; (3) make advances on space discretization and related issues, such as handling boundary conditions and satisfying local maximum principles; (4) test the approach on applications to porous media; and (5) educate and train students in an interdisciplinary setting.  The project will lead to a very general computational framework can approximate all the necessary physics in a locally mass conservative way.  It will be simple to implement, handle general computational meshes in two and three space dimensions, be high order accurate in both space and time, maintain local mass conservation properties, be robust (i.e., unconditionally linearly stable), and maximize mesh resolution. The schemes will be efficient on high performance computers, which are memory bandwidth limited, because local information that can fit in cache memory will dominate the computations, and the global system of discrete equations will have about as small a number of degrees of freedom as possible.  The project is expected to have a broader impact on the STEM workforce and its diversity, and on the geosciences through applications of the schemes, and it may impact broad areas of science and engineering, especially those that use models of complex, coupled problems for which the mathematical structure of the application may not be well understood.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913136","Approximate Singular Value Expansions and Solutions of Ill-Posed Problems","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","07/01/2019","05/19/2021","Rosemary Renaut","AZ","Arizona State University","Standard Grant","Yuliya Gorb","06/30/2023","$206,998.00","","renaut@asu.edu","660 S MILL AVENUE STE 204","TEMPE","AZ","852813670","4809655479","MPS","1253, 1271","102Z, 1515, 9263","$0.00","The primary focus of this project is on the development of novel and efficient computational algorithms for the solution of large scale inverse problems. Examples of the kinds of problems that are relevant for  the planned mathematical developments for this study arise in (i) medical image reconstruction from data acquired without invasive procedures and (ii) measurements of the permeability of a porous medium which is of great importance for predicting flow and transport of fluids and contaminants in the subsurface.  Improved approaches for the solution of such problems, both in terms of computational cost and efficiency, have significant societal impact. Students in applied mathematics will be trained in the techniques that are being developed and graduate and undergraduate students from underrepresented groups will be supported for their roles in this project. As such, the project contributes to the training of the next generation of a broad group of students in the mathematical sciences. <br/><br/>The principal investigator will extend and enhance the linear algebra techniques that are inherent within the solvers for the large scale inverse problems. Specific goals for the project include the (i) mathematical and computational analysis of  oversampled iterative Krylov algorithms; (ii) the development and analysis of hybrid preconditioning of randomized singular value decomposition estimates for large scale under-determined problems, and (iii) assessment of  techniques that incorporate multiple regularization types that are required for the inversion of such large scale and under sampled problems. The encompassing goal of this project is the recognition that significant information of a large scale problem is contained within the dominant spectral subspace obtained via dimension reduction. Thus the  research brings together studies of resolution and rank estimation for the underlying systems of equations that are solved using the latest linear algebra techniques  and provides theoretically-justified down-sampling for data and model compression.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912818","Collaborative Research: Machine Learning and Inverse Problems in Discrete and Continuous Settings","DMS","COMPUTATIONAL MATHEMATICS","06/15/2019","06/11/2019","Daniel Sanz-Alonso","IL","University of Chicago","Standard Grant","Yuliya Gorb","05/31/2021","$58,626.00","","sanzalonso@uchicago.edu","5801 S ELLIS AVE","CHICAGO","IL","606375418","7737028669","MPS","1271","079Z, 9263","$0.00","The goal of this project is to push forward the principled use of data in science and applications. By means of rigorous mathematical analysis, the PIs intend to uncover the hidden unity of seemingly unrelated learning problems and methodologies, facilitating the transfer of theoretical and computational developments and unifying the growing applied literature. The proposed work intends to partially satisfy the societal and scientific need to build paradigms that combine data and complex mathematical models to obtain more accurate predictions while accounting for uncertainty quantification.<br/><br/>The PIs intend to address some of the new challenges that the increasing complexity of models and the growing size of data sets have brought to the foundations of optimization and Bayesian approaches to machine learning and inverse problems. This project will emphasize the connection between statistical consistency and algorithmic scalability: consistent problems are often computationally tractable, and a key principle for the design of scalable algorithms is to exploit statistical consistency wherever present. The specific research projects that will be pursued have five overarching themes: <br/>i) The analysis of continuum limits of discrete objects defined on random data.<br/>ii) The study of new regularization techniques. <br/>iii) The design and analysis of scalable sampling algorithms. <br/>iv) The use of discrete approximations of complex models. <br/>v) The quantification of uncertainty in the solutions. <br/>Contributing in a substantial manner to this wide range of themes will require close collaboration between the PIs.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913201","Collaborative Research: Multilevel Methods for Optimal Control of Partial Differential Equations and Optimization-Based Domain Decomposition","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","06/11/2019","Andrei Draganescu","MD","University of Maryland Baltimore County","Standard Grant","Yuliya Gorb","06/30/2023","$219,999.00","Bedrich Sousedik","adraganescu@gmail.com","1000 HILLTOP CIR","BALTIMORE","MD","212500001","4104553140","MPS","1271","9263","$0.00","Optimal control of differential equations (PDECO) plays an important role in an ever increasing number of real-life applications ranging from petroleum reservoir modeling to weather prediction and the optimal shape design of airplane wings. While traditional PDECO uses deterministic models, this project targets PDECO where the differential equations also include uncertainties, such as irregular fluctuations in the ground composition, or turbulent wind speeds. The ultimate aim is to dramatically improve the solution quality and the computing time of such optimal control problems. The novel algorithms resulted from this project will impact optimization problems arising in geophysics, weather modeling etc. These problems are generic and advances in solution techniques will also benefit other sciences. Open source software will be created and shared with the community. Four graduate students will benefit from the project. Special attention will be given to recruit students from underrepresented groups. <br/><br/><br/>The project is focused on developing robust, scalable multilevel solvers for mainly two classes of potentially large-scale PDECO problems: PDECOs constrained by stochastic partial differential equations (PDEs) and by nonlocal PDEs. An additional thrust is to develop multilevel solvers in support of optimization-based domain decomposition - another kind of PDECO - for the forward PDE-models themselves. Multilevel/multigrid solvers are known to be optimal for many classes of forward models. However, their application to solve PDECO problems is still in its infancy. A naive application of multilevel methods to solve such optimization problems can lead to dependence on resolution (mesh-dependence) and on other parameters of the problem such as the stochastic dimension or the number of subdomains. In addition, since each iterate involves at least one PDE solve, the cost of solving such optimization problems can be prohibitive for large-scale, high-resolution problems, especially for problems that are significantly more expensive than the traditional, deterministic ones. The algorithms developed in this project aim to set new standards of efficiency and robustness.  Novel mathematical tools will further advance the knowledge in numerical analysis and optimization. New special topics courses will be developed based on the research generated in the project and the notes will be shared with the community. The results of the research will be actively disseminated via technical research papers and talks at national and international conferences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912902","Collaborative Research: Hybrid Fluid-Structure Interaction Material Point Method with applications to Large Deformation Problems in Hemodynamics","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","07/18/2019","Eugenio Aulisa","TX","Texas Tech University","Standard Grant","Yuliya Gorb","07/31/2022","$250,000.00","","eugenio.aulisa@ttu.edu","2500 BROADWAY","LUBBOCK","TX","79409","8067423884","MPS","1271","9263","$0.00","Heart valve associated issues in the human organism are the cause of cardiac arrest and heart failure, which may have devastating consequences on a person's health and even lead to death. While not necessarily fatal, pathologies associated with leg vein valves can nevertheless cause severe distress to the people affected and have a negative impact on their life with possibly major complications. For the treatment of valve associated diseases, the most common practice nowadays is the replacement of the malfunctioning valve with a prosthetic device. Unfortunately, prosthetic valves have issues with long term durability and post-implantation complications. Given the necessity of improving the design and selection of existing prosthetic valves, computational methodologies are becoming a valuable tool. The nature of blood flow inside a human valve renders the modeling problem considerably challenging from the mathematical and computational standpoints, as multiple physical phenomena mutually interact. Specifically, the major challenges are the large structural displacements experienced by the valve leaflets, while preserving accurate description of the hydrodynamic force at the fluid-solid interface. The focus of this project is on developing new fluid-structure interaction methodologies with specific interest in the case of large deformations. The important insight provided in this project will enable future valve design optimization while avoiding costly empirical design iterations. In addition to the obvious potential impact on society, the proposed project will be useful to many other applications in science and engineering, and also have beneficial impact on the training, education, and careers of junior researchers in an important, exciting, and mathematically, computationally, and societally impactful area of research.<br/><br/>This project is about the development, analysis, and implementation of novel computational techniques for the coupling of finite element methods (FEMs) to material point methods (MPMs) in fluid-structure interaction (FSI) problems. The use of different discretization techniques for the study of multiscale and multiphysics problems is a powerful tool for computational simulations. For instance, one-dimensional models are coupled with multi-dimensional models for computational cost reduction, or FEMs are coupled with finite volume methods to exploit the advantages of the algorithmic and mathematical features of these two methods. With the same idea, the coupling of FEM with MPM represents a promising combination, if different deformation regimes occur within the dynamical regime of a physical model. As a matter of fact, the FEM reaches its best accuracy for small deformations whereas the MPM mixed Eulerian-Lagrangian formulation becomes beneficial when large deformations occur. FEM-MPM coupling has, in fact, been studied only by very few authors, including the PIs, and the coupling of an FSI framework with an MPM approach is yet to be explored.  The use of the material point methodology would avoid the mesh entanglement issues that plague many existing FSI methods. To design the desired coupling approach, preliminary work is needed. First, the coupling between an MPM solid body immersed in an FEM fluid will be addressed, using benchmark problems from the FSI literature. At the same time, the mechanical properties of a solid body discretized with the mixed FSI-MPM approach will be studied and the accuracy of the method will be investigated using the Taylor bar test in which a cylinder impacts a rigid wall. Then, the knowledge gained from the preparatory work will be used to realize an FSI-MPM coupling methodology for biological valves, with the valve leaflets modeled with the MPM and the blood vessel and blood flow described in an FEM-FSI framework. Appropriate solvers and preconditioners will also be selected and studied because the discretized nonlinear and linear systems will likely be large and highly coupled. Lastly, the FSI-MPM coupling approach will also be applied for the simulations of stented arteries, with the stent described using the MPM. In this way, complex meshing procedure for the stent can be avoided, while capturing its dynamical behavior.  The computational techniques developed within the proposed research will be applicable and prove to be invaluable tools for a broad spectrum of applications such as human valve fluid and structural dynamics, aerospace and civil engineering problems, dam breaking, and airfoil design, to name a few. All our findings will be implemented in FEMuS, an open source library written in C++ language, freely downloadable online. Our effort will hopefully contribute to the standardization of novel computational techniques that are currently available only in research software. Nevertheless, researchers from all over the world can potentially access our findings and join us in this effort, with a substantial speed up in the standardization procedure.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912908","Numerical Methods for Fluid-Structure Interaction Problems with Large Displacements","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","06/21/2019","Martina Bukac","IN","University of Notre Dame","Standard Grant","Yuliya Gorb","06/30/2023","$174,942.00","","mbukac@nd.edu","940 Grace Hall","NOTRE DAME","IN","465565708","5746317432","MPS","1271","9263","$0.00","Fluid-structure interaction (FSI) problems arise in many applications, such as geomechanics, aerodynamics, and blood flow dynamics (hemodynamics). In hemodynamic applications, mathematical models must capture the non-linear coupling between blood and the elastic structural dynamics of vessel walls, soft tissue, or cardiac muscles. These structural dynamics create 'moving domain' FSI problems that are challenging to numerically solve and analyze. Fast and efficient FSI solvers are valuable for bioengineering applications since the combination of numerical algorithms with experimental and clinical measurements provides an innovative approach to understanding the basic function of many components of the cardiovascular system and their mutual interaction. The PI will develop a class of numerical methods and underlying theory for non-linear FSI problems with large displacements. The research aims at making fundamental contributions to development of algorithms and numerical analysis of such problems. The proposed research will push the boundaries of our ability to model FSI problems in hemodynamics, including fracture propagation in soft tissue. <br/> <br/>The goal of this project is the development of a class of numerical methods and underlying theory for solving non-linear FSI problems with large displacements. Proposed methods will be specially designed for problems arising from hemodynamics. We will consider elastic and poroelastic structures where solid mechanics are described by hyperelastic constitutive models. Both partitioned and monolithic methods will be developed. Special attention will be given to numerical analysis of the proposed methods. The research goals will be achieved through the following specific aims: Aim 1: Development of noniterative, domain decomposition methods for FSI problems with porohyperelastic structures using secondorder Backward Differentiation Formula time discretization and the Crank-Nicolson Leapfrog time discretization; Aim 2: Development of non-iterative, domain decomposition methods for FSI problems with thick, hyperelastic structures; and Aim 3: Development and analysis of a monolithic, phase-field approach for FSI problems with hyperelastic structures.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913072","High Order Methods for Kinetic Transport Models","DMS","COMPUTATIONAL MATHEMATICS","08/15/2019","06/14/2019","Fengyan Li","NY","Rensselaer Polytechnic Institute","Standard Grant","Yuliya Gorb","07/31/2024","$275,000.00","","lif@rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","MPS","1271","9263","$0.00","Accurate, robust and efficient simulations of kinetic transport models are of fundamental importance to many applications in physics and engineering, such as rarefied gas dynamics, plasma physics, nuclear and biomedical engineering, and network dynamics.  While fluid models often provide lower dimensional approximations, they are valid only when the systems are closed to their  equilibria, and therefore kinetic transport models are necessary to account for a wider range of phenomena, including those displaying multiple scales in space and/or time or those involving particles from  multiple energy groups.  This project aims at advancing computational tools of high order accuracy for time-dependent multi-scale kinetic transport models,  both algorithmically and mathematically.<br/><br/>Kinetic transport equations are mathematical descriptions of the transport of particles such as  neutrons, photons, molecules as well as their interaction with a host medium or among themselves, and they arise in a broad range of applications. The numerical challenges  lie in the high dimensionality of the phase space, small scales, multiple scales in space (and even in time),  nonlinear interactions, collision operators with multi-fold integrals, as well as the conservation or positivity property of the solutions.  The objective of this project is therefore to take important steps  in  the understanding and simulations of the time-dependent multi-scale kinetic transport models, with the aim of: 1) providing accurate deterministic simulation tools with excellent stability to the kinetic transport community, and 2) developing novel analytical and numerical techniques to address  some challenges related to accurate multi-scale kinetic transport simulations. The longer term goal is to develop algorithms robustly  simulating more realistic kinetic models with high resolution and good efficiency.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913076","Numerical Methods for Wave Equations in Time and Frequency Domain","DMS","COMPUTATIONAL MATHEMATICS","06/15/2019","06/19/2019","Daniel Appelo","CO","University of Colorado at Boulder","Standard Grant","Leland Jameson","04/30/2022","$303,373.00","","appelo@vt.edu","3100 MARINE ST","BOULDER","CO","803090001","3034926221","MPS","1271","9263","$0.00","An intrinsic feature of waves is their ability to propagate over large distances without changing their shape. This ability allows waves to carry information, be it through speech or electronic transmission of data. Waves can also be used to probe the interior of the earth, the human body or engineered structures like buildings or bridges. This probing can be turned into images of the interior by the means of solving inverse problems, and in the extension, mitigate seismic hazards by accurate predictions of ground motion caused by earthquakes. In this project the principal investigator will develop computational simulation tools that increases our ability to exploit the properties of wave propagation for the common good. The tools developed in the project can also be used to design modern materials with exotic properties that cannot be found in nature. Such metamaterials can enable better sensing technologies and faster acoustic and electromagnetic circuit components such as miniaturized speakers, 5G components and other millimeter wave technologies. <br/><br/>The research will use a new idea that enables the use of time domain methods for wave equations to design frequency domain Helmholtz type solvers. The approach is remarkable in that the underlying linear operator corresponds to a symmetric positive definite matrix allowing the  solution of a coercive problem rather than an indefinite Helmholtz problem. As the proposed Helmholtz solvers rely solely on evolving the wave equation they will be massively parallel, scalable and high order accurate. A goal of the research is to solve the Helmholtz equation in three dimensions at higher frequencies, and on a larger number of cores than is currently possible. The research will also seek to improve the time-step constraints of time domain discontinuous Galerkin methods by exploiting approximation spaces built on discrete periodic extensions from equidistant node data. Such improvements will result in faster simulation times and more accurate predictions. Applications of the methods to modeling of micropolar materials and to simulation of seismic waves will be carried out in collaboration with researchers from academic institutions and national laboratories.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913073","Efficient Numerical Simulations of Oceanic Flows with Application to Coastal Modeling","DMS","COMPUTATIONAL MATHEMATICS","07/15/2019","07/10/2019","Zhu Wang","SC","University of South Carolina at Columbia","Standard Grant","Yuliya Gorb","06/30/2022","$167,916.00","","wangzhu@math.sc.edu","1600 HAMPTON ST # 414","COLUMBIA","SC","292083403","8037777093","MPS","1271","9150, 9263","$0.00","Coastal ocean modeling has been developed for better serving climate impact assessments that are closely related to pressing society problems such as coastal flooding. To resolve multiple scales in ocean circulations and deal with complicated coastal topography, it is quite natural to use multi-resolution meshes in numerical simulations of oceanic flows. Typically, the grid sizes would vary from 100 km in major ocean basins to 1km in coastal regions. This, however, brings grand computational challenges: During explicit time integrations, the time step size would be restricted by the smallest grid size in the entire domain. Such a small time step size would make the numerical simulations unaffordable, especially for the purpose of climate modeling because long-term simulations are needed in such applications. To overcome this issue, this project puts forth new schemes that will be substantially more efficient compared to current algorithms used in ocean models while keeping their fidelity. This award will support one graduate student each year.<br/><br/>We propose innovative, efficient numerical methods for simulating oceanic flows with application to coastal modeling. The new approaches comprise two major mathematical and computational developments: (i) conservative local time stepping, which allows the use of spatially-variable time step sizes in regions of different resolutions while keeping desired physical quantities conserved; and (ii) structure-preserving reduced order modeling, which significantly decreases the spatial dimension while maintaining the inherent Hamiltonian structure in the resultant low dimensional model. These approaches provide fast yet accurate and stable numerical solvers for simulating oceanic flow problems, which would enhance the simulation capability of current coastal ocean modeling and further increase computational efficiency required to solve pressing society problems such as coastal flooding. As a first step, we will study the shallow water equations on an unstructured, multi-resolution mesh. The effectiveness of the proposed methods will be demonstrated by verifying their stability and numerical accuracy. More complicated test cases and real-world applications will be further considered in this project.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913004","Collaborative Research: Multilevel Methods for Optimal Control of Partial Differential Equations and Optimization-Based Domain Decomposition","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","06/11/2019","Harbir Antil","VA","George Mason University","Standard Grant","Yuliya Gorb","06/30/2022","$100,000.00","","hantil@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","MPS","1271","9263","$0.00","Optimal control of differential equations (PDECO) plays an important role in an ever increasing number of real-life applications ranging from petroleum reservoir modeling to weather prediction and the optimal shape design of airplane wings. While traditional PDECO uses deterministic models, this project targets PDECO where the differential equations also include uncertainties, such as irregular fluctuations in the ground composition, or turbulent wind speeds. The ultimate aim is to dramatically improve the solution quality and the computing time of such optimal control problems. The novel algorithms resulted from this project will impact optimization problems arising in geophysics, weather modeling etc. These problems are generic and advances in solution techniques will also benefit other sciences. Open source software will be created and shared with the community. Four graduate students will benefit from the project. Special attention will be given to recruit students from underrepresented groups. <br/><br/>The project is focused on developing robust, scalable multilevel solvers for mainly two classes of potentially large-scale PDECO problems: PDECOs constrained by stochastic partial differential equations (PDEs) and by nonlocal PDEs. An additional thrust is to develop multilevel solvers in support of optimization-based domain decomposition - another kind of PDECO - for the forward PDE-models themselves. Multilevel/multigrid solvers are known to be optimal for many classes of forward models. However, their application to solve PDECO problems is still in its infancy. A naive application of multilevel methods to solve such optimization problems can lead to dependence on resolution (mesh-dependence) and on other parameters of the problem such as the stochastic dimension or the number of subdomains. In addition, since each iterate involves at least one PDE solve, the cost of solving such optimization problems can be prohibitive for large-scale, high-resolution problems, especially for problems that are significantly more expensive than the traditional, deterministic ones. The algorithms developed in this project aim to set new standards of efficiency and robustness.  Novel mathematical tools will further advance the knowledge in numerical analysis and optimization. New special topics courses will be developed based on the research generated in the project and the notes will be shared with the community. The results of the research will be actively disseminated via technical research papers and talks at national and international conferences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1846854","CAREER: Computational Methods for Multiscale Kinetic Systems: Uncertainty, Non-Locality, and Variational Formulation","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","05/30/2023","Li Wang","MN","University of Minnesota-Twin Cities","Continuing Grant","Yuliya Gorb","06/30/2024","$400,001.00","","wangli1985@gmail.com","200 OAK ST SE","MINNEAPOLIS","MN","554552009","6126245599","MPS","1271","1045, 9263","$0.00","Kinetic theory has emerged as a critical tool in studying many-particle systems with random motion, which arise widely in plasma physics, semiconductors, animal swarms, nuclear engineering, among many others. It bridges the gap between microscopic particle system and macroscopic continuum description, and therefore is at the core of multiscale modeling. In addition to its multiscale nature, this project intends to advance the understanding and computation of kinetic theory in new, emerging aspects that involve uncertainties, non-localities, and variational formulations. A parallel educational objective is to prepare and train students at all levels for multi-disciplinary research through advanced courses, topic seminars, and summer programs.<br/><br/>The specific aims of the project include: (1) utilize the variational formulation of macroscopic and kinetic equations to develop scalable, structure preserving, mathematically justifiable methods via advanced optimization techniques; (2) design multiscale computational methods for nonlocal interacting kinetic systems, with emphases on nonlocal collision and connection to fractional diffusion; (3) develop robust algorithms for hyperbolic equations with uncertainty, especially in treating discontinuous solutions; (4) study the inverse problem for nonlinear kinetic systems, including stability analysis with varying scales, numerical regularization and algorithms. The proposed activity is on an interdisciplinary topic and of general interest to both computational mathematicians and scientists from other areas. The variational methods provide a new perspective in overcoming difficulties that are shared among most partial differential equation (PDE) models nowadays: multiple scales, high dimensionality and necessity in preserving physical quantities. The research outcome will have an impact on other disciplines including computational optimal transport, optimal control theory, mean field games, and machine learning. The fractional diffusion solvers will be equally applicable to photon transport through cosmic dust or atmosphere, electron beam dose calculation, and other nonlocal PDEs arising in material science, finance, and plasma physics. Uncertainties that are omnipresent in kinetic equations have a profound influence on the solution behavior and must be carefully quantified. The analysis and algorithms investigated through this project, in both forward and inverse setting, will facilitate the understanding of sensitivity in the system under random perturbations, and largely advance the modern design of device with optimal performance.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913309","Inverse Problems and Imaging with Nonlinear Physics","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","06/20/2019","Kui Ren","NY","Columbia University","Standard Grant","Yuliya Gorb","09/30/2023","$313,866.00","","kr2002@columbia.edu","202 LOW LIBRARY 535 W 116 ST MC","NEW YORK","NY","10027","2128546851","MPS","1271","9263","$0.00","This project aims at studying imaging and inverse problems where nonlinear effects in physics play significant roles. Nonlinear physics could either help us image objects that could not be imaged with only linear physics or prevent us from imaging objects that we would have been able to image in the absence of such nonlinear effects. In either case, understanding the impact of such nonlinear effects would help us improve the quality of the underlying imaging modalities. The goal of the project is to perform detailed mathematical and numerical analysis to characterize the effects of nonlinearity on image reconstructions in such cases.<br/><br/>The main research efforts in this project include, but are not limited to: (i) developing efficient reconstruction algorithms for imaging through nonlinear dispersive media; (ii) developing mathematical theory and computational methods for imaging two-photon absorption and second harmonic generation in optics; and (iii) analyzing quantitative photoacoustics with nonlinear absorption and developing corresponding computational image reconstruction algorithms. The mathematical ideas developed in this project are expected to provide insights on future studies of similar imaging and inverse problems related to nonlinear partial differential equations. The research is also expected to have impact on the development of practically useful methods for imaging through nonlinear media as well as imaging nonlinear physical properties of given media. This project involves an integrated educational component that aims at training advanced undergraduate, master and PhD students.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912999","Sub-Linear Complexity Methods for Multiscale Problems Without Scale Separation","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","07/30/2019","Yoonsang Lee","NH","Dartmouth College","Standard Grant","Yuliya Gorb","01/31/2023","$99,839.00","","Yoonsang.Lee@dartmouth.edu","7 LEBANON ST","HANOVER","NH","037552170","6036463007","MPS","1271","9150, 9263","$0.00","Many problems in science and engineering involve complicated interactions between a wide range of scales in space and time, which are computationally challenging to solve for all relevant scales due to a huge simulation cost. The proposed work aims to extract salient features of multiscale problems with a significantly reduced simulation cost. This research will enable fast simulation methods for large-scale computational problems, including optimal design of material properties such as conductivity, elasticity, and long-life cycle of batteries, etc. Also, seismology and acoustic scientific communities will benefit from the proposed work in investigating and studying underground and underwater physics such as object detection, localization, material classification, etc. The project also considers applications in numerical weather forecast methods that significantly improve the prediction accuracy using a large number of samples to quantify uncertainties in the weather forecast models.  This project will fund one graduate student in year 2 of the project.<br/><br/>The overarching goal of the project is novel sub-linear complexity methods that apply to non-separable multiscale problems. The sub-linear complexity provides a significantly improved efficiency that extracts essential and salient features of the problems without computationally resolving all active scales. The basis of the project is the extraction of effective behaviors through a seamless application of the standard method for separated scale problems. The proposed research offers a unique way to tackle non-separable scale problems without ad-hoc parameter tuning while maintaining a low simulation cost. The mathematical methods to be developed allow judicious applications of the homogenization theory for two-scale problems. Thus, the project has a significant potential to enhance the applicability of the standard computational methods developed for two-scale problems to a wide range of problems. Also, the application and validation in the context of the numerical weather forecast will contribute to connecting deterministic and stochastic multiscale modeling frameworks.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1941197","Graph-Based Regularization Techniques and Their Applications","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","05/15/2023","Jing Qin","KY","University of Kentucky Research Foundation","Standard Grant","Yuliya Gorb","06/30/2024","$186,006.00","","jing.qin@uky.edu","500 S LIMESTONE","LEXINGTON","KY","405260001","8592579420","MPS","1271","062Z, 9150, 9263","$0.00","The rapid development of science and technology ushers in a new era of big data that requires developing specialized algorithms to process a large amount of data. Signal processing and other related techniques aim to recover signals of interest or some of their properties; this goal can be reduced to an optimization question. Due to physical limitations of hardware, the size of the acquired data is in general much smaller than that of the underlying signal, resulting in an ill-posed problem for signal recovery with infinitely many solutions. Regularization techniques have been developed to address this inherent ill-posedness. Despite being widely applied in low-dimensional signal processing, regularization has seen limited use in processing high-dimensional data sets, especially those best represented by graphs, that is, networks with sophisticated connections. This project aims to further develop graph-based regularization techniques, with potential to revolutionize imaging and data analysis technologies in many areas of data science.<br/><br/>This project aims to develop a useful graph-based regularization framework for various signal processing problems, to address major theoretical and computational challenges for its applications, to provide new interpretations of low-dimensional regularization techniques, and to demonstrate its capability for handling large-scale data sets. The research has three objectives: (1) Develop novel graph-based regularization techniques along with rigorous theoretical guarantees to handle the more challenging signal processing problems and related inverse problems; (2) Develop efficient numerical algorithms to solve the corresponding optimization problems; and (3) Conduct numerical experiments in imaging applications to demonstrate the advantages of the proposed approaches in terms of accuracy and efficiency. The research aims to improve data processing techniques and to infuse new insights into mathematical signal and image processing, with a variety of applications such as medical imaging and remote sensing.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1841324","Topological and Rigorous Computational Methods for High Dimensional Dynamics","DMS","COMPUTATIONAL MATHEMATICS","02/01/2019","10/30/2018","Konstantin Mischaikow","NJ","Rutgers University New Brunswick","Standard Grant","Leland Jameson","01/31/2020","$12,000.00","","mischaik@math.rutgers.edu","3 RUTGERS PLZ","NEW BRUNSWICK","NJ","089018559","8489320150","MPS","1271","7556","$0.00","The conference 'Topological and Rigorous Computational Methods for High Dimensional Dynamics' is to be held on April 1 - April 30, 2019<br/>in Centre des Recherches Mathematiques (CRM), Canada. The revolution of computational and data driven science is well underway. However, mathematically rigorous frameworks for processing the output of this science is lagging.  This is of serious concern since these same computational and data driven techniques are having immediate impacts on the private and social sectors of society. It is essential that within the new generation of mathematicians there are researchers capable of addressing these issues.  Through the tutorials, junior researchers will be introduced to rapidly developing concepts, techniques, and computational tools designed to address these challenges. Through the workshop lectures they will be made aware of the latest developments in the field.<br/>Of equal importance is that their presence will allow them to interact with leaders in the field, to begin to develop connections with researchers from across the world, and ideally to begin research projects that lay the foundations of new techniques for rigorous understanding of the complex nonlinear systems of interest today and in the future.<br/><br/>This project will provide support for junior researchers from the USA to participate in a month long special program at the Centre des Recherches Mathematiques (CRM) entitled Topological and Rigorous Computational Methods for High Dimensional Dynamics.  The activities will take place from  April 1 - April 30, 2019 and consist of tutorials, workshops, and time for collaboration.  The research activities of the CRM program focus on two topics.  The first theme is how to effectively and rigorously identify invariant structures in infinite dimensional dynamical systems, for example those generated by partial differential equations. The second theme is how to extract robust information from poorly resolved dynamical systems, for example when only partial or coarse data is available.<br/><br/>Conference website: <br/>http://www.crm.math.ca/crm50/en/activities/2019-activities/topological-and-rigorous-computational-methods-for-high-dimensional-dynamics/<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913144","Fast Algorithm for Interface Relaxation and Efficient Computational Modeling of Molecular Binding and Unbinding","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","06/20/2019","Li-Tien Cheng","CA","University of California-San Diego","Standard Grant","Yuliya Gorb","06/30/2023","$325,000.00","Bo Li","lcheng@math.ucsd.edu","9500 GILMAN DRIVE","LA JOLLA","CA","920930021","8585344896","MPS","1271","9263","$0.00","This project develops rigorous scientific theories and powerful computational tools to investigate the principal mechanisms by which drug and protein molecules associate and dissociate. Often, a drug molecule moves around in a crowded environment, and finds a spot of the surface of a protein to bind to, stays there, and can also leave, unbinding from the protein. During such binding and unbinding events, often repeated, both molecules constantly change their internal atomic positions. They also interact with other molecules, particularly the water molecules, in the surrounding environment. There are two key scientific questions on such complex processes that are characterized by multiple spatiotemporal scales and many-body effects. One is how stable the drug-protein bound unit is. Such thermodynamic stability severs as a criterion for searching drug molecules capable of binding to targeted proteins. The other is how fast or slow the binding and unbinding can occur. Such kinetics has been found recently in experiments and computer simulations to be critical to the drug effectiveness and efficacy. For decades, the scientific communities have made an enormous amount of effect, searching the quantitative answers to these questions to guide the computer-aided drug design and discovery. A recent assessment by the National Institutes of Health of the existing such computer programs, however, has concluded that advanced scientific theories are needed urgently to improve the practice. The success of this project can therefore provide a solid theoretical foundation as well as computational algorithms for drug design and discovery, potentially helping reduce the very high cost often needed for laboratory experiments and speed up the process of drug discovery. In addition, this highly interdisciplinary research project provides unique opportunities for students at different levels to receive training at the interface of mathematical, computational, and biological sciences, keeping our nation's strength in scientific research in a highly competitive international environment.<br/><br/>To tackle the extreme complex problem of molecular association and dissociation, the investigators design, implement, and analyze a very fast binary level-set method for interface relaxation to capture the molecular interfacial structures in the framework of an advanced, variational molecular solvation theory. The new method combines the strength of the threshold dynamics and the binary level-set representation, and utilizes the locality of the underlying energy landscape, and new pixel-flipping techniques to achieve very high efficiency.  They also develop a new and hybrid computational approach to the kinetics of interface stochastic dynamics, coupling the interfacial energy minimization by the fast algorithm, the string method for transition pathways, and a novel, multi-state Brownian dynamics simulations. All these are applied specifically to investigating the molecular binding and unbinding kinetics for which, some of the conventional methods such as the standard Brownian dynamics simulations may fail. It is expected that this project will advance significantly the basic research in scientific computing and numerical analysis, particularly those of the interface dynamics and stochastic modeling. If successful, this research can help resolve some of the bottle-neck issues in solving very complex scientific problems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1906664","Conference on Modern Challenges in Imaging in the Footsteps of Allan Cormack","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","06/01/2019","03/22/2023","Eric Todd Quinto","MA","Tufts University","Standard Grant","Pedro Embid","05/31/2024","$39,386.00","Misha Kilmer, Fulton Gonzalez, Eric Miller","todd.quinto@tufts.edu","169 HOLLAND ST","SOMERVILLE","MA","021442401","6176273696","MPS","1266, 1271","7556, 9263","$0.00","This award will support participants in the conference ""Modern Challenges in Imaging in the Footsteps of Allan Cormack"" at Tufts University, August 5-9, 2019. Tufts professor Allan Cormack provided the mathematical foundations of X-ray computed tomography, winning the Nobel Prize in Physiology or Medicine in 1979 for this work. This international conference will honor his achievements and expand on his legacy by gathering top international researchers in mathematics, engineering, science, and medicine to communicate current research challenges and to inspire new lines of inquiry. Image reconstruction plays a crucial role in many aspects of human life such as healthcare, national security, non-destructive testing, and geophysical exploration - all of which will be represented at this conference. Image reconstruction involves the determination of features of an object based on some measured or observed data from the exterior of the object. The measurements are acquired using data from X-rays, pressure waves, sound waves, electric current, etc. The recovery of the object from this data is known as an inverse problem, which is solved using either analytic reconstruction formulas or iterative methods. The conference is structured to provide cross-fertilization between fields and to provide opportunities for senior and junior researchers to interact. This will be promoted at several levels: between subject areas; between prominent and younger researchers; and with a very strong emphasis on discussions between graduate students and established researchers. Graduate students and those new to the field will be encouraged to participate in a poster session in which they will present their research. Diverse groups of faculty and students will be recruited through broad advertising. Results are planned to be disseminated in a special issue of one of the premier journals in the field of inverse problems and, when possible, talks will be posted on the conference website https://math.tufts.edu/faculty/equinto/Cormack2019/.<br/><br/>A large portion of the conference will involve the following topics: X-ray, optical, photo-acoustic, multi-energy, Compton, and multi-spectral tomography. The conference will also include dynamic tomography and limited data problems. Conference themes include the mathematics and algorithms behind tomographic reconstruction, including machine learning, data diversity, sparse sampling, regularization, dictionary learning, and related approaches. Along with this, lectures will be given on the theoretical underpinnings of tomography including integral geometry and microlocal reconstruction. Finally, the conference will deal with applications including those in medical, security, and industrial domains. These topics are highly interrelated and the conference will serve as an avenue for researchers to share their insights and results among the different specializations. Researchers from pure, applied, and computational mathematics and computer science, as well as from science, industry, and medicine will participate in the conference. This will facilitate new collaborations among participants from the different areas to target opportunities for synergy across disciplines to catalyze new research.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912048","Advances in Robust Multilevel Preconditioning Methods for Sparse Linear Systems","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","06/05/2019","Yousef Saad","MN","University of Minnesota-Twin Cities","Standard Grant","Yuliya Gorb","07/31/2023","$299,999.00","","saad@umn.edu","200 OAK ST SE","MINNEAPOLIS","MN","554552009","6126245599","MPS","1271","9263","$0.00","Solving linear systems of equations is at the heart of many large scale numerical simulations in sciences and engineering. These systems can have tens or hundreds of millions simulations in the aerodynamic design of airplanes and equilibrium models in macro-economics. In most common situations, the equations encountered in these applications are 'sparse' in the sense that each equation involves a small number of unknowns or parameters. This project is about the effective solution of such systems by a class of methods that are termed 'iterative'. An iterative method does not attempt to compute an exact solution by the age-old method of elimination. Instead, it generates a sequence of approximations that gradually approaches the solution. However, in spite of the numerous advances made in past decades in iterative solution methods for linear systems, practitioners still face difficulties when applying these methods to certain types of problems. The proposal aims at advancing the state-of-the art in a specific class called Preconditioning Krylov subspace methods. In essence, the techniques proposed combine preconditioners (making the problem easier to solve by exploiting approximate elimination), with good acceleration methods (combining successive iterates to accelerate convergence) and Domain Decomposition ideas (decomposing the problem into parts so as  to exploit parallel treatment of each part).<br/><br/>This project focuses on the class of Preconditioned Krylov Subspace Methods (PKSMs) for solving linear systems of equations. These methods try to reach a compromise between generality and efficiency by combining an accelerator (e.g., GMRES) and a preconditioner (e.g., Incomplete LU or Algebraic Multi-Grid). It is now well-known that the preconditioner holds the key to the success of this combination. The primary goal of this project is to address the two most important weaknesses of these methods. Their first weakness is their lack robustness in some situations, e.g., when the linear system at hand is highly indefinite or ill-conditioned. In the past researchers have often limited their attention to diagonally dominant systems that arise from discretizing Poisson-like equations. However, the more realistic problems addressed by engineers and scientists have become much harder to solve, leading to a demand for new types of preconditioners. The second weakness of iterative methods is that preconditioners have traditionally been developed with sequential environments in mind, and therefore they often perform poorly in parallel environments. An effort must be made to develop better, more scalable, parallel methods by adopting a view-point that is based on domain-decomposition from the start. To improve the parallel efficiency of preconditioners it is vital to incorporate ideas that exploit a multilevel paradigm. A second avenue to be explored in this project aims primarily at improving robustness by a class of methods that will extend and optimize a strategy based on the Cauchy integral formula for developing preconditioners. The starting point of the project is to expand the PI's research on Multi-Level Low-Rank (MLR) approximation techniques, focusing on a parallel Domain Decomposition framework. MLR techniques have shown a great potential in addressing the issues raised above. First, they rely on an approximate inverse viewpoint and as such these methods tend to be far more robust than their Incomplete LU (ILU) counterparts. They can handle highly indefinite linear systems, such as those arising from wave scattering simulations, more effectively than existing methods. Second, MLRs do not require factorizations and are excellent candidates for high-performance computers, e.g., ones equipped with Graphical Processing Units (GPUs). Finally, they are easy to update in that it is inexpensive to augment or refine them in order to improve their accuracy in the situation when their observed performance is not satisfactory. Different ways to define low-rank approximations will be explored which are all rooted in the Domain-Decomposition framework and Schur complement techniques. The second part of the planned work is to consider extensions of the idea of incorporating complex shifts when solving linear systems. The techniques to be developed here will aim specifically at highly indefinite systems such as those that arise from wave propagation phenomena (Helmholtz, Maxwell). The broader impacts of this project include the free distribution of general purpose codes developed by the PI's research team, and the training of graduate and undergraduate students at a time where demand for specialists in computational mathematics is strong. Among other training activities, the PI will continue the practice of freely disseminating books (two books currently available), lecture notes (three courses currently posted), and MATLAB scripts for educational purposes, as these can play a major role in promoting knowledge and know-how in the theory and application of numerical linear algebra.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1847865","CAREER: Large-Scale Optimization Problems with Applications in Emerging Radiotherapy Modalities","DMS","COMPUTATIONAL MATHEMATICS","06/01/2019","05/18/2023","David Papp","NC","North Carolina State University","Continuing Grant","Yuliya Gorb","05/31/2024","$400,000.00","","dpapp@ncsu.edu","2601 WOLF VILLAGE WAY","RALEIGH","NC","27607","9195152444","MPS","1271","1045, 9263","$0.00","Radiotherapy is one of the most common forms of cancer treatment, given to nearly one million patients each year in the United States. It is a form of personalized medicine: everything from the orientation and modulation of the treatment beams to the treatment schedule, altogether, thousands of parameters, are tailored for each patient, using computational methods referred to as numerical optimization. Several recent technological, mathematical, and biological insights have motivated the departure from conventional forms of treatment; these include spatiotemporally fractionated therapy; proton therapy; combined photon, proton, and electron therapy; and arc therapy. However, the design of optimal personalized treatments with these new treatment approaches also present new mathematical challenges. This Faculty Early Career Development (CAREER) award funds research into the design and mathematical analysis of numerical optimization methods which, besides other applications in science and engineering, will enable the rigorous assessment and more widespread use of novel radiotherapy treatment modalities.<br/><br/>The focus of the project is the development and analysis of numerical methods for large-scale deterministic and stochastic optimization problems. The primary research objectives of this proposal are (1) to develop efficient sampling algorithms for large-scale stochastic constrained optimization, and (2) to develop numerical methods for large-scale convex conic optimization problems in which even a single Newton-step is too expensive. Both the mathematical and the applied components of the proposal are being integrated into the computational and modeling components of undergraduate and graduate courses developed by the PI. The grant also supports the PI's recently established outreach collaboration with artists and designers, which is aimed at broadening the public's appreciation and understanding of current applied mathematics research, in particular the importance of mathematical optimization in medicine, health care, and beyond.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1840260","RTG: Modeling and Computations for Complex Systems at Southern Methodist University","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, WORKFORCE IN THE MATHEMAT SCI","08/01/2019","08/15/2023","Alejandro Aceves","TX","Southern Methodist University","Continuing Grant","Pedro Embid","07/31/2024","$2,315,143.00","Wei Cai, Andrea Barreiro","aaceves@smu.edu","6425 BOAZ LANE","DALLAS","TX","75205","2147684708","MPS","1266, 1271, 7335","7301","$0.00","Mathematical modeling and computation are of critical importance in addressing contemporary scientific and engineering challenges.  By providing to junior scholars the opportunity to work in interdisciplinary teams of mathematicians, engineers, chemists and neuro-scientists studying complex, large scale systems, the Southern Methodist University Research Training Group (SMU-RTG) will develop the trainees skills in modeling and computation. In addition, the SMU-RTG will increase the number of US citizens and permanent residents undertaking advanced studies in computational and applied mathematics and pursuing careers both in and out of academia. The SMU-RTG will pursue this goal through the formation of three vertically-integrated research training groups, each of which will partner SMU mathematicians with scientists in other disciplines. Moreover, by partnering on a summer undergraduate research program with the University of Texas Rio Grande Valley (UTRGV - a Hispanic-serving institution), more students from underrepresented groups will be encourage to undertake graduate studies in STEM fields.  <br/><br/>The research groups involved in the SMU-RTG will address challenging problems in emerging scientific fields: data-driven models in neuroscience, the nonlinear dynamics of the electric power grid and other large-scale networks, and the fabrication and modeling of nanoscale structures. The research activities will create opportunities for the trainees through strategic partnerships with both academic and non-academic institutions: UT Southwestern Medical Center, DOE laboratories, and SMU Engineering. A centerpiece of the year-round activities will be a 10-week summer undergraduate research program with participants from both SMU and UTRGV. Each group will begin its program with a 2-week summer school, which will introduce undergraduates, graduate students and postdocs to fundamental concepts and techniques used by one of the research groups.  This activity will provide exciting and substantive research experiences to students of all backgrounds. The Department of Mathematics at SMU is well-positioned to execute both the research and educational goals of this project, building on its core strengths in modeling and scientific computing and its ongoing success in placing graduates in a range of careers, from industry to national laboratories. The research themes reflect both the department's existing strengths and pressing societal needs, carrying out research that will contribute to improved understanding of the human brain in both health and disease, the reliability of crucial infrastructure, and novel devices with applications in medicine and beyond.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1840265","RTG: Data-Intensive Research and Computing at the University of California, Merced","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, WORKFORCE IN THE MATHEMAT SCI","06/01/2019","05/19/2023","Arnold Kim","CA","University of California - Merced","Continuing Grant","Stacey Levine","05/31/2024","$2,092,605.00","Roummel Marcia, Francois Blanchette","adkim@ucmerced.edu","5200 N LAKE RD","MERCED","CA","953435001","2092012039","MPS","1266, 1271, 7335","7301, 9263","$0.00","The overarching objective of this program is to address the national need to train the next-generation workforce to be highly skilled in the field of computational and data-enabled sciences. To achieve this objective, we propose to establish the Data-Intensive Research And Computing (DIRAC) Research Training Group (RTG). The DIRAC RTG leverages strengths of the UC Merced Applied Mathematics faculty to provide undergraduate and graduate students, and postdoctoral researchers a training experience that prepares them for careers in academia, industry, and government. A key challenge is that computational and data-enabled sciences involve inextricable ties between mathematics, science, technology, and engineering. UC Merced Applied Mathematics is well positioned to address this challenge because of its three main approaches to science that will be at the core of this RTG: (1) modeling of physical and biological systems, (2) scientific computing, and (3) data analysis. To provide its trainees a collaborative training experience in computational and data-enabled sciences, the DIRAC RTG will foster Small Mentoring and Research Training (SMaRT) teams, which are vertically integrated, community-based mentoring structures, each centered on one of four research themes: (I) energy and the environment, (II) sensing and imaging, (III) mathematical biology, and (IV) numerical analysis. These SMaRT teams will provide support to individuals, guide their training, and produce a well-trained, nimble workforce that can contribute to the fast-paced modern computational research. Additionally, the DIRAC RTG is committed to serving the underrepresented and first-generation students that UC Merced Applied Mathematics actively recruits into its undergraduate and graduate programs. Built into each SMaRT Team are active measures for recruiting inclusive teams of trainees, providing continuous mentorship and support to retain these trainees, and developing the professional skills of trainees needed to succeed upon completion of this training program.<br/><br/>Computational and data sciences are new paradigms for scientific inquiry and discovery that incorporate mathematics, statistics, computer science, and domain-specific knowledge. Since computational and data-enabled sciences are relatively new, their natural and effective integration into existing training programs in mathematics remains to be perfected.  This RTG project brings together the entire Applied Mathematics faculty of UC Merced with the common goal of developing a modernized and comprehensive training program for undergraduate and graduate students, and postdoctoral associates that integrates these subjects in a natural and effective way and prepares the trainees for successful careers in academia, government, and industry in a broad range of fields. The proposed RTG project has three major components: (1) a balanced curriculum tightly integrated with research which is modernized to reflect the current needs in computational and data-enabled sciences; (2) a vertically integrated mentoring program that engages undergraduate, graduate, postdoctoral associates, and faculty participants; and (3)  the development of extensive, dynamic, and supportive communities focused on education, research, and professional development. The thematic research areas considered focus on timely and important issues and are divided into (I) energy and the environment, (II) sensing and imaging, (III) mathematical biology, and (IV) numerical analysis. This training program focuses on enhancing each trainee's skills and experience in the process of research (as opposed to just the products of research) and provides practical teaching training, communication skills, and professional development. The activities in this RTG are crucial to making systematic improvements to the existing training program at UC Merced, which can then serve as a model for other programs. These institutional changes will profoundly transform mathematics programs and have long-lasting impact on training the future generations of computational and data-enabled scientists.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913083","Finite Element Exterior Calculus with Smoother Piecewise Polynomials","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","06/21/2019","Johnny Guzman","RI","Brown University","Standard Grant","Yuliya Gorb","06/30/2023","$300,000.00","","Johnny_Guzman@brown.edu","1 PROSPECT ST","PROVIDENCE","RI","029129127","4018632777","MPS","1271","9263","$0.00","Finite element methods are the computational workhorse in simulating many problems in engineering, physics, chemistry and biology. For each particular application, different type of finite elements are needed. In 1980, Nedelec made a monumental connection between different finite elements that has found even more applications. This project will generalize these connections to different finite elements of smoother type. These connections will allow us to tackle new applications.<br/><br/>The research will build and analyze finite element spaces on simplicial meshes in arbitrary dimension that fit in a finite element complex following the framework of the finite element exterior calculus (FEEC). The distinctive feature of this proposal is that we will build spaces that are smoother than traditional spaces (e.g. Whitney/Nedelec forms). Smoother spaces are more natural for some applications: plate problems, fluid flow problems. We will accomplish this by using splits of simplices that provide more structure than an arbitrary simplicial decomposition of a domain. The left most spaces of the complex will coincide with functions spaces that have been studied in the spline community. The far right spaces are ones that are associated with inf-sup stable finite element spaces for fluid flow problems. Thus, we plan to connect these function spaces in a natural way into a finite element complex. In addition, we will explore connections with the spline and applied algebraic geometry communities.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912854","Design and Analysis of Structure Preserving Discretizations to Simulate Pattern Formation in Liquid Crystals and Ferrofluids","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","06/21/2019","Franziska Weber","PA","Carnegie-Mellon University","Standard Grant","Yuliya Gorb","06/30/2023","$199,915.00","","franzisw@andrew.cmu.edu","5000 FORBES AVE","PITTSBURGH","PA","152133815","4122688746","MPS","1271","9263","$0.00","Complex fluids are mixtures that have a coexistence between two phases. Some examples include shaving cream, blood, and the liquid crystals used in displays (LCD displays) like the one you are probably using right now to read this abstract. On a microscopic scale, the molecules of complex fluids have a special structure, which at a macroscopic scale affects the mechanical response to stress and strain. For instance, the molecules of liquid crystals react to electric fields on a microscopic scale, which on a macroscopic scale changes the polarization of the light passing through the material. Monitors take advantage of this property to allow a certain amount of red, green, or blue light through each pixel. We have barely scratched the surface of what is possible to achieve with complex fluids. Medical researchers hope to exploit the microscopic properties of ferrofluids for magnetic drug targeting, to control with precision the parts of the human body the drug is able to interact with. Materials engineers hope to use complex fluids to assemble nano-structures such as the silicon circuits in CPUs. Mathematical models and computer simulations can be used to describe the dynamics of these fluids. The goal of this research project is to design and analyze new computational algorithms that simulate the behavior of liquid crystals and ferrofluids. The algorithms will be used in simulations which may complement and ultimately replace expensive physical experiments. This research activity may also contribute to our general understanding of pattern formation in complex materials.<br/><br/>Mathematical models for ferrofluids and liquid crystals consist of systems of partial differential equations. Due to the inherent fine scale structure of the fluids under consideration, these partial differential equations are highly nonlinear and coupled. Preserving discrete versions of energy balances, length and other constraints of the solutions of these nonlinear partial differential equations is crucial for obtaining fast and stable numerical schemes that capture realistic scenarios of their dynamics. The aim of this research project is to develop efficient and convergent finite volume and discontinuous Galerkin methods for the Rosensweig model of ferrohydrodynamics, multi-phase flow models of ferrofluids, and models of liquid crystal flows, that mimic the intrinsic structure of the underlying partial differential equations at the discrete level. The resulting algorithms will be implemented and used for extensive simulations to compare to physical observations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912958","Collaborative Research: Sparse Optimization in Large Scale Data  Processing: A Multiscale Proximity Approach","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","06/11/2019","Yuesheng Xu","VA","Old Dominion University Research Foundation","Standard Grant","Yuliya Gorb","06/30/2023","$125,000.00","","y1xu@odu.edu","4111 MONARCH WAY","NORFOLK","VA","235082561","7576834293","MPS","1271","9263","$0.00","There is an emergent demand in areas of national strategic interest such as information technology, nanotechnology, biotechnology, civil infrastructure and environment for abstracting useful knowledge for decision making or uncovering truth from large-scale data acquired via various means such as sensors and internet. A core issue of these areas is to develop accurate mathematical models, which govern the abstraction process, and to design efficient algorithms that solve the underlying optimization problems for the models. A challenge of the tasks comes from the large-scale nature of given data. This nature requires determining a large number of model parameters and it is computationally expensive. To address this challenge, this project will take advantage of certain intrinsic multiscale structure of given data in modeling so that the resulting models have significantly fewer parameters to be determined. It is also crucial to introduce efficient algorithms for solving the resulting optimization problems for the models, which have intrinsic multiscale structures. The second goal of this proposed research is to provide rigorous training of young mathematicians and computational scientists so that they have the skill sets needed to face the challenges of the big data era through this proposed research and its associated educational components. Outcomes of the proposed research and its educational component will certainly contribute to the Federal strategic interest areas.<br/><br/>This research project addresses several critical issues of processing large-scale data, such as high dimensionality and high noise, through properly choosing structured sparsity promoting non-convex functions in modeling and through synthesizing the multiscale representation of data and using fixed-point equations/inclusions involved the proximity operator in solving the resulting optimization problem. Structured non-convex sparsity promoting functions are proposed to overcome drawbacks of the existing modeling of large-scale data, leading to the design of efficient single-scale proximity algorithms. Multiscale analysis has been developed to efficiently represent data, while how multiscale representation of data is used to improve convergence of the fixed-point proximity algorithm remains unsolved. The proposed multiscale proximity method avoids iterations on the full large-scale of the fixed-point equation/inclusion. Instead, when data are represented in a multiscale analysis, iterations of the multiscale proximity algorithm are conducted only on a (small-scale) lower frequency component of the equation/inclusion (based on a single-scale algorithm), and only one functional evaluation on a (large-scale) high frequency component is required. The multiscale algorithm will preserve accuracy of the single-scale algorithm while accelerating its convergence significantly. This leads to a fast algorithm for solving the fixed-point equation/inclusion involved the proximity operator.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913080","Novel Virtual Element Methods with Applications in Interface Problems","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","05/30/2019","Shuhao Cao","CA","University of California-Irvine","Standard Grant","Yuliya Gorb","06/30/2021","$153,626.00","Long Chen","scao@umkc.edu","160 ALDRICH HALL","IRVINE","CA","926970001","9498247295","MPS","1271","9263","$0.00","Interface problems arise from many important complex multiphysics and biological systems, such as those involving the evolutions of multi-fluid/material interfaces, tumor growth, or stem cell deformation. Computer-aided simulation is a cost-friendly tool for the studies of these challenging interface problems. To approximate the governing mathematical equations of these systems, Virtual element method (VEM) is an emerging powerful tool in the scientific computing community. The objective of this research project is to develop both theoretical and practical aspects of various VEMs. Being able to reliably answer the question ""can we trust our simulation results?"" justifies the use of VEMs in simulating these complex systems. Meanwhile, this project strives to provide the public with a state-of-the-art VEM computer program that saves valuable computing resources. In addition, this research project creates opportunities to pass the torch on to graduate students to become the next generation computational mathematicians.<br/><br/>Solving elliptic partial differential equations with high-contrast diffusion coefficients play a central role in the modeling these complex systems. This project shall develop an in-depth robust a priori error analysis of VEM on elliptic interface problems. Different from the existing VEM analysis, this project devises a new novel paradigm to study the error analysis for the interface VEM, and further clarifies the dependence of the VEM convergence on the polytopal mesh geometries, justifying the VEM's applicability on interface-fitted mesh which may become extremely irregular or degenerate near the interfaces. Meanwhile, this project learns from the novelty of VEM framework to improve the analyses of traditional approaches for interface problems. The VEM's meta-formulation for elliptic problems enables us to construct immersed finite element spaces naturally in higher order and/or in 3-D.  Higher order interface VEMs, the a posteriori error estimation, and the adaptive polytopal mesh refinement are to be studied to render VEM more efficient and effective. This integrated study enables us to attack the challenging 3-D interface problems, which, in turn, broadens the scope in terms of both theory and tools for the whole numerical partial differential equation community. Last but not least, a portable and highly-vectorized VEM software library shall be made publicly available, including the semi-structured interface-fitted mesh generation, vectorized assembling, polytopal adaptivity, and fast multigrid solvers. The portability of the computer code enables the researchers to incorporate the VEM into existing software libraries dealing with interface problems, thus facilitating the interdisciplinary research in simulating those complex systems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1855584","Rocky Mountain Mathematics Consortium Summer School: Inverse Problems in Imaging","DMS","COMPUTATIONAL MATHEMATICS","05/15/2019","05/09/2019","Long Lee","WY","University of Wyoming","Standard Grant","Yuliya Gorb","04/30/2020","$25,000.00","","llee@uwyo.edu","1000 E UNIVERSITY AVE DEPARTMENT","LARAMIE","WY","820712000","3077665320","MPS","1271","7556, 9150, 9263","$0.00","This award provides participant support to the Rocky Mountain Mathematics Consortium (RMMC) summer school, to be held in June 2019 at the University of Wyoming. The summer school provides an intellectually stimulating environment for graduate students and junior faculty from various backgrounds in the Rocky Mountain area to learn and discuss immensely important subjects in mathematical sciences. The RMMC summer school held annually at the University of Wyoming since 1996. It has a long tradition of encouraging the participation of female graduate students and early-career researchers in mathematical sciences. The theme for the 2019 RMMC summer school is ""Inverse problems in imaging''. The program of the 2019 summer school will take place over six days. It will include short courses on selected topics given by six lecturers. There will be working group sessions. The working groups will help channel scientific discussions and the exchange of ideas on open problems and challenges in the area of inverse problems and its applications in medical and geophysical imaging.<br/> <br/>The program of  2019 RMMC summer school is split into several topics in inverse problems and imaging. The topics include regularization methods for inverse problems in imaging, optical imaging with biomedical applications, electrical impedance tomography (EIT) and the D-bar method, statistical inference for geophysical imaging, and integral equations, sampling methods and their applications in inverse scattering. The invited lecturers are leaders in these fields. The summer school not only provides an opportunity for young scientists, including graduate students, postdocs, and junior faculty in the Rocky Mountain area to interact with some of the best mathematical scientists in inverse problems and imaging sciences but also introduces the state-of-the-art techniques and research in inverse problems and image sciences to the Rocky Mountain scientific community. The web link to the RMMC summer school is https://www.uwyo.edu/mathstats/rmmc/summer19/index.html.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2005272","Topics of Immersed Finite Element Methods","DMS","COMPUTATIONAL MATHEMATICS","08/15/2019","11/13/2019","Xu Zhang","OK","Oklahoma State University","Standard Grant","Leland Jameson","08/31/2021","$49,809.00","","xzhang@okstate.edu","401 WHITEHURST HALL","STILLWATER","OK","740781031","4057449995","MPS","1271","9150, 9263","$0.00","Interface problems are ubiquitous. When simulations involve multiple materials or multi-physics, interface problems arise. Many real-world problems in fluid mechanics, material science, mechanical engineering, and biomedical engineering are modeled by three-dimensional interface problems. The immersed finite element methods (IFEM) are a class of numerical methods for solving interface problems on interface-unfitted meshes. Two interrelated problems will be investigated in this research project. The first problem aims to design a self-adaptive IFEM based on the a posteriori error estimation. The second problem focuses on development, implementation, and analysis of three-dimensional IFEM.<br/><br/>The first problem concerns the study of both residual-based and recovery-based error estimation for various immersed finite element discretizations. These include the immersed finite element approximation in conforming, nonconforming and discontinuous Galerkin frameworks. Rigorous mathematical analysis will be carried out for the reliability and efficiency error estimates of IFEM. The second problem focuses on interface problems of three spatial dimensions. It aims to develop an innovative approach to efficiently construct the three-dimensional immersed finite element functions. These immersed finite element functions will be implemented in various numerical schemes for three-dimensional interface problems. Theoretically, both a priori and a posteriori error estimates will be conducted for new IFEM schemes. Computationally, a three-dimensional IFEM software package will be developed with the feature of adaptive mesh refinement."
"1911320","Collaborative Research: High-Fidelity Modeling of Poromechanics with Strong Discontinuities","DMS","COMPUTATIONAL MATHEMATICS","07/15/2019","07/10/2019","Mary Wheeler","TX","University of Texas at Austin","Standard Grant","Yuliya Gorb","06/30/2023","$300,000.00","","mfw@ices.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271","9263","$0.00","Poromechanics with strong discontinuities has numerous important applications such as simulating fluid flow in natural static and hydraulic dynamic fractures, fracture analysis of aging bones, multiple-network poroelastic theory arising in dementia and Alzheimer's disease, and evaluation of accelerated degradation of ceramic matrix composites in aerospace shuttles. Here mathematical modeling is challenging because it involves not only coupled chemical reactions, diffusion, and deformation but also initiation, propagation, and branching of cracks in the bulk matrix as well as fluid flowing through cracks. To address these challenges, high fidelity numerical schemes and multiphysics models must be coupled in order to simulate these processes and their interactions accurately and efficiently. This project will benefit public and decision makers including energy producers, health providers, aerodynamicists, and hydrogeologists.<br/><br/>The objective of this project is to study the following fundamental relationships linking flow, chemistry, and mechanics: stability, a priori, and a posteriori error estimation of dynamic discontinuous Galerkin discretizations, physically consistent material models for the deformation and failure of the media, efficient and accurate material solution techniques, and scaling characteristics of mechanical properties.  This knowledge will be used in the design of locally conservative finite element methods coupling porous media flow, reactive transport, and mechanics that run efficiently on high-performance computing platforms.  The team will investigate: (1) Development of fundamental understanding of poromechanics with strong discontinuities in the setting of chemo-mechanical coupled models; (2) Formulation and analyses of flow, mechanical, and reactive transport models solved using high-fidelity numerical algorithms; (3) Developing error estimates for iterative coupling solution techniques; (4) Verifying and validating fluid structure interactions using published data from target data sets.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912779","New Finite Element Techniques for Simulating Flows and Waves","DMS","COMPUTATIONAL MATHEMATICS","09/01/2019","05/24/2019","Jay Gopalakrishnan","OR","Portland State University","Standard Grant","Yuliya Gorb","08/31/2023","$374,446.00","","gjay@pdx.edu","1600 SW 4TH AVE","PORTLAND","OR","972015522","5037259900","MPS","1271","9263","$0.00","Computer simulations of various natural and technological processes require accurate and efficient numerical approximation of flows and waves. This project advances the state of the art by developing unconventional approaches that improve numerical techniques at the heart of such simulations. In addition to the anticipated mathematical inventions, the project also plans to develop a public-domain open-source software product  implementing the new techniques and use the product to solve simulation problems in varied application domains including geological hazard mitigation and material science. Through inclusion of under-represented minorities, the project activities contribute to the foundation's goals to widen participation of all in science.<br/><br/>The technical work on the project is divided into two lines of inquiry. One leads to new methods for capturing wave solutions of hyperbolic systems, methods that are expected to excel on the emerging many-core architectures. Another line of inquiry leverages a new mathematical ingredient to obtain structure-preserving numerical approximations of viscous flows. The first line of inquiry is motivated by the observation that when hyperbolic solutions can be advanced in time by varying amounts at varying spatial locations, the allocation of computational resources is optimized. When this can also be done concurrently, much faster simulations are possible. New fast methods on unstructured spacetime meshes of causal spacetime tents are the projected outcome. The advances from this project benefit simulation of various wave propagation systems as well as inviscid compressible flows. Viscous incompressible flows are targeted by the second line of inquiry. Using a Sobolev space of matrix-valued functions, novel formulations are constructed that yield optimal fluid stress approximations, exact mass conservation, and pressure robustness. Work in both lines of inquiry involve answering several technical questions, shown to be fundamental, and of potential disciplinary impact beyond the confines of this project.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913180","RUI: Computational Methods for Measuring Topological Entanglement in Polymers","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","02/10/2023","Jin Wang","TN","University of Tennessee Chattanooga","Standard Grant","Yuliya Gorb","07/31/2024","$125,000.00","Eleni Panagiotou, Jin Wang","jin-wang02@utc.edu","615 MCCALLIE AVE","CHATTANOOGA","TN","374032504","4234254431","MPS","1271","9229, 9263","$0.00","This project aims to investigate the effects of polymer entanglement and architecture on material properties using computational and mathematical techniques. Entangled polymer physics are a subject of study since Edwards' original model in the 60's which is still under examination. Under some conditions we can see polymer chains as mathematical curves in space and measure their topological complexity. However, the use of topological entanglement for the study of polymer entanglement has not been fully explored, due to the difficulty of bridging the two notions, requiring background from topology and polymer physics and engineering. The project consists of an inter-disciplinary effort with researchers from Mathematics and Chemical Engineering to solve the problem of quantifying the effects of topological entanglement and polymer architecture to material properties of polymers. Our contribution is an innovative approach that integrates analytical, computational and experimental methods to solve a problem at the interface of polymer physics, topology and geometry. Understanding how microscopic properties affect material properties will lead not only to the smart manufacturing of new materials, but also to the understanding of living matter. This award will support 1 graduate student for each of the three years of the project.<br/> <br/>In order to understand and quantify the interplay between microstructure and macroscopic properties of polymers, we propose to use mathematical concepts from topology and investigate properties of polymers at different length-scales through computer simulations. Our results will be complemented and validated by experimental data.  The proposed works can be summarized as follows: (1) the creation of new methods to account for polymer entanglement in Self-Consistent Field Theory (SCFT) simulations, (2) the development of new partitioned algorithms to simulate the fluid-structure interaction for entangled polymers (3) the development of new computational user-packages for measuring topological entanglement of open curves and (4) the combined application of all the above mentioned tools to understand the self-assembly, organization and viscoelastic properties of polymer melts of varying architecture using simulations and experiments.   This study advances knowledge at the area of topology and geometry, by defining and studying new tools for measuring the geometrical/topological complexity of open curves in space and also advances computational infrastructure, by designing and prototyping algorithms in reusable code that in particular studies aspects in entangled polymer simulations (such as fluid-structure interactions for such systems and topological interactions). This work also extends SCFT simulations to account for topological aspects of polymers in a way that it is computationally feasible, which is presently absent in SCFT simulations. This holistic approach will thoroughly study entanglement in polymers of varying architecture that are currently of great interest in materials and manufacturing and nanotechnology, with the potential of immediate impact of our results to practical manufacturing. Our results also provide valuable tools for studying biopolymers with potential impact in biotechnology. This project has educational objectives including strong impact on undergraduate research with a commitment in promoting underrepresented groups in STEM.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912704","Direct and Inverse Scattering Problems in Elastic Waves: Analysis and Computation","DMS","COMPUTATIONAL MATHEMATICS","08/15/2019","07/30/2019","Peijun Li","IN","Purdue University","Standard Grant","Yuliya Gorb","12/31/2022","$149,782.00","","lipeijun@math.purdue.edu","2550 NORTHWESTERN AVE STE 1900","WEST LAFAYETTE","IN","479061332","7654941055","MPS","1271","9263","$0.00","Scattering problems are concerned with the effect that an inhomogeneous medium has on an incident field. Driven by significant applications in diverse scientific areas such as radar and sonar, geophysical exploration, nondestructive testing, medical imaging, near-field optical microscopy, and nano-optics,<br/>the scattering problems have been extensively studied by many researchers, especially for acoustic and electromagnetic waves. However, many theoretical analysis and numerical computation are left undone for elastic waves due to the complexity of the underlying model equations. The research is multidisciplinary by nature and lies at the interface of mathematics, physics, engineering, and materials sciences. It will contribute towards better understandings of the complex physical and mathematical problems in scattering theory of elasticity. It has significant potential for advancing the frontiers of applied and computational mathematics, and for evolving new mathematics and science. The results of the proposed research activities will be disseminated through publications, seminars, minisymposia, conferences, and workshops. The PI will introduce an advanced graduate course and a graduate seminar series. These will aid in the recruitment and retention of talented students with diverse backgrounds throughout the academic pipeline. The software codes and new course materials developed in the project will be disseminated on a public website and will be available for download by the scientific community. The research and educational components will be integrated together to help to train a new generation of researchers and foster greater awareness and interests in applied and computational mathematics with particular applications to scattering theory among graduate students and postdocs. <br/><br/>This project outlines a three-year research plan for developing effective mathematical models, examining fundamental mathematical issues, and designing efficient computational methods for new and important classes of direct and inverse scattering problems in elastic waves. The proposed research builds on the PI?s prior research accomplishments in the area of scattering theory for acoustic and electromagnetic waves. It concerns the following three topics: (1) time-domain obstacle scattering problem; (2) time-harmonic medium scattering problem; (3) inverse random source scattering problem. The mathematical modeling and analysis techniques and computational methods developed in this project will address several key scientific challenges and open problems in direct and inverse scattering theory for elastic waves, which include modeling and computation of the elastic wave propagation in an inhomogeneous medium, numerical solution of the elastic wave equations and well-posedness of the associated model, uniqueness and stability of stochastic inverse source scattering problem. The proposed computational models and tools are highly promising for quantitative study of the complex physical and mathematical problems in elasticity. They have great potentials to provide inexpensive and easily controllable virtual prototypes of the structures in the design and fabrication of novel elastic devices.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913243","Learning Dynamics from Data: Discovering Interaction Laws of Particle and Agent Systems","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","07/24/2019","Fei Lu","MD","Johns Hopkins University","Standard Grant","Yuliya Gorb","12/31/2022","$299,998.00","Mauro Maggioni","flu15@jhu.edu","3400 N CHARLES ST","BALTIMORE","MD","212182608","4439971898","MPS","1271","075Z, 079Z, 9263","$0.00","Particle and agent-based systems are ubiquitous in science, for example, particle systems in fundamental physics, agent-based systems that model opinion dynamics under the social influence, prey-predator dynamics, flocking and swarming, and phototaxis in cell dynamics. To understand the mechanism of these systems, a fundamental challenge is to infer the laws of interaction between the particles and agents from observational data. This project aims to develop mathematical and statistical theory and  computationally efficient algorithms for learning these interaction laws from observations in the form of trajectories of the systems. The theory provides performance guarantees and uncertainty quantification in the estimations, therefore providing foundations for model selection and for optimal data collection. The algorithms are scalable to large data sets, avoiding the curse of dimensionality, and are applicable to a wide variety of systems from Physics, Biology, Ecology and Social Sciences.<br/><br/>The interaction laws vary largely for different systems, and there is no analytical form in general. The PIs propose non-parametric statistical inference approaches for learning the interaction laws, with no reference or assumption on their analytical form. The research will develop a systematical learning theory for the non-parametric regression of the interaction kernels, whose values are not observed and can not be computed from the data of trajectories of the particles or agents in the system. The theory will study the identifiability of the interaction kernels, the consistency of the estimators, and the optimal choice of hypothesis spaces to achieve optimal rate of convergence of the estimators. With the guidance from the learning theory, we will design computationally efficient algorithms with the following features: (i) avoiding the curse of dimensionality by focusing on the intrinsic dimension of the interaction kernels; (ii) with theoretical guarantee and uncertainty quantification which can be used for model selection and optimal data collection; (iii) scalable to large data sets by implementing in parallel.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1903654","North American High Order Methods Conference (NAHOMCon)","DMS","COMPUTATIONAL MATHEMATICS","06/01/2019","05/27/2022","Gustaaf Jacobs","CA","San Diego State University Foundation","Standard Grant","Yuliya Gorb","07/31/2022","$25,000.00","","gjacobs@mail.sdsu.edu","5250 CAMPANILE DR MC1947","SAN DIEGO","CA","921821901","6195945731","MPS","1271","7556, 9263","$0.00","This award provides participant support to the North American High Order Methods Conference (NAHOMCon), to be held June 2-5, 2019 at the San Diego State University. The conference will serve as a forum for computational scientists, mathematicians, scientists and engineers to share ideas and techniques on and further the state of the art of advanced high order methods used to solve a broad range of scientific and engineering problems. American competitiveness depends heavily on technological advances.Yet American research on high order methods has been at a disadvantage compared to that in European or other nations due to the lack of conferences devoted to the subject. This conference will have broad impacts by providing a forum for researchers on high order numerical methods for the solution of scientific and engineering problems of strategic importance. It also recognizes the need for younger researchers, women and minorities  to have a forum in the US. More details about the conference can be found at https://www.nahomcon19.sdsu.edu/.<br/><br/>High order approximations to PDEs, be they finite difference, finite element or spectral, have needed advantages over lower order methods. Of course, they have lower errors for a given number of degrees of freedom. But also they are usually designed to have lower dissipation and dispersion errors. Their high resolution makes them more suitable for intrinsic multiscale problems such as turbulence computations, chemically reacting flows and  nuclear fusion reaction. The NSF currently supports numerous research projects on high order methods, but no nationwide conferences are in place that are focused on their study. The proposed conference topics are based on the general thrusts of these projects and are the forefront of high order method development. They include provably stable schemes, fast solvers for high order methods, methods for complex geometries, efficient and parallel implementations. Applications are considered in a range of fields including geoscience, fluid mechanics, combustion, solid mechanics, electromagnetics, biomedical, and image processing.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1930036","US Participation at the Twenty-sixth Internaltional Domain Decomposition Conference","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","07/16/2019","Jinchao Xu","PA","Pennsylvania State Univ University Park","Standard Grant","Leland Jameson","01/31/2021","$15,000.00","","xu@math.psu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271","7556, 9263","$0.00","Scientific computing is an important and general interdisciplinary research field and plays a crucial role in many application areas in science and engineering. In recent years, there has been tremendous growth in both the need for large-scale scientific computing and the amount of computing power, thanks to new high performance computing (HPC) clusters with millions of cores. Domain decomposition methods represent one of the most powerful and versatile techniques for the efficient parallel solution of such large-scale scientific problems. The goal of the current project is to provide financial support for US-based early career researchers, i.e., graduate students and post-docs, to attend the 26th International Conference on Domain Decomposition Methods, to be held in Hong Kong from December 2-6, 2019. The conference is part of a series that is considered one of the most successful in Applied and Computational Mathematics. The NSF-funded US participants will benefit from learning about cutting-edge developments in domain decomposition methods and latest worldwide trends in high performance computing. They will also have the opportunity to develop new collaborations with other researchers from Asia and around the world. The proposal will support up to 10 participants to travel to this workshop and some of these 10 are expected to be graduate students at US universities.<br/><br/>Domain decomposition methods (DDM) can be regarded as a divide-and-conquer strategy for solving mathematical problems posed in a physical domain, reducing a large problem into many smaller, but easier-to-solve, problems. They are particularly suited for making efficient use of distributed memory architectures, which are able to solve many such smaller problems in parallel. As we approach the dawn of exascale computing, such scalable techniques are vital tools for solving complex problems in physics and engineering that would otherwise be intractable. Since 1987, the International Conferences of Domain Decomposition Methods have been held in 15 countries throughout Asia, Europe and North America. In this conference, now in its 26th edition, researchers in domain decomposition and related fields will present and discuss state-of-the-art methodologies and developments and propose future directions in high performance computing. Early career researchers will be able to participate in one of three ways: as speakers at a minisymposium organized by fellow participants, by giving a contributed talk, or by presenting a poster. The NSF-funded US participants, consisting of graduate students, postdocs and other early career researchers who lack their own funding, will benefit from learning new developments in domain decomposition methods and latest trends in high performance computing. MOre details are available at the conference website: https://www.math.cuhk.edu.hk/conference/dd26/?Conference-Home<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913006","Information-Based Complexity Analysis for Large-Scale Nonlinear Optimization","DMS","COMPUTATIONAL MATHEMATICS, EPSCoR Co-Funding","07/01/2019","06/21/2019","Yuyuan Ouyang","SC","Clemson University","Standard Grant","Yuliya Gorb","12/31/2022","$243,756.00","","yuyuano@clemson.edu","201 SIKES HALL","CLEMSON","SC","296340001","8646562424","MPS","1271, 9150","079Z, 9150, 9263","$0.00","Recent years have seen rapid advances in the fields of data analysis, which has impacts in various disciplines. Optimization has been an important tool in solving problems arising from data analysis applications. Modern applications with large volume datasets and sophisticated data structures bring great challenges to designing scalable and efficient numerical optimization algorithms for large-scale nonlinear optimization problems. While the goal of optimization algorithm design is to solve the problems of interest as efficiently as possible, it is equally important to study the complexity of the problems of interest themselves. In particular, the complexity analysis of a class of nonlinear optimization problems reveals the fundamental performance limits of any algorithms for solving problems in such class. The discovered performance limits would then encourage one to design efficient algorithms that reach such performance limits. <br/> <br/>First-order methods are a class of numerical optimization algorithms that only need to access the information on function value and first-order derivatives. Due to the computational efficiency and scalability, first-order methods have been widely used to solve large-scale nonlinear optimization problems. This proposal addresses the important question of performance limits of first-order methods through the information-based complexity theory. The problems of interests are nonlinear optimization with different special structures. In order to accelerate computation, many special problem structures have been explored in the literature on algorithm design. By utilizing the problem structure, several newly designed algorithms are able to achieve improved computational performance. However, comparing with the rapidly growing number of new and novel algorithms on structured nonlinear optimization, the complexity analysis and the design of worse-case instances does not match with the advancement in algorithm design. This proposal aims to close some of the aforementioned gaps by constructing several worst-case examples that demonstrate the performance limits of first-order methods, in the hope of broaden the understanding of efficiency of first-order methods and the difficulty of certain nonlinear optimization models.<br/><br/>This project is jointly funded by Computational Mathematics Program, DMS/MPS, and the Established Program to Stimulate Competitive Research (EPSCoR).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912685","Collaborative Research:  Accurate, Efficient and Robust Computational Algorithms  for Detecting Changes in a Scene Given Indirect Data","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","06/11/2019","Anne Gelb","NH","Dartmouth College","Standard Grant","Yuliya Gorb","07/31/2024","$139,999.00","","annegelb@math.dartmouth.edu","7 LEBANON ST","HANOVER","NH","037552170","6036463007","MPS","1271","9150, 9263","$0.00","Detecting change from a temporal sequence of collected data is important in a wide variety of applications, including speech recognition, medical monitoring, credit card fraud detection, automated target recognition, and video surveillance. In applications such as medical monitoring, it is very important to find where the change occurs. In other applications, such as video surveillance, the type of change, e.g. the movement or insertion/deletion of an object of interest, is also critical.  While detecting such changes from direct data (e.g. images already formed) has been well studied, there are many applications, such as magnetic resonance imaging (MRI), ultrasound, and synthetic aperture radar (SAR) where the temporal sequence of data are acquired indirectly. The typical approach to detecting changes in these applications would be to first form the image or signal of interest.  As a consequence, information that is stored in the indirect data that may be valuable to detecting change is often lost. Therefore, this project seeks to develop accurate, efficient, and robust computational algorithms for detecting changes in a signal or image from a given temporal sequence of indirect data without first reconstructing the signal or image of interest. Additionally, the project seeks to incorporate the change information  to develop better image and signal reconstruction algorithms.  Both graduate and undergraduate students will be involved in the research investigations to enhance their career preparation in science and engineering.  The participants will apply these new techniques on publicly available data sets, notably obtained for MRI, ultrasound, and SAR applications.  <br/><br/>The PIs will employ tools in frame theory, optimization, and statistics to develop and rigorously analyze new change detection and image/signal recovery algorithms. Specifically, the PIs will address the following technical issues in the proposed work: (1) the incorporation of prior information with appropriate mathematical/statistical formulation in the model; (2) the extraction of rotation/translation of an object from a sequence of indirect data; (3) model parameters tuning through statistical analysis; (4) the employment of intra- and inter-signal correlations in the recovery algorithms; (5) the design of distributed algorithms for the resulting large-size optimization model.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913229","Consistent Multi-Scale Treatments of Ion Transport in Biological Environments","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","06/21/2019","Lina Ma","CT","Trinity College","Standard Grant","Yuliya Gorb","06/30/2022","$100,000.00","","lina.ma@trincoll.edu","300 SUMMIT ST","HARTFORD","CT","061063100","8602975347","MPS","1271","9263","$0.00","Modeling and numerical simulations of practical biology processes have always been limited, either because the model itself lacks the accordance to important real world physics law or the prohibitively high computational cost to simulate the process at molecular level. Extensive research in molecular biology shows that molecules control macroscopic biological function. The communication between significantly different temporal and physical scales becomes vital in representing an accurate biological process. This project is designed to bridge the critical gaps between different physical scales. It emphasizes on adopting consistent physical laws throughout various scales. It aims to develop multi-scale models, and further conduct numerical simulations to investigate biological process. The result of the project will deliver a substantial advance in both scientific computing and biological modeling. A more complete model advances the understanding of living organisms, and will have broader impacts in bioengineering and human health. <br/><br/>This project will investigate the ionic transport with applications to processes occurring near or across cell membranes. To study diffusion, ion transport, and heat flow in one consistent framework, we propose the following approach. (a) In order to ensure the consistency with important physical principles and the robustness of the model, we pose the mathematical problem within an energetic variational framework. Highly accurate numerical method will be chosen to simulate the model. (b) Based on the full molecular dynamics model, we will choose appropriate local ion density and current, the local energy and energy flux, while making sure that the conservation laws are exactly satisfied at every scale. This coarse-graining procedure reduces the full molecular description to a system of equations at a much larger spatial, and more importantly, much longer temporal scales. (c)The longer time regime and the finer time scale will communicate with each other and update the corresponding coefficients. With this new integrated mathematical framework, this project will address the fundamental modeling difficulty, and develop efficient numerical schemes to improve the realization of the role of ionic solutions in determining biological functions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913038","Geometric Approximation and Variational Problems","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","06/20/2019","Thomas Yu","PA","Drexel University","Standard Grant","Yuliya Gorb","07/31/2024","$299,999.00","","yut@drexel.edu","3141 CHESTNUT ST","PHILADELPHIA","PA","191042816","2158956342","MPS","1271","9263","$0.00","The proposed research program address problems in geometric numerical methods. Besides numerous engineering applications, accurate computational methods for approximation and estimation of geometric information can help understanding and saving lives. Numerical treatment of biomembrane problems is one example of application to life sciences. Approximation methods of manifold-valued data can be applied to diffusion tensor image data for reconstructing white matter structure of human brain; such techniques have shown promises in diagnosing psychiatric disorders. Due to the success in applications such as machine learning, signal processing, and control system, large scale numerical optimization is now considered as a key component of engineering, a patient study of optimization methods for specific geometric problems with practical relevance will contribute to the understanding of solving large scale optimization problems. The projects outlined in this research also provide interdisciplinary research and training opportunities for graduate students, and stimulate collaboration among computational mathematicians, engineers and scientists. The publicly available software implementation of our research results further facilitates such training and collaborations.<br/><br/>A number of projects under the headline of ""geometric approximation and variational problems"". Extensions of the Wmincon software with applications to geometric variational problems in general relativity This work details a line of research related to geometric approximation and variational problems, including systematic studies of numerical solution of biomembranes and bilayer plate models from mechanical engineering, as well as approximation and analysis of geometric data. The projects will lead to a cross fertilization of geometry, optimization theory, computational mathematics, as well as application areas such as engineering simulation, processing of novel geometric signals, and geometric machine learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1854383","FRG: Collaborative Research: Non-Smooth Geometry, Spectral Theory, and Data: Learning and Representing Projections of Complex Systems","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","06/21/2019","Dimitrios Giannakis","NY","New York University","Standard Grant","Leland Jameson","11/30/2021","$536,419.00","","dimitrios.giannakis@dartmouth.edu","70 WASHINGTON SQ S","NEW YORK","NY","100121019","2129982121","MPS","1271","079Z, 1616, 9263","$0.00","Complex, time-evolving systems are ubiquitous in nature and society, with examples ranging from the Earth's weather and climate, to the function and dynamics of biomolecules, and the behavior of markets and economies. Despite their apparent complexity, many such systems exhibit a form of underlying organized structure (``building blocks''), whose discovery would enhance our ability to understand and predict a wide range of phenomena. The goal of this project is to develop the next generation of mathematical and algorithmic tools that can harness the information content of large datasets acquired from experiments and observations to create coherent representations of complex systems, and use these representations to perform prediction, and ultimately, control. These objectives will be addressed through a novel combination of mathematical techniques, bridging dynamical systems theory and differential geometry with machine learning and data science. The newly developed techniques will be tested and applied in real-world problems through collaboration with domain experts in the areas of climate dynamics, space physics, and condensed matter physics. The project will also contribute to STEM workforce and curricular development through training of students and postdoctoral researchers, and design of multi-disciplinary lecture courses.      <br/><br/>The modern scientific method is undergoing an evolutionary change wherein large data sets and machine learning algorithms have the potential to outperform classical first-principles approaches for certain complex phenomena.  For these tools to be accepted by the scientific community, a rigorous mathematical framework is required to match the verifiability and quantifiability of the classical modeling approach.  Recently, a new tool called the diffusion forecast has been developed based on provably consistent estimators, which learn the unknown structure of a large class of stochastic dynamical systems on manifolds.  Moreover, the results of many published numerical experiments indicate that this framework can be applied far beyond the restricted context of the current theory.  In particular, the evidence suggests that the consistency proofs can be extended to non-autonomous projections of complex systems, deterministic chaotic systems represented by non-compact operators, non-smooth domains such as fractal attractors, and even generalized tensors on metric-measure spaces. This project will undertake a rigorous mathematical unification of these problems, leading to transformative advances in our ability to model and describe complex systems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912847","Efficient and Adaptive Methods for Simulating Multiscale Effects in Optical Metamaterials","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/01/2019","06/21/2019","Matthias Maier","TX","Texas A&M University","Standard Grant","Yuliya Gorb","08/31/2022","$125,000.00","","maier@math.tamu.edu","400 HARVEY MITCHELL PKY S STE 30","COLLEGE STATION","TX","778454375","9798626777","MPS","1266, 1271","9263","$0.00","The project centers on the development of novel computational approaches to simulate the optical properties of metamaterials. Metamaterials are small optical devices that manipulate light on a microscopic scale. An important aspect of the project is the dissemination of the developed numerical algorithms in form of publicly available open source software. As such the project will enable and foster research directions in optics that require a strong computational component. In addition to the dissemination of the research to the scientific community, results will be presented to students through graduate courses, mentoring of students, and university-internal research and student seminars. In particular, the PI plans to develop a new graduate-level course about advanced finite element methods for optical problems. Efforts will be made to attract female and minority students and stimulate their interest by presenting and incorporating exciting new research topics in numerical methods courses on upper-division undergraduate level.<br/><br/>Metamaterials are specifically engineered, periodically aligned microstructures that exhibit unusual optical properties. A major challenge that manifests in the simulation of scattering processes involving metamaterials is that they are of pronounced two-scale character, meaning that relevant optical processes act on very different length scales. This is complicated by the fact that realistic experimental geometries contain 1D discontinuities at boundaries of the 2D material sheets. Such discontinuities cause edge effects that are challenging to simulate due to their dominant and singular behavior. The project centers around the development and analysis of novel computational approaches for the simulation of scattering processes in complex optical devices, that are able to cope with the two-scale character and the occurrence of edge effects: (1) a parallel and adaptive finite element method for 3D device simulations will be developed and implemented that combines goal-oriented local mesh refinement and domain decomposition for MPI parallelization and preconditioning; (2) a heterogeneous multiscale method will be developed and analyzed that incorporates model-adaptive strategies for an efficient sampling of effective metamaterial parameters; (3) special emphasis will be given in both research directions to connect the algorithmic and numerical development to interdisciplinary applications.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1846690","CAREER: Mathematical Modeling from Data to Insights and Beyond","DMS","COMPUTATIONAL MATHEMATICS","06/01/2019","05/17/2023","Yifei Lou","TX","University of Texas at Dallas","Continuing Grant","Yuliya Gorb","05/31/2024","$400,213.00","","yifei.lou@utdallas.edu","800 WEST CAMPBELL RD.","RICHARDSON","TX","750803021","9728832313","MPS","1271","1045, 9263","$0.00","This project will develop both analytical and computational tools for data-driven applications. In particular, analytical tools will hold great promise to provide theoretical guidance on how to acquire data more efficiently than current practices. To retrieve useful information from data, numerical methods will be investigated with emphasis on guaranteed convergence and algorithmic acceleration. Thanks to close interactions with collaborators in data science and information technology, the investigator will ensure the practicability of the proposed research, leading to a real impact. The investigator will also devote herself to various outreach activities in the field of data science. For example, she will initiate a local network of students, faculty members, and domain experts to develop close ties between mathematics and industry as well as to broaden career opportunities for mathematics students. This initiative will have a positive impact on the entire mathematical sciences community. In addition, she will advocate for the integration of mathematical modeling into K-16 education by collaborating with The University of Texas at Dallas Diversity Scholarship Program to reach out to mathematics/sciences teachers.<br/><br/>This project addresses important issues in extracting insights from data and training the next generation in the ""big data"" era. The research focuses on signal/image recovery from a limited number of measurements, in which ""limited"" refers to the fact that the amount of data that can be taken or transmitted is limited by technical or economic constraints. When data is insufficient, one often requires additional information from the application domain to build a mathematical model, followed by numerical methods. Questions to be explored in this project include: (1) how difficult is the process of extracting insights from data? (2) how should reasonable assumptions be taken into account to build a mathematical model? (3) how should an efficient algorithm be designed to find a model solution? More importantly, a feedback loop from insights to data will be introduced, i.e., (4) how to improve upon data acquisition so that information becomes easier to retrieve? As these questions mimic the standard procedure in mathematical modeling, the proposed research provides a plethora of illustrative examples to enrich the education of mathematical modeling. In fact, one of this CAREER award's educational objectives is to advocate the integration of mathematical modeling into K-16 education so that students will develop problem-solving skills in early ages. In addition, the proposed research requires close interactions with domain experts in business, industry, and government (BIG), where real-world problems come from. This requirement helps to fulfill another educational objective, that is, to promote BIG employment by providing adequate training for students in successful approaches to BIG problems together with BIG workforce skills.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1907169","Conference on Computational Mathematics and Applications (CCAM)","DMS","COMPUTATIONAL MATHEMATICS","05/15/2019","05/15/2019","Jichun Li","NV","University of Nevada Las Vegas","Standard Grant","Leland Jameson","04/30/2021","$18,389.00","Zhijian Wu, Monika Neda","jichun.li@unlv.edu","4505 S MARYLAND PKWY","LAS VEGAS","NV","891549900","7028951357","MPS","1271","7556, 9150, 9263","$0.00","This award provides participant support to Conference on Computational Mathematics and Applications (CCMA), to be held at University of Nevada Las Vegas (UNLV), October 25-27, 2019. Computational Mathematics is a rapidly growing multidisciplinary field lying at the intersection of mathematics and many disciplines of science and engineering. With the increasing of computational technology in recent years, the pivotal role of Computational Mathematics continues to expand to broader areas that include not only the traditional science and engineering, but also social sciences, finance, medical science and data science. In order to disseminate the state-of-the-art computational techniques and put them into broad applications, the organizers propose to host ""Conference on Computational Mathematics and Applications (CCMA) at the University of Nevada Las Vegas (UNLV) during October 25-27, 2019. Holding the proposed conference at UNLV will not only provide a strong stimulus for our graduate students and increase the local research activity for mathematicians and people from other related disciplines, it will also serve as a new catalysis for proposing new computational methodology and pointing some new research directions in scientific computing.<br/><br/>This conference will bring many prominent scholars in Computational and Applied Mathematics to address important topics that have fundamental scientific merits and significant application values.  Topics to be focused are: ""Recent advances in wave propagation and applications"", ""Numerical methods for stochastic PDEs and applications"", ""Numerical analysis and modeling of complex fluids"", and ""Machine Learning for Scientific Computing"". The organizers plan to host around 60 participants with 6 invited plenary 50-minute talks, and several parallel sessions of 30-minute talks. The organizers will strive to support about 10 postdocs and junior faculty, especially women and under-represented minorities. The subjects covered in this conference will benefit not only mathematics, but also many other computational related fields such as mechanical engineering, geosciences, physics, and medical sciences. To create a long term impact, a refereed conference proceeding will be published after the conference either as a book in the AMS Contemporary Mathematics series or as a special issue of a computational science journal. More details are available at http://cams.sites.unlv.edu/conferences/ccma2019/ccma2019.html.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912866","Non-convex Variational Image Processing: Boosting Classical Methods with Machine Learning","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","07/29/2019","Thomas Goldstein","MD","University of Maryland, College Park","Standard Grant","Yuliya Gorb","07/31/2022","$198,152.00","","tomg@cs.umd.edu","3112 LEE BLDG 7809 REGENTS DR","College Park","MD","207420001","3014056269","MPS","1271","079Z, 9263","$0.00","Recent advances in machine learning and AI, particularly those based on artificial neural networks, have enabled us to build systems that solve difficult information processing problems with human-like accuracy.  For example, neural networks can recognize objects, predict how proteins fold, automate manufacturing processing, and use computer vision to navigate a vehicle or analyze satellite imagery. Unfortunately, these advanced AI systems come with their own unique problems.  Like humans, neural networks can behave erratically, sometimes making strange and unexplainable decisions when asked to perform tasks that differ even a little from their training. For this reason, classifical image and signal processing methods are still the go-to solution when reliability, interpretability, and computational speed at needed.  The goal of this research project is to mash up the performance and power of neural networks with the speed and reliability and classical algorithms. This research project also features an integrated teaching plan involving graduate students and undergraduate interns.<br/> <br/>To achieve this goal, we consider three interrelated research thrusts.  First, we consider ways that deep networks can help to automate and improve classical algorithms.  For example, networks can be used to automate the selection of hyper-parameters, choose objective functions to minimize, identify noise types and levels that are present in data, and make other decisions that are needed to optimally tune the performance of classical imaging system.  Second, we consider ways that neural networks can be 'plugged in' to classical variational imaging methods. For example, classical image priors (such as wavelet sparsity or total variation), can be replaced with more sophisticated priors defined by neural networks. Third, we consider efficient algorithms for solving minimization problems that arise when complex neural networks are used as components in classical optimization problems.  Better algorithms will allow us to solve these complex problems efficiently, and without human oversight. This new suite of approaches has the potential to improve that state of the art for a range of important practical problems that have been studied by the PI. This includes enhancing deblurring problems of the type used for microscopy of new materials, boosting segmentation algorithms used to identify faults in semiconductor manufacturing, and solving complex resource allocation problems for medical applications.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1906266","Sage-Days Workshop on Computational Arithmetic Dynamics 2019","DMS","COMPUTATIONAL MATHEMATICS, CDS&E-MSS","11/01/2019","06/27/2019","Benjamin Hutz","MO","Saint Louis University","Standard Grant","Yuliya Gorb","10/31/2020","$22,500.00","Adam Towsley, Paul Fili","benjamin.hutz@slu.edu","221 N GRAND BLVD","SAINT LOUIS","MO","631032006","3149773925","MPS","1271, 8069","7556, 9150, 9263","$0.00","This award supports participation in the Sage-Days Workshop on Computational Arithmetic Dynamics held November 17-20, 2019 at Saint Louis University. The use of computers in the sciences over the last several decades has expanded enormously. With the increasing complexity of problems to be solved and increasing capacity of hardware to solve these problems, it is essential that students and researchers have cutting-edge computational tools available to them. This workshop brings together researchers in dynamical systems to further the development of open-source computational tools for use both in research and applications. Arithmetic dynamics is a relatively new area of mathematics at the intersection of number theory, dynamical systems, and arithmetic geometry. At its most fundamental, it concerns the resolution of systems of equations that arise from iterated systems. Its value to other disciplines lies in concrete constructions and computational tools. Applications range from weather prediction, to cellular modelling, to cryptography. Modern computational tools have great potential in these applications. These tools will be implemented in the open-source software Sage and made freely available to the public under the GNU public license. In addition to the development of computational tools, another main goal of the workshop is the training in the use of these computational tools. Participants of this workshop will become proficient in the current tools and be able to train colleagues and students in their use. Finally, these tools will be used to improve the database of dynamical systems. For ages, mathematicians have been compiling tables of computationally intensive information for widespread use. These tools are currently capable of computing an extensive set of properties that would be of use to the research community in an organized searchable form. The database of dynamical systems performs this service for the dynamical systems community.<br/><br/>A goal of this workshop is to improve the current set of computational tools for dynamical systems included in the computer algebra system Sage. The tools allow one to quickly and efficiently work with explicit examples to test and prove new theories, to compute examples too complicated to be worked out by hand, and to allow students to explicitly investigate conjectures and specific examples. With the maturity of the current set of tools, we have reached the point where we can compute many properties of dynamical systems. Consequently, the creation of a database to organize the known examples is feasible. A comprehensive efficiently searchable collection of examples will be of considerable use to the research community. The current prototype of the database of dynamical systems will be improved and expanded at this workshop. With the tools freely available, the main barrier to their use is training/education. The organizers will actively recruit women and other under-represented in mathematics groups to this workshop, with a focus on graduate students, post-docs, and early career faculty.<br/><br/>More information is available at the workshop web page http://mathstat.slu.edu/~hutzba/sage_days_2019.html<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912747","Flexible and Sound Computational Harmonic Analysis Tools for Graphs and Networks","DMS","COMPUTATIONAL MATHEMATICS","06/15/2019","07/08/2019","Naoki Saito","CA","University of California-Davis","Standard Grant","Yuliya Gorb","05/31/2024","$400,000.00","","saito@math.ucdavis.edu","1850 RESEARCH PARK DR, STE 300","DAVIS","CA","956186153","5307547700","MPS","1271","9263","$0.00","In recent years, the field of data analysis on graphs and networks is experiencing rapid growth due to a confluence of several trends in science and technology: the advent of new sensors and social network infrastructure, together with the availability of low-cost computing devices, has ignited an explosion in research and development activities in both academia and industry. It has become a pressing issue to develop more flexible yet mathematically sound tools for graph data analysis. The algorithms and software tools to be developed will make a positive impact in solving practical data analysis problems on graphs and networks in diverse fields, e.g., biology and medicine (analyzing data measured on neuronal networks); computer science (analyzing friendship relations in social networks); electrical engineering (monitoring and controlling sensor networks); geology (measuring stream flows in a ramified river network); and civil engineering (monitoring traffic flow on a road network), to name a few. Moreover, those algorithms and software tools will be highly useful for data in conventional formats such as usual digital signals and images. This is because those tools can treat the conventional data as graphs, consequently can extract signal features that are not readily accessible by conventional methods. Students engaged in this project will be trained to be the next generation of interdisciplinary scientists who have deep knowledge in one area yet have open mind to the other areas and try to actively seek collaborations with domain experts (such as neuroscientists or civil engineers). The proposed project will also bring in the insights gained by the experience of the PI in the different fields: image analysis; scientific computing; statistical signal processing; computational neuroscience; and harmonic analysis. These students will gain broad perspectives, which will be helpful for their future career, either in academia or in industry.<br/><br/>The goal of this project is to develop flexible and sound computational harmonic analysis tools for analyzing data recorded on graphs and networks and demonstrate their usefulness on a variety of applications. The PI team has developed such a tool, called the Generalized Haar-Walsh Transform (GHWT), which completely lifted the conventional Haar-Walsh wavelet packet transform from the regular lattice setting to the much more general graph setting. Yet, that is not enough. The proposed project will extend the GHWT to make it more flexible and adaptive to graph data of interest. In particular, the PI team will develop the extended GHWT (eGHWT) and the associated best-basis selection algorithm for graphs that will significantly improve the previous GHWT with the similar computational cost, and apply it to important problems ranging from simultaneous image segmentation and compression to matrix data analysis. The PI team will also investigate what would be the natural dual domain of a given graph and how one could build a sound graph wavelet theory and generate smooth multiscale basis dictionaries on graphs. This part begins with the idea of defining a multiscale metric between any two eigenvectors of the graph Laplacian matrix of an input graph. Then, the project will construct the natural dual domain of the graph, i.e., a low dimensional Euclidean space where those eigenvectors are embedded using that metric (like the Fourier domain lattice for the regular spatial lattice case). Once this is done, it should be able to build natural and sound wavelets and multiscale basis dictionaries on that graph by appropriately grouping and clustering the eigenvectors in the dual domain in a similar manner to how the conventional Littlewood-Paley theory organizes the sinusoids in the regular lattice case.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912816","From Quantum Entanglement to Tensor Decomposition by Global Optimization","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","06/20/2019","Moody Chu","NC","North Carolina State University","Standard Grant","Yuliya Gorb","06/30/2024","$470,788.00","","chu@math.ncsu.edu","2601 WOLF VILLAGE WAY","RALEIGH","NC","27607","9195152444","MPS","1271","7203, 9263","$0.00","Entanglement and separability are twins. Entanglement is the most basic mode when characterizing the coupling or interaction of multiple parts within a system; separability is to represent the complicated system in an equivalent but more manifesting relationship for understanding and control. This project aims to develop methods to numerically measure the ""absolute"" gap between an entangled state and its nearest separable state with the new tool of global optimization techniques. The initial goal is to establish a basal paradigm for gauging entanglement and separability with global optimization technologies in the context of quantum informatics. With modest modification, the paradigm can be applied across different fields. Results from this research will make it possible to address separability issues in many other contexts, such as economic development, agricultural production, industrial manufacture, environmental evolution, social networks, and applied mechanics, where constituents, factors, parts, or subsystems are regularly intertwined.<br/><br/>Quantum entanglement is regarded as an indispensable resource for many applications due to the potential of quantum computing for fast, concurrent computation. The nonlinear correlations among subsystems make it difficult to analyze by traditional decomposition techniques. On the other hand, the notion of tensors has also gained new attention thanks to its great descriptive flexibility. Both structures share similar features concerning entanglement and separability. There have been many activities and achievements on both fronts. Yet, the avenue of numerically measuring the ""absolute"" gap between an entangled state and its nearest separable state has never been fully undertaken. This project aims to tackle both quantum entanglement and low-rank tensor approximation under one framework by global optimization techniques. When global optimization is finished, within the prescribed error tolerance we have in hand the metric between a given state and the set of separable states, by which we can gauge the quality of entanglement, draw conclusions on whether the given system is robustly entangled, and extend the knowledge to other applications. This project aims to establish theoretic and algorithmic foundations to: 1) exploit the geometric properties of entanglement; 2) develop a common platform for new algorithms effective in robustness, speed, and accuracy; and 3) explore the generalization to applications with additional constraints. This research together with the resulting software package is expected to find wide applicability extending from quantum mechanics to data analysis, network analysis, and other fields. The work will solidify study of many features under one unified framework.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1902350","Mathematics - Opportunities in Research and Education (MORE)","DMS","INFRASTRUCTURE PROGRAM, ALGEBRA,NUMBER THEORY,AND COM, COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY, Combinatorics","08/01/2019","08/16/2022","Eleanor Jenkins","SC","Clemson University","Standard Grant","Yuliya Gorb","07/31/2024","$25,480.00","Elena Dimitrova, Nicole Bannister Sinwell, Keisha Cook, Keri Sather-Wagstaff","lea@clemson.edu","201 SIKES HALL","CLEMSON","SC","296340001","8646562424","MPS","1260, 1264, 1271, 7334, 7970","7556, 9150, 9263","$0.00","The participation of underrepresented students in mathematical sciences doctoral programs is an issue of national concern. MORE: Mathematics - Opportunities in Research and Education is a new, annual workshop designed to increase the number of these students who pursue graduate degrees in mathematics; develop a peer network for support in continuing education and career goals; and equip participants with strategies to increase retention among those who enter graduate programs in the mathematical sciences. This is achieved through a unique active workshop format engaging students in highly relevant mathematics tied to applications that address societal needs. MORE specifically targets and prioritizes the participation of female, minoritized, and/or first-generation college students, involves them mathematics via experiential learning in a collaborative setting, establishes a peer/mentor community, and provides them with insight on and support for mathematical graduate experiences. The MORE workshop gives participants strength in numbers in ways that mobile their collective promise in mathematics, thus leading to a better qualified and more diverse workforce.<br/><br/>The MORE: Mathematics - Opportunities in Research and Education conference serves as an early professional development and community-building opportunity for undergraduate mathematical sciences majors.  The target audience for the workshop includes women, first-generation college students, and students traditionally under-represented in the mathematical sciences. In addition to helping students build a peer mentoring network, the workshop will introduce students to current research questions introduced by two topical plenary speakers.  These presentations will be followed by working group sessions, where students advance the research question through guided discussion and exploration led by graduate students. Topics are selected for their timeliness and accessibility. Panels and other activities are arranged to demystify the graduate school experience. Graduate students assisting in cooperative breakout sessions will receive mentor training, providing them with translational skills. MORE also provides materials to a larger audience through its Get MORE page, which highlights upcoming opportunities of interest, and the SEGS: Success and Enrichment in Graduate School page, which focuses on topics that are tied to documented barriers to success for the target group of participants.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913277","Filtering Strategies for Radiation Transport Equations","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","07/30/2019","Cory Hauck","TN","University of Tennessee Knoxville","Standard Grant","Yuliya Gorb","07/31/2023","$99,992.00","","chauck@utk.edu","201 ANDY HOLT TOWER","KNOXVILLE","TN","379960001","8659743466","MPS","1271","9263","$0.00","Radiation is the fundamental mechanism of energy exchange in many physical processes and in the operations of devices for energy and medical applications.  In addition, radiation is used as an experimental tool to explore the basic structure of materials. Improved mathematical algorithms and analysis of radiation transport equations will enable important advances in these areas. More generally, these equations serve as a mathematical prototype for a variety of kinetic models that are used to describe dilute gases, plasmas, and multiphase flows. They also demonstrate the fundamental multi-scale nature of driven-dissipative systems. Historically, radiation transport equations have been a driver for many fundamental developments in basic numerical methods research.  That trend will continue with this project.  On the education side, this project will support and train a student for a career in computational mathematics. This includes support for travel to attend conferences and workshops in order to share research and provide networking opportunities. This grant will support 1 graduate student per year for 3 years.<br/><br/>This project seeks to address one of the fundamental challenges in the kinetic description of radiation: the onset of ray effects in the discrete ordinates approximation of the radiation transport equation. The approach proposed here is based on the use of filters, which smooth the mathematical solution of these equations in a specified manner, in order to improve the fidelity of numerical solutions computed with under-resolved meshes.  The project will advance numerical methods for radiation transport equations and, more generally, for kinetic equations and complex multi-physics systems. It will enable to the development of spectral approximation techniques and the synthesis of such techniques into the solution of large scale equations. It will introduce analysis tools to better understand and improve the accuracy of numerical approximation that are under-resolved, and it will establish connections with other types of filtering and sub-scale modeling approaches that are currently used in the simulation of fluids.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912737","Collaborative Research: Data-driven Path Metrics for Machine Learning","DMS","COMPUTATIONAL MATHEMATICS","07/15/2019","07/12/2019","James Murphy","MA","Tufts University","Standard Grant","Yuliya Gorb","06/30/2022","$10,000.00","","jmmurphy11@gmail.com","169 HOLLAND ST","SOMERVILLE","MA","021442401","6176273696","MPS","1271","075Z, 079Z, 9263","$0.00","The era of big data has introduced unprecedented computational and mathematical challenges. Traditional machine learning algorithms often lack scalable computational complexity, while modern approaches lack solid mathematical foundations. Moreover, high data dimensionality creates challenges for traditional methods of data analysis. The principal investigators (PIs) propose to combine classic dimension reduction methods with data-driven distances, so that both the distance and embedding procedure are data dependent. This novel approach allows for greater flexibility in balancing the density-based and geometric features of the data, achieves a density-based simplification of geometry, and insightfully represents the data in a small number of dimensions. In contrast to black box methods such as deep learning, the developed methodology can be rigorously analyzed to derive strong theoretical guarantees for several statistical and machine learning tasks. This research will contribute computational tools for cancer immunogenomics and the investigators will consult with the Rogel Cancer Center at the University of Michigan for scientific questions related to tumor immunology and T-cell biology. In addition, new data analysis tools will be made publicly available in an open source software package. <br/><br/>The investigators' approach is driven by the analysis of a family of data-dependent path metrics. These metrics are both density-sensitive and geometry-preserving, with the balance governed by the choice of a single parameter p. By utilizing the space of paths through data, the PIs will obtain density based metrics and embeddings while avoiding the explicit computation of a density estimator, which may be unreliable in a large number of dimensions. The PIs will propose a simple yet highly flexible data model which does not assume the data is sampled from a manifold or collection of manifolds, and investigate the continuous limit of these metrics and an associated graph Laplacian operator. By continuously varying the parameter p, the PIs will propose to create data videos which represent the data from multiple perspectives. The PIs will investigate both multidimensional scaling and graph Laplacian embeddings as mechanisms for obtaining path-based low dimensional representations, and will explore fast algorithms with scalable computational complexity for approximating these metrics. The PIs will contextualize path metrics in the larger frame work of data-driven metrics and focus specifically on the analysis of biological data.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1937717","Collaborative Research:   Selection Methods for Algebraic Design of Experiments","DMS","COMPUTATIONAL MATHEMATICS","05/02/2019","06/21/2019","Elena Dimitrova","CA","California Polytechnic State University Foundation","Standard Grant","Leland Jameson","07/31/2021","$63,917.00","","edimitro@calpoly.edu","1 GRAND AVE BLDG 15","SAN LUIS OBISPO","CA","934079000","8057562982","MPS","1271","9150, 9263","$0.00","Data science has emerged as an important field for making decisions based on data collected from sectors as varied as healthcare and housing.  Though data are plentiful, thanks to phone apps, merchant loyalty cards, and social media accounts, there is still a question of whether more data translates to more knowledge. Furthermore collection and storage can be problematic especially when data are sensitive, as it is often the case with clinical trials and genetic experiments.  The problem of selecting information-rich data becomes crucial for creating models that can reliably predict the outcome of future experiments. Few results have been published on the amount of necessary data, and currently there are no guidelines for generating specific data sets which would unambiguously identify a predictive model. As a first step towards developing a complete theory, the PIs will focus on models described by finite-valued nonlinear polynomial functions. (For example, the internal ""function"" in WedMD's Symptom Checker returns medical conditions according to symptoms input by the user.)  They will construct the smallest data sets that have a single associated polynomial model and study properties of such data sets.  From these computational experiments, they will build the appropriate theory, design algorithms, and generate code that can be later developed into software complete with a graphical user interface. Graduate students will participate at the appropriate level of each component of the project. Such an experience will provide them possible topics for an MS or PhD dissertation and will very likely inspire a career-long involvement in the STEM disciplines. The theoretical results will advance the fields of design of experiments, network inference, and finite dynamical systems through the determination of criteria for selecting data sets to uniquely identify models. The algorithms will serve as a guide for experimentalists in determining the data that are needed to identify the structure of a network of interest. Such knowledge has the potential to drastically reduce wasted resources that arise from too much data with too little information.<br/><br/>While this is the age of big data, there is still a question of whether more data translates to more knowledge. Particularly when collecting data is expensive or time consuming, as it is often the case with clinical trials and biomolecular experiments, the problem of selecting information-rich data becomes crucial for creating relevant models. Finite-state multivariate polynomial functions have successfully been used to model complex networks from discretized data; however, few results have been published on the amount of data necessary for such models, with the majority applying to Boolean models only. It is still unknown which data points explicitly identify such discrete models, and as a consequence, there are no methods for generating the specific data sets which would unambiguously identify the model.  The PIs will address the issue of the minimality and specificity of data to uniquely identify discrete polynomial models by developing the appropriate theory, designing algorithms, and generating code that can be later built into software. Graduate students will participate at the appropriate level of each component of the project. This project will resolve some important computational issues in network inference and will improve experimental design and model selection by eliminating the effect of computational artifacts that arise when working with nonlinear multivariate polynomials. The theoretical results will advance the fields of design of experiments and network inference through the establishment of criteria to select data sets to uniquely identify models. The proposed work will also increase the utility of polynomial dynamical systems as models of complex networks by establishing the minimal amount of the data for unique model identification. The algorithms will serve as a guide for experimentalists in determining the data that are needed to identify the structure of a network of interest. Such knowledge has the potential to drastically reduce the number of experiments performed and to eliminate the generation of data with little intrinsic value."
"1913094","Collaborative Research: Transforming Serendipity Elements from Theory to Practice","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","08/26/2020","Andrew Gillette","AZ","University of Arizona","Standard Grant","Yuliya Gorb","06/30/2022","$132,999.00","","agillette@math.arizona.edu","845 N PARK AVE RM 538","TUCSON","AZ","85721","5206266000","MPS","1271","9263","$0.00","This project aims to significantly reduce the computation time and effort required to carry out a wide variety of simulations used in modern scientific and engineering applications.  In settings as varied as magnetohydrodynamics (used in studies of nuclear fusion) and electro-diffusion (used in studies of cardiac arrhythmia), a technique called the ""finite element method"" is a preferred computational procedure for designing and computing highly accurate descriptions of the relevant physical phenomena.  While finite element methods have been in use for nearly half a century, recent mathematical insights have indicated that certain kinds of methods could be implemented in such a way that they would produce results of the same order of accuracy while requiring orders of magnitude less computational work.  Such techniques are known as ""serendipity methods"" and serve as the focus of the proposed work.  A key impact of the research will be incorporation of these methods into a widely used, open source, community-developed software package known as the Firedrake Project.<br/><br/>From high-level method analysis to specific computational tricks, the proposed work will significantly expand understanding of the benefits and limitations of serendipity finite element methodologies.  For serendipity elements, the project will make precise the common mantra of ""same accuracy, less work"" by simultaneously exploring the expected computational benefits via algebraic and analytical techniques, as well as actual computational benefits via implementation and numerical simulations within the Firedrake software package.  On the theoretical side, the research will advance knowledge via investigation of the algebraic structure of serendipity spaces and its exploitation to allow new Helmholtz decompositions of the associated polynomial spaces, identification of efficient ""short injections"" of serendipity bases into standard tensor product bases, and development of sparse quadrature rules.  The investigators will combine expertise on element mapping and physically-defined basis elements to create an order-preserving handling of non-affinely mapped square element geometries, a key roadblock in prior attempts at implementation of serendipity elements.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913096","Sparsity Preserving Algorithms for Rank Structured Systems","DMS","COMPUTATIONAL MATHEMATICS","09/01/2019","06/21/2019","Michael Stewart","GA","Georgia State University Research Foundation, Inc.","Standard Grant","Yuliya Gorb","08/31/2023","$186,676.00","","mastewart@gsu.edu","58 EDGEWOOD AVE NE","ATLANTA","GA","303032921","4044133570","MPS","1271","9263","$0.00","This project focuses on developing reliable and efficient<br/>computational methods for solving equations obtained from<br/>discretization of elliptic partial differential equations that arise<br/>in engineering and science.  The methods are expected to be of direct<br/>use in the fast solution of various problems in electrostatics and<br/>materials engineering and also to have utility in accelerating<br/>computations associated with numerical methods for time dependent<br/>simulations.  The project will extend a class of highly stable<br/>orthogonal methods based on sparse banded representations to equations<br/>with more complicated structures than have been considered before in<br/>the context of this class of algorithms.  The stability and efficiency<br/>of the methods will be analyzed and an efficient software<br/>implementation of all the methods will be developed and released.<br/><br/>The project involves the development of fast direct algorithms for<br/>elliptic partial differential equations.  The methods are based on<br/>Givens-weight techniques that exploit rank structure in order to limit<br/>fill-in when computing a QR or LQ factorization.  There are four main<br/>components to the project: The extension of orthogonal Givens-weight<br/>algorithms to strongly admissible rank structures, the development of<br/>efficient block operations acting on blocks that are obtained from<br/>discretization of particular subdomains, the analysis of the methods<br/>for numerical stability and complexity, and the development of an<br/>efficient software library implementing the algorithms.  The<br/>overarching goal is to bridge a gap between the more flexible classes<br/>of methods that have uncertain numerical stability and the highly<br/>stable orthogonal methods that are applicable only to problems with a<br/>restricted weakly admissible rank structure.  The techniques used are<br/>expected to lead to algorithms with linear or near-linear complexity,<br/>good practical efficiency, and provable backward stability.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912654","Solving Multiscale Problems and Data Classification with Subsampled Data by Integrating Partial Differential Equation Analysis with Data Science","DMS","COMPUTATIONAL MATHEMATICS","09/01/2019","07/25/2019","Thomas Hou","CA","California Institute of Technology","Standard Grant","Yuliya Gorb","08/31/2022","$250,000.00","","hou@acm.caltech.edu","1200 E CALIFORNIA BLVD","PASADENA","CA","911250001","6263956219","MPS","1271","075Z, 079Z, 9263","$0.00","In many practical applications, one often needs to provide solutions to quantities of interest to a large-scale problem but with only subsampled data and partial information of the physical model.  Existing computational solvers cannot be used directly for this purpose. On the other hand, many powerful techniques have been developed in data science to represent and compress data for useful information with extreme efficiency and low computational complexities. A crucial factor for the success of these methods is to exploit some special features in these high-dimensional data. The purpose of this project is to integrate physical models with data science to develop a new generation of computational methods that can solve large-scale physical or data science problems using only subsampled data and partial knowledge of the physical model. The mathematical analysis will help reveal certain important solution structures so that one can use techniques from data science to give accurate approximations for those quantities of interest. Without identifying these special solution structures and using the physical model as a constraint, the current techniques from data science cannot be used directly to achieve PI's goal. This project can have a substantial impact for the computational science and data science communities, for national technology and society. Additional impact will be the involvement of graduate students. This research provides a solid training in mathematical analysis, physical modeling, and data science. The interdisciplinary training they receive in this project will be very important for their future careers in mathematics and science.<br/>  <br/>The recent advances in data science offer tremendous opportunities for computational sciences. A key to the success in data science is to exploit some special features in the high-dimensional data. Traditional PDE solvers have not taken full advantage of the special solution structures. PDE analysis and data science complement each other. PDE analysis can identify some important solution structures that can help the PI to design a more effective deep generative network to solve the physical problem. Without the guidance from the PDE analysis, naive application of current machine learning algorithms to multiscale problems would fail. The solution of the nonconvex optimization problem can easily get stuck in local minimum and may converge to the wrong solution. The PI will identify some key ingredients that would make such integration successful, investigate what type of PDEs can be compressed and what algorithms can be used to approximate quantities of interest with a small percentage of subsampled data and partial knowledge of the physical model. This research will also provide valuable theoretical understanding of some deep learning methods for solving multiscale problems. The PI will consider both inverse and forward problems. For the forward problem, he will develop a novel multiscale method based on subsampled data to reconstruct the solution with guaranteed accuracy.  For the inverse problem, the PI will post it as a Bayesian inverse problem and use Deep Generative Networks. An essential ingredient in this approach is to introduce a novel multiscale invertible flow to approximate the transport map, which enables the PI to develop an efficient sampling algorithm to capture the multiple modes in the posterior distribution.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913133","Discrete Maximal Parabolic Regularity for Time Discontinuous Galerkin Methods with Applications","DMS","COMPUTATIONAL MATHEMATICS","09/01/2019","05/31/2019","Dmitriy Leykekhman","CT","University of Connecticut","Standard Grant","Yuliya Gorb","08/31/2023","$174,999.00","","dmitriy.leykekhman@uconn.edu","438 WHITNEY RD EXTENSION UNIT 11","STORRS","CT","062691133","8604863622","MPS","1271","9263","$0.00","Parabolic problems touch many areas of pure and applied mathematics and serve as a model of many environmental and real-life problems, such as optimal location of wastewater outfalls, location of the pollution sources, modeling of calcium waves in a heart cell and etc. Usually the resulting equations are very complicated to be treated analytically and must be solved by numerical methods. The analysis of such approximations is usually hard and technical and requires expertise in time and space discretization methods. For continuous problems the importance of the maximal parabolic regularity is well-recognized and has a number of applications, for example to nonlinear problems, optimal control problems and generally to problems where sharp results are required. In contrast to the continuous case, the discrete maximal parabolic regularity only recently came to the attention of the numerical analysis community and its potential is not yet fully realized. Such results, for example, reduce the analysis of transient problems to stationery ones, which are usually much less technical with many results already available in the literature. This for example would benefit a number of researchers, especially who are at the beginning of their careers and are not experts in time discretization methods.<br/><br/>In this research the principal investigator will extend the theory of discrete maximal parabolic regularity for discontinuous Galerkin time schemes in several directions. The research plan includes the following projects. The first project extends the known results to non-symmetric autonomous elliptic operators, such as transient advection-reaction-diffusion problems, including the advection-dominated case. Such problems are classical and have been at the center of research for many years. As an application of such results, the PI intends to answer some of the open questions, for example whether the stabilized methods require stabilization parameters that depend on the time steps. In the second project, the PI intends to extend our previous results for non-autonomous problems to more general norms, that are important for a number of applications, for instance, quasilinear parabolic equations and optimal control problems. Finally, the PI plans to investigate more general parabolic systems, such as transient Stokes and Navier-Stokes problems, which are very important for the fluid flow problems and to obtain fully discrete best approximation type result in general Lebesgue space norms.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1933403","Complex Analysis: Techniques, Applications and Computations","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, ANALYSIS PROGRAM","09/01/2019","06/27/2019","Stefan Llewellyn Smith","CA","University of California-San Diego","Standard Grant","Victor Roytburd","08/31/2020","$26,000.00","","sgls@ucsd.edu","9500 GILMAN DRIVE","LA JOLLA","CA","920930021","8585344896","MPS","1266, 1271, 1281","7556, 9263","$0.00","This award supports the participation of early-career US-based mathematicians in the 4-month program ""Complex Analysis: Techniques, Applications and Computations'' to be held at the Isaac Newton Institute (INI) for Mathematical Sciences (Cambridge, UK) from September 2 to December 19, 2019. The program includes three workshops and sets of masterclasses (expository lectures given by leaders in the field), and will give junior scientists, at a critical career stage, a chance to participate in a workshop and masterclass in their research area. The workshops are ""The complex analysis toolbox: new techniques and perspectives"", from September 9 to 13, 2019; ""Complex analysis in mathematical physics and applications"", from October 28 to November 1, 2019; and ""Computational complex analysis"", from December 9 to 13, 2019. Complex variable and analytic function theory play an elemental role in a diverse array of applications and areas of mathematics. The classical work carried out over decades in traditional fields is now providing the foundations and inspiration for new and rapid growth in many exciting new directions. The INI program will advance the field by bringing together key researchers working at the frontiers of these new developments and will help steer future endeavors by identifying the most important scientific challenges arising from the new techniques, methodologies and insights. The program will also focus on elucidating the unexpected connections between different branches of complex analysis that have been emerging over the past few years. To this end, the program will encompass mathematicians as well as physicists and engineers working on theoretical aspects, computational methods, mathematical modeling and applications.<br/><br/>The award will be aimed at supporting participation in the workshops and secondarily the broader program. The main impact will be the training and career development of junior researchers. Bringing together scientific leaders for extended periods will provide a synergistic forum for creative collaboration, which will be particularly beneficial to the early-career participants who will be supported. They will have the opportunity to learn from senior colleagues and to highlight their work to the community, and will bring new ideas for their research programs back to the US, thereby enhancing the mathematical sciences infrastructure as a secondary impact of the award. The organizers will also hold a moderated session discussing how complex analysis is taught, and exploring new innovations in the classroom, including demonstrations. This will be particularly useful for junior participants who may be embarking on teaching careers. A diversity committee has been formed to identify promising diverse participants (female or underrepresented minorities) and involve them in the program and workshops. The website for the program can be found at https://www.newton.ac.uk/event/cat and includes details about the workshops.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913209","A New Multiscale Framework for Hyperbolic Problems","DMS","COMPUTATIONAL MATHEMATICS","06/15/2019","06/19/2019","Bjorn Engquist","TX","University of Texas at Austin","Standard Grant","Leland Jameson","05/31/2022","$444,927.00","Yen-Hsi Tsai","engquist@math.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271","9263","$0.00","In this project, the PIs will develop a novel computational framework for building numerical algorithms that are capable of fully utilizing the power of the next generation super computers. By fully using the large scale computing power, these algorithms will be able to perform highly accurate simulations of important physical phenomena involving propagation of different types of waves. These simulations provide important data and information for further decision making.<br/><br/>In many physical applications, one typically is interested in computing certain observables and effective properties from the given systems that involve many temporal and length scales. However, the computational complexity required to numerically resolve all the scales in the given system is unfeasible. Multiscale algorithms have been developed to compute the effective properties of systems that have sufficiently wide separation of scales, and certain homogeneity and ergodic properties. As multiscale computation for these classical settings have reached a relatively mature stage, it is now necessary to develop new strategies addressing some of the core problems of scientific computing for the coming era. This project will involve multiscale hyperbolic problems. Hyperbolic problems characteristically support oscillations in the solutions, and phase errors typically dominate the numerical solutions and do not dissipate in time. These properties make accurate long time simulations very difficult. The project will further tackle a harder class of hyperbolic problems in which a wide spectrum of non-negligible scales is present. With the stagnation of processor core performance, parallel computation for these more challenging multiscale problems becomes inevitable. On the other hand, computations of hyperbolic problems will not benefit from the available exa-scale computing power unless parallelization-in-time can be performed, as the speed-up from spatial domain decomposition has saturated. It is widely recognized that robust and convergent numerical computation using such parallel-in-time algorithms still remains a main challenge for hyperbolic problems. The investigators will leverage success of earlier NSF supported research and develop a new multiscale framework that enables stable parallel-in-time computation for multiscale hyperbolic problems. An essential component of the framework involves making up the deficiencies of the typical multiscale models by judiciously utilizing data collected from suitable ensembles of the parallel computations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1939203","Collaborative Research:  Accurate, Efficient and Robust Computational Algorithms  for Detecting Changes in a Scene Given Indirect Data","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","07/08/2019","Guohui Song","VA","Old Dominion University Research Foundation","Standard Grant","Yuliya Gorb","07/31/2023","$140,000.00","","gsong@odu.edu","4111 MONARCH WAY","NORFOLK","VA","235082561","7576834293","MPS","1271","9263","$0.00","Detecting change from a temporal sequence of collected data is important in a wide variety of applications, including speech recognition, medical monitoring, credit card fraud detection, automated target recognition, and video surveillance. In applications such as medical monitoring, it is very important to find where the change occurs. In other applications, such as video surveillance, the type of change, e.g. the movement or insertion/deletion of an object of interest, is also critical.  While detecting such changes from direct data (e.g. images already formed) has been well studied, there are many applications, such as magnetic resonance imaging (MRI), ultrasound, and synthetic aperture radar (SAR) where the temporal sequence of data are acquired indirectly. The typical approach to detecting changes in these applications would be to first form the image or signal of interest.  As a consequence, information that is stored in the indirect data that may be valuable to detecting change is often lost. Therefore, this project seeks to develop accurate, efficient, and robust computational algorithms for detecting changes in a signal or image from a given temporal sequence of indirect data without first reconstructing the signal or image of interest. Additionally, the project seeks to incorporate the change information  to develop better image and signal reconstruction algorithms.  Both graduate and undergraduate students will be involved in the research investigations to enhance their career preparation in science and engineering.  The participants will apply these new techniques on publicly available data sets, notably obtained for MRI, ultrasound, and SAR applications.  <br/><br/>The PIs will employ tools in frame theory, optimization, and statistics to develop and rigorously analyze new change detection and image/signal recovery algorithms. Specifically, the PIs will address the following technical issues in the proposed work: (1) the incorporation of prior information with appropriate mathematical/statistical formulation in the model; (2) the extraction of rotation/translation of an object from a sequence of indirect data; (3) model parameters tuning through statistical analysis; (4) the employment of intra- and inter-signal correlations in the recovery algorithms; (5) the design of distributed algorithms for the resulting large-size optimization model.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1854204","FRG: Collaborative Research: Non-Smooth Geometry, Spectral Theory, and Data: Learning and Representing Projections of Complex Systems","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","06/21/2019","Tyrus Berry","VA","George Mason University","Standard Grant","Yuliya Gorb","06/30/2023","$395,425.00","","tberry@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","MPS","1271","079Z, 1616, 9263","$0.00","Complex, time-evolving systems are ubiquitous in nature and society, with examples ranging from the Earth's weather and climate, to the function and dynamics of biomolecules, and the behavior of markets and economies. Despite their apparent complexity, many such systems exhibit a form of underlying organized structure (``building blocks''), whose discovery would enhance our ability to understand and predict a wide range of phenomena. The goal of this project is to develop the next generation of mathematical and algorithmic tools that can harness the information content of large datasets acquired from experiments and observations to create coherent representations of complex systems, and use these representations to perform prediction, and ultimately, control. These objectives will be addressed through a novel combination of mathematical techniques, bridging dynamical systems theory and differential geometry with machine learning and data science. The newly developed techniques will be tested and applied in real-world problems through collaboration with domain experts in the areas of climate dynamics, space physics, and condensed matter physics. The project will also contribute to STEM workforce and curricular development through training of students and postdoctoral researchers, and design of multi-disciplinary lecture courses.      <br/><br/>The modern scientific method is undergoing an evolutionary change wherein large data sets and machine learning algorithms have the potential to outperform classical first-principles approaches for certain complex phenomena.  For these tools to be accepted by the scientific community, a rigorous mathematical framework is required to match the verifiability and quantifiability of the classical modeling approach.  Recently, a new tool called the diffusion forecast has been developed based on provably consistent estimators, which learn the unknown structure of a large class of stochastic dynamical systems on manifolds.  Moreover, the results of many published numerical experiments indicate that this framework can be applied far beyond the restricted context of the current theory.  In particular, the evidence suggests that the consistency proofs can be extended to non-autonomous projections of complex systems, deterministic chaotic systems represented by non-compact operators, non-smooth domains such as fractal attractors, and even generalized tensors on metric-measure spaces. This project will undertake a rigorous mathematical unification of these problems, leading to transformative advances in our ability to model and describe complex systems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913016","Fluid-filled Fracture Propagation with a Phase Field Approach in Subsurface by Employing Nonlinear Strain Limiting Models and Enriched Galerkin Methods","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","07/22/2019","Sanghyun Lee","FL","Florida State University","Standard Grant","Yuliya Gorb","08/31/2022","$99,116.00","","slee17@fsu.edu","874 TRADITIONS WAY","TALLAHASSEE","FL","323060001","8506445260","MPS","1271","9263","$0.00","The project aims to investigate the way in which pressurized and fluid-filled cracks or fractures spread through subsurface materials. In porous materials such as soils and rocks, the flow of the fluids through the material's pores can force significant deformations (such as cracks and fractures) to occur in the solid porous media. These poromechanical interactions are crucial to many important problems such as tunnel construction, subsidence, dam or levee failure, and CO2 sequestration. <br/><br/>The classic mathematical model governing the spread of these deformations is formulated by coupling linear elasticity or poroelasticity with deformation systems. However, one of the major disadvantages of classical linear elasticity models is that strain values are linearly proportional to stress values. Thus, it contradicts the assumptions of the model, and it may not accurately predict realistic scenarios. This project focuses on establishing the nonlinear strain limiting model, a new class of theoretical model. The advantage of the nonlinear strain limiting models over classical linearized models is that strain remains bounded even if the stress tends to infinity, which is critical for fluid-filled fractures. The new model will be extended to consider poroelasticity. Next, the poroelasticity model will be coupled with a phase field approach to implement quasi-static fluid-filled fracture propagation.  Moreover, the novel enriched Galerkin (EG) finite element approximations will be employed in the project to address several crucial issues for numerical discretization. It is well known that classical Galerkin finite element methods generally do not guarantee local mass conservation, which could lead to non-physical oscillation. EG methods will be investigated to overcome these challenges, and their stability and convergence for the poroelasticity system will be analyzed. The findings will then be used to develop a forecasting tool to predict the path of quasi-static fracture propagation and will be utilized to evaluate and validate the performance of these new models.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1907412","East Coast Optimization Meeting (ECOM) 2019","DMS","COMPUTATIONAL MATHEMATICS","04/01/2019","07/20/2021","Harbir Antil","VA","George Mason University","Standard Grant","Yuliya Gorb","08/31/2022","$17,680.00","","hantil@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","MPS","1271","7556, 9263","$0.00","The award provides participant support to the East Coast Optimization Meeting (ECOM) to be held at George Mason University, Fairfax, VA. Date: April 4-5, 2019. The goal of ECOM is to introduce students and early-career researchers to current trends in optimization as well as to provide a strong networking environment between academia, industry, and the national laboratories. The focus of first meeting is Stochastic Optimization. Stochastic optimization problems arise in virtually all science and engineering fields. Common examples of stochastic optimization problems are: (i) determining an allocation of financial assets that minimize the potential for loss subject to market variability; (ii) controlling injection wells in second-stage oil recovery to maximize the net present value of a reservoir in which the subsurface rock properties are unknown; and (iii) designing a photonic meta-material to maximize light absorption subject to uncertain operating environments. For each of these problems, a decision maker must choose an allocation/control/design prior to observing the uncertain outcome (i.e., decisions are deterministic).  As a result, one must properly quantify the risks associated with each decision in order to control the outcome variability.  This need has led to the modern theory of stochastic and in particular risk-averse optimization. The meeting will provide a unique opportunity for graduate students, postdocs and other early career scientists to take courses from two of the best researchers in stochastic optimization and thus help train next generation of scientists. In addition, there will be four invited talks from the experts in the field and the students and postdocs will have an opportunity to share their work via contributed presentations. The knowledge gained during the meeting will be of relevance to fields such as finance, physics, biology, data science, machine (deep learning), and engineering. The meeting has an affiliation from Association of Women in Mathematics (AWM).<br/> <br/>Accurately representing the uncertainty when solving stochastic optimization problems often requires an enormous number of samples, which traditionally resulted in intractable nonlinear optimization problem.  However, owing to the recent advances in high-performance computing, computational simulation and numerical optimization, the numerical solution of such problems has become computationally feasible.  Additionally, this past year, four stochastic optimization researchers received prestigious awards including two Dantzig Award winners (one of our keynote speaker was among the two), a Khachiyan Prize winner and a Farkas Prize winner.  For these reasons, the topic of stochastic optimization is very timely for the inaugural East Coast Optimization Meeting. The proposed meeting has the potential to advance knowledge and understanding in modeling, optimization, numerical analysis, implementation and software development. Stochastic optimization encompasses numerous aspects from statistics, probability theory, optimization and variational analysis, convex analysis, and applied mathematics.  The meeting will stimulate new developments in these important areas of mathematics. The tutorials and invited talks will focus on real life problems and will discuss new optimization solvers to handle these problems. Thus the attendees can tackle new set of challenging problems. The variety of topics discussed in the meeting, stochastic optimization, modeling, partial differential equations, risk averse optimization is of much wider interest. For instance, these are relevant in finance, physics, biology, data science, and engineering. Participation from all these fields is expected. The ideas created in the meeting will be actively disseminated. We will upload the lecture notes on the conference website. These resources will help create new graduate courses. More details about the meeting are available at http://math.gmu.edu/~hantil/ECOM/2019/.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912705","Collaborative Research: Hybrid Fluid-Structure Interaction Material Point Method with applications to Large Deformation Problems in Hemodynamics","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","07/18/2019","Max Gunzburger","FL","Florida State University","Standard Grant","Leland Jameson","07/31/2022","$100,432.00","","gunzburg@fsu.edu","874 TRADITIONS WAY","TALLAHASSEE","FL","323060001","8506445260","MPS","1271","9263","$0.00","Heart valve associated issues in the human organism are the cause of cardiac arrest and heart failure, which may have devastating consequences on a person's health and even lead to death. While not necessarily fatal, pathologies associated with leg vein valves can nevertheless cause severe distress to the people affected and have a negative impact on their life with possibly major complications. For the treatment of valve associated diseases, the most common practice nowadays is the replacement of the malfunctioning valve with a prosthetic device. Unfortunately, prosthetic valves have issues with long term durability and post-implantation complications. Given the necessity of improving the design and selection of existing prosthetic valves, computational methodologies are becoming a valuable tool. The nature of blood flow inside a human valve renders the modeling problem considerably challenging from the mathematical and computational standpoints, as multiple physical phenomena mutually interact. Specifically, the major challenges are the large structural displacements experienced by the valve leaflets, while preserving accurate description of the hydrodynamic force at the fluid-solid interface. The focus of this project is on developing new fluid-structure interaction methodologies with specific interest in the case of large deformations. The important insight provided in this project will enable future valve design optimization while avoiding costly empirical design iterations. In addition to the obvious potential impact on society, the proposed project will be useful to many other applications in science and engineering, and also have beneficial impact on the training, education, and careers of junior researchers in an important, exciting, and mathematically, computationally, and societally impactful area of research. This project will support 2 graduate students per year for each year of the three year project.<br/><br/>This project is about the development, analysis, and implementation of novel computational techniques for the coupling of finite element methods (FEMs) to material point methods (MPMs) in fluid-structure interaction (FSI) problems. The use of different discretization techniques for the study of multiscale and multiphysics problems is a powerful tool for computational simulations. For instance, one-dimensional models are coupled with multi-dimensional models for computational cost reduction, or FEMs are coupled with finite volume methods to exploit the advantages of the algorithmic and mathematical features of these two methods. With the same idea, the coupling of FEM with MPM represents a promising combination, if different deformation regimes occur within the dynamical regime of a physical model. As a matter of fact, the FEM reaches its best accuracy for small deformations whereas the MPM mixed Eulerian-Lagrangian formulation becomes beneficial when large deformations occur. FEM-MPM coupling has, in fact, been studied only by very few authors, including the PIs, and the coupling of an FSI framework with an MPM approach is yet to be explored.  The use of the material point methodology would avoid the mesh entanglement issues that plague many existing FSI methods. To design the desired coupling approach, preliminary work is needed. First, the coupling between an MPM solid body immersed in an FEM fluid will be addressed, using benchmark problems from the FSI literature. At the same time, the mechanical properties of a solid body discretized with the mixed FSI-MPM approach will be studied and the accuracy of the method will be investigated using the Taylor bar test in which a cylinder impacts a rigid wall. Then, the knowledge gained from the preparatory work will be used to realize an FSI-MPM coupling methodology for biological valves, with the valve leaflets modeled with the MPM and the blood vessel and blood flow described in an FEM-FSI framework. Appropriate solvers and preconditioners will also be selected and studied because the discretized nonlinear and linear systems will likely be large and highly coupled. Lastly, the FSI-MPM coupling approach will also be applied for the simulations of stented arteries, with the stent described using the MPM. In this way, complex meshing procedure for the stent can be avoided, while capturing its dynamical behavior.  The computational techniques developed within the proposed research will be applicable and prove to be invaluable tools for a broad spectrum of applications such as human valve fluid and structural dynamics, aerospace and civil engineering problems, dam breaking, and airfoil design, to name a few. All our findings will be implemented in FEMuS, an open source library written in C++ language, freely downloadable online. Our effort will hopefully contribute to the standardization of novel computational techniques that are currently available only in research software. Nevertheless, researchers from all over the world can potentially access our findings and join us in this effort, with a substantial speed up in the standardization procedure.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913119","Certification Algorithms for Polynomial System Solving","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","07/28/2019","Michael Burr","SC","Clemson University","Standard Grant","Leland Jameson","07/31/2022","$72,387.00","","burr2@clemson.edu","201 SIKES HALL","CLEMSON","SC","296340001","8646562424","MPS","1271","9150, 9263","$0.00","Certified algorithms are computations that are guaranteed to never produce a wrong answer when implemented on a real-world computer. These algorithms are important in any setting where the correctness of a computation is critical and errors cannot be tolerated.  Such algorithms have potential applications in many fields, including optimization, automation, and graphics.  For example, with self-driving cars, it is vital that the decision-making algorithms do not make errors.  For instance, if a non-certified algorithm were to miss a small, but important detail, a car might not fit through a gap or cause an accident. As this type of automation becomes more common, the need for corresponding certified computation will increase.  The work in this particular project involves the design, development, and implementation of efficient certified methods for finding common solutions to systems of polynomials.  The development of the algorithms described in this project fills a current gap in the field of numerical algebraic geometry since previous approaches are either non-certified, i.e., may make mistakes in some cases, or impractical certified methods, i.e., take too long to produce an answer in practical situations.  The work in this project is intended to solve these problems, i.e., to be practical and certified. <br/><br/>For many computations, algorithms can only produce an approximation to the true answer.  Certified algorithms not only produce a final result from a computation, but they also provide estimates on the error between the final answer and the true answer.  Developing certified algorithms is a (new) challenge for computational mathematics and computer science. A certified algorithm must, first, be proved to be correct when assuming that a computer can represent all real numbers. Second, the correctness of the algorithm must be justified when the allowed numbers are approximated by the much smaller set of numbers that can be represented on a computer.  Therefore, two of the main challenges in certified methods can be summarized as (1) Since many problems involve discretizing a continuous variable, the theory must be developed to ensure that the choice of discretization does not miss any interesting behaviors between discrete steps and (2) Since not all real numbers can be represented on a computer, all tests and computations must be developed to work with approximations, but still produce meaningful data about the underlying real number.  The project involves the design, implementation, and development of an efficient and certified homotopy continuation algorithm in dimensions greater than one.  The work generalizes the preliminary exploration and implementation developed by the PI in the univariate case.  This prototype is very efficient because of its use of new subroutines, based on interval methods, which have more flexibility than previous approaches.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1914795","Structure-Preserving Discretizations: Finite Elements, Splines, and Isogeometric Analysis","DMS","COMPUTATIONAL MATHEMATICS","04/01/2019","04/03/2019","Michael Neilan","PA","University of Pittsburgh","Standard Grant","Leland Jameson","03/31/2020","$10,000.00","","neilan@pitt.edu","4200 FIFTH AVENUE","PITTSBURGH","PA","152600001","4126247400","MPS","1271","7556, 9263","$0.00","This award provides participants support to the conference ""Structure-Preserving Discretizations: Finite Elements, Splines, and Isogeometric Analysis"", to be held at University of Pittsburgh on May 31 - June 1, 2019. Structure preserving discretizations are computational paradigms to solve physical models arising in several scientific and engineering fields such as computational fluid dynamics, structural mechanics, and cosmology.  This class of methods produce faithful approximations with several desirable properties including long-time stability and accuracy, the exact enforcement of conservation laws (e.g., mass, energy, momentum), enhanced stability properties with respect to model parameters, absence of numerical artifacts, and reduced computational errors.  Altogether, these algorithms produce high-fidelity computational simulations that remain true to the physics of the underlying models.  The goal of the conference is to bring together mathematicians and engineers with diverse research backgrounds to interact, communicate, collaborate, and discuss recent developments in the field of structure preserving discretizations.  This will allow cross-fertilization of various viewpoints in this field, lead to better understandings of these methods, and the development of novel algorithms and theoretical results.<br/><br/>One focus of the conference is the finite element exterior calculus (FEEC) framework, a powerful class of structure preserving discretizations that formulates finite element methods in the calculus of differential forms. A key feature of this approach is to combine tools from homological algebra and functional analysis to develop finite dimensional subcomplexes of the canonical de Rham complex.  While the FEEC framework has been successfully applied to the de Rham complex with minimal smoothness, recent progress has extended this methodology to higher order Sobolev spaces, i.e., spaces with greater smoothness.  The extension of conforming finite element spaces of high-order Sobolev spaces in the FEEC framework necessitates the use of piecewise polynomial spaces with high regularity, i.e., smooth multivariate splines. This is an extensively studied and active research area, but the theory and construction, and even the language of smooth polynomial splines is relatively unknown to researchers in finite element analysis.  The conference will bring together researchers working in finite element analysis, multi-variate splines, isogeometric analysis, and algebraic geometry to collaborate and communicate current trends and to share diverse viewpoints on common problems. The conference will also define and discuss critical open problems in these different sub-fields, and expose graduate students and early career researchers to the intersection of finite element analysis, the theory of multivariate splines, isogeometric analysis, and applied algebraic geometry. More details are available at https://sites.google.com/view/spd2019/home.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1821870","Recent Developments on Mathematical/Statistical Approaches in Data Science","DMS","COMPUTATIONAL MATHEMATICS","03/01/2019","06/28/2018","Yifei Lou","TX","University of Texas at Dallas","Standard Grant","Yuliya Gorb","10/31/2019","$16,457.00","","yifei.lou@utdallas.edu","800 WEST CAMPBELL RD.","RICHARDSON","TX","750803021","9728832313","MPS","1271","7556, 9263","$0.00","A workshop on Recent Developments on Mathematical/Statistical Approaches in Data Science will be held at the University of Texas, Dallas, in the Spring of 2019. The workshop will bring together researchers from different disciplines including computational and applied mathematics, statistics, computer science, and engineering to report on cutting-edge methodologies and state-of-the-art computational algorithms in data science. The workshop will provide an opportunity to all the participants to submit their related works to a special issue in the journal of Inverse Problem and Imaging (IPI). The funding provided will be primarily allocated in support of junior researchers such as graduate students, post-docs, and entry-level faculty members, specifically to under-represented minorities and women in the STEM. The organizers will coordinate invited speakers to serve as mentors to junior researchers during the poster session and the career luncheon. The organizers also invite speakers from different countries to promote international collaborations.<br/> <br/> <br/>Due to the blooming of 'big data' and an emerging field of data science, there is a need to bring together researchers from different disciplines to keep up with recent developments. The objectives of this workshop are (1) to facilitate discussions and foster collaborations among the participants with different backgrounds and expertise; (2) to attract new researchers to the field of data science and to offer mentoring service to junior participants in this field; and (3) to bridge the gap between the theoretical development in academia and practical applications in industry. The proposed workshop will be multidisciplinary with topics ranging from scientific computing and statistics to various applications in data science.  As a result, this workshop will strengthen the relationship between mathematicians and other scientists/engineers who are interested in data science. In addition, the workshop will advance the development of computational methods, statistical theories, and tools for big data analysis. Furthermore, the workshop will build close connections between academia and industry to establish and facilitate research collaborations in a variety of data-driven applications.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912626","Global-in-Time Domain Decomposition Methods for Evolution Partial Differential Equations with Applications to Flow and Transport in Fractured Porous Media","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","05/30/2019","Thi Thao Phuong Hoang","AL","Auburn University","Standard Grant","Yuliya Gorb","07/31/2023","$149,660.00","","tzh0059@auburn.edu","321-A INGRAM HALL","AUBURN","AL","368490001","3348444438","MPS","1271","9150, 9263","$0.00","Mathematical modeling and numerical simulation of multiscale and multiphysics processes are essentially involved in a large number of scientific and engineering problems. Particularly in many applications in environmental sciences and geosciences, one is concerned with the modeling of flow and transport in porous media containing fractures and faults. There the spatial and temporal scales associated with various geological layers and fractures or different physical processes may vary with several orders of magnitude. The goal of this project is to enhance the efficiency of numerical techniques for fractured porous medium applications by designing and analyzing novel computational methods based on parallel global-in-time domain decomposition. These methods facilitate the coupling of different models and enable the use of different time step sizes and spatial mesh sizes in different regions of the computational domain. Thus the proposed methods can be used as an efficient and accurate computational tool for solving large-scale, strongly heterogeneous, coupled evolution partial differential equations arising from diverse application fields such as groundwater flow and contaminant transport, hydraulic fracture, geological disposal of nuclear waste and geological carbon sequestration. The numerical simulations carried out in this project would also provide new insights to the understanding of the long-term behavior and performance of geological nuclear waste repositories. Graduate students will be involved in this project and will be offered a great opportunity to participate in an interdisciplinary research environment.<br/><br/>Although domain decomposition methods have been well studied for many scientific and engineering problems, no enough attention and work have been devoted to fractured porous medium applications with local time stepping. This project focuses on the design and analysis of efficient global-in-time domain decomposition methods for reduced fracture models, in which the fractures are treated as manifolds of one dimension less than the medium. Three model problems will be considered: the linear transport problem, the multiphysics flow and the incompressible two-phase flow, respectively. The developed methods are based on either physical transmission conditions or optimized transmission conditions on the space-time interface fractures; the latter conditions involve more general transmission operators, motivated by the physics of the underlying problem, with some coefficients that can be optimized to improve the convergence rates of the iterations. Importantly, the proposed methods make possible the use of different time step sizes and spatial grids in the interface fractures and in the surrounding medium. The PI will also study the application of the proposed methods to numerical simulation and investigation of fluid flow and contaminant transport in fractured porous media arising from the framework of geological nuclear waste disposal.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913129","An Optimal Transport Based Multiscale Method for Inverse Problems","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","06/21/2019","Yunan Yang","NY","New York University","Standard Grant","Yuliya Gorb","06/30/2022","$176,332.00","","yy38@nyu.edu","70 WASHINGTON SQ S","NEW YORK","NY","100121019","2129982121","MPS","1271","9263","$0.00","Since the advent of computing powers, the application of inverse problem theory has extended to almost all fields of science and engineering that use mathematical methods. Examples of inverse problems can be found in various fields within medical imaging, several areas of geophysics including earthquake source inversion and hydrocarbons exploration and many machine learning applications in data science. The proposed study will connect optimal transport, a classical analysis subject, with many widely used methods in data-driven problems. Results of this research will offer better understandings of existing numerical methods and promote the development of the new techniques for solving inverse problems with high accuracy and fast convergence. The wide range of applications will also increase partnerships and collaboration between academia and industry. Students will be offered many opportunities of joining this research in translating attractive theoretical properties of optimal transport onto various applications in modern science and engineering.<br/><br/>The proposed research analyzes the intrinsic multiscale features in optimal transport-based seismic inversion to build robust algorithms for solving general nonlinear large-scale inverse problems. The focus is on designing objective functions in constrained local optimization. A standard approach of measuring the least-squares mismatch between model predictions and data is to use frequency marching and weighting methods in which different frequencies are treated separately; first the low-frequency errors are eliminated followed by high-frequency errors. This particular ordering based on the multiscale inversion scheme addresses two of the biggest challenges in inversion by mitigating problems with local minima in gradient-based optimization and accelerating convergence. The PI's recent work has introduced a framework for seismic inverse problems using the Wasserstein distance as the objective function. Using the theory of optimal transport, the PI proved that this metric offers a convex optimization landscape and the PI's numerical experiments demonstrate the convergence to global minimizers for cases where the least-squares norm has difficulties. The proposed research will investigate the connections between optimal transport-based inversion with existing frequency marching and weighting methods to extend the optimal transport techniques to nonlinear inverse problems beyond seismology. In particular, the PI will formulate optimal transport-based inversion for quantitative photoacoustic tomography (QPAT) and cryogenic electron microscopy (cryo-EM). Methods in this work will be developed using existing frameworks of iterative methods and dynamical systems for convergence analysis. Theoretical results from this research will shed light on the relationship between data fitting (residual reduction) and model fitting (solution error) in various data-driven inverse problems and iterative methods. Computational algorithms will be developed for inversion in seismic imaging, medical imaging, and biology.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912653","Collaborative Research: Transforming Serendipity Elements from Theory to Practice","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","06/21/2019","Robert Kirby","TX","Baylor University","Standard Grant","Yuliya Gorb","06/30/2022","$167,000.00","","Robert_Kirby@baylor.edu","700 S UNIVERSITY PARKS DR","WACO","TX","767061003","2547103817","MPS","1271","9263","$0.00","This project aims to significantly reduce the computation time and effort required to carry out a wide variety of simulations used in modern scientific and engineering applications. In settings as varied as magnetohydrodynamics (used in studies of nuclear fusion) and electro-diffusion (used in studies of cardiac arrhythmia), a technique called the ""finite element method"" is a preferred computational procedure for designing and computing highly accurate descriptions of the relevant physical phenomena. While finite element methods have been in use for nearly half a century, recent mathematical insights have indicated that certain kinds of methods could be implemented in such a way that they would produce results of the same order of accuracy while requiring orders of magnitude less computational work. Such techniques are known as ""serendipity methods"" and serve as the focus of the proposed work. A key impact of the research will be incorporation of these methods into a widely used, open source, community-developed software package known as the Firedrake Project.<br/><br/>From high-level method analysis to specific computational tricks, the proposed work will significantly expand understanding of the benefits and limitations of serendipity finite element methodologies. For serendipity elements, the project will make precise the common mantra of ""same accuracy, less work"" by simultaneously exploring the expected computational benefits via algebraic and analytical techniques, as well as actual computational benefits via implementation and numerical simulations within the Firedrake software package. On the theoretical side, the research will advance knowledge via investigation of the algebraic structure of serendipity spaces and its exploitation to allow new Helmholtz decompositions of the associated polynomial spaces, identification of efficient ""short injections"" of serendipity bases into standard tensor product bases, and development of sparse quadrature rules. The investigators will combine expertise on element mapping and physically-defined basis elements to create an order-preserving handling of non-affinely mapped square element geometries, a key roadblock in prior attempts at implementation of serendipity elements.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1916281","Collaborative Research: A Two-Week Mentored Program to Prepare Graduate Students for Industrial Careers","DMS","INFRASTRUCTURE PROGRAM, APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/01/2019","06/19/2019","David Edwards","DE","University of Delaware","Standard Grant","Swatee Naik","06/30/2022","$18,600.00","Louis Rossi","dedwards@udel.edu","220 HULLIHEN HALL","NEWARK","DE","197160099","3028312136","MPS","1260, 1266, 1271","7556, 9150, 9263","$0.00","The 15th annual Graduate Student Mathematical Modeling Camp (GSMMC) will be held June 12-15, 2019 at the University of Delaware, followed the week after by the 35th annual Mathematical Problems in Industry (MPI) workshop, June 17-21, 2019 at the New Jersey Institute of Technology. GSMMC is a mentored, problem-solving workshop, at which small teams of Ph.D. students from across the U.S. are guided through successful mathematical modeling of real-world problems presented by faculty or experienced postdoctoral mentors. Under careful mentoring, student participants build their modeling, teamwork and presentation skills during the week: via the teamwork on modeling and simulating the problems; through the final team presentations made at the end of the week; and in writing the final reports that are produced. Training activities also include numerical simulations and the preparation of a final report outlining their discoveries.  These skills are put to use and consolidated the following week at MPI, where industrial participants present immediate modeling challenges facing their industries, on which academic participants (faculty, postdocs, and the Ph.D. students from GSMMC) work. Significant progress on the industrial problems is usually made, and Ph.D. student participants take the lead in presenting the findings to the participants from industry in final presentations at the week's end. In addition to building their skillsets and resumes, student participants are exposed to valuable networking interactions with a range of industrial participants.<br/><br/>The GSMMC-MPI program is designed to integrate interdisciplinary research and education for graduate students. The GSMMC is focused on graduate student education and training: its chief intellectual merit lies in the development and analysis, by students, of the mathematical models for the problems presented. Problems are highly interdisciplinary, presenting students with a novel intellectual challenge. With the preparatory training provided by the GSMMC, students are ready for the more open-ended, research-level environment of MPI. The questions posed at MPI challenge participants to design new ways of modeling and analyzing industrial mathematics problems in emerging areas of technology. Mathematical modeling, analytical techniques, numerical simulations, and data analysis must all be used effectively. The collaborative approach to problem solving, which involves mathematicians ranging from graduate students to experienced faculty, is central to the structure of MPI and provides significant additional training to graduate students, while promoting effective scientific communication. Full details for both events may be found at<br/>https://www.mathsci.udel.edu/events/conferences/gsmmc-2019<br/>https://web.njit.edu/~rmoore/MPI2019/MPI2019home.php<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913163","Efficient Algorithms Related to and Beyond the Large Deviation Technique","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","06/20/2019","Xiaoliang Wan","LA","Louisiana State University","Standard Grant","Yuliya Gorb","07/31/2023","$195,768.00","","xlwan@math.lsu.edu","202 HIMES HALL","BATON ROUGE","LA","708030001","2255782760","MPS","1271","9150, 9263","$0.00","Mathematical modeling methods based on partial differential equations are widely used in engineering and scientific applications, which have been one of the most important tool for mankind to understand a large variety of phenomena originating from human activity and technological development. The stochastic partial differential equations generalize the partial differential equations by taking into account the uncertainty, which is ubiquitous in reality. In this project, we focus on the simulation and quantification of rare events in stochastic partial differential equations that can model some important phenomena such as regime change in climate, rogue ocean waves, abnormal weather, etc, which may occur rarely but have major impact on our life.<br/><br/>The main goal of this project is to develop efficient numerical algorithms to capture rare events in infinite dimensional systems. We will integrate the techniques for numerical solution of partial differential equations, such as finite element method, reduced basis method, etc, (for the space-time dimension), with the ideas from large deviation theory, statistics, and deep learning (for the random dimension). When the large deviation principle is applicable, we will consider numerical solution of a nonlocal variational problem to seek the most probable event. The algorithm will be developed and analyzed in the framework of finite element method and calculus of variation. When the large deviation principle is not applicable, we will develop a strategy to seamlessly couple the reduced-order modeling and the generative models from deep learning, based on which a more general cross entropy method will be constructed for rare event simulations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1855853","Spring School Series: Models and Data","DMS","COMPUTATIONAL MATHEMATICS","03/15/2019","03/05/2019","Wolfgang Dahmen","SC","University of South Carolina at Columbia","Standard Grant","Yuliya Gorb","12/31/2020","$24,930.00","Peter Binev, Sean Yee","dahmen@math.sc.edu","1600 HAMPTON ST # 414","COLUMBIA","SC","292083403","8037777093","MPS","1271","7556, 9263","$0.00","Modern sensor and digital computing technology has been generating an enormous wealth of data carrying information that is expected to have a transformative impact on virtually all branches of science, technology and society as a whole. The need to extract quantifiable information from such data sets has stimulated, in particular, a vibrant development of diverse mathematical methodologies. Despite the size of available data sites, often referred to as ""Big Data"", they nevertheless often fall short of providing enough information about a complex process to come up with reliable predictions, a must for any technological design. The physical laws that govern such processes can often be formulated in terms of mathematical models with excellent predictive capabilities. The more detailed information is sought on complex processes the more complex the models become with ensuing consequences for their mathematical and numerical treatment. Moreover, the identification of proper models in the classical sense may become increasingly limited. Therefore, a proper integration or synthesis of information provided by data as well as by models will be of paramount lasting importance. The central objective of the Spring School is to support young researchers in developing the necessary conceptual orientation. The project helps accelerating and fostering a broad based expertise in most topical research areas with high impact on technology and society.  Internationally renowned experts, representing  the relevant areas, will deliver six two-hour block lectures. These lectures aim, in particular, at unveiling important conceptual interconnections between different areas that are often not obvious. The lectures will be interlaced with break out sessions and opportunities for the participants to actively engage. <br/> <br/><br/>This covers forward and inverse tasks in Uncertainty Quantification, parameter and state estimation, data assimilation, machine learning, structural imaging in material science, and modeling. The goal is to pair these topics with recent methodological developments, in particular, those that are able to cope with the challenge of spatial high-dimensionality shared by all the above topics. Examples, to name a few, are sparse high-dimensional polynomial expansions, deep neural <br/>networks, low-rank and tensor methods, certifiable model order reduction concepts, sparsity promoting regularization concepts, and greedy strategies. The target attendance of about 30 young researchers is to warrant a most effective interaction with the lecturers. An internet platform and a common repository will be maintained to collect and share relevant information during periods between the workshops and to initiate future collaboration. <br/><br/>More details are available at http://people.math.sc.edu/imi/dasiv/SpringSchool/<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912689","Collaborative Research:  Accurate, Efficient and Robust Computational Algorithms  for Detecting Changes in a Scene Given Indirect Data","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","06/11/2019","Guohui Song","NY","Clarkson University","Standard Grant","miao-jung ou","08/31/2019","$140,000.00","","gsong@odu.edu","8 CLARKSON AVE","POTSDAM","NY","136761401","3152686475","MPS","1271","9263","$0.00","Detecting change from a temporal sequence of collected data is important in a wide variety of applications, including speech recognition, medical monitoring, credit card fraud detection, automated target recognition, and video surveillance. In applications such as medical monitoring, it is very important to find where the change occurs. In other applications, such as video surveillance, the type of change, e.g. the movement or insertion/deletion of an object of interest, is also critical.  While detecting such changes from direct data (e.g. images already formed) has been well studied, there are many applications, such as magnetic resonance imaging (MRI), ultrasound, and synthetic aperture radar (SAR) where the temporal sequence of data are acquired indirectly. The typical approach to detecting changes in these applications would be to first form the image or signal of interest.  As a consequence, information that is stored in the indirect data that may be valuable to detecting change is often lost. Therefore, this project seeks to develop accurate, efficient, and robust computational algorithms for detecting changes in a signal or image from a given temporal sequence of indirect data without first reconstructing the signal or image of interest. Additionally, the project seeks to incorporate the change information  to develop better image and signal reconstruction algorithms.  Both graduate and undergraduate students will be involved in the research investigations to enhance their career preparation in science and engineering.  The participants will apply these new techniques on publicly available data sets, notably obtained for MRI, ultrasound, and SAR applications.  <br/><br/>The PIs will employ tools in frame theory, optimization, and statistics to develop and rigorously analyze new change detection and image/signal recovery algorithms. Specifically, the PIs will address the following technical issues in the proposed work: (1) the incorporation of prior information with appropriate mathematical/statistical formulation in the model; (2) the extraction of rotation/translation of an object from a sequence of indirect data; (3) model parameters tuning through statistical analysis; (4) the employment of intra- and inter-signal correlations in the recovery algorithms; (5) the design of distributed algorithms for the resulting large-size optimization model.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913272","Hybrid Finite Element Methods for Geometric Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","05/31/2019","Ari Stern","MO","Washington University","Standard Grant","Yuliya Gorb","06/30/2023","$212,640.00","","stern@wustl.edu","ONE BROOKINGS DR","SAINT LOUIS","MO","631304862","3147474134","MPS","1271","9150, 9263","$0.00","Finite element methods are among the most important, powerful tools in scientific computing. Their applications include several areas of Federal strategic interest: materials and manufacturing, biomedical engineering and biotechnology, structural engineering and civil infrastructure, environmental engineering, and more. They are widely used by scientists and engineers in academia, industry, and national laboratories to simulate large, complex physical systems. These physical systems often obey ""conservation laws,"" which state that some quantity -- like mass, or energy, or electric charge -- can move around in space, but cannot appear or disappear spontaneously. It is desirable that simulations of these systems also obey these conservation laws, because they are so fundamental; otherwise, the simulated results may not be physically meaningful or trustworthy. However, this is not always the case with current methods. In this project, the PI will develop and analyze finite element methods that obey these conservation laws and preserve related physical properties. The success of this project would lead to new computational methods and improved understanding of current methods for a wide variety of scientific applications. Because the specific applications addressed by the proposed research are of high scientific value, this could have important ramifications for computational physics and engineering.<br/><br/>The PI proposes to investigate structure-preserving hybrid finite element methods for partial differential equations (PDEs) containing local symmetries, invariants, and conservation laws. In applications, these locally-invariant geometric structures often have important physical meaning (e.g., conservation of charge in electromagnetics), so it is desirable to devise conservative numerical methods that preserve these structures exactly rather than approximately. Hybrid methods provide a natural framework for this, since one may examine local invariants, element-by-element, in terms of numerical traces and fluxes on their boundaries. The proposed research consists of two main components. (1) Hamiltonian PDEs, which are ubiquitous in physical applications, satisfy the multisymplectic conservation law, which is closely tied to physically-important reciprocity phenomena, traveling waves, dispersion relations, and bifurcations. The PI will extend his recent joint work on multisymplectic hybridizable discontinuous Galerkin (HDG) methods for spatial discretization to time-evolution problems, using spatial HDG semidiscretization and spacetime HDG methods. (2) While the time evolution of Maxwell's equations automatically preserves a divergence constraint associated with charge conservation, this is generally not true for finite element discretizations. Preliminary results show that this can be resolved using a class of hybrid methods, where charge conservation holds in the sense of the numerical electric flux. The PI proposes to extend this by analyzing nonconforming hybrid methods for the Maxwell eigenvalue problem, as well as hybrid methods for Yang-Mills theory using finite element exterior calculus.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913293","Mathematical and Computational Studies on Bose-Einstein Superfluid","DMS","COMPUTATIONAL MATHEMATICS","07/01/2019","06/21/2019","Yanzhi Zhang","MO","Missouri University of Science and Technology","Standard Grant","Leland Jameson","06/30/2023","$175,000.00","","zhangyanz@mst.edu","300 W 12TH ST","ROLLA","MO","654096506","5733414134","MPS","1271","9150, 9263","$0.00","Bose-Einstein condensate (BEC), predicted by S. Bose and A. Einstein in the early 1920s, is a state of matter near absolute zero temperature for which all atoms lose their individual properties and condense into a macroscopic coherent 'super-wave'. Since its first experimental realization in 1995 (2001 Nobel Prize in Physics awarded to E. A. Cornell, W. Ketterle, and C. E. Wieman), BEC has been the focus of active research both experimentally and theoretically. It not only provides a new platform to investigate quantum properties of matter but also opens new perspectives for understanding the phenomena of superconductivity and superfluidity. The recent launch of the Cold Atom Laboratory to the space station on May 21, 2018 has once again drawn the spotlight to BEC superfluidity. This project focuses on the fundamental mathematical and computational issues arising in the study of Bose-Einstein superfluids to understand its behavior under the influence of artificial gauge fields and long-range dispersive interactions. It could potentially benefit the development of advanced technologies, for instance, superconducting quantum interference devices and atom interferometer-based sensors. <br/><br/>The main objectives of this research are to build mathematical and computational treatments for the magnetic Schrodinger equations, to promote the understanding of Bose-Einstein superfluidity, so as to advance the experiments and applications of BEC. This project proposes systematic research on the mathematical modeling and numerical simulations of BEC superfluids in the presence of long-range dispersion interactions. On one hand, new mathematical and numerical issues introduced by the long-range dispersion will be investigated in detail. First, effective absorbing boundary conditions will be developed to avoid the artificial reflections of waves at the computational boundary, one persistent problem in wave simulations. Then accurate and efficient numerical methods will be designed to discretize the magnetic Schrodinger models. On the other hand, the solution properties of BEC will be studied analytically and numerically to understand the influence of long-range dispersion interaction and its interplay with nonlinear interactions. Both stability analysis and numerical simulations will be carried out to study the modulation instability and wave collapse due to the competition of dispersion and nonlinear interactions. Moreover, the properties of quantized vortices in the presence of artificial gauge field and nonlocal dispersive and/or nonlinear interactions will be investigated, so as to advance the understanding of BEC superfluidity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913134","Optimization Techniques for Geometrizing Real-World Data","DMS","COMPUTATIONAL MATHEMATICS","09/01/2019","06/20/2019","Soledad Villar","NY","New York University","Standard Grant","Yuliya Gorb","09/30/2020","$50,615.00","","svillar3@jhu.edu","70 WASHINGTON SQ S","NEW YORK","NY","100121019","2129982121","MPS","1271","9263","$0.00","Data is a common denominator to scientific fields, governments, and private enterprises. Being able to exploit data to find patterns has produced scientific breakthroughs and shifted business paradigms in the last several decades. This project focuses on mathematical and algorithmic techniques for specific data science problems, tailored to currently relevant domain problems, technologies, and volumes of data. The theoretical problems we consider are (i) clustering (which essentially consists on grouping data according to similarity in an unsupervised way), (ii) dimensionality reduction (reducing the volume of the data while preserving its relevant features), and (iii) quadratic assignment (finding correspondences between different datasets). The main underlying application we consider in this project is computational biology, in particular the processing of single-cell sequencing data. The technology for single-cell sequencing has been very recently developed and it is improving quickly, producing new datasets, problems and challenges that are interesting from a mathematical point of view and have potentially enormous impact. The project will have mathematicians working closely to computational biologists with the goal of identifying data science problems occurring in the scientific domain and to develop appropriate algorithms and mathematical tools.<br/><br/>Given single-cell genetic expression data indicating how many times each gene is expressed in each cell, one objective is to select a few genes that can be used to identify different classes of cells. This problem is known in the computational biology literature as genetic marker selection. In a first approach we assume the class of each cell is known and the problem can be posed as supervised dimensionality reduction. We model it as a projection factor recovery problem, and we approach it using optimization tools such as semidefinite and linear programming. The objective is two-fold, we aim to study mathematical properties of the model we devise, and to develop an efficient tool to be used by practitioners. A second stage of the project is to make the problem unsupervised, therefore clustering will be a fundamental step. We will study stability properties of clustering methods and we will provide an efficient algorithm to evaluate the quality of clusters, based on statistical and optimization techniques. The potential use of this tool is general to data science and not just gene expression datasets. Finally, a third objective is to align datasets coming from different experiments. This problem is ubiquitous in data science, with graph matching and shape matching as some particular cases. In the context of computational biology the alignment problem is known as batch correction and it can be modeled with optimal transport or as a quadratic assignment problem. We will develop alignment algorithms and study their convergence and recovery properties under different data models.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1911325","Collaborative Research: High-Fidelity Modeling of Poromechanics with Strong Discontinuities","DMS","COMPUTATIONAL MATHEMATICS","07/15/2019","09/14/2020","Ruijie Liu","TX","University of Texas at San Antonio","Standard Grant","Leland Jameson","08/31/2020","$36,288.00","","ruijie.liu@utsa.edu","One UTSA Circle","San Antonio","TX","782491644","2104584340","MPS","1271","9263","$0.00","Poromechanics with strong discontinuities has numerous important applications such as simulating fluid flow in natural static and hydraulic dynamic fractures, fracture analysis of aging bones, multiple-network poroelastic theory arising in dementia and Alzheimer's disease, and evaluation of accelerated degradation of ceramic matrix composites in aerospace shuttles. Here mathematical modeling is challenging because it involves not only coupled chemical reactions, diffusion, and deformation but also initiation, propagation, and branching of cracks in the bulk matrix as well as fluid flowing through cracks. To address these challenges, high fidelity numerical schemes and multiphysics models must be coupled in order to simulate these processes and their interactions accurately and efficiently. This project will benefit public and decision makers including energy producers, health providers, aerodynamicists, and hydrogeologists.<br/><br/>The objective of this project is to study the following fundamental relationships linking flow, chemistry, and mechanics: stability, a priori, and a posteriori error estimation of dynamic discontinuous Galerkin discretizations, physically consistent material models for the deformation and failure of the media, efficient and accurate material solution techniques, and scaling characteristics of mechanical properties.  This knowledge will be used in the design of locally conservative finite element methods coupling porous media flow, reactive transport, and mechanics that run efficiently on high-performance computing platforms.  The team will investigate: (1) Development of fundamental understanding of poromechanics with strong discontinuities in the setting of chemo-mechanical coupled models; (2) Formulation and analyses of flow, mechanical, and reactive transport models solved using high-fidelity numerical algorithms; (3) Developing error estimates for iterative coupling solution techniques; (4) Verifying and validating fluid structure interactions using published data from target data sets.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1852593","Data Science and Image Analysis Conference of the Pacific Northwest","DMS","COMPUTATIONAL MATHEMATICS","04/01/2019","03/26/2019","Laramie Paxton","WA","Washington State University","Standard Grant","Leland Jameson","03/31/2020","$20,520.00","Charles Moore, VIKTORIA TAROUDAKI, Justin Marks","laramie.paxton@wsu.edu","280 Lighty","PULLMAN","WA","991641060","5093359661","MPS","1271","7556, 9263","$0.00","This award will provide funding for sixty students and junior researchers, with a focus on recruiting and funding women and members of underrepresented groups, to attend the Data Science and Image Analysis Conference of the Pacific Northwest at Washington State University in Pullman, Washington, February 29th and March 1st, 2020. The conference will promote close collaborations on current and ongoing areas of research through a highly interactive and open format, with discussions taking place in both larger and smaller groups. The first day will have professionals from industry, government, and academia in the fields of data science and image analysis come together, along with students and post-doctoral researchers, to collaborate on open problems through short talks, in-depth group discussions, and breakout sessions. The second day will consist of professional development activities for students and junior researchers, and will feature presentations from members of this group, with direct feedback provided from professionals. The conference will provide a unique opportunity for students and junior researchers to participate and will encourage future collaborations among all levels of researchers. <br/><br/>The ever-increasing demand for managing and analyzing ""big data""in nearly every sector of society, from finance and security to health care and social media, has led to a wide range of applications across numerous fields of research. Similarly, image analysis techniques have continued to be developed and incorporated into a multitude of disciplines, such as biomedical imaging, machine learning, and computer vision. Since many important societal outcomes are dependent on these fields, the conference can make a broad impact on society by widely sharing the progress made on the open problems discussed, which has the potential to lead to even further progress in data science and image analysis and thus to advance scientific discovery. With the demand for experts in these areas growing rapidly, the conference will also serve to increase the number of researchers entering STEM fields, especially women and members of underrepresented groups. Discussion topics will include topological data analysis, bioinformatics, learning from remote sensing data, financial & economic prediction, image segmentation and filtering in biomedical imaging, hyperspectral imaging, pattern recognition, shape analysis, and image reconstruction. More information can be found at datascienceandimageanalysis.com.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1913294","New Hierarchies, Cutting Planes, and Algorithms for Mixed Integer Optimization","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","04/23/2020","Akshay Gupte","SC","Clemson University","Standard Grant","Yuliya Gorb","07/31/2020","$44,573.00","","agupte@clemson.edu","230 Kappa Street","CLEMSON","SC","296340001","8646562424","MPS","1271","9150, 9263","$0.00","Mathematical optimization problems arise in many applications in diverse fields in science and engineering. A large portion of these problems require discrete decisions to be made, where some of the unknowns are restricted to take only integer values. There continues to be a pressing need to further improve the performance of the state-of-the-art for solving mixed integer problems, especially when the unknowns in the problem are constrained through nonlinear relationships. This research project develops new mathematics for optimizing mixed integer problems. The overall impact will be visible through the implementation of new and sophisticated algorithms for solving these problems. An auxiliary algorithm will be developed to aid our main algorithm and it will also be applicable to optimization in decision theory, game theory, and cryptography. The algorithms will be empirically tested on benchmark problems, and used to solve an application in oil and gas industry and a fundamental problem in statistical learning that is widely-used for predictive analytics. Research from this project will be integrated into classroom through the development of a new graduate course that teaches algebraic and combinatorial methods in discrete optimization. The award will provide support for graduate student training through research.<br/><br/>The primary research objective of this project in computational mathematics is to derive novel polyhedral relaxations for the feasible regions of mixed integer problems (MIPs) through an innovative interpretation of discrete feasible regions arising from ordered sets of integral vectors under some monomial ordering. The research activities involve developing a rich body of knowledge about cutting planes, valid inequalities, and polyhedral relaxations for MIPs, approximation algorithms for MIPs, and using discretization methods to efficiently approximate MIPs with polynomial constraints. Thus, this project will establish new connections between computational algebra,  combinatorics, and mathematical optimization. One of our methods for generating cutting planes using a monomial order generalizes and strengthens the cutting planes derived from the well-known split disjunctions. The theory we develop does not depend explicitly on the algebraic representation of the feasible set, therefore making it applicable to all classes of MIP and presenting a very different approach than many of the existing studies that explicitly depend on the linearity of the constraints.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1945322","9th Workshop on Parallel-in-Time Integration","DMS","COMPUTATIONAL MATHEMATICS","10/15/2019","08/09/2019","Benjamin Ong","MI","Michigan Technological University","Standard Grant","Leland Jameson","09/30/2021","$25,185.00","Jacob Schroder","ongbw@mtu.edu","1400 TOWNSEND DR","HOUGHTON","MI","499311200","9064871885","MPS","1271","7556, 9263","$0.00","9th Workshop on Parallel-in-Time Integration<br/>Michigan Technological University Houghton, Michigan June 8-12,2020.<br/>http://conferences.math.mtu.edu<br/><br/>Computer models and simulations play a central role in the study of complex systems in engineering, life sciences, medicine, chemistry, and physics. Utilizing modern supercomputers to run models and simulations allows for experimentation in virtual laboratories, thus saving both time and resources. Although the next generation of supercomputers will contain an unprecedented number of processors, this will not automatically increase the speed of running simulations. New mathematical algorithms are needed that can fully harness the processing potential of these new systems. Parallel-in-time methods, the subject of this workshop, are timely and necessary, as they extend existing computer models to these next generation machines by adding a new dimension of scalability. Thus, the use of parallel-in-time methods will provide dramatically faster simulations in many important areas, such as biomedical applications (e.g., heart modeling), computational fluid dynamics (e.g., aerodynamics and weather prediction), and machine learning. Computational and applied mathematics plays a foundational role in this projected advancement. <br/><br/>The primary focus of the  parallel-in-time workshop is to disseminate cutting-edge research and facilitate scientific discussions on the field of parallel time integration methods. This workshop aligns with the National Strategic Computing Initiative (NCSI) objective: 'increase coherence between technology for modeling/simulation and data analytics'.  The need for parallel time integration is being driven by microprocessor trends, where future speedups for computational simulations will come through using increasing numbers of cores and not through faster clock speeds. Thus as spatial parallelism techniques saturate, parallelization in the time direction offers the best avenue for leveraging next generation supercomputers with billions of processors. Regarding the mathematical treatment of parallel time integrators, one must use advanced methodologies from the theory of partial differential equations in a functional analytic setting, numerical discretization and integration, convergence analyses of iterative methods, and the development and implementation of new parallel algorithms. Thus, the workshop will bring together an interdisciplinary group of experts spanning these areas. NSF support for this conference will be used to engage junior researchers in this important research topic.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1931844","Symposium on Computational Modeling and Image Processing of Biomedical Problems","DMS","COMPUTATIONAL MATHEMATICS","08/01/2019","07/22/2019","Zhengfu Xu","MI","Michigan Technological University","Standard Grant","Yuliya Gorb","07/31/2020","$15,000.00","Jingfeng Jiang","Zhengfux@mtu.edu","1400 Townsend Drive","Houghton","MI","499311295","9064871885","MPS","1271","7556","$0.00","Title: Symposium on Computational Modeling and Image Processing of Biomedical Problems<br/>Conference location: Michigan Technological University (MTU) <br/>Date: June 15-17,  2019<br/>Website: http://pages.mtu.edu/~zhengfux/Overview.htm. <br/><br/><br/>From the discovery of penicillin (1928) to Human Genome Project (1990), breakthroughs in medicine have greatly impacted billions of people on earth. Among them, developments of medical imaging techniques such as x-ray imaging, computed tomography (CT) scans, magnetic resonance imaging (MRI), and a variety of other radiological imaging techniques have allowed the examination of the internal condition of the body without the use of invasive surgical procedures. Furthermore, medical imaging technologies are being increasingly used to provide guidance for surgery, biopsy, and radiation therapy in real-time. We are now on the cusp of another breakthrough era, given the availability of data, computational power, and novel computing methodology such as artificial intelligence, thereby potentially elevating human healthcare to a level never seen before. Mathematics, particularly, computational and applied mathematics, plays a foundational role in the projected advancement. <br/><br/>The primary focus of the proposed interdisciplinary symposium is to provide an update on recent important contributions to computational and numerical methods in biomedical problems. Applying novel mathematics and modeling techniques to extract new or additional information from complex bio-medical datasets are particularly encouraged. Topics of interest include mathematical and computing methods and their immediate applications in the following areas: a) Novel mathematical image formation/reconstruction/processing methods and their applications in biomedical problems; b)Novel mathematical algorithms enabling multi-scale and multi-physics simulation related to biomedical problems;c) Scientific visualization and analytics of  (BIG) biomedical data; d) Novel machine learning and statistical analysis methods and their application in (BIG) biomedical data. One of the main challenges when integrating mathematics into biomedical sciences is overcoming existing barriers. Unfamiliarity with biomedical language, distinct disciplinary-bound approaches to research in the mathematics community, and 'artificial' academic boundaries aimed at 'preserving subject integrity' can hinder developments in this line of interdisciplinary research. The secondary objective of this symposium is to provide a platform so that intelligent exchanges among applied mathematicians, biomedical engineers, and clinical scientists can take place, fostering interdisciplinary collaborations. A concerted effort will be made to include underrepresented students and early and middle-career mathematicians in the symposium. Using existing resources available at the Michigan Technological University, the organizers will work together with the Center of Diversity and Inclusion and other partners to recruit students who are typically from economically-disadvantageous backgrounds to attend this symposium. In addition, it is planned to create a future network of support and interaction among participants to enable further research and collaboration.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1916232","Collaborative Research: A Two-Week Mentored Program to Prepare Graduate Students for Industrial Careers","DMS","INFRASTRUCTURE PROGRAM, APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/01/2019","06/19/2019","Linda Cummings","NJ","New Jersey Institute of Technology","Standard Grant","Swatee Naik","06/30/2020","$11,400.00","Richard Moore","linda.j.cummings@njit.edu","University Heights","Newark","NJ","071021982","9735965275","MPS","1260, 1266, 1271","7556, 9263","$0.00","The 15th annual Graduate Student Mathematical Modeling Camp (GSMMC) will be held June 12-15, 2019 at the University of Delaware, followed the week after by the 35th annual Mathematical Problems in Industry (MPI) workshop, June 17-21, 2019 at the New Jersey Institute of Technology. GSMMC is a mentored, problem-solving workshop, at which small teams of Ph.D. students from across the U.S. are guided through successful mathematical modeling of real-world problems presented by faculty or experienced postdoctoral mentors. Under careful mentoring, student participants build their modeling, teamwork and presentation skills during the week: via the teamwork on modeling and simulating the problems; through the final team presentations made at the end of the week; and in writing the final reports that are produced. Training activities also include numerical simulations and the preparation of a final report outlining their discoveries.  These skills are put to use and consolidated the following week at MPI, where industrial participants present immediate modeling challenges facing their industries, on which academic participants (faculty, postdocs, and the Ph.D. students from GSMMC) work. Significant progress on the industrial problems is usually made, and Ph.D. student participants take the lead in presenting the findings to the participants from industry in final presentations at the week's end. In addition to building their skillsets and resumes, student participants are exposed to valuable networking interactions with a range of industrial participants.<br/><br/>The GSMMC-MPI program is designed to integrate interdisciplinary research and education for graduate students. The GSMMC is focused on graduate student education and training: its chief intellectual merit lies in the development and analysis, by students, of the mathematical models for the problems presented. Problems are highly interdisciplinary, presenting students with a novel intellectual challenge. With the preparatory training provided by the GSMMC, students are ready for the more open-ended, research-level environment of MPI. The questions posed at MPI challenge participants to design new ways of modeling and analyzing industrial mathematics problems in emerging areas of technology. Mathematical modeling, analytical techniques, numerical simulations, and data analysis must all be used effectively. The collaborative approach to problem solving, which involves mathematicians ranging from graduate students to experienced faculty, is central to the structure of MPI and provides significant additional training to graduate students, while promoting effective scientific communication. Full details for both events may be found at<br/>https://www.mathsci.udel.edu/events/conferences/gsmmc-2019<br/>https://web.njit.edu/~rmoore/MPI2019/MPI2019home.php<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
