"AwardNumber","Title","NSFOrganization","Program(s)","StartDate","LastAmendmentDate","PrincipalInvestigator","State","Organization","AwardInstrument","ProgramManager","EndDate","AwardedAmountToDate","Co-PIName(s)","PIEmailAddress","OrganizationStreet","OrganizationCity","OrganizationState","OrganizationZip","OrganizationPhone","NSFDirectorate","ProgramElementCode(s)","ProgramReferenceCode(s)","ARRAAmount","Abstract"
"1115709","Temporal Multi-Scale Simulation Tools Kinetic Plasma Equations","DMS","COMPUTATIONAL MATHEMATICS","10/01/2011","09/19/2011","Andrew Christlieb","MI","Michigan State University","Standard Grant","Leland Jameson","09/30/2015","$200,000.00","","christli@msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1271","9263","$0.00","In this work the PI and his student consider the development of novel methods for problems in kinetic transport.  The goal is to develop methods that are capable of bridging multiple time scales.    For instance, many problems in plasma physics, such as modeling edge plasma problems in fusion systems,  can exhibit behavior which is consistent with both diffusion dominated transport as well as collisionless flow in the same problem at the same  time.  Generally speaking, this class of problems can be summarized as hyperbolic systems with stiff relaxation terms.  Typically the stiff relaxation term can be nondimensionalized, leading to a scaling constant out in front of the relaxation term of the form 1/d.  In the problems of interest, as d approaches zero,  the system transitions from hyperbolic to parabolic. One approach to such problems is to use domain decomposition methods coupled with appropriate models for the various physical behaviors.   However, a major difficulty with this approach is defining the boundary conditions for  the two way coupling between the domains.   The approach taken in this work is to develop numerical methods for the kinetic systems which can recover the correct limiting behavior in the limit of the system becoming collision dominated.   The particular class of methods we focus on here are referred to as Asymptotic Preserving (AP)  methods.  The goal in designing an AP method is to develop time stepping strategies that maintain their order of accuracy for any d.  In particular, as d approaches zero, the AP method should recover a consistent discretization for the limiting behavior.  However, developing AP methods which are high order have proven difficult to construct.  Further, for a range of important test problems, the CFL for the AP method is restricted to time steps less than the square of the spatial discretization.   In this work, the PI and his student investigate a new method based on a pseudo upwinding method inside of the  AP framework, which gives rise to a method which has a convergence rate independent of d with an apparent CFL of the time step proportional to the spatial discretization.  Further, the PI proposes a novel method for lifting low order AP methods to high order based on integral deferred correction, a defect correction methodology developed by the PI and his collaborators.  The approach is generalizable  to a wide class of kinetic equations with stiff relaxation terms. <br/><br/>A large number of important problems in science are characterized by multiple length scales.  This includes studying the aerodynamics of spacecraft launch and reentry, the characterization of micro/nano mechanical systems and the study of charge particle transport, such as disassociated electrons and ions, in plasma lighting, micro chip design, and clean energy systems of the future, such as fusion, to name a few.      In these examples,  on the smallest scales, the individual atoms which make up the gas can be thought of as billiard balls bouncing around, each billiard ball  having its own speed and direction.  The gas molecules collide with each other, as well as the boundaries of obstacles in the flow,  exchanging  energy and momentum with each other as well as the environment.   On this scale the system is well characterized by models know as kinetic equations, which describe the behavior of the gas from a  probabilistic perspective.   Kinetic equations account for time scales of individual atoms colliding with each other.    On the largest length scales, the gas exhibits collective behavior such as wind, which we think of as having a single speed.   As the density of a gas changes from low density to high density, the system behavior changes from individual particles to a collective average behavior.  This transition happens in many systems, one interesting  example is  the reentry of a spacecraft, where at high altitude the atmosphere is a very low density gas and at ground level the atmosphere is 20 orders of magnitude higher in density.  At low densities, these systems exhibit effects only described by kinetic models.   At high densities, the systems exhibit collective behavior described my much simpler models.  The critical  kinetic time scale, described  by inter-particle collisions, scales as one over the density.     The importance of this work is to develop a new class of simulation tools that can handle the very stiff time scales associated with systems that undergo this very sharp transition in densities that can efficiently simulate both the rarified and dense gas regimes, as well as the transition in density.  This framework will allow for the  simulation of problems previously outside the scope of standard kinetic solvers, allowing the solvers to recover the correct limiting behavior with orders of magnitude increase in efficiency over existing methods."
"1115293","Polynomial Optimization and Convex Algebraic Geometry","DMS","COMPUTATIONAL MATHEMATICS","07/01/2011","06/06/2011","Rekha Thomas","WA","University of Washington","Standard Grant","Junping Wang","09/30/2014","$342,819.00","","thomas@math.washington.edu","4333 BROOKLYN AVE NE","SEATTLE","WA","981950001","2065434043","MPS","1271","9263","$0.00","This study focuses on problems from polynomial<br/>optimization and convex algebraic geometry. The latter is a new<br/>research area that concerns convex sets and convex hulls of sets that<br/>are described algebraically and arise in optimization.  The key tool is the use of efficient algorithms in  semidefinite programming, a branch of convex optimization  that is used in polynomial optimization. The<br/>first set of questions studies the general phenomenon of when a given<br/>convex body is the linear projection of a slice (by an affine plane)<br/>of a closed convex cone. This phenomena is central to all<br/>lift-and-project methods for discrete and polynomial optimization. This study<br/>provides a uniform view of all lift-and-project<br/>methods via new notions of cone factorizations of certain operators<br/>associated to the convex body. The investigator and collaborators have<br/>recently constructed a new hierarchy of convex relaxations for<br/>algebraic sets called theta bodies. Various open questions about these<br/>bodies are posed. The methods<br/>from polynomial optimization and convex algebraic geometry can be applied to problems<br/>from computer vision. Here the application is primarily to object reconstruction from<br/>images taken by multiple cameras.<br/><br/>The work of the PI with her collaborators improvies our understanding of the algebraic and geometric<br/>structures that underlie optimization problems that involve<br/>polynomials. Such problems have a wide array of applications and admit<br/>methods from both the algebraic and analytic sides of<br/>mathematics. This research considers both improvements in our understanding of the theoretical aspects of polynomial optimization, and the application of these methods to problems in computer vision."
"1129181","International Conference on Interdisciplinary Applied and Computational Mathematics","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, Catalyzing New Intl Collab","08/15/2011","08/04/2011","Di Liu","MI","Michigan State University","Standard Grant","Junping Wang","08/31/2013","$38,000.00","","richardl@math.msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1266, 1271, 7299","5978, 7556, 9200, 9263","$0.00","The proposed International Conference on Interdisciplinary Applied and Computational Mathematics is a five-day conference to be held June 17-21, 2011 at Zhejiang University, Hangzhou, China. This conference will bring together leading researchers in the world to discuss recent advances on Multiscale, Multiphysics, and Stochastic Modeling, Analysis and Computation of Direct, Inverse, and Imaging Problems and Applications. The conference focuses on three related topics. The first is the development of multi-scale, multiphysics modeling, analysis, and computation techniques that are critically important for the simulation and design of nano materials and fabrications. The second is the integration of inverse problem techniques with imaging analysis methods for important physical processes that arise in nondestructive testing, optical imaging, near-field microscopy, and nano/bio imaging.  The third is the uncertainty quantification of the large scale problems focusing on imaging and inverse problems in random media as well as numerical solutions of stochastic partial differential equations. There will be about three plenary speakers each day, giving 1-hour talks. While the plenary speakers are predominantly from a mathematical background, many of the local speakers will be form an experimental background. Also there will be three introductory talks which lay out the nature of the challenges in each area, and a forward looking session at the end of the conference. A poster session will be available to graduate students and postdocs for advertising their research results. The NSF fund will be used to support US-based scientists (mostly junior researchers) for attending the conference and exchanging new ideas in various application areas.  <br/><br/>Recent innovative developments of the multi-scale, multi-physics modeling and computational methods, inverse problem methods, and imaging techniques are applicable to describe many other physical processes and will have impact on the modeling and computation of the models in computational biology, multi-scale modeling of materials science, nano technology, and imaging science. Advances in these fields will greatly contribute to the development nano technologies for solar energy harvesting, medical imaging and therapeutics. Many physical systems, devices and processes of importance to science and engineering are not very well understood and controlled due to uncertainty in physical models and their parameters, multi-scale material properties, the operating environment, or measurement. While numerical simulations offer a viable alternative for critical decision making, simulation uncertainties from physical, analytical, or numerical errors must be characterized and managed. General and efficient mathematical models and novel computational algorithms must be developed for modeling multi-scale, multi-physics processes with appropriate control of uncertainty. The understanding of the role of stochastic effects on the direct, inverse, and imaging problems will have broad impact on the advancement of these key areas of scientific study. By combining these areas into a focused conference, and interspersing theoretical, applied, and computational talks, we hope to promote a cross-fertilization between scientists with various disciplinary backgrounds. By outlining the potential impact that theoretical tools can have on the most salient issues of our day, the workshop will influence and invigorate the educational efforts at the institutions of the speakers and workshop participants."
"1115363","Fast multiscale Gaussian wavepacket transforms and multiscale Gaussian beams for high-frequency waves and inverse problems","DMS","COMPUTATIONAL MATHEMATICS","09/01/2011","08/13/2011","Jianliang Qian","MI","Michigan State University","Standard Grant","Junping Wang","08/31/2014","$179,999.00","","qian@math.msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1271","9263","$0.00","The investigator, with his students and collaborators, develops novel and efficient numerical methods for modeling high-frequency wave propagation and solution of associated inverse problems. These problems arise from seismic wave propagation, geometrical optics, optimal control, computerized tomography (CT), medical imaging, and material sciences. The proposal focuses on advancing fast multiscale Gaussian wavepacket transforms and multiscale Gaussian beam methods, a novel approach for this challenging problem, from theoretical, algorithmic, and practical perspectives. This interdisciplinary research complements the PI's educational goals by integrating education and research activities at undergraduate and graduate levels. Problems under consideration include exploring the deep connection between multiscale Gaussian beams and fast multiscale Gaussian wavepacket transforms to devise new algorithms for decomposing given data into Gaussian beams, developing new multiscale Gaussian beam methods for modeling acoustic, elastic and anisotropic waves, analyzing linearized inverse problems for acoustic and elastic wave equations by using multiscale Gaussian beams in the high frequency regime, devising novel algorithms to implement the resulting linearized inversion formulas, and validating the resulting algorithms by using synthetic data.<br/><br/>Modeling of high frequency waves is of great strategic value in diverse science and engineering disciplines, ranging from the US petroleum industry, seismic imaging, radar, sonar, medical imaging, remote sensing, submarine detection, material sciences to nanotechnology. The current surge in price for crude oil and other earth resources increasingly demands better imaging techniques in exploration seismology. The increasing amount of data in global and exploration seismology requires more sophisticated mathematical models. The techniques developed as part of this project provide crucial tools for the development of the next-generation seismic imaging tools with the potential to enable substantial cost savings in seismic explorations, expedite routine data processing, and protect the environment by optimizing drilling sites. Students from the PI's institution are involved in this innovative interdisciplinary research project."
"1217563","Development of Discontinuous Galerkin Methods for Kinetic Transport Models and Control Problems with State Constraints","DMS","COMPUTATIONAL MATHEMATICS","11/10/2011","05/09/2012","Yingda Cheng","MI","Michigan State University","Standard Grant","Junping Wang","07/31/2014","$73,276.00","","ycheng@math.msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1271","6863, 9263","$0.00","The objective of this project is to develop and analyze novel discontinuous Galerkin (DG) <br/>methods for solving partial differential equations arising from various application areas. The DG <br/>method is a class of finite element methods using completely discontinuous piecewise polynomial <br/>space for the numerical solution and the test functions. Those robust, compact, locally <br/>conservative methods can treat arbitrarily unstructured meshes and are ideal for hp-adaptive <br/>strategies. The good properties of the scheme call for further research in areas that are <br/>traditionally not solved by DG methods. In this grant proposal, the PI plans to conduct research <br/>in the following directions: (1) a positivity-preserving DG method for solving the kinetic <br/>equations, including the Boltzmann equations and Vlasov equations, (2) application of the <br/>proposed method to solar cell/semiconductor device simulations and plasma physics, (3) a novel <br/>DG solver for the Hamilton-Jacobi equations and its applications in control problems with state <br/>constraints.    <br/> <br/>The proposed activity lies between algorithm development, analysis and applications.  <br/>Developing robust, high-order accurate, cost-efficient  numerical algorithms for kinetic models <br/>and control problem is very challenging, not only because of the high dimensionality of such <br/>models, but also because of the fact that a deep understanding of the underlying physics is <br/>required. The eventual goal is to produce solvers that are  computationally efficient and suit the <br/>need for applications. The PI's work arises from the computational demand of real world <br/>applications. Many ideas developed in this proposal will have straightforward applications and <br/>impacts in semiconductor device simulations, high-efficiency fuel cell modeling, control problems <br/>and plasma physics. The PI actively interacts  with students and faculty members in mathematics, <br/>physics, electrical engineering and chemistry departments.  In addition, the PI will integrate the <br/>project with the training of  graduate students in order to communicate in a broader context."
"1114336","Computational Methods in Numerical Algebraic Geometry","DMS","COMPUTATIONAL MATHEMATICS","09/01/2011","08/22/2011","Jonathan Hauenstein","TX","Texas A&M Research Foundation","Standard Grant","Junping Wang","10/31/2012","$94,000.00","","hauenstein@nd.edu","400 HARVEY MITCHELL PKWY S STE 3","COLLEGE STATION","TX","778454375","9798626777","MPS","1271","9263","$0.00","This project aims to contribute to numerical algebraic geometry by developing and implementing new algorithms used to solve polynomial systems arising in many applications.  One goal is the development of an algorithm for solving large-scale structured polynomial systems which naturally arise in computing overconstrained mechanisms as well as computing real and singular points on algebraic sets.  This algorithm will utilize the regeneration method, developed by Hauenstein, Sommese, and Wampler, which computes the solutions of a polynomial system by building from the solutions of smaller polynomial systems.  Regeneration together with the exploitation of structure will allow one to solve many naturally occurring polynomial systems which are beyond the reach of current methods.  Another goal is the training of one or more undergraduate students in this area. The students will also help with the development of some of the algorithms and testing of the software developed by this proposal.  Additionally, as a group, we will apply the newly developed algorithms to new problems arising from applications.<br/><br/>Polynomial systems naturally arise in many areas of science, engineering, economics, and biology with their solutions, for example, describing the design of specialized robots, equilibria of chemical reactions and economic models, and describing the stability of tumors.  The real solutions to these polynomial systems are often of particular interest to researchers as they often describe the physically meaningful solutions, e.g., a constructible robot.  The new algorithms and software developed will allow a broad range of scientists, engineers, and economists who encounter polynomial systems to compute physically meaningful solutions to systems which are beyond the reach of current solving techniques. Additionally, the students involved in this project will gain knowledge and research experience in the mathematical sciences."
"1115587","Solving Polynomial Systems by the Polyhedral Homotopy","DMS","COMPUTATIONAL MATHEMATICS","09/15/2011","09/06/2011","Tien-Yien Li","MI","Michigan State University","Standard Grant","Junping Wang","08/31/2015","$240,000.00","","li@math.msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1271","9263","$0.00","A group led by the PI has successfully developed a software package, HOM4PS-2.0, implementing the  ""polyhedral homotopy continuation"" method for solving polynomial systems. The solver leads existing software packages for solving polynomial systems in speed by a large margin. The essence of the proposed project is the further development in all aspects of the solver HOM4PS-2.0. In particular, for the need of solving larger polynomial systems, a major aspect of the project is the advanced development of the parallel version of the solver. The landscape of computation hardware is quite different from even a decade ago. Developments in new processor design and network technology have allowed supercomputers and computer clusters to grow larger and faster than ever, including new ideas such as cycle scavenging, grid computing, virtual supercomputers, multiple cores, and GPUs (graphics processing units). The proposed project will investigate and implement versions of HOM4PS-2.0 that take optimum advantage of heterogeneous computing platforms, with special emphasis on clusters, cloud computing, multicore and GPUs. In addition we plan to find ways to implement highly serial parts of the original algorithm, such as mixed volume computation and path-jumping detection on parallel architectures. The proposed project intends to fully incorporate all the cutting-edge parallel computing technologies in our solver for solving larger and larger polynomial systems. <br/><br/>The problem of solving polynomial systems arises very frequently in various fields of science and engineering, such as, formula construction, geometric intersection, inverse kinematics, robotics, computer vision and the computation of equilibrium states of chemical reaction equations, etc. Science and engineering problems pose an increasing demand for solving larger and larger polynomial systems. To deal with such large systems, more computing resources are needed to greatly enlarge the capability of our solver, HOM4PS-2.0. For this purpose the parallelization of the original algorithms becomes inevitably essential. Computational technology is experiencing a major sea change in which one either rides the wave or goes under. To embrace this challenge, the core of the project is to fully incorporate the cutting-edge parallel computing technologies for solving larger and larger polynomial systems. The ultimate goal is a more powerful suite of high-quality software package which will provide the scientific community a reliable source for solving polynomial systems in practice."
"1115277","Complex Singularities in Numerical Analysis and Nonlinear Dynamics","DMS","COMPUTATIONAL MATHEMATICS","09/15/2011","09/15/2011","Divakar Viswanath","MI","Regents of the University of Michigan - Ann Arbor","Standard Grant","Junping Wang","08/31/2015","$264,998.00","","divakar@umich.edu","1109 GEDDES AVE, SUITE 3300","ANN ARBOR","MI","481091079","7347636438","MPS","1271","9263","$0.00","This project will investigate the precise analytic form of the complex singularities of<br/>the Lorenz system, the figure-eight solution of the three-body problem, and signals obtained<br/>from the Navier-Stokes boundary layer. Both analytic and numerical techniques<br/>will be used. Research on the Lorenz system has the aim of understanding the analytic<br/>continuation of the Lorenz solutions to the entire complex plane. With regard to the<br/>figure-eight solution, the project will show that the complex singularities of this system<br/>have an appealingly simple structure. The Navier-Stokes boundary layer has been<br/>studied primarily using techniques from spectral analysis. We will locate and elucidate<br/>singularities of the analytic continuation of the signal in the complex plane, and and<br/>obtain a measurement as well as an understanding of the time scales imposed by the<br/>outer flow.<br/><br/>This project endeavors to benefit the public in two respects. Firstly, we aim to obtain<br/>new insights into the Navier-Stokes boundary layer which is of immense importance in<br/>engineering and meteorology. As an example of its importance, we mention that a<br/>major part of the energy intake of automobiles is dissipated in the boundary layer.<br/>Secondly, we will write a new book that puts computer architecture at the heart of<br/>scientific computing. This book will introduce a style of scientific computing that is<br/>deeply informed by recent progress in computer architecture to a wider audience."
"1115384","Computational Theory and Methods for Solving Differential Multiple Solution Problems","DMS","COMPUTATIONAL MATHEMATICS","10/01/2011","09/15/2011","Jianxin Zhou","TX","Texas A&M Research Foundation","Standard Grant","Junping Wang","09/30/2014","$153,160.00","","jzhou@math.tamu.edu","400 HARVEY MITCHELL PKWY S STE 3","COLLEGE STATION","TX","778454375","9798626777","MPS","1271","9263","$0.00","The PI proposes to develop Computational Theory and Methods for Solving Multiple Solution Problems representing four types of natures: (1) a general problem, where a usual continuation transform used in a Newton continuation method fails to do so, a singular transform is proposed to solve an augmented problem for a New solution; (2) nonlinear eigen problems (NEP) in the nonlinear Schrodinger equation, a basic model in physics, for both focusing and defocusing cases, an implicit variational method is developed to solve NEP on its energy profile. After discovering their mathematical structure, new local maxmin methods are designed to solve the defocusing cases; (3) singularly perturbed problems from math biology and other reaction-diffusion systems for both focusing/defocusing cases, an adaptive local refinement method is developed to numerically solve the problem. (4) Steklov nonlinear boundary-value problems in corrosion engineering and scattering applications, a boundary integral equation approach is used to develop a local minmax/maxmin-boundary element method for finding multiple solutions. All the proposed problems have strong and wide application background but are not yet solvable in the literature. New methods will be developed by exploring the mathematical structure of the problems, deriving solution characterizations, implementation tests, convergence and instability analysis. The PI has conducted investigations on the projects. Preliminary analysis/numerical results are very promising. Due to its unprecedented and complex nature, the research in this proposal has to be creative and original; multi-disciplinary knowledge and collaboration on advanced nonlinear analysis, PDE, multi-level optimization, numerical algorithm design/implementation/analysis, are required.<br/><br/>Multiple (unstable) solutions to many systems have been observed and mathematically proved to have a variety of configurations, instability/maneuverability, but are not applicable with conventional technology. So traditional analysis/computation focus on stable solutions. Scientists are now able to induce and control unstable solutions with NEW advanced (synchrotron, laser, etc.) technologies and search for new applications for higher performance index, in particular, for MISSION CRITICAL SITUATIONS. So far people's knowledge on such solutions is still very limited and unstable solutions are too elusive to traditional numerical methods. The PI proposes to develop efficient/reliable numerical methods to solve such problems and establish their related math justification. The outcome of this proposal will (a) provide efficient/reliable numerical algorithms for people to use and promote new application; (b) lay a solid math foundation for solving such problems; (c) significantly enhance people?s knowledge on the nature and properties of such problems and can be used in computational math education due to their general setting. (d) The proposed projects provide an excellent opportunity for multi-disciplinary collaboration and to give Ph.D. students a balanced training on creative thinking, advanced analysis, numerical computation and problem solving. Three Ph.D. students are working the projects for their theses."
"1118756","Second Midwest Conference on Mathematical Methods for Images and Surfaces","DMS","COMPUTATIONAL MATHEMATICS","07/01/2011","06/22/2011","Guowei Wei","MI","Michigan State University","Standard Grant","Junping Wang","06/30/2012","$20,000.00","Yang Wang","wei@math.msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1271","7556, 9263","$0.00","This award provides support for a two-day Midwest Conference on Mathematical Methods for Images and Surfaces, to be held on August 27-28, 2011 on the campus of Michigan State University. This meeting was originally planned to bring together researchers of all career stages who work or are interested in mathematical methods for images and surfaces. However, after looking at the schedules and participants of many other conferences we feel that there is a strong need to reach out to researchers in their early careers, particularly in their training period. We have decided to make this conference one that focuses more on bringing together junior researchers.  We hope that this conference will serve as a venue for junior researchers to connect with one another and with a group of more senior researchers who have a track record of willingness to mentor junior faculties. Among invited 15 speakers, 6 are female, 11 are junior researchers (including PhD student who has done outstanding research work), and 5 are experts from molecular biology, computer science, mechanical engineering, physiology and radiology. This conference has no invited plenary speakers and all talks are of equal length, which provides an opportunity for young researchers to meet each other in a relaxed yet scientifically rigorous setting. The award will be used entirely for supporting graduate students, postdocs, junior faculty, and researchers from under-represented groups. The research areas represented at the conference span a diverse array of topics in mathematical images and surfaces. Example topics include but are not limited to level set methods, Mumford-Shah functional,  higher-order curvature flows, geometric flows for biomedical surface generations, differential geometry based multiscale modeling, partial differential equation transform, surface free energy minimization, wavelet and multiresolution analysis, compressed sensing, cellular imaging and cellular image analysis, biomedical imaging, molecular imaging, bioluminescence imaging,  fluorescent imaging, PET imaging,  ultrasound imaging, MRI, the analysis of protein, virus and membrane surfaces, image segmentation, computational anatomy, pattern recognition, machine learning, and video analysis and processing.  This conference will provide a forum to exchange new ideas and results in images and surfaces and foster interdisciplinary collaborations. Further information can be found at our conference web site: http://www.mth.msu.edu/MCMM2/index.html."
"1115572","Efficient Sructured Direct Solvers and Robust Structured Preconditioners for Large Linear Systems and Their Applications","DMS","COMPUTATIONAL MATHEMATICS","08/15/2011","06/27/2013","Jianlin Xia","IN","Purdue University","Continuing Grant","Junping Wang","07/31/2014","$65,000.00","","xiaj@purdue.edu","2550 NORTHWESTERN AVE STE 1900","WEST LAFAYETTE","IN","479061332","7654941055","MPS","1271","9263","$0.00","In this project, the investigator and his students design new efficient structured matrix techniques for large linear systems, including fast direct solvers and robust effective preconditioners. These techniques take advantage of certain hidden rank structures in linear systems arising from practical applications. Efficient multi-layer structures and flexible rank requirements are considered. The methods have nearly linear complexity for linear systems arising from the discretization of certain partial differential equations. They can also work as effective preconditioners. Robustness of preconditioning for positive definite problems is shown. The methods are useful for problems which have been considered difficult for classical direct or iterative solvers.<br/><br/>This project has broader impacts in many complex numerical problems and engineering simulations, such as differential equations, seismic imaging, climate, electromagnetic field simulation, signal processing, and integrated circuit simulation. The major computational work in these applications is often to solve large-scale linear systems, which can benefit from the efficient black-box solvers or preconditioners developed in this project. These methods help break some classical lower complexity bounds. Students are involved in all aspects of the project, and are trained in various mathematical and engineering areas. The investigator's team plan to build a freely available open source package for both practical applications and education. Minisymposia organized by the investigator, as well as conferences talks, seminars, and journal articles, are used to exchange ideas and to disseminate the results."
"1115453","Workshop on Verification and Validation in Computational Science","DMS","COMPUTATIONAL MATHEMATICS","08/01/2011","07/01/2011","Joseph Powers","IN","University of Notre Dame","Standard Grant","Junping Wang","07/31/2012","$20,000.00","Andrew Sommese","powers@nd.edu","940 Grace Hall","NOTRE DAME","IN","465565708","5746317432","MPS","1271","7556, 9263","$0.00","The proposed workshop will bring together participants from applied mathematics and a wide range of computational science disciplines, mostly concerned with the solution of nonlinear partial differential equations (PDEs), for the purpose of sharing their expertise, techniques, and problematical issues with participants of similar basic interest but differing application areas. Five keynote speakers from diverse disciplines have accepted invitations to speak, with application fields of bioengineering, autonomous vehicle dynamics, computational mechanics, aerodynamics, and physics. Specific areas where applied mathematics plays a strong role will be elicited, including multiscale and multiphysics problems, single-grid error estimators with practical metrics for nonlinear problems and uncertainty quantification. Participation by applied mathematicians, graduate students, post-doctoral researchers, young faculty, and under-represented groups will be encouraged through the application of NSF funds towards travel <br/>grants.  <br/><br/>The intellectual merit of the work is embodied in its addressing a fundamentally challenging topic:  how to capture complicated multiscale phenomena with computational tools in a fashion which respects both the underlying mathematics as well as experimental observation.  For non-linear multiscale problems, these answers are not easy; however, their understanding is critical in areas of importance to the nation where rigorous predictive tools are now being used.  Specific examples include flood and storm surge dynamics, groundwater contaminant flow, human blood circulation response to surgical interventions, combustion and fire safety, response of civilian infrastructure such as bridges and roads to stimuli, as well as a variety of aerospace applications.  The workshop will bring together some of the world's leading experts in a diverse set of fields in the physical, mathematical, and computational sciences.  The broader impacts of the Workshop are clear as well. Since decision-makers and leaders, and thus society at large, are relying more and more on computational methods to aid in decision-making process, it is in the interest of all that the predictions of these methods can be used with confidence by non-experts.  The Workshop will raise awareness in a variety of key scientific communities of some of the critical issues and methods for verification and validation.  Additionally, the Workshop will seek participation from a broad range of the scientific community by making available NSF-supported travel grants to members of under-represented groups."
"1115734","Parallel Preconditioned Eigenvalue and Singular Value Solvers","DMS","COMPUTATIONAL MATHEMATICS","08/15/2011","06/27/2013","Andrew Knyazev","CO","University of Colorado at Denver-Downtown Campus","Continuing Grant","Junping Wang","07/31/2014","$180,000.00","Julien Langou","Andrew.Knyazev@ucdenver.edu","1380 LAWRENCE ST STE 300","DENVER","CO","802042055","3037240090","MPS","1271","9263","$0.00","This award, from the computational mathematics program of the Division of Mathematical Sciences, supports the research of the principal investigator, which covers a balanced mix of theoretical investigations, software support and development, and advances for modern applications. The research focuses on design of new efficient robust parallel preconditioned methods for interior eigenvalue and singular value computations. The main emphasis is on the following challenging issues: investigating availability and efficiency of preconditioning; avoiding the folded spectrum approach, analyzing the possibility of computing the singular values of an operator using preconditioning; and establishing convergence theory for novel iterative solvers. For the latter, a novel application of classical majorization theory permits analysis of the convergence behavior of block eigenvalue and singular value solvers. This work is also relevant for applications; the singular vectors, corresponding to the largest singular values of a matrix are used for performing the principal component analysis of data described by a data matrix. Here the focus is on multi-dimensional image segmentation.<br/><br/><br/>The topic of this research is motivated by the fact that the class of problems under consideration describes many phenomena in physics and mechanics, and for practical calculations may require extreme computational power. Advances in the computational approaches can provide noticeable improvements in the accuracy and efficiency of calculations. Implementing the developments in publicly available software enhances the potential for significant broader impact, due to the relevance of the software for a large range of applications. The application specifically targeted by the PI is image segmentation, such as occurs in tracking moving objects in videos. Additional impact of the project is on graduate student training. The research of the PI provides an opportunity to train students in important computational research motivated by real practical applications."
"1114901","Computational Methods for Inverting the Soft X-Ray Transform","DMS","COMPUTATIONAL MATHEMATICS","07/01/2011","05/23/2013","Gabor Herman","NY","CUNY Graduate School University Center","Continuing Grant","Junping Wang","09/30/2014","$239,992.00","","gabortherman@yahoo.com","365 5TH AVE STE 8113","NEW YORK","NY","100164309","2128177526","MPS","1271","9263","$0.00","The aim of this project is the mathematical development, computational <br/>implementation, testing and evaluation of procedures for inverting the soft x-ray <br/>transform, which has arisen recently from experimental cellular biology, but has <br/>not previously been subjected to a rigorous treatment from the computational <br/>mathematics point of view. The soft x-ray transform is the appropriate mathematical <br/>model for the physical process by which two-dimensional projections are <br/>acquired in soft x-ray microscopy (SXM), which has the unique capability of <br/>imaging whole cells in their native environment with high resolution. The proposed<br/>novel computational methods for inverting this accurate image formation <br/>model for SXM are designed to improve the resolution in the reconstructions of the <br/>three-dimensional (3D) structures from their SXM projections.  It is conjectured <br/>that such a treatment will result in improved accuracy and usefulness as <br/>compared to the currently used heuristic procedures. <br/><br/>In many areas of biology, the understanding of a 3D structure provides a way <br/>of understanding its function. Many structures, such as single molecules, <br/>viruses, cells, etc., are too small to be viewed with the naked eye. <br/>Microscopy has been providing images with information about<br/>details of these structures. However, unprocessed microscopic images <br/>present structures that are superimposed over each other, making<br/>them hard to interpret. Combining multiple images from different directions <br/>of the same structure by techniques of 3D reconstruction allows accurate <br/>visualization of such structures. The understanding of 3D shapes of <br/>structures is important in many biomedical areas, for example, in drug <br/>design. Of the many approaches to unraveling 3D biological structures, <br/>soft X-ray microscopy (SXM) has the unique capability of providing <br/>high-resolution details of subcellular 3D structures in their native environment, <br/>i.e., the whole cell. Such currently-unavailable structural information will be <br/>important for understanding many biological processes. An example is <br/>mitochondrial dysfunction as it occurs in human diseases, understanding <br/>of which is important for assessing cardiovascular and nervous <br/>system function in mitochondrial disorders."
"1115627","Multispectral Tomosynthesis Imaging: Mathematical Models, Algorithms and Software","DMS","COMPUTATIONAL MATHEMATICS, COFFES","09/15/2011","09/15/2011","James Nagy","GA","Emory University","Standard Grant","Junping Wang","08/31/2014","$270,000.00","Ioannis Sechopoulos","jnagy@emory.edu","201 DOWMAN DR","ATLANTA","GA","303221061","4047272503","MPS","1271, 7552","7552, 9263","$0.00","This project focuses on the development of computational methods for<br/>tomosynthesis breast image reconstruction, a technique used to<br/>reconstruct 3-dimensional images using slightly modified versions of<br/>conventional x-ray systems. The mathematical models addressed in this<br/>project are difficult ill-posed inverse problems; computed solutions<br/>are very sensitive to errors in the data, and implementation for large<br/>scale 3-dimensional images is nontrivial.  All previous breast<br/>tomosynthesis image reconstruction algorithms use a simplified, but<br/>incorrect assumption that the source x-ray beam is comprised of<br/>photons with a constant energy; that is, the x-ray beam is assumed to<br/>be monoenergetic.  The simplified monoenergetic assumption results in<br/>a linear mathematical model.  This project uses the physically<br/>correct, and hence more accurate, assumption that the x-ray beam is<br/>polyenergetic.  The resulting mathematical model is nonlinear,<br/>providing great challenges to the development and analysis of<br/>mathematical models, as well as for the development of computational<br/>methods.  However, as this project reveals, the nonlinear model allows<br/>for reconstructing images with substantially fewer artifacts than the<br/>linear model.  Moreover, the nonlinear model can incorporate<br/>parameterizations to allow for explicit decomposition of the breast<br/>into distinct materials, such as, glandular tissue, adipose tissue,<br/>calcifications, and iodinated contrast agents, thereby providing<br/>improved diagnostic information.<br/><br/>In the US, over 200,000 women are diagnosed with breast cancer every<br/>year, but there is a 97% five-year survival rate if the cancer is<br/>localized, and if it is discovered before it spreads to other parts of<br/>the body.  Therefore, improved imaging techniques that help to detect<br/>and diagnose breast cancer early can have a profound impact on the<br/>healthcare of women.  The research in this project focuses on<br/>tomosynthesis imaging, which just received FDA approval for clinical<br/>use in 2011, because it has the potential to provide substantially<br/>better screening capabilities than mammography. The new mathematical<br/>and computational approaches developed in this work are designed to<br/>unlock the potentially transformative benefits of tomosynthesis for<br/>breast cancer screening, providing significantly better diagnostic<br/>information to physicians.  In addition to its application to breast<br/>cancer screening, tomosynthesis, in its whole-body implementation can<br/>be used for many other applications where standard x-ray and CT are<br/>used, such as chest imaging for detection of lung nodules, as well as<br/>non-medical imaging applications such as nuclear waste inspections and<br/>explosive detection.  Thus, advances in computational methods for this<br/>application can have a very broad impact in the imaging field.<br/>Collaborations between researchers in Mathematics and Computer Science<br/>and researchers in the Department of Radiology and Imaging Sciences<br/>and Winship Cancer Institute at Emory University facilitates<br/>transitioning new software to clinical use."
"1115692","Numerical Linear Algebra Tools for the Analysis of Complex Networks","DMS","COMPUTATIONAL MATHEMATICS","08/01/2011","06/30/2011","Michele Benzi","GA","Emory University","Standard Grant","Junping Wang","05/31/2015","$303,046.00","","mbenzi@emory.edu","201 DOWMAN DR","ATLANTA","GA","303221061","4047272503","MPS","1271","9263","$0.00","This project concerns the development, analysis and application<br/>of numerical linear algebra tools for the quantitative study of<br/>important properties of large-scale complex networks, such as<br/>centrality, betweenness and communicability measures. Specifically,<br/>the investigator and his collaborators study efficient algorithms<br/>for the fast approximation of the entries of matrix functions<br/>such as the exponential and the resolvent of adjacency matrices<br/>and graph Laplacians, as well as their traces. While these<br/>matrices are quite sparse, in the case of complex networks<br/>they behave very differently from the matrices associated with<br/>regular lattices (grids), such as those arising from discretizations<br/>of partial differential equations. Hence, there is a need to<br/>develop new methods, both computational and analytical, to deal<br/>with these very large-scale problems. The investigator brings<br/>together expertise in classical numerical analysis and approximation<br/>theory, as well as methods from spectral graph theory and modern<br/>network analysis, to enable efficient computations involving large<br/>graphs. Potential applications include the analysis of social networks,<br/>the study of biological and neurological networks, applications in physics<br/>and operations research, and so forth.<br/><br/><br/>Over the last decade or so, the emerging field of network science<br/>has had a profound influence on such different domains as physics,<br/>chemistry, biology, operations research, engineering and the social<br/>sciences. A deep understanding of network structure and dynamics is<br/>of great importance also for Homeland Security and for many businesses,<br/>including financial institutions and e-commerce. Detailed, quantitative<br/>models of massive and complex networks are now pervasive owing to the unprecedented availability of data on just about any conceivable topic. Extracting useful information from these massive data sets and networks requires fast and accurate algorithms. Such algorithms can be used, for instance, to rank the `importance' of elements of a network, i.e., to determine which nodes are essential for the proper functioning of a network. They are also used to determine bottlenecks in a network, and critical connections in a graph. The importance of these notions for crucial parts of the infrastructure of a country, such as power or transportation grids,<br/>cannot be overstated. The investigator and his collaborators develop fast computer techniques to solve these and related problems."
"1115291","Development and applications of the finite element exterior calculus","DMS","TOPOLOGY, COMPUTATIONAL MATHEMATICS","07/15/2011","05/21/2014","Douglas Arnold","MN","University of Minnesota-Twin Cities","Continuing Grant","Junping Wang","06/30/2015","$452,821.00","","arnold@umn.edu","200 OAK ST SE","MINNEAPOLIS","MN","554552009","6126245599","MPS","1267, 1271","9263","$0.00","This project will develop, extend, and apply the finite element exterior calculus, a new approach to the design and validation of stable finite element methods for a variety of partial differential equations.  Finite element exterior calculus brings tools from geometry, topology, and functional analysis to provides both algorithms and supporting theory which can form the foundation on which progress can be made on solving crucial problems in computational science.  Although developed only recently, finite element exterior calculus has already been adopted by many researchers and has enabled the development of robust and accurate numerical methods for important applications.  A major direction of research which will be pursued is the development of the finite element exterior calculus of time-dependent problems. For this, the Hodge heat equation and the Hodge wave equation will serve as the basic model problems, and Maxwell's equations of electromagnetism and the equations of elastodynamics are two of the numerous applications.  Another important direction is the development of spaces and complexes of finite element differential forms on cubical meshes and the study of the approximation properties of such spaces when the elements of the mesh are distorted. The proposer will also study the application of the finite element exterior calculus to solving the Einstein equations, which are the fundamental equations of general relativity.<br/><br/>Computer simulation of physical systems coming from solid mechanics, fluid dynamics, electromagnetism, and other areas, are applied in countless ways every day in problems as varied as the design of aircraft, the prediction of climate, and the development of cardiac devices.  Once a physical system has been modeled by a system of mathematical equations, successful simulation depends not only on powerful computer hardware but also on mathematical algorithms that can harness the computer's high speed number-crunching to obtain accurate solutions of model's equations. While such algorithms exist for many important equations, and moreover have been certified by mathematical analysis so we can have confidence in the results, there are many other problems for which accurate and certifiable algorithms are yet to be discovered. This proposal focuses on a new approach to the development and analysis of computational algorithsm for simulation that has in recent years achieved great success for simulations involving the deformation of solid materials, like auto bodies or construction beams.  A primary goal of this project is to increase the range of systems which can be simulated accurately and confidently."
"1115856","A Stochastic Multiscale Computational Framework for Multiphysics Systems","DMS","COMPUTATIONAL MATHEMATICS","10/01/2011","09/14/2011","Ivan Yotov","PA","University of Pittsburgh","Standard Grant","Junping Wang","09/30/2014","$239,998.00","","yotov@math.pitt.edu","4200 FIFTH AVENUE","PITTSBURGH","PA","152600001","4126247400","MPS","1271","7569, 9263","$0.00","The primary objective of this project is to develop a stochastic multiscale computational framework for modeling multiphysics systems arising in science and engineering applications with multiscale and uncertain input parameters.  The mathematical models involve transient Stokes-Darcy systems coupled with systems of reaction-advection-diffusion equations. A multiblock domain decomposition methodology provides robust and efficient multiphysics and multinumerics couplings. The simulation domain is decomposed into a union of subdomains, each one associated with a physical, mathematical, and numerical model. Physically consistent interface conditions are imposed using mortar finite elements. Coarse scale mortar spaces lead to efficient and accurate multiscale approximations. Stochastic partial differential equations are employed to model uncertainty in the physical parameters. Sparse collocation methods are used for approximations in probability space. The project will investigate 1) mathematically rigorous and physically meaningful multiphysics models; 2) robust, accurate and efficient multiscale physical space and stochastic space discretization techniques; 3) a posteriori error estimates for adapting the models, the numerical grids in physical space, and the set of collocation points in stochastic space; 4) multiscale stochastic-based data assimilation and parameter estimation algorithms; 5) multiscale parallel domain decomposition solvers and preconditioners.<br/><br/>The work will emphasize computational modeling of energy and environment applications, in particular coupling of surface water with groundwater in hydrological systems, as well as biomedical applications such as modeling the inflammatory response in the human body. Both types of systems involve complex interactions of different physical processes and exhibit variability and uncertainty in the input parameters on a wide range of spatial and temporal scales. Computational modeling of coupled subsurface and surface flows and transport can provide reliable and cost effective predictions in contaminant remediation of rivers, lakes, wetlands, and aquifers. Inflammation plays a major role in the response of the human body to trauma, infection, or various diseases. Mathematical and computational modeling of these very complex processes can provide better understanding of their dynamics and spatial characteristics and may lead to the design of more effective treatments."
"1158839","Novel Numerical Methods for Partial Differential Equations with Low-regularity Data","DMS","COMPUTATIONAL MATHEMATICS","09/01/2011","06/11/2012","Hengguang Li","MI","Wayne State University","Standard Grant","Junping Wang","08/31/2015","$60,066.00","","li@wayne.edu","5700 CASS AVE STE 4900","DETROIT","MI","482023692","3135772424","MPS","1271","9263","$0.00","Elliptic partial differential equations (PDEs) with low-regularity data (i.e., singular solutions and low-regularity coefficients) frequently appear in mathematical models from diverse scientific disciplines. These equations in general present a multiscale character, which increases the complexity of the problem and poses numerous challenges on the finite element approximation and on the design of multigrid schemes. Despite continuous developments from the computational community, some fundamental questions still remain open. Addressing major issues in both theoretical analysis and practical implementation, this proposal aims at a systematic investigation on various aspects of the finite element method (FEM) and multigrid (MG) methods solving elliptic PDEs with low-regularity data, with a wide range from the theoretical estimates of PDEs to the development of state-of-the-art numerical algorithms. In particular, the proposed research consists of two major components: 1) the optimal FEMs for singular solutions, including (I) the establishment of a unified framework for the analysis of a wide variety of singular solutions in weighted Sobolev spaces and(II) the development and implementation of effective grading algorithms to improve the accuracy of the numerical solution approximating these singular solutions; 2) the MG theory for axisymmetric problems, including the estimation of basic MG cycles for the axisymmetric Laplace operator and the design of new smoothers for the axisymmetric Stokes problem in weighted spaces. The proposed research will produce new a priori results (e.g., the well-posedness and regularity) for various singular solutions in weighted spaces, unitize the full potential of graded meshing techniques for singular solutions, expand the scope of the MG theory on axisymmetric equations, and foster innovative ideas on solving PDEs with broader applications. <br/><br/>The proposed research has many applications in various fileds of science and engineering. A class of singular solutions of elliptic PDEs are from the non-smoothness of the computational domain and the non-smoothness of the interface in transmission problems. The study on these singularities shall produce effective numerical algorithms solving problems in aerospace engineering (aircraft design), in mechanical engineering (crack propagation), and in elastography of medical imagining (modeling different levels of stiffness in human tissues). The research on singular solutions from the singular coefficients shall provide new theoretical results and modern finite element techniques to tackle Schroedinger equations with various singular potentials in quantum mechanics. In addition, the MG analysis on axisymmetric models shall lead to a more complete MG theory in singular spaces and in turn bring new fast numerical solvers for these equations that are frequently used in fluids and i  n electromagnetic fields. These are the fields that have profound impact on national security, development of new energy, and novel medical research. Results from this project will be disseminated through collaboration with other scholars, publication of peer-reviewed articles, and presentations at professional meetings. With the development of a software package, the PI also expects to design a project-oriented course on the finite element method for senior undergraduate/graduate students in math and engineering, which will equip the students with a better understanding on the algorithm and a valuable programming experience."
"1115317","Computational Methods for Parameter-Dependent Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","08/01/2011","07/11/2011","Howard Elman","MD","University of Maryland, College Park","Standard Grant","Junping Wang","07/31/2014","$210,000.00","","elman@cs.umd.edu","3112 LEE BLDG 7809 REGENTS DR","College Park","MD","207420001","3014056269","MPS","1271","9263","$0.00","Modern numerical simulation using models based on partial differential equations is characterized by high dimensionality together with parameter dependence.  High dimensionality is required to achieve accuracy in discrete approximations, especially for three-dimensional or multi-component models. Parameter dependence stems from a variety of sources.  Parameters may correspond to time or to specific terms such as Reynolds numbers in fluids, for which the properties of solutions are wanted at a variety of parameter choices. Alternatively, they may be used to specify components of a model such as material properties, geometry, or boundary conditions, for which it is desired to perform multiple simulations.  These same sets of parameters may instead be uncertain and treated as random variables, for which simulations are used to identify statistical properties of solutions.  All these scenarios require the computation of many discrete solutions, which may be prohibitively expensive when the discrete models are large in scale.  Our aim in this project is to explore, develop and refine computational algorithms to reduce these costs.  Our emphasis will be on effective use of reduced basis methods, which project high-dimensional models into subspaces of significantly smaller dimension with the aim of quickly and efficiently constructing accurate approximate solutions over a wide range of parameters.<br/><br/>The potential impact of this approach lies in its use in wide varieties of engineering and scientific simulations. These include models of groundwater flows and other environmental phenomena, where uncertain properties such as boundary conditions or permeabilities of media in which fluids are found are treated as parameters; aerodynamic simulations, where material properties of structures or qualities of combustible material are parameters that must be analyzed for their effects on efficiency and safety; and in models of biological processes, for example blood flows or chemical reactions in cells, which depend on parameters such as fluid viscosity or reaction rates.  The development of efficient algorithmic strategies based on reduction of problem size will significantly enhance the prospects of performing such simulations quickly, enabling engineers and scientists to use the results of simulations in the field and for real-time decision making."
"1115698","A new approximation for effective Hamiltonians","DMS","COMPUTATIONAL MATHEMATICS","10/01/2011","08/12/2013","Hong-Kai Zhao","CA","University of California-Irvine","Continuing Grant","Leland Jameson","09/30/2015","$298,511.00","","zhao@math.duke.edu","160 ALDRICH HALL","IRVINE","CA","926970001","9498247295","MPS","1271","9263","$0.00","Hamilton-Jacobi equations are nonlinear hyperbolic partial differential equation for which classical solution does not exist in general. Appropriate weak solution, the viscosity solution, has to be defined. Hence traditional homogenization techniques based on asymptotic expansion and assumption of regularity do not work. Both mathematical theory and numerical method for homogenization of nonlinear problem is far from adequate. Currently the homogenization of Hamilton-Jacobi  equation is through the definition of a cell problem for each momentum variable. Hence many cell problems have to be solved. The key motivation of this study is a new formulation proposed by the PI and his collaborators that links the effective Hamiltonian to a suitable effective equation. The main advantage of this formulation is that only one auxiliary equation needs to be solved in order to compute the effective Hamiltonian for all momentum variables. Furthermore, the effective equation in our formulation is a standard Hamilton-Jacobi equation with boundary value for which many efficient numerical algorithms are available. <br/><br/>Hamilton-Jacobi equations have many important applications in classical mechanics, dynamical systems, optimal control, geophysics, geometric optics, combustion and image processing. For many applications the corresponding Hamiltonians may have multiple scales, such as oscillatory potential in classical mechanics or fluctuating velocity field in front propagation. In this project the PI proposes a new formulation to study homogenization of a class of Hamilton-Jacobi equations and develop efficient numerical algorithms for computing the corresponding effective Hamiltonians. Results coming from this project will provide important mathematical foundation and efficient numerical methods for many applications in science and engineering. In addition integration with education at different levels will be designed. Supervised research projects and seminars related to the proposed research will be available to junior/senior undergraduates and graduates."
"1115961","Theory,  Algorithm and Appliction for H(curl) and H(div) Problems","DMS","COMPUTATIONAL MATHEMATICS","10/01/2011","09/15/2011","Long Chen","CA","University of California-Irvine","Standard Grant","Leland Jameson","09/30/2014","$179,987.00","","chenlong@math.uci.edu","160 ALDRICH HALL","IRVINE","CA","926970001","9498247295","MPS","1271","7569, 9263","$0.00","This proposal is on the study of advanced numerical methods for partial differential equations that involve curl and div differential operators such as Maxwell's equations and linear elasticity. The theme of research is on the development, application, and analysis of multilevel adaptive finite element methods.  The proposal consists of three parts. The first part focus on the theoretical investigation of Adaptive Finite Element Methods (AFEM) applied to H(curl) and H(div) problems. The PI propose to establish a complete convergence theory of AFEM for H(curl) and H(div) problems including definite and indefinite Maxwell's equations and mixed methods for linear elasticity, and to develop a framework to analyze local multigrid methods on adaptive grids with minimal regularity assumption. The second part is on the algorithmic development for H(curl) and H(div) problems.  The PI plans to combine Newton's iteration and two-grid methods to develop a fast two-grid method for computing H(curl) and H(div) eigenvalue problems. Another algorithmic development is on a coupling method of finite volume method and finite element method for linear elasticity problems. The third part concentrates on the simulation of cloaking device. The theories and algorithms studied in the first two parts will be applied to simulate approximate cloaking models of electromagnetic waves. The PI propose to use AFEM, multigrid, and high order edge elements to develop a software package which could provide more insight on the design of electromagnetic materials.<br/><br/>The multilevel adaptive methods developed and studied in this work are expected to have a broader impact on the numerical solutions of a large class of practical problems. Special target applications are Maxwell's equations and simulation of cloaking device.s Maxwell's equations describing the evolution of electromagnetic fields in material media have a wide range of practical applications such as design of antenna, microwave, circuits, electromagnetic scattering, and wireless technologies. The transformation optics allows for the design of electromagnetic materials that steer light around a hidden region, returning it to its original path on the far side. As a result, the contents of the hidden region, such as a helicopter, tank or ship, disappears from view. The cloaks show promise and could one day serve as protective shields or improve wireless communications by making signal-blocking obstacles ""disappear."" Our numerical simulation can provide insight on the design of such new materials. In addition, a fully integrated involvement in undergraduate and graduate computational mathematics education is an integral part of the project. By including code into the software package iFEM, the PI will be able to improve a project-oriented course on adaptive finite element methods for better education and training of the next generation of computational mathematicians."
"1115408","Approximation of Infinite Dimensional Dynamics","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","10/01/2011","06/15/2014","Erik Van Vleck","KS","University of Kansas Center for Research Inc","Standard Grant","Junping Wang","09/30/2015","$226,332.00","","erikvv@ku.edu","2385 IRVING HILL RD","LAWRENCE","KS","660457552","7858643441","MPS","1266, 1271","9150, 9251, 9263","$0.00","In many areas of science and engineering differential equations are employed as<br/>models of complex phenomena. The focus in this proposal is on the approximation<br/>of solutions of infinite dimensional dynamical systems. In particular, the investigator<br/>and his colleagues are interested in understanding the dynamics of the finite dimensional <br/>approximations and how they relate to the dynamics of the original dynamical system. <br/>The specific issues to be investigated are related to stability of solutions of spatially <br/>discrete reaction-diffusion equations, the dynamics of so-called anti-diffusion lattice <br/>differential equations, dynamics and computation of traveling waves for neutral mixed <br/>type functional differential equations and rigorous computation of periodic orbits <br/>for retarded delay equations, robust stability for time dependent linear Hamiltonian systems, <br/>numerical techniques for efficient computation of Lyapunov exponent like quantities based <br/>upon nonlinear flows, and approximation techniques for stability spectra of delay equations <br/>and partial differential equations. Techniques to investigate these systems combine <br/>numerical analysis and dynamical systems ideas to gain a better understanding of <br/>approximation dynamics. <br/><br/>Often in complex systems the differential equations used in modeling are infinite <br/>dimensional, but necessarily these models are approximated by finite dimensional <br/>systems in order to perform numerical simulations. In order to understand the behavior of <br/>these models, the investigator and his colleagues are interested in similarities <br/>and differences in the behavior of the original infinite dimensional system and <br/>finite dimensional approximations, for example those obtained through discretization. <br/>Understanding the impact of discretization leads to greater confidence when <br/>making inferences from simulation results. In addition, stability analysis is useful <br/>in understanding the robustness of complex biological phenomena that occur in the <br/>environment and in identifying instabilities, for example, in models of weather prediction. <br/>Discrete models of both biological and physical processes are becoming more important as <br/>the need for detailed, microscopic models increases and should benefit from improved <br/>analysis and computational capabilities."
"1115118","Topics in anisotropic mesh adaptation and application to anisotropic diffusion problems","DMS","COMPUTATIONAL MATHEMATICS","09/15/2011","09/12/2011","Weizhang Huang","KS","University of Kansas Center for Research Inc","Standard Grant","Junping Wang","08/31/2015","$180,000.00","","whuang@ku.edu","2385 IRVING HILL RD","LAWRENCE","KS","660457552","7858643441","MPS","1271","7569, 9150, 9263","$0.00","The investigator will study anisotropic mesh adaptation for use in the numerical solution of partialdifferential equations. The studies will be based on a so-called M-uniform mesh approach of anisotropic mesh adaptation where any nonuniform mesh is generated as a uniform one in the metric specified by a tensor. Success has been made with the approach in facilitating a better understanding of existing algorithms and in developing new methods. A specific application area is the numerical solution of anisotropic diffusion problems. New mesh conditions and metric tensors for use in mesh generation have been developed with the approach so that finite element approximations to a class of anisotropic diffusion problems satisfy a discrete maximum principle and exhibit no spurious oscillations and artifacts. The research topics will include the extension of the existing theory to three dimensional problems and time dependent problems and the development of a posteriori anisotropic error estimates and metric tensors.<br/><br/>The project is concerned with the development of efficient and reliable methods for the numerical solution of anisotropic diffusion problems and other problems exhibiting anisotropic features. Those problems arise from several application areas including plasma physics (fusion experiments and astrophysics), groundwater contamination modeling, petroleum reservoir simulation, image processing, and global  climate simulation that are crucial to our national's economy, environment, and security. Unfortunately, standard numerical methods often produce spurious oscillations and artifacts and introduce excessive numerical dissipation in the numerical solution due to the highly anisotropy and heterogeneous nature of diffusion in those problems. In this project, anisotropic mesh adaptation will be employed to overcome these difficulties. It is a type of mesh adaptation that allows the size, shape, and orientation of mesh elements to change throughout the physical domain. The investigator has demonstrated in his work that a linear finite element solution can be made to satisfy the maximum principle and thus contains no spurious oscillations when a properly chosen anisotropic mesh is used. In-depth studies of anisotropic mesh adaptation will be carried out along this line in the project.  Maximum-principle preserving schemes will be developed for time dependent problems and three dimensional problems and their application to anisotropic diffusion problems will be investigated. The studies will lead to a better understanding of anisotropic mesh adaptation and provide a useful tool for the numerical simulation of application problems, including anisotropic diffusion problems which have many important applications."
"1115759","Numerical methods for linear and nonlinear implicit PDE simulation ---- Domain Decomposition and Nonlinear Multigrid Methods","DMS","COMPUTATIONAL MATHEMATICS","09/01/2011","06/27/2011","Xuemin Tu","KS","University of Kansas Center for Research Inc","Standard Grant","Junping Wang","08/31/2015","$79,368.00","","xtu@math.ku.edu","2385 IRVING HILL RD","LAWRENCE","KS","660457552","7858643441","MPS","1271","9150, 9263","$0.00","This project combines mathematical analysis and numerical algorithm design for the solution of linear and nonlinear partial differential equations (PDEs). Algorithms will be incorporated in the scientific software library PETSc which is widely used in the scientific community for physical modeling. These algorithms are bscalable, and easily parallelizable, and thus useful for large scale multidisciplinary simulations. Additionally the PI's research  provides a solid theoretical support for the algorithms.<br/> The PI's research promises to have a major impact in several areas: computational fluid dynamics, material sciences, and acoustic scattering. The PI and her collaborators plan to publish archival articles on the new algorithms and also present  results in conferences. Graduate students at the University of Kansas are impacted through the PI's plans to incorporate research results into her graduate level class on numerical methods. This course is available to a broad group of students from mathematical and engineering departments."
"1211635","Novel mixed and DG methods","DMS","COMPUTATIONAL MATHEMATICS","11/18/2011","04/24/2012","Jay Gopalakrishnan","OR","Portland State University","Standard Grant","Junping Wang","10/31/2013","$161,185.00","","gjay@pdx.edu","1600 SW 4TH AVE","PORTLAND","OR","972015522","5037259900","MPS","1271","6863, 9263","$0.00","Ever increasing demands on computational solution techniques necessitate development of new and improved methods.  Two classes of methods, increasingly being used in simulation of physical and engineering systems, are finite element methods of the mixed type and the discontinuous Galerkin (DG) type.  Building sound mathematical foundations for these methods increases their reliability, reveals avenues to improve them, and helps discover radically new methods.  In this spirit, five lines of research are proposed on the following topics: (i) mixed methods (ii) discontinuous Petrov-Galerkin (DPG) schemes(iii) hybridizable discontinuous Galerkin (HDG) methods (iv) simulation of photonic membranes, and (v) complex axisymmetric simulations. The first deals with new stress elements and their implications in mixed methods for elasticity with weakly imposed stress symmetry. The second pursues a new DPG paradigm in the design of schemes where optimal test spaces are automatically computed. The third, concerns DG methods that mimic mixed methods, yet having the added advantage of flexible stabilization, and continues a line of research previously supported by the foundation. Both source problems and eigenproblems are considered.  The remaining two lines of research, considers applications in need of new mathematical developments, e.g., (iv) needs good nonlinear eigensolvers and (v) needs sound treatment of singularities.<br/><br/>Methods for computer simulation are an indispensable tool in modern scientific research.  The proposed research brings fresh mathematical ingredients that spawn novel simulation methods. These mathematical techniques have the advantage of being broadly applicable. Accordingly, several disparate application areas can be targeted, including solid mechanics, transport phenomena, fluid flow, wave propagation, triggered lightning, and nanophotonic membranes. To detail a few examples, application of the new methods to fluid flow, through industrial and academic collaborations, can potentially benefit the aircraft industry.  Reliable simulation methods can inexpensively guide experimentation of next generation nanophotonic devices.  Finally, human resource development is integrated into the activities through training and participation of graduate students in the research."
"1115631","Collaborative Research: Higher-Order Two-Fluid Methods for Simulations of Particle-Laden Flow","DMS","COMPUTATIONAL MATHEMATICS","09/01/2011","08/17/2011","Babak Shotorban","AL","University of Alabama in Huntsville","Standard Grant","Leland Jameson","08/31/2014","$30,103.00","","babak.shotorban@uah.edu","301 SPARKMAN DR NW","HUNTSVILLE","AL","358051911","2568242657","MPS","1271","9150, 9263","$0.00","In this effort the PIs and their student develop a high-order two-fluid method based on a new set of coupled two-fluid hyperbolic conservation PDEs and a Hybrid WENO-spectral method. The two-fluid model is unprecedented, obtained from first principles utilizing an Eulerian approach for the description of particles, which have been predominantly modeled through lower-order methods in the Lagrangian frame of the particle. In the Eulerian frame, the particle phase is modeled through a set of hyperbolic Eulerian transport equations governing the behavior of the Probability Density Function of particle properties. The equations are derived by a novel statistical method based on a method of moments via an averaged Liouville equation. The PIs propose to develop a method based on a high-order resolution, hybrid multidomain WENO-spectral method for the two-fluid model. The high- resolution method is projected to improve over existing lower- order method by capturing discontinuous interfaces and shocks sharply, while accurately resolving small scale, unsteady particle-laden flow features.  The focus of this proposal is on the development of a stable and consistent capturing of discontinuous particle-gas interfaces as well as a stable and consistent source coupling between the particle and gas phases. Another focus will be on the regularization of non- linear, singular and stiff source terms that couple the gas and particle PDEs. The two-fluid method will be assessed against published benchmarks, including a one-way coupled isotropic turbulence and two-way coupled shock particle interaction, computed with a more established Eulerian- Lagrangian method.<br/><br/>Explosions and combustion processes generate environments where fluid turbulence and shocks have an intimate and mutual interaction with particles. Various engineered systems and natural processes involve high speed particle dynamics, shock- turbulence interaction, and particle flow interactions; such phenomena play key roles in debris flow and contaminant spread due to explosions, controlling supersonic combustion, high- speed coating processes for high-performance aerospace and electronic components. The volcanic explosions in Iceland, for example, generated shocks, accelerated turbulent gas flows and micro-scale dust particles that were carried for hundreds of miles over several days not only polluting the environment but affecting air traffic for an extended period of time. The proposed research develops an advanced numerical tool that enables (improved) computation of these flows which will ultimately enhance understanding of a large class of engineering and environmental problems. This knowledge can be used directly in design improvements, control of pollution and the effects of explosion processes on society. This proposal, moreover, increases the number of students from underrepresented groups in STEM education by involving students in the Mathematics, Engineering, Science Achievement (MESA) program at SDSU."
"1115574","Collaborative Research:  Inversion of the Broken-Ray Radon Transform and Applications","DMS","COMPUTATIONAL MATHEMATICS","07/01/2011","07/01/2011","John Schotland","MI","Regents of the University of Michigan - Ann Arbor","Standard Grant","Junping Wang","06/30/2015","$212,108.00","","john.schotland@yale.edu","1109 GEDDES AVE, SUITE 3300","ANN ARBOR","MI","481091079","7347636438","MPS","1271","9263","$0.00","This project assembles a team of applied and computational mathematicians and physicists to develop, analyze and implement reconstruction algorithms for the broken-ray Radon transform (BRT) and its generalizations. The BRT describes the propagation of single-scattered particles or waves. This situation is typical of x-ray imaging at clinical energies or optical imaging of nearly transparent tissues and model organisms. The intent of the proposed research is to provide theoretically, numerically justified and practically applicable reconstruction algorithms for the BRT with applications to both x-ray computed tomography and optical tomography in the weak-scattering regime. In particular, the investigators propose to derive and analyze BRT-based scanning protocols and corresponding inversion techniques to reconstruct the absorption and scattering coefficients. Associated scanning protocols, which provide the optimum balance between spatial resolution and stability to noise, are to be developed. In addition, questions of uniqueness and stability (in the scale of Sobolev spaces) are a concern. Techniques of microlocal analysis may be used to characterize the propagation of singularities.  Efficient numerical algorithms for inverting the BRT are to be implemented and tested using data derived from radiative transport forward solvers that account for both single- and multiple-scattering, hence connecting the research to the experimental regime. <br/><br/>One of the grand challenges in imaging is to address the problem of scattering. <br/>It is generally believed that only unscattered particles or waves carry useful information about the medium through which they have traveled. The Investigators aim to show that this is not the case. By making use of mathematical methods and computational approaches that exploit the presence of scattering, they seek to transform a variety of biomedical and security-related x-ray and optical imaging technologies. This research is a collaboration between applied and computational mathematicians and physicists and their work with three graduate students. Broad dissemination of the results of the research is anticipated through publications and generation of publicly available software."
"1115252","Computation of the Semiclassical Limit of Schroedinger's Equation, Anisotropic Grain Growth, and Epitaxial Growth Using Kinetic Monte Carlo","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/15/2011","07/11/2011","Peter Smereka","MI","Regents of the University of Michigan - Ann Arbor","Standard Grant","Junping Wang","06/30/2015","$149,999.00","","psmereka@umich.edu","1109 GEDDES AVE, SUITE 3300","ANN ARBOR","MI","481091079","7347636438","MPS","1266, 1271","9263","$0.00","This proposal involves three projects where each one builds from prior NSF support. This first project involves the simulation of grain boundary motion in two and three dimensions using our recently developed multiphase variational level set framework. It is planned to extend this formulation to allow for the possibility of arbitrary surface tension between grains. This will be accomplished by combining this formulation with minimizing movements. The second project concerns the efficient computation the semi-classical limit of the Schroedinger equation. The proposed algorithm is based on the observation that if one transforms the Schroedinger equation using a transformation inspired by Gaussian wave packets, one arrives at another Schroedinger equation that is much more amenable to computation in the semiclassical limit project. The third project concerns modeling and efficient simulation of epitaxial growth using kinetic  Monte Carlo (KMC).  We plan to model and simulate both liquid drop epitaxy and heteroepitaxial growth. In each of these cases we aim to develop highly efficient KMC algorithms to allow simulation on time and lengths not previously possible, thereby facilitating model development and allowing comparison with experiments.<br/><br/>Each of the proposed projects has the potential to have a significant impact on problems that are both fundamental and technologically important. Epitaxial growth is scientifically interesting since it has effects on both nanoscales and mesoscales.  It is technologically relevant since quantum dot materials are made in this way.  Our proposed techniques will greatly increase the simulation speed  thereby facilitating  model development. The study of grain boundary motion using curvature flow is a classic problem in applied and computational mathematics which has importance in material science  since  various properties of polycrystalline substances can crucially depend on the details of the grain patterns.  The fast simulation of the semi-classical limit of the Schroedinger equation could  provide deeper insight into chemical reaction dynamics, molecular-surface scattering, and photodissociation, for example."
"1115615","Collaborative Research: Inversion of the Broken-Ray Radon Transform and Applications","DMS","COMPUTATIONAL MATHEMATICS","07/01/2011","07/01/2011","Alexander Katsevich","FL","The University of Central Florida Board of Trustees","Standard Grant","Rosemary Renaut","06/30/2016","$100,000.00","","Alexander.Katsevich@ucf.edu","4000 CENTRAL FLORIDA BLVD","ORLANDO","FL","328168005","4078230387","MPS","1271","9263","$0.00","This project assembles a team of applied and computational mathematicians and physicists to develop, analyze and implement reconstruction algorithms for the broken-ray Radon transform (BRT) and its generalizations. The BRT describes the propagation of single-scattered particles or waves. This situation is typical of x-ray imaging at clinical energies or optical imaging of nearly transparent tissues and model organisms. The intent of the proposed research is to provide theoretically, numerically justified and practically applicable reconstruction algorithms for the BRT with applications to both x-ray computed tomography and optical tomography in the weak-scattering regime. In particular, the investigators propose to derive and analyze BRT-based scanning protocols and corresponding inversion techniques to reconstruct the absorption and scattering coefficients. Associated scanning protocols, which provide the optimum balance between spatial resolution and stability to noise, are to be developed. In addition, questions of uniqueness and stability (in the scale of Sobolev spaces) are a concern. Techniques of microlocal analysis may be used to characterize the propagation of singularities.  Efficient numerical algorithms for inverting the BRT are to be implemented and tested using data derived from radiative transport forward solvers that account for both single- and multiple-scattering, hence connecting the research to the experimental regime. <br/><br/>One of the grand challenges in imaging is to address the problem of scattering. <br/>It is generally believed that only unscattered particles or waves carry useful information about the medium through which they have traveled. The Investigators aim to show that this is not the case. By making use of mathematical methods and computational approaches that exploit the presence of scattering, they seek to transform a variety of biomedical and security-related x-ray and optical imaging technologies. This research is a collaboration between applied and computational mathematicians and physicists and their work with three graduate students. Broad dissemination of the results of the research is anticipated through publications and generation of publicly available software."
"1115390","Collaborative Research: Stable and Efficient Convexity-Splitting Schemes for Bistable Gradient PDEs","DMS","COMPUTATIONAL MATHEMATICS","07/15/2011","07/05/2011","Steven Wise","TN","University of Tennessee Knoxville","Standard Grant","Junping Wang","09/30/2014","$160,000.00","","swise1@utk.edu","201 ANDY HOLT TOWER","KNOXVILLE","TN","379960001","8659743466","MPS","1271","9150, 9263","$0.00","The goal of this research is to design robust, efficient, and practical numerical methods for bistable gradient equations (BGEs).  These form a a special class of partial differential equations (PDEs) that describe important phenomena in materials, fluids, and biology research. For this work the PIs plan detailed investigations of the slope selection (SS), no slope selection (NSS), phase field crystal (PFC) and Cahn-Hilliard (CH) equations, which are important 4th or 6th-order BGEs that must typically be solved over large space and time scales.  Numerical solution of these equations (and BGEs in general) can pose enormous challenges.  In this work the PIs will develop convex splitting (CS) schemes for BGEs.  CS schemes are 1st or 2nd-order accurate in time and at least 2nd-order accurate in space.  They are simple, powerful, and particularly well-suited to studying large spatiotemporal morphological evolution accurately and efficiently.  1st-order  (in time) CS schemes have been known for about ten years; but, up to now, the underlying theory has been incomplete and their application, somewhat limited.  The proposed high-order CS schemes (2nd-order in time, 2nd-order and higher in space) are novel features of the PIs work.  All CS schemes have two important properties: they are unconditionally energy stable and unconditionally uniquely solvable.  The energy stability can often be exploited to prove various norm stabilities, as well as convergence.  The unique solvability follows from the fact that the schemes are derived as the gradients of strictly convex functionals.  As a result, practical solvers can always be crafted, since gradient descent methods will converge unconditionally.  A big challenge of this work is in designing truly efficient solvers for the potentially highly nonlinear CS schemes.  The PIs have had some early, important successes in this direction, having crafted nearly optimally efficient nonlinear multigrid solvers for the PFC and Cahn-Hilliard-Hele-Shaw (CHHS) equations.  In this work they will extend these achievements by deriving sophisticated, efficient, and time and space adaptive solvers for a variety of BGEs.  The PIs will apply their CS schemes and efficient solvers to study the complicated long-time dynamics of models for thin film coarsening, tumor growth and treatment, two-phase fluid flow, and crystal growth.<br/><br/>BGEs allow researchers to create models of a great number of physical and biological phenomena, and hence this work will have a direct impact on many scientific disciplines. The specific equations that the PIs will focus on (SS, NSS, PFC, and CH equations) are vital for understanding phase transformations of materials at the atomic and nanometer scales, the complex processes in biological growth and development, and the complicated topological change involved in two-phase flows.  For a specific example, the SS equation can be used model the formation of nano-scopic hills and valleys on the surfaces of certain materials, such as those used in semiconductor devices.  Knowing how these nano-structures form and move during device processing is critical for precise manufacture.  Mathematical modeling (using BGEs, for example) is often a more practical alternative to doing laboratory experiments to find ``optimal"" processing procedures.  However, in most practical situations, solutions to BGEs can only be approximated using computerized algorithms.  The primary goal of this research is to develop 2D and 3D algorithms that approximate the solutions as accurately, efficiently, and robustly as possible.  The computer algorithms and source codes created from this work will apply to even more general models than will be explored in this research and will therefore advance the field of computational science as a whole.  The PIs will make their software packages available in the public domain so that researchers will have direct access to their algorithms.  In addition to working toward their research goals, the PIs will help to build and reinforce the human resources pipeline in the field of computational sciences, which is one of the broader goals in STEM education in the US.  Both graduate and undergraduate students will receive training in high-performance scientific computing, numerical mathematics, and modeling; and their work is expected to form the bases of peer-reviewed publications, conference talks, technical reports, and theses.  As a major component of this effort, the PIs will continuously  support and mentor two UMass, Dartmouth undergrads through the CSUMS program.  These students will get hands-on training in algorithm and software development.  This type of training is rare in the typical undergraduate curriculum.  Using this research as a venue, the PIs will work to inspire students, especially undergraduates and those from traditionally underrepresented groups, to pursue careers in science and engineering."
"1115455","Computational methods in arithmetic geometry","DMS","ALGEBRA,NUMBER THEORY,AND COM, COMPUTATIONAL MATHEMATICS","07/15/2011","12/20/2013","Andrew Sutherland","MA","Massachusetts Institute of Technology","Standard Grant","Rosemary Renaut","06/30/2016","$117,446.00","Andrew Sutherland","andrewvsutherland@gmail.com","77 MASSACHUSETTS AVE","CAMBRIDGE","MA","021394301","6172531000","MPS","1264, 1271","9263","$0.00","The PIs propose several investigations in computational arithmetic geometry.  These include the further development of generic group algorithms and numerical  computation of p-adic cohomology, the further investigation of the distribution  of Frobenius eigenvalues of curves of low genus, and the efficient computation  and tabulation of modular polynomials.<br/><br/>Computational arithmetic geometry in general, and the proposed research in  particular, bears relevance to several aspects of applied computer science,  including the reliable transmission and storage of digital data and the  security of electronic communication.  In addition to research, the proposed  activities also include undergraduate participation in algorithm and software  development, integrating research and training activities while producing tools of high value to the research community."
"1115978","New Exponential Integrators and Applications","DMS","COMPUTATIONAL MATHEMATICS","08/15/2011","08/01/2013","Mayya Tokman","CA","University of California - Merced","Continuing Grant","Junping Wang","07/31/2015","$300,001.00","","mtokman@ucmerced.edu","5200 N LAKE RD","MERCED","CA","953435001","2092012039","MPS","1271","9263","$0.00","The need to numerically solve initial value problems for large stiff systems of ordinary differential equations (ODEs) arises in an overwhelming majority of scientific and engineering fields.  Traditionally implicit solvers have been used to overcome the stability restrictions on the time step and improve computational efficiency compared to explicit schemes. Recently, however, exponential integrators emerged as an efficient alternative to commonly used techniques.  While several of such integrators have been proposed, significant research efforts are needed to construct, analyze and optimize these integrators. The PI proposed a class of new exponential propagation iterative schemes of Runge-Kutta type (EPIRK) which are designed to maximize computational efficiency for solving very large stiff systems. The research sponsored by this grant will produce new EPIRK methods designed to have good scalability on parallel high-performance computing platforms. The study of the new integrators will produce methodologies for construction of efficient exponential schemes and explore properties of these methods.  An important part of the project is the development of adaptive versions of the algorithms and implementation of new integrators as a general-use software package for both serial and parallel platforms. The software will be used to study several application problems in plasma physics and biomodeling and will be made widely available.<br/><br/>In a variety of scientific and engineering applications researchers want to predict behavior of complex systems which evolve on a wide range of temporal and spatial scales. Such systems, for instance, arise in many geo-engineering applications such as storing greenhouse gases, extraction of oil and gas from highly porous and fractured media or managing groundwater resources. Another example of a multiscale problem is modeling magnetic reconnection, one of the most fundamental processes in astrophysical and laboratory plasmas that governs such important phenomena as solar flares, magnetic substorms in the Earth?s magnetosphere and dynamics of magnetic fusion experiments. Computer modeling has become an essential tool in studying such systems. However, in order to be able to simulate the behavior of these systems on a computer advanced mathematical tools that offer exceptional efficiency on high-performance computing platforms have to be developed. The numerical techniques that will result from this project will allow prediction of the behavior of a wide range of complex systems of scientific and engineering interest over the parameter regimes inaccessible to standard methods."
"1115331","Superconvergent Discontinuous Galerkin methods for Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","10/01/2011","09/14/2011","Bernardo Cockburn","MN","University of Minnesota-Twin Cities","Standard Grant","Leland Jameson","09/30/2015","$419,998.00","","cockburn@math.umn.edu","200 OAK ST SE","MINNEAPOLIS","MN","554552009","6126245599","MPS","1271","7569, 9263","$0.00","In this proposal, the investigator studies and develops a new, emerging generation of discontinuous Galerkin methods characterized by being easier to implement, by having enhanced stability and convergence properties, and by displaying an improved flexibility for handling arbitrarily-shaped domains. The investigator will focuses his effort in four particular problems. The first is in the area of fluid flow and consists in establishing a general theory of very competitive numerical methods for the incompressible Navier-Stokes equations. The second is in the area of continuum mechanics and consists in the study of optimally convergent methods for fourth-order problems in order to pave the way to the devising of numerical methods for non-linear shells. The third is in the area of non-linear conservation laws and consists in the introduction of new techniques geared towards overcoming the two main difficulties that have dragged down for more than a decade the development of efficient, high-order accurate methods for these useful equations. The last is in the area of techniques for handling curved boundaries and consists in replacing the traditional paradigm of meshing the domain with high accuracy by the new approach of using a very simple mesh of a box containing the domain and employing special approximation techniques near its border.<br/><br/><br/>The computer simulation of physical phenomena is a highly valued tool of practical interest in a wide variety of applications in Engineering and Physics. The investigator studies an emerging and promising technique of carrying out these simulations with highly accurate and more efficient algorithms for a wide range of problems of practical interest. They include many applications to Aerospace and Mechanics (incompressible fluid flow, subsonic and supersonic flow) as well as to Civil Engineering (solid structures)."
"1115714","Novel Numerical Methods for Partial Differential Equations with Low-regularity Data","DMS","COMPUTATIONAL MATHEMATICS","09/01/2011","08/22/2011","Hengguang Li","MN","University of Minnesota-Twin Cities","Standard Grant","Junping Wang","07/31/2012","$60,066.00","","li@wayne.edu","200 OAK ST SE","MINNEAPOLIS","MN","554552009","6126245599","MPS","1271","9263","$0.00","Elliptic partial differential equations (PDEs) with low-regularity data (i.e., singular solutions and low-regularity coefficients) frequently appear in mathematical models from diverse scientific disciplines. These equations in general present a multiscale character, which increases the complexity of the problem and poses numerous challenges on the finite element approximation and on the design of multigrid schemes. Despite continuous developments from the computational community, some fundamental questions still remain open. Addressing major issues in both theoretical analysis and practical implementation, this proposal aims at a systematic investigation on various aspects of the finite element method (FEM) and multigrid (MG) methods solving elliptic PDEs with low-regularity data, with a wide range from the theoretical estimates of PDEs to the development of state-of-the-art numerical algorithms. In particular, the proposed research consists of two major components: 1) the optimal FEMs for singular solutions, including (I) the establishment of a unified framework for the analysis of a wide variety of singular solutions in weighted Sobolev spaces and(II) the development and implementation of effective grading algorithms to improve the accuracy of the numerical solution approximating these singular solutions; 2) the MG theory for axisymmetric problems, including the estimation of basic MG cycles for the axisymmetric Laplace operator and the design of new smoothers for the axisymmetric Stokes problem in weighted spaces. The proposed research will produce new a priori results (e.g., the well-posedness and regularity) for various singular solutions in weighted spaces, unitize the full potential of graded meshing techniques for singular solutions, expand the scope of the MG theory on axisymmetric equations, and foster innovative ideas on solving PDEs with broader applications. <br/><br/>The proposed research has many applications in various fileds of science and engineering. A class of singular solutions of elliptic PDEs are from the non-smoothness of the computational domain and the non-smoothness of the interface in transmission problems. The study on these singularities shall produce effective numerical algorithms solving problems in aerospace engineering (aircraft design), in mechanical engineering (crack propagation), and in elastography of medical imagining (modeling different levels of stiffness in human tissues). The research on singular solutions from the singular coefficients shall provide new theoretical results and modern finite element techniques to tackle Schroedinger equations with various singular potentials in quantum mechanics. In addition, the MG analysis on axisymmetric models shall lead to a more complete MG theory in singular spaces and in turn bring new fast numerical solvers for these equations that are frequently used in fluids and i  n electromagnetic fields. These are the fields that have profound impact on national security, development of new energy, and novel medical research. Results from this project will be disseminated through collaboration with other scholars, publication of peer-reviewed articles, and presentations at professional meetings. With the development of a software package, the PI also expects to design a project-oriented course on the finite element method for senior undergraduate/graduate students in math and engineering, which will equip the students with a better understanding on the algorithm and a valuable programming experience."
"1139712","The 8th International Conference on Scientific Computing and Applications","DMS","COMPUTATIONAL MATHEMATICS","10/01/2011","09/21/2011","Jichun Li","NV","University of Nevada Las Vegas","Standard Grant","Junping Wang","09/30/2012","$20,660.00","Hongtao Yang","jichun.li@unlv.edu","4505 S MARYLAND PKWY","LAS VEGAS","NV","891549900","7028951357","MPS","1271","7556, 9150, 9263","$0.00","This proposal seeks support for The 8th International Conference on Scientific Computing and Applications (SCA 2012) to be held at University of Nevada Las Vegas during April 1-4, 2012.  The conference is the eighth in a sequence of international meetings held every two years in different countries in North America and Asia. The proposed conference will bring together researchers working in various fields of scientific computing and its applications to solve scientific and industrially oriented problems,  and to provide a forum for the participants to meet and exchange ideas between computational mathematics, engineering and industrial communities. The intellectual merit of the conference is embodied in its addressing many fundamentally challenging topics:  Multiphase Flow in Porous Media; Geophysical Fluid Dynamics; Climate Simulation; Modeling of Renewable Energy; Numerical Techniques for Wave Propagations; Numerical Methods for Stochastic PDEs. <br/> <br/>The NSF funding will be used to cover the travel cost for about 30 conference participants, who will be predominantly students and junior researchers from U.S., but the organizers expect to also cover the travel and subsistence expenses of some senior participants. The conference organizers will make their great efforts in attracting young participants, especially participants from under-represented groups, and providing valuable opportunities for them to network with leaders of computational mathematics. The conference will provide a better understanding and applications in areas of importance to the nation such as national security,  environment, nano science, and energy. Specific examples include developing robust and efficient scientific computing tools for oil reservoir simulation, fuel Cells, biofuels, design of invisibility cloak, ice-sheet models for the next generation climate simulation, etc."
"1115530","Spectral and spectral collocation methods for Hamiltonian systems","DMS","COMPUTATIONAL MATHEMATICS","09/01/2011","08/22/2011","Zhimin Zhang","MI","Wayne State University","Standard Grant","Junping Wang","08/31/2014","$120,000.00","","zzhang@math.wayne.edu","5700 CASS AVE STE 4900","DETROIT","MI","482023692","3135772424","MPS","1271","9263","$0.00","The objective of this project is to develop some robust and high accuracy numerical algorithms and related mathematical theory for Hamiltonian systems. The research efforts will be devoted to constructing ""essentially"" (accuracy is in a range of the computer round-off error) volume conserving (symplectic) and energy conserving algorithms. Some recent mathematical theory in spectral methods, finite element superconvergence, as well as discontinuous Galerkin methods will be employed in the project.<br/><br/>Phenomena in different scientific disciplines such as classical mechanics, molecular dynamics, hydrodynamics, electrodynamics, plasma physics, relativity, and astronomy, etc. can be described by Hamiltonian dynamical systems. The success of the project will impact science and engineering practices. This research will widen the body of knowledge in the scientific community on both mathematical theory and practical algorithmic design. The project contains solid multi- and interdisciplinary components and has wide application in scientific computing."
"1115280","Hybridizable discontinuous Galerkin methods for higher order partial differential equations","DMS","COMPUTATIONAL MATHEMATICS","09/01/2011","08/29/2011","Fatih Celiker","MI","Wayne State University","Standard Grant","Junping Wang","08/31/2015","$135,514.00","","celiker@wayne.edu","5700 CASS AVE STE 4900","DETROIT","MI","482023692","3135772424","MPS","1271","9263","$0.00","In order to understand, predict, and eventually control a complex natural or manufactured physical system, one often models it using partial differential equations. Nevertheless, in practically all models arising from complex modern applications, obtaining an exact solution in the form of basic mathematical functions is not a possibility. Thus, a practitioner must resort to what is called a numerical method for computing an approximate solution to the partial differential equations defining the model. Numerical simulations thus play a key role in modern science and technology. They also allow significant reduction in manufacturing costs by designing and testing various models merely on computers before actually building a physical model. Successful computation of approximate solutions to practical problems of interest in part depends on advances in computer technology. However, more importantly, it hinges upon the design, analysis, and implementation of efficient, reliable, accurate, and robust numerical methods.<br/><br/>One of the most widely used family of numerical methods is the finite element method, which has become an indispensable tool for simulation of a wide variety of phenomena arising in science and engineering such as the design of aircrafts, automobiles, bridges, oil platforms, and more recently of nano-materials, to name a few. Discontinuous Galerkin (DG) methods constitute a special subfamily of finite element methods which are known for their stability, robustness, versatility, and high-order accuracy.<br/>In this project, the PI will develop and analyze hybridizable DG (HDG) methods for problems arising in structural mechanics. Particular emphasis will be on devising such methods for problems dealing with thin domains such as beams, plates, and shells, since they pose challenges which have attracted much interest in the scientific computing community. The hybridization procedure allows the elimination of many of the globally coupled degrees of freedom rendering the linear system significantly smaller than that of its classical DG counterparts. The resulting HDG methods enjoy desirable properties of DG methods such as stability, high-order convergence, and robustness, and in certain cases they exhibit even better properties. Mathematical analysis of such phenomena is also a part of the proposed project. This project consists of several parts: HDG methods for Naghdi arches; biharmonic problems; Reissner-Mindlin plates; and fourth-order time-dependent problems. Notwithstanding each of these steps is worthy of interest in its own right, one of the ultimate goals of the PI is to devise efficient numerical methods for shell models, and each one of the above steps constitute a stepping stone towards this goal."
"1065046","FRG: Collaborative Research: Error Quantification and Control for Gravitational Waveform Simulation","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","06/15/2011","06/24/2013","Donald Estep","CO","Colorado State University","Continuing Grant","Henry Warchall","05/31/2016","$288,115.00","","donald.estep@colostate.edu","601 S HOWES ST","FORT COLLINS","CO","805212807","9704916355","MPS","1266, 1271","1616, 9263","$0.00","The purpose of this project is to develop practical rigorous methods for estimating the error in computed waveforms from gravitational wave simulation with reliable accuracy, in support of the NSF-funded Laser Interferometer Gravitational Observatory (LIGO).  The project brings together a team of applied and computational mathematicians with expertise in constructing error estimates for solutions of partial differential equations and physicists with expertise in numerical solutions of the Einstein equation and gravitational wave data analysis.  The primary technical goal is to develop and analyze new mathematical and computational methods that can be used by the gravitational physics community to compute rigorous and reliably accurate estimates for the errors of numerical solutions of the Einstein equations and the gravitational waveforms that are determined from them.  In particular, this research explores the following issues:<br/>(1) Error quantification and a posteriori analysis using adjoint sensitivity techniques, and their associated numerical implementation;<br/>(2) Adaptive algorithms that are driven by goal-oriented error control, and their associated theoretical convergence analysis; and<br/>(3) The role of covariance symmetry and associated geometric structures in error analysis and the construction of numerical methods.<br/>As part of the a posteriori analysis, the project team will develop the basic theory of adjoint operators and duality for the Einstein equations. This will provide the foundation for future investigations into sensitivity analysis, data assimilation and uncertainty quantification for using LIGO data. It should be emphasized that the main thrusts of the proposed research are discretization-neutral, and therefore have broad applicability to the breadth of numerical relativity codes in existence.<br/><br/>The NSF-supported Laser Interferometer Gravitational Observatory (LIGO) can be successful only if highly accurate gravitational waveform models are available for use as part of the data analysis process, both for detecting gravitational waves and also for measuring the physical properties of any detected signals.  The strongest sources of gravitational waves are expected to be collisions between heavy, dense stars or black holes, which can only be modeled accurately using complex numerical simulations to calculate the anticipated gravitational waveforms.  Such waveforms are needed to construct the filters that allow detection of the weak gravitational-wave signals in the noisy detector, and such waveforms are also needed to measure the physical properties of the sources of any detected signals.  The waveform accuracy needed to accomplish the required data analysis tasks is quite high.  However, the numerical relativity community has yet to develop the analytic and computational tools needed to evaluate rigorously the accuracy of the numerical waveform models.  If the qualitative accuracy measures currently used by the numerical relativity community are too optimistic, the rigorous new methods developed by this project could make the difference between success and failure of LIGO.  If the current numerical waveforms are in fact accurate enough, the methods developed by this project could improve the computational efficiency of determining waveforms with a specified accuracy level, and thus reduce the cost of producing them."
"1109325","Adaptive Finite Element Methods for Multiscale Geometric PDE: Modeling, Analysis, and Computation","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","10/01/2011","08/12/2013","Ricardo Nochetto","MD","University of Maryland, College Park","Continuing Grant","Michael Steuerwalt","09/30/2014","$639,970.00","","rhn@math.umd.edu","3112 LEE BLDG 7809 REGENTS DR","College Park","MD","207420001","3014056269","MPS","1266, 1271","7237, 9263","$0.00","Nochetto<br/>DMS-1109325<br/><br/>     Capturing the essential behavior of nonlinear phenomena at the micro- and nanoscales with the simplest and crudest models is of fundamental importance in science and engineering.  This allows for understanding of basic mechanisms, the design and implementation of efficient numerical methods for simulation and control of ensuing processes, and the analysis of both models and algorithms.  Mathematical models in biophysics (such as biomembranes in both fluid and gel state), in materials science (such as crystal surface morphologies and bilayer actuators), and in shape optimization (including electro-wetting on dielectric) are typical yet quite distinct examples that the investigator studies in the project.  The governing partial differential equations are geometric and exhibit disparate space-time scales: point and line singularities (interfaces), thin layers, and large domain deformations, perhaps leading to topology changes.  The goal of the project is to model and control such multiscale phenomena, and to design, test, and analyze reliable and efficient adaptive finite element methods for them with space-time error control based on a posteriori error estimation.<br/><br/>     Understanding the mechanisms of nonlinear phenomena at micro- and nanoscales is essential in many areas of science and engineering.  The investigator develops mathematical models and reliable computational methods for studying a wide range of such problems.  This project deals with applications of Federal strategic interest such as nano and microtechnology (such as the design and control of micro electro-mechanical system (MEMS)), biotechnology (such as the study of biomembranes), and high performance computing (such as the design of novel efficient numerical methods).  It is a collaborative endeavor involving a number of scientists in the US and abroad, as well as several graduate students and postdocs.  A substantial effort is devoted to education and human resource development."
"1115931","Fast Integral Equation Methods for High-Dimensional Diffusion Problems","DMS","COMPUTATIONAL MATHEMATICS","09/01/2011","08/08/2011","Johannes Tausch","TX","Southern Methodist University","Standard Grant","Junping Wang","08/31/2015","$129,990.00","","tausch@smu.edu","6425 BOAZ LANE","DALLAS","TX","75205","2147684708","MPS","1271","7569, 9263","$0.00","The unifying theme of this project is the development and analysis of<br/>numerical methods for high-dimensional diffusion problems. In<br/>particular, the research will be focused in two areas, namely solving<br/>boundary value problems to the heat equation in three dimensions using<br/>thermal layer potentials. The second issue is the computation of the<br/>discrete Gauss transform for data sets in many dimensions.  Both<br/>topics involve computations with integral operators that have a Gauss<br/>kernel. Since these operators are non-local, naive algorithms scale<br/>quadratically in the number of data points. Realistic problems can<br/>involve enormous data sets and are therefore tractable only if fast<br/>methods, that exploit certain analytic properties of the kernel, are<br/>applied.  This project will employ high-order Nystrom techniques that<br/>are combined with Chebyshev and exponential expansions for the rapid<br/>evaluation of integral operators.<br/><br/>The ability to solve the heat equation efficiently is fundamental in<br/>many applications of science, technology and medicine. For instance,<br/>heat conduction plays an important role in the modeling of geothermal<br/>systems, melting, welding, and in thermography as a means to detect<br/>breast cancer. Often, the task is to identify an unknown heat source<br/>from known surface temperatures and fluxes.  The solution of such<br/>inverse problems involves solving the forward problem many times,<br/>therefore speed is essential for numerical methods.  The discrete<br/>Gauss transform is used to find relations in large data sets. This can<br/>be patterns, correlations, or accumulations in images, texts, or<br/>internet traffic. Concrete applications are, for instance, machine<br/>recognition of faces, voices and handwriting.  By engaging a graduate<br/>as well as undergraduate students in research, the proposed activities<br/>will also contribute to excellence and growth in the education of the<br/>future workforce."
"1115658","Collaborative Research: Reduced Order Model Approaches for Time Dependent Nonlinear PDE Constrained Optimization","DMS","COMPUTATIONAL MATHEMATICS","08/15/2011","07/01/2011","Ronald Hoppe","TX","University of Houston","Standard Grant","Junping Wang","12/31/2015","$149,925.00","","rohop@math.uh.edu","4300 MARTIN LUTHER KING BLVD","HOUSTON","TX","772043067","7137435773","MPS","1271","9263","$0.00","This project develops, analyses and implements projection based reduced order models (ROMs) for optimization problems associated with nonlinear evolution partial differential equations (PDEs). These ROMs determine a subspace that  contains the essential (for the optimization) dynamics  of the nonlinear evolution PDEs and project these PDEs onto the subspace. If the subspace is small, the original nonlinear PDEs in the optimization problem can be replaced by a small system of ordinary differential equations and the resulting approximate optimization problem can be solved efficiently. The efficient generation of ROMs together with error estimates that can monitor the quality of the ROMs is challenging. This project expands and integrates ideas from goal oriented adaptive mesh refinement, proper orthogonal decomposition (POD), and model management approaches in optimization to overcome these challenges. Specifically, model management ideas from optimization are used determine at which optimization parameters the nonlinear evolution PDE needs to be solved to generate snapshots for the ROM. Furthermore, for the numerical solution of the PDE and generation of snapshots a combination of goal-oriented dual weighted based adaptive space-time finite element approximations of the PDE and discrete Galerkin-POD will be used. In particular, local-in-time and local-in-space dual weighted residuals for the control of the error in time and the error in space will be obtained that also provide a prediction of appropriate time steps at which snapshots are taken. The goal is the derivation of an a posteriori error estimator for the ROM error that gives us information about the number of reduced basis functions that need to be included. This novel approach will result in an Adaptive Discrete Galerkin-POD (ADGPOD) algorithm for an efficient and reliable ROM-based numerical solution of PDE constrained optimization. In addition the resulting ROMs will be demonstrated on several applications, including flow control/design problems and the optimal control of Asymmetrical-Flow Field-Flow-Fractionation processes for the fast separation of nanoparticles, proteins, and other macromolecules.<br/><br/><br/>The optimal design of processes and systems in engineering and life science applications often requires the optimal control/optimization of systems of nonlinear partial differential equations (PDE). The numerical solution of such problems typically amounts to the solution of large nonlinear algebraic systems requiring extensive storage and computational time. On the other hand, the design engineers are interested to run optimal designs on their PCs within a couple of minutes. This can be achieved only by a dramatic reduction of the dimension of the problem, i.e., by developing a reduced model for the underlying PDE system that captures the essential dynamics of the expensive high fidelity simulation. Although reduced order models have been shown to work well for a wide spectrum of applications, they not yet well understood from a theoretical point of view, especially for nonlinear problems. This project will provide a better theoretical foundation of reduced order models for nonlinear problems, it will develop novel algorithmic tools for the efficient generation of reliable reduced order models, and it will demonstrate the algorithms on important science and engineering applications."
"1115288","Local properties of the finite element solutions to PDE constrained optimal control problems","DMS","COMPUTATIONAL MATHEMATICS","10/01/2011","09/15/2011","Dmitriy Leykekhman","CT","University of Connecticut","Standard Grant","Junping Wang","09/30/2014","$126,383.00","","dmitriy.leykekhman@uconn.edu","438 WHITNEY RD EXTENSION UNIT 11","STORRS","CT","062691133","8604863622","MPS","1271","9263","$0.00","The research objective of this project is to develop a strong theoretical <br/>foundation on local properties of finite element solutions for advection-<br/>dominated optimal control problems. The advection-diffusion partial <br/>differential equations (PDEs) are known to be difficult to approximate because <br/>their solutions often exhibit discontinuities, layers, and shocks. The <br/>structure of the solutions to optimal control problems is even more <br/>complicated because of the coupling in the optimality system of the governing <br/>advection-dominated PDE with an advection-dominated adjoint PDE. It is known <br/>that convergence behavior of finite element methods applied to single <br/>advection-dominated PDEs can be very different from the convergence behavior <br/>of finite element methods applied to advection-dominated optimal control <br/>problems. Understanding the global and local convergence behavior is crucial <br/>for reliable and efficient solution of advection-dominated optimal control <br/>problems, especially in the presence of control and state constraints, and <br/>objective functions that depend on pointwise state information. This project <br/>intends to deepen our understanding for various problems and to help develop <br/>reliable numerical methods.   <br/><br/><br/>Mathematics proved to be extremely useful in modeling many real life problems <br/>coming from environment, technology, climate, and etc. However, many <br/>mathematical models require special parameters that can not be measured <br/>directly. Examples can be shapes in modeling technological devises, physical <br/>coefficients in environmental processes, controls in navigation and etc. and <br/>need to be estimated.  Mathematically, estimation of such paramters often <br/>leads to optimization problems with constraints in the form of system partial <br/>differential equations (PDEs). Usually, such system of PDEs is well understood <br/>and there are many available numerical techniques to solve it. However, it <br/>does not immediately apply that the method that works well for the underlying <br/>system of PDEs will work for the constrained optimization problem.  In our <br/>previous work, we showed such differences in the case of a simple model <br/>problem. In this proposal we intend to investigate more complicated model <br/>problems that cover a broader range of applications."
"1115834","Collaborative Research: Efficient Solvers for Nonlinear Eigenvalue Problems and Applications","DMS","COMPUTATIONAL MATHEMATICS","09/01/2011","08/25/2011","Ren-Cang Li","TX","University of Texas at Arlington","Standard Grant","Junping Wang","08/31/2014","$169,941.00","","rcli@uta.edu","701 S. NEDDERMAN DR","ARLINGTON","TX","760199800","8172722105","MPS","1271","9263","$0.00","This project involves the development of advanced computational methods for solving genuine nonlinear eigenvalue problems.  In this project, skillful combination of Kublanovskaya's nonlinear QR algorithm with modern rank-revealing and structure-preserving techniques for small and medium size dense problems enhances the capabilities of new methods. A novel trimmed linearization via Pade rational approximation extends the enhancements for solving large but sparse problems.  The investigators seek to develop a systematic and unified treatment of the relevant mathematical theory, and produce numerical methods and software tools for the genuine nonlinear eigenvalue problems.  In addition to advancing research in nonlinear eigenvalue problems, the project provides training for graduate students in computational mathematics and interdisciplinary research tools.<br/><br/>Eigenvalue problems are ubiquitous in computational science and engineering, where they arise in the study of dynamics of structures, simulation of nanostructured photovoltaic conversion materials to advance energy science, and many other scenarios. Eigenvalues explain a wide range of physical phenomena such as vibrations and frequencies, (in)stabilities of dynamical systems, and energy excitation states of electrons and molecules.  Many eigenvalue problems occur naturally in nonlinear form. In this project, the investigators study the underlying nonlinear problems without relying on linearization approximations. The promise of substantially improved methods for computing solutions of nonlinear eigenvalue problems, brings immediate benefits to a wide range of practical applications."
"1115523","Collaborative Research: Proximity Algorithms for Optimization Problems Arising from Image Processing","DMS","COMPUTATIONAL MATHEMATICS","08/15/2011","06/28/2013","Lixin Shen","NY","Syracuse University","Continuing Grant","Junping Wang","07/31/2014","$200,000.00","Yuesheng Xu","lshen03@syr.edu","900 S CROUSE AVE","SYRACUSE","NY","132440001","3154432807","MPS","1271","9263","$0.00","The restoration of degraded images is a fundamental and challenging problem in image processing. This problem is ill-posed. The total-variation regularization and its variants are commonly used to convert to a well-posed problem. The resulting regularized model usually has a non-differentiable objective functional, which together with the large dimension of the underlying image makes the minimization theoretically and numerically difficult. Typical numerical treatments for this minimization are indirect in the sense that the methods are developed for a smoothed or dual model of the original model. With this project, the principal investigators use tools from convex analysis to find the solution of the image restoration models directly under a unified framework. The PIs address more general mathematical challenges and computational difficulties associated with the obtained fixed-point formulation.  This project provides a fixed-point characterization for the solutions of models with  least squares and max norm fidelity terms combined with the total variation regularization term. The study considers images corrupted by Gaussian noise, impulsive Gaussian noise and Poisson noise, which are all of relevance for different applications. <br/> <br/>Restoring images from available data is required in a variety of applications including computer tomography; natural resources and pollution control via satellite imaging in environmental sciences; and fingerprint and face recognition in security identification. Advanced mathematical models and efficient computational algorithms for solving this problem are essential. The developed numerical schemes  support improved automatic image restoration for these applications. Furthermore, interdisciplinary approaches resulting from the projects enrich upper level undergraduate and graduate curriculum development and teaching activities."
"1045153","EMSW21-RTG: Geometric, Topological and Statistical Methods for Analyzing Massive Datasets","DMS","APPLIED MATHEMATICS, TOPOLOGY, STATISTICS, COMPUTATIONAL MATHEMATICS, WORKFORCE IN THE MATHEMAT SCI","08/01/2011","06/24/2015","John Harer","NC","Duke University","Continuing Grant","Leland Jameson","07/31/2018","$1,839,327.00","Ingrid Daubechies, Scott Schmidler, Shayn Mukherjee, Mauro Maggioni, Paul Bendich","john.harer@duke.edu","2200 W MAIN ST","DURHAM","NC","277054640","9196843030","MPS","1266, 1267, 1269, 1271, 7335","7301, 9263","$0.00","In the past decade, the analysis of massive, high-dimensional, time-varying data sets has become a critical issue for a large number of scientists and engineers.  Observations across several disciplines, by researchers studying dramatically different problems, suggest the existence of geometrical and topological structures in many data sets, and much current research is devoted to modeling and exploiting these structures to aid in prediction and information extraction. Recent work by the investigators, among others, has shown that integrating statistical methodologies with ideas derived from computational topology and diffusion geometry often leads to strikingly superior results than by conventional means. The investigators now propose to bring these methods into the mathematics/statistics curriculum and departmental structure in a formal way, by establishing a vertically integrated program of undergraduate and graduate research and education. This activity has broad support from programs within the Division of Mathematical Sciences, including Applied Mathematics, Computational Mathematics, Statistics and Topology programs, as well as Division of Mathematical Sciences Workforce Program.<br/>This involves new undergraduate courses in the core theoretical areas, graduate topics courses, an extensive summer research program for undergraduates, as well as year long seminars aimed at both graduate and undergraduate students.  In addition, the investigators will disseminate their ideas via summer workshops aimed at small-college faculty, and methodology workshops directed to faculty from other large research institutions.<br/><br/><br/><br/>The need to analyze massive, complex data arises in a wide variety of scientific areas of national importance, including for example satellite image analysis, medical genomics, and internet security.<br/>The investigators propose a program of training future mathematical scientists to attack these new types of problems. The program will be vertically integrated, fostering extensive collaboration between post-docs, undergraduate and graduate students, and senior faculty, and will comprise a dynamic mixture of theoretical coursework and hands-on research activity. Participants in the program will gain valuable professional experience to distinguish them in the industrial and academic job-market."
"1115333","Collaborative Research: AFfield Expansion Method for Acoustic Scattering from Topography: Extensions to Elasticity and the Inverse Problem","DMS","COMPUTATIONAL MATHEMATICS, Geophysics, OPPORTUNITIES FOR RESEARCH CMG","09/01/2011","06/27/2013","David Nicholls","IL","University of Illinois at Chicago","Continuing Grant","Junping Wang","08/31/2015","$129,999.00","","davidn@uic.edu","809 S MARSHFIELD AVE M/C 551","CHICAGO","IL","606124305","3129962862","MPS","1271, 1574, 7215","1574, 7215, 9263","$0.00","This proposal initiates a new collaboration aimed at improving methods of waveform inversion by including topography in seismic wave modeling and reducing the reliance of these methods on data at extremely low-frequency.  The Principal Investigators propose to adapt and improve methods developed for simulating scattering from a diffraction grating. Their approach has extensions to linear elasticity and provides general improvements for solving the inverse problem.  Significant mathematical advances are required to develop robust and efficient techniques for this application. The Boundary Perturbation Method extends the Field Expansion approach to an arbitrary number of layers with independent topographies and allows for rapid and accurate simulation of acoustic wave propagation in two dimensions.  Extensions to three dimensions and to the general equations of elasticity are required. Moreover, the extension of frequency-independent discretizations based on Geometric Acoustics to multilayered elastic models is a significant and necessary mathematical advance.  Additionally, advances in the inverse problem are also necessary to make the technique truly applicable to the seismic imaging problem. The standard method of ""full-waveform inversion"" requires data at frequencies which are too low to record in practice.  The PIs' approach casts the forward problem as the application of a sequence of topography-dependent operators where the interface shapes appear rather explicitly.  A number of iteration schemes are proposed for the recovery of these shapes, using re-arrangements of the compositions coupled to standard regularizing techniques from the theory of ill-posed problems.  <br/><br/>The propagation properties of seismic waves in layers of sediment are crucial in many technologies including the determination of inner earth properties and structure, earthquake detection and prediction, and hydrocarbon (oil and gas) exploration.  In light of its many important applications, it is not surprising that a vast array of numerical and experimental techniques have been brought to bear upon this problem.  However, several gaps in understanding and capability still exist. The PIs' address some of these questions through sophisticated numerical simulations which will be validated against both laboratory experiments and field measurements from the Tibetan plateau."
"1112897","Continuous Regularization for Nonlinear Ill-Posed Problems","DMS","COMPUTATIONAL MATHEMATICS","10/01/2011","09/14/2011","Alexandra Smirnova","GA","Georgia State University Research Foundation, Inc.","Standard Grant","Junping Wang","09/30/2015","$250,000.00","","asmirnova@gsu.edu","58 EDGEWOOD AVE NE","ATLANTA","GA","303032921","4044133570","MPS","1271","9263","$0.00","In the modern theory of irregular (ill-posed, unstable) problems, numerous regularized computational methods are known. These methods are being constantly improved and supplemented with new algorithms. Applied inverse problems are the main sources of this development. One of the primary approaches to the construction and investigation of stable methods for solving ill-posed operator equations is iterative regularization. Numerous convergence theorems describe the efficiency of iteratively regularized algorithms for different classes of unstable problems, and give existence results. However it is quite hard to navigate among discrete schemes and the corresponding convergence theorems. Proofs of these theorems are usually based on the contraction mapping principle and are sometimes rather complicated. In this project, PI conducts research on continuous regularization, which is based on the analysis of asymptotic behavior of nonlinear dynamical systems in Banach and Hilbert spaces. When a convergence theorem is proven for a continuous method, one can investigate various discrete schemes generated by this continuous process. Thus, construction of a discrete numerical scheme is split into two parts: development of a continuous process and numerical integration of the corresponding nonlinear operator-differential equation. Consequently, when it comes to a convergence theorem for a discrete scheme, one can differentiate between the sufficient conditions for the convergence of a continuous process, which stem from the nature of the ill-posed problem, and the conditions that originate from a specific method of numerical integration.<br/><br/>The research will have a broad impact on a large number of scientific disciplines (biomedical imaging, gravitational sounding, chaos theory, spectroscopy, computerized tomography, and other areas of science and engineering) since the corresponding applied inverse problems can be investigated in the framework of this proposal both, theoretically and numerically. These problems are ""ill-posed"" in the sense that their solutions are unstable with respect to noise in the observed image data. For this reason, classical methods of computational mathematics cannot be applied. To overcome this instability and to simultaneously incorporate a priori information, one uses special techniques known as regularization methods. PI's research interests lie in the development and analysis of these regularization methods."
"1065438","FRG: Collaborative Research: Error Quantification and Control for Gravitational Waveform Simulation","DMS","Gravity Theory, APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","06/15/2011","04/29/2013","Lee Lindblom","CA","California Institute of Technology","Continuing Grant","Henry Warchall","08/31/2014","$384,753.00","","llindblom@ucsd.edu","1200 E CALIFORNIA BLVD","PASADENA","CA","911250001","6263956219","MPS","1244, 1266, 1271","1616, 9263","$0.00","The purpose of this project is to develop practical rigorous methods for estimating the error in computed waveforms from gravitational wave simulation with reliable accuracy, in support of the NSF-funded Laser Interferometer Gravitational Observatory (LIGO).  The project brings together a team of applied and computational mathematicians with expertise in constructing error estimates for solutions of partial differential equations and physicists with expertise in numerical solutions of the Einstein equation and gravitational wave data analysis.  The primary technical goal is to develop and analyze new mathematical and computational methods that can be used by the gravitational physics community to compute rigorous and reliably accurate estimates for the errors of numerical solutions of the Einstein equations and the gravitational waveforms that are determined from them.  In particular, this research explores the following issues:<br/>(1) Error quantification and a posteriori analysis using adjoint sensitivity techniques, and their associated numerical implementation;<br/>(2) Adaptive algorithms that are driven by goal-oriented error control, and their associated theoretical convergence analysis; and<br/>(3) The role of covariance symmetry and associated geometric structures in error analysis and the construction of numerical methods.<br/>As part of the a posteriori analysis, the project team will develop the basic theory of adjoint operators and duality for the Einstein equations. This will provide the foundation for future investigations into sensitivity analysis, data assimilation and uncertainty quantification for using LIGO data. It should be emphasized that the main thrusts of the proposed research are discretization-neutral, and therefore have broad applicability to the breadth of numerical relativity codes in existence.<br/><br/>The NSF-supported Laser Interferometer Gravitational Observatory (LIGO) can be successful only if highly accurate gravitational waveform models are available for use as part of the data analysis process, both for detecting gravitational waves and also for measuring the physical properties of any detected signals.  The strongest sources of gravitational waves are expected to be collisions between heavy, dense stars or black holes, which can only be modeled accurately using complex numerical simulations to calculate the anticipated gravitational waveforms.  Such waveforms are needed to construct the filters that allow detection of the weak gravitational-wave signals in the noisy detector, and such waveforms are also needed to measure the physical properties of the sources of any detected signals.  The waveform accuracy needed to accomplish the required data analysis tasks is quite high.  However, the numerical relativity community has yet to develop the analytic and computational tools needed to evaluate rigorously the accuracy of the numerical waveform models.  If the qualitative accuracy measures currently used by the numerical relativity community are too optimistic, the rigorous new methods developed by this project could make the difference between success and failure of LIGO.  If the current numerical waveforms are in fact accurate enough, the methods developed by this project could improve the computational efficiency of determining waveforms with a specified accuracy level, and thus reduce the cost of producing them."
"1115817","Collaborative Research: Efficient Solvers for Nonlinear Eigenvalue Problems and Applications","DMS","COMPUTATIONAL MATHEMATICS","09/01/2011","08/25/2011","Zhaojun Bai","CA","University of California-Davis","Standard Grant","Junping Wang","08/31/2015","$155,000.00","","bai@cs.ucdavis.edu","1850 RESEARCH PARK DR, STE 300","DAVIS","CA","956186153","5307547700","MPS","1271","9263","$0.00","This project involves the development of advanced computational methods for solving genuine nonlinear eigenvalue problems.  In this project, skillful combination of Kublanovskaya's nonlinear QR algorithm with modern rank-revealing and structure-preserving techniques for small and medium size dense problems enhances the capabilities of new methods. A novel trimmed linearization via Pade rational approximation extends the enhancements for solving large but sparse problems.  The investigators seek to develop a systematic and unified treatment of the relevant mathematical theory, and produce numerical methods and software tools for the genuine nonlinear eigenvalue problems.  In addition to advancing research in nonlinear eigenvalue problems, the project provides training for graduate students in computational mathematics and interdisciplinary research tools.<br/><br/>Eigenvalue problems are ubiquitous in computational science and engineering, where they arise in the study of dynamics of structures, simulation of nanostructured photovoltaic conversion materials to advance energy science, and many other scenarios. Eigenvalues explain a wide range of physical phenomena such as vibrations and frequencies, (in)stabilities of dynamical systems, and energy excitation states of electrons and molecules.  Many eigenvalue problems occur naturally in nonlinear form. In this project, the investigators study the underlying nonlinear problems without relying on linearization approximations. The promise of substantially improved methods for computing solutions of nonlinear eigenvalue problems, brings immediate benefits to a wide range of practical applications."
"1112984","Chemotaxis Models in Biology and Texture Development in Materials: Numerical Methods, Analysis, and Modeling","DMS","COMPUTATIONAL MATHEMATICS","09/01/2011","08/29/2011","Yekaterina Epshteyn","UT","University of Utah","Standard Grant","Junping Wang","08/31/2015","$149,581.00","","epshteyn@math.utah.edu","201 PRESIDENTS CIR","SALT LAKE CITY","UT","841129049","8015816903","MPS","1271","9150, 9263","$0.00","The focus of the proposed project is to develop new numerical and analytical techniques to study problems in Biology and Materials Science. These problems give rise to challenging issues for analysis, modeling, and simulations. In this project two areas have been selected for the research directly from potential applications: chemotaxis and chemotaxis models in Biology and texture development and evolution of microstructure in Materials. Chemotaxis refers to mechanisms by which cellular motion occurs in response to an external stimulus, usually a chemical one. Chemotaxis is an important process in many medical and biological applications, including bacteria/cell aggregation and pattern formation mechanisms, as well as tumor growth. Mathematical models of the biological systems are an important tool used in the study of these patterns. Although there is an extensive literature on this subject, only a few numerical methods have been proposed for chemotaxis models. Chemotaxis systems are usually described by highly nonlinear time-dependent partial differential equations. Therefore, development of accurate and efficient numerical methods is crucial for the modeling and analysis of the chemotaxis. Furthermore, a common property of all existing chemotaxis systems is their ability to model a concentration phenomenon that mathematically results in solutions, which rapidly grow in small neighborhoods of concentration points/curves. The solutions may blow up or may exhibit a very singular, spiky behavior.  This blow-up represents a mathematical description of a cell concentration phenomenon that occurs in real biological systems. In either case, capturing such solutions numerically is a very challenging problem. The goal of the first project is to design, implement and analyze novel accurate and efficient numerical methods, as well as develop new analytical methods to study chemotaxis models along with closely related problems in physics and biology. The goal of the second project is to study texture development and evolution of microstructure in Materials. Cellular networks are ubiquitous in nature. They exhibit behavior on many different length and time scales and are generally metastable. Most technologically useful materials are polycrystalline microstructures composed of a myriad of small crystallites, called grains, separated by interfaces, called grain boundaries. The energetics and connectivity of the grain boundary network plays a crucial role in determining the properties of a material across a wide range of scales.  A central goal of research in materials science is to develop technologies capable of producing an arrangement of grains -a texture- appropriate for a desired set of material properties. The main objective of the second project is to understand the role of energy in material texture development. For this, a recently discovered Grain Boundary Character Distribution is introduced and investigated by the use of a large scale simulation and mathematical analysis. Grain Boundary Character Distribution is a new characterization of the texture which is found to be strongly correlated to the interfacial energy. This research will lead to new analytical/computational tools to study grain networks, along with a better understanding of grain boundary distributions, grain boundary properties, and how they evolve during materials processing.<br/><br/>The path to new scientific discoveries lies through new areas of research, interdisciplinary collaboration, and new opportunities. The proposed projects will involve interdisciplinary research and will enhance infrastructure through the development of new analytical and computational tools. The first part of the proposed work, will make fundamental contributions to the development of new numerical and analytical methods which will be used in solving biomedical problems, for example in developing a better understanding of cancer,  as well as initiating new collaboration among disciplines. In the second part of the proposal, both new knowledge and new tools will emerge from this part of the project, which will be used to increase the reliability of materials used, for example in aircraft, microprocessors, and many other devices. Educational activities for the proposed projects include the mentorship of graduate and undergraduate students and the development of new modeling course."
"1238711","Novel Discretization Schemes for Fully Nonlinear Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","09/01/2011","07/24/2012","Michael Neilan","PA","University of Pittsburgh","Standard Grant","Junping Wang","07/31/2014","$116,165.00","","neilan@pitt.edu","4200 FIFTH AVENUE","PITTSBURGH","PA","152600001","4126247400","MPS","1271","9150, 9263","$0.00","The aim of this project is to develop, analyze, and implement the finite element method for fully nonlinear second order partial differential equations (PDEs).  The research is based on a recent discovery of the PI that Lagrange finite element methods and discontinuous Galerkin methods can be used to approximate the Monge-Ampere equation, the prototypical fully nonlinear second order PDE.  As these methods are simple to implement, the computation of the highly nonlinear problem can be performed efficiently and accurately.  The project will expand on these results to obtain simple, efficient, yet accurate numerical schemes for a general class of fully nonlinear equations.  In addition, the PI will develop and analyze various discretization methods including mixed finite element methods, local discontinuous Galerkin methods, hybridizable Galerkin methods, and Petrov Galerkin methods.<br/><br/><br/><br/>Mathematical modeling plays a key role in the investigation and understanding of many phenomena occurring in the natural sciences, the social sciences and engineering.  Yet even for simple problems, closed form solutions are unavailable, and therefore their numerical approximations are the only viable option. As the problems become ever more complex, the need for novel computational methods and innovative analysis becomes imperative to put the United States in the forefront in science and engineering.  The class of problems studied in this project arise in numerous mathematical modeling applications including weather phenomena, determining the initial shape of the universe, optimal reflector design, differential geometry, optimal transport, mathematical finance, image processing, and mesh generation.  Despite their significance in the physical sciences and pure and applied mathematics, the numerical approximation of these problems remains a relatively untouched area.  Therefore, there is a growing need to develop accurate schemes for these types of equations.  As progress of solving any of these application problems largely depends on progress of solving their governing equations, and since numerical methods for these equations are still in their infancy, any progress in the design, implementation, and convergence analysis will have an immediate impact in advancing these application areas."
"1068888","A Workshop in Computational and Analytic Mathematics","DMS","COMPUTATIONAL MATHEMATICS","09/15/2011","09/26/2011","Jon Vanderwerff","CA","La Sierra University","Standard Grant","Leland Jameson","08/31/2012","$15,720.00","","jvanderw@lasierra.edu","4500 RIVERWALK PKWY","RIVERSIDE","CA","925053344","9517852158","MPS","1271","7556, 9263","$0.00","The investigator and his colleagues organize a workshop on Computational and Analytical Mathematics that features the topics of Variational Analysis, Optimization Algorithms, High Performance Computing, Number Theory, and Experimental Mathematics, all of which are very active areas of mathematical research. The objectives of this workshop are to chart promising research directions in these areas, to survey the state-of-the-art of theory and practice, to identify emerging problems driven by applications, and to discuss new approaches for solving these problems. The blend of topics of the workshop provides a unique opportunity for participants in these areas of research to meet as a group, and the workshop solicits participants at all stages of their careers --- from students to international leaders in their disciplines.<br/> <br/>The workshop participants explore how new methodology from variational analysis has surprising fundamental consequence in economics; in particular, concerning the existence of stable solutions the theory of economics. Another topic explored at the workshop is the use of variational methods in financial trading. The participants also present the state of the art on using the computer to generate and prove mathematical identities and formulas. This type of tool provides scientists with a dynamic reference source for the sort mathematics often used in scientific calculations and applications. The workshop participants also study applications of optimization in image reconstruction which related to medical imaging technology such as MRIs. Another intriguing topic of the workshop is the exploration of the fractal distribution of brain synapses and how fractals can be used to model real-world laboratory situations of this kind. All presentations from the workshop are streamed live over the internet and videos of those presentations are archived permanently at the conference website."
"1065972","FRG: Collaborative Research: Error Quantification and Control for Gravitational Waveform Simulation","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","06/15/2011","05/29/2013","Michael Holst","CA","University of California-San Diego","Continuing Grant","Henry Warchall","05/31/2015","$454,905.00","Melvin Leok","mholst@math.ucsd.edu","9500 GILMAN DRIVE","LA JOLLA","CA","920930021","8585344896","MPS","1266, 1271","1616, 9263","$0.00","The purpose of this project is to develop practical rigorous methods for estimating the error in computed waveforms from gravitational wave simulation with reliable accuracy, in support of the NSF-funded Laser Interferometer Gravitational Observatory (LIGO).  The project brings together a team of applied and computational mathematicians with expertise in constructing error estimates for solutions of partial differential equations and physicists with expertise in numerical solutions of the Einstein equation and gravitational wave data analysis.  The primary technical goal is to develop and analyze new mathematical and computational methods that can be used by the gravitational physics community to compute rigorous and reliably accurate estimates for the errors of numerical solutions of the Einstein equations and the gravitational waveforms that are determined from them.  In particular, this research explores the following issues:<br/>(1) Error quantification and a posteriori analysis using adjoint sensitivity techniques, and their associated numerical implementation;<br/>(2) Adaptive algorithms that are driven by goal-oriented error control, and their associated theoretical convergence analysis; and<br/>(3) The role of covariance symmetry and associated geometric structures in error analysis and the construction of numerical methods.<br/>As part of the a posteriori analysis, the project team will develop the basic theory of adjoint operators and duality for the Einstein equations. This will provide the foundation for future investigations into sensitivity analysis, data assimilation and uncertainty quantification for using LIGO data. It should be emphasized that the main thrusts of the proposed research are discretization-neutral, and therefore have broad applicability to the breadth of numerical relativity codes in existence.<br/><br/>The NSF-supported Laser Interferometer Gravitational Observatory (LIGO) can be successful only if highly accurate gravitational waveform models are available for use as part of the data analysis process, both for detecting gravitational waves and also for measuring the physical properties of any detected signals.  The strongest sources of gravitational waves are expected to be collisions between heavy, dense stars or black holes, which can only be modeled accurately using complex numerical simulations to calculate the anticipated gravitational waveforms.  Such waveforms are needed to construct the filters that allow detection of the weak gravitational-wave signals in the noisy detector, and such waveforms are also needed to measure the physical properties of the sources of any detected signals.  The waveform accuracy needed to accomplish the required data analysis tasks is quite high.  However, the numerical relativity community has yet to develop the analytic and computational tools needed to evaluate rigorously the accuracy of the numerical waveform models.  If the qualitative accuracy measures currently used by the numerical relativity community are too optimistic, the rigorous new methods developed by this project could make the difference between success and failure of LIGO.  If the current numerical waveforms are in fact accurate enough, the methods developed by this project could improve the computational efficiency of determining waveforms with a specified accuracy level, and thus reduce the cost of producing them."
"1134934","Second Workshop on Computational Issues in Nonlinear Control","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/01/2011","08/17/2011","William McEneaney","CA","University of California-San Diego","Standard Grant","Michael Steuerwalt","08/31/2012","$25,000.00","","wmceneaney@ucsd.edu","9500 GILMAN DRIVE","LA JOLLA","CA","920930021","8585344896","MPS","1266, 1271","7556","$0.00","The investigators are organizing the Second Workshop on Computational Issues in Nonlinear Control, which will be held in Monterey, California during the first half of November, 2011. This workshop will bring together top researchers in the areas of numerical methods for nonlinear control as well as related areas of computational methods.  This will include researchers from the US, Europe and Australia.  Further, a significant portion of the workshop attendees will include graduate students, postdoctoral fellows, and junior faculty.  Researchers from lesser-known institutions within the southwestern US, specifically including members of the CalState system will be invited as well. In addition to the PI, Prof. W. McEneaney (UC San Diego), the organizers include Profs. W. Kang and A.J. Krener of the Naval Postgraduate School.  The website of the conference is http://www.nps.edu/Academics/Schools/GSEAS/Departments/Math/pdf_sources/MWCINC2.pdf .<br/><br/>Major developments in the theory of nonlinear control began taking place roughly a half-century ago. Of course, further advances in the theory have been made since. However, over the intervening decades, application of this theory has seriously lagged due to the lack of sufficiently fast and robust associated numerical methods. A particularly vexing problem has been the so-called curse-of-dimensionality, which loosely speaking, refers to the fact that standard numerical methods for these problems have been such that the computational requirements grow exponentially with problem complexity. In fact, numerous advances in control were partly motivated as means for avoiding this numerical bottleneck. In recent years, a number of remarkable new approaches have been developed to combat the fundamental computational difficulties. At this workshop, we will share ongoing developments in order to accelerate this progress."
"1115865","Mathematical Models and Adaptive Algorithms for Tumor Growth","DMS","COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY","09/15/2011","09/08/2011","Serge Prudhomme","TX","University of Texas at Austin","Standard Grant","Junping Wang","08/31/2015","$319,987.00","J. Tinsley Oden","serge@ices.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271, 7334","9263","$0.00","The objectives of the proposed project are to develop physically sound and mathematically rig-<br/>orous diffuse-interface models for tumor growth, to analyze the well-posedness of problems based on<br/>these models, to design efficient time-stepping schemes and finite-element discretization algorithms,<br/>to build the computer software implementing these algorithms, and to develop solution verification<br/>methods based on a posteriori error estimation. The focus of the research work will be on the devel-<br/>opment and analysis of mathematical models that describe at the continuum scale avascular growth<br/>of tumors, i.e. in the absence of nearby blood vessels, and aim at predicting the evolution of large tu-<br/>morous regions while ignoring the behavior of individual cells. Continuum models of tumor growth<br/>can be derived from first principles through the continuum theory of mixtures. Mixture theory pro-<br/>vides an elegant and general framework for modeling multicomponent media such, as living tissue,<br/>composed of several species of interacting constituents. A remarkable property of phenomenological<br/>models based on mixture theory is that, when considering the concentration gradients of various<br/>constituents into the Helmholtz free energy functionals, one obtains diffuse-interface models that<br/>introduce smooth transitional boundaries between the various constituents. The resulting equa-<br/>tions are systems of the Cahn-Hilliard type, namely complex systems of nonlinear time-dependent<br/>fourth-order partial-differential equations. Such diffuse-interface tumor-growth models have been<br/>proposed only recently in the literature and the mathematical analysis and development of efficient<br/>discretizations for such systems are only in the initial stage. The main objectives in this research<br/>project are thus to address several important open issues related to the development of spatio-<br/>temporal diffuse-interface phase field models for computer predictions of tumor growth, including:<br/>(1) development of formulations that satisfy thermodynamical properties of the system; (2) devel-<br/>opment of a rigorous mathematical framework for the analysis of tumor-growth models based on<br/>gradient ow theory; (3) development of new stable and high-order accurate time-stepping schemes<br/>by using semi-implicit splitting approaches; and (4) development of efficient goal-oriented error<br/>estimation algorithms for the control of spatial and temporal discretization errors for the highly<br/>nonlinear time-dependent coupled problem embodied by the proposed tumor-growth models.<br/><br/>Cancer is a disease of the genome, characterized by uncontrolled cellular growth and invasion,<br/>that afflicts every year millions of Americans from all age categories. The primary motivation<br/>of the research project is thus concerned with one of the grand challenges of our times, that<br/>is, to understand the mechanisms of cancer so that reliable treatments, or better, preventative<br/>measures, can be determined to relieve the impact this disease has on so many people. It has<br/>turned out to be a difficult endeavor, due to many reasons, but the most important ones could<br/>be that there are more than one hundred different types of cancer and the causes and effects of<br/>each type occur on a wide range of scales-specific mutations happen at the molecular scale while<br/>tumors may invade a significant portion of the human body. It is not too uncommon to believe<br/>that biologists or medical physicians are the main players in cancer research; however, more and<br/>more scientists from other disciplines, such as mathematics or physics, are getting involved in<br/>the investigation of possible causes of tumor development and behavior. It is in fact our hope<br/>that mathematical and computational tools could provide new insights that could help guide more<br/>fundamental research issues to be addressed by biologists and medical physicians. We believe that<br/>computer simulations represent powerful means for furthering discovery and acquiring scientific<br/>knowledge. These simulations will help in the future explore detailed mechanisms of tumor growth<br/>in natural environments that cannot be directly studied in patients."
"1112612","RUI: Large-scale Algorithm Analysis and GPU Implementations for Compressed Sensing and Matrix Completion","DMS","COMPUTATIONAL MATHEMATICS, EPSCoR Co-Funding","08/01/2011","07/25/2011","Jeffrey Blanchard","IA","Grinnell College","Standard Grant","Rosemary Renaut","07/31/2016","$160,080.00","","blanchaj@grinnell.edu","733 BROAD ST","GRINNELL","IA","501122227","6412694983","MPS","1271, 9150","9150, 9229, 9263","$0.00","This project considers the fusion of two timely research topics: algorithms for compressed sensing and matrix completion, and their implementation using graphical processing units (GPUs). Compressed sensing is a relatively new paradigm in signal processing where the acts of acquiring a signal and compressing the measurements are combined into a single operation. The number of compressed measurements acquired is proportional to the information content of the signal rather than, as is traditional, equal to the ambient dimension of the signal.  Although the number of measurements is significantly reduced resulting in an undetermined system of equations, low-complexity greedy algorithms can be guaranteed to reconstruct an accurate approximation to the measured signal provided that the underlying signal was sparse, i.e. had only a few important components. Matrix completion similarly exploits the simplicity of the target matrix having only a few independent columns; in other words, one recovers a low rank matrix from a limited number of measurements. Typical applications include compressive radar, geophysical data analysis, medical imaging, and computer vision. The data sets from these applications are typically, however, at least an order of magnitude beyond the currently available simulation levels.  By employing the computational power of GPUs this project provides a platform for overcoming computational barriers and the necessary large-scale testing on problems up to three orders of magnitude beyond current empirical testing regimes.<br/><br/><br/><br/>Traditionally, a signal is measured by acquiring every component in the signal and then compressing the signal with an appropriate computational algorithm.  For example, digital cameras capture an image with a huge number of pixels and then a compression scheme such as JPEG is used to reduce the size of the digital image for storage or dissemination.  In many cases, the costs and challenges associated with taking measurements are considerable.  In compressed sensing and matrix completion, the measurement process is altered in order to reduce the number of measurements but the signal reconstruction process is necessarily more difficult.  Compressed sensing and matrix completion transfer the workload from the measurement process to computational resources dedicated to the signal reconstruction.  A typical example in medical imaging is magnetic resonance imaging (MRI) where the time required to obtain a diagnostic level MRI causes unnecessary discomfort for patients and even pediatric sedation.  Compressed sensing MRI has demonstrated the ability to produce diagnostic caliber images in a fraction of the time.  The increased computational burden requires fast, efficient algorithms and many such algorithms have been introduced or updated for compressed sensing.  The observed performance of these algorithms is substantially superior to their pessimistic theoretical guarantees, but testing of these algorithms has been constrained by their imposed computational burden. In this project, the PI and collaborators  develop software capable of providing near real-time signal reconstruction from compressed measurements through development of new techniques, and by exploiting the computational performance gains offered by new architectures with graphical processing units. The resulting software validation is aimed to provide practioners with guidance on algorithm choice most appropriate to the application.  Undergraduate students at the PI's institution have the opportunity to participate in the PI's research  and are exposed to the challenges presented, but gains to be achieved, when exploiting new scientific computing architectures."
"1114816","An Integrated Framework for High-Order Aeroacoustics of Complex Configurations","DMS","COMPUTATIONAL MATHEMATICS","10/01/2011","09/13/2011","Antony Jameson","CA","Stanford University","Standard Grant","Leland Jameson","09/30/2014","$425,354.00","","antony.jameson@tamu.edu","450 JANE STANFORD WAY","STANFORD","CA","943052004","6507232300","MPS","1271","7569, 9263","$0.00","Direct numerical simulation of noise production and propagation remains prohibitively expensive for engineering problems due to resolution requirements. Consequently, hybrid approaches are adopted, which consist of predicting near-field flow quantities via a suitable computational fluid dynamics simulation, and far-field sound radiation by aero-acoustic integral methods, or acoustic analogy formulations. It is critical that the complex flow physics associated with sound generation in the near field is accurately captured by the computational fluid dynamics simulation. Therefore, it is necessary to use a high-order numerical scheme with very low dispersion/dissipation errors. Also, the most significant airframe noise sources are landing gear and high-lift components, such as slats and flaps. The geometric complexity of these components calls for use of numerical methods that can perform well on unstructured grids. The high-order Vincent-Castonguay-Jameson-Huynh (VCJH) schemes recently developed by the principal investigator and colleagues at Stanford University with National Science Foundation funding satisfy both of the aforementioned requirements. In the present work, a state-of-the-art computational framework will be developed for performing aero-acoustics simulations by integrating advanced sub-grid scale (SGS) models for large-eddy simulations (LES) of turbulent flow, and a new Ffowcs Williams-Hawkings (FWH) acoustic analogy formulation for sound propagation, with a graphical processing unit (GPU) enabled high-order VCJH flow solver for unstructured grids. The resulting software will enable the principal investigator and colleagues to undertake high-fidelity large scale aero-acoustics simulations over complex configurations at an affordable cost. The ability to perform such simulations will greatly facilitate design of new aircraft with reduced noise signatures.<br/><br/>The future growth of commercial air transportation (currently predicted to triple by the year 2030) may be severely limited by its adverse environmental impacts (both emissions and noise). Noise regulations have become, and will continue to become, increasingly stringent, and noise reduction is now a major consideration in the design of transport aircraft. Although computer simulations currently play a major role in airplane design, their ability to predict noise, and in particular airframe noise (which is the largest component of noise during landing) remains very limited. The principal investigator and his colleagues aim to combine new mathematical and computational techniques to advance the state-of-the-art in noise prediction, and thereby enable design of new, quieter aircraft, with the ultimate target of restricting their noise footprint to within airport perimeters. A successful outcome is significant to the United States economy because commercial aircraft continue to be the largest single export sector."
"1115915","Topics in Geometric and Multiscale Numerical Methods","DMS","COMPUTATIONAL MATHEMATICS","07/15/2011","07/08/2011","Thomas Yu","PA","Drexel University","Standard Grant","Junping Wang","06/30/2015","$230,825.00","","yut@drexel.edu","3141 CHESTNUT ST","PHILADELPHIA","PA","191042816","2158956342","MPS","1271","9263","$0.00","There is an emerging interest in various disciplines<br/>of science and engineering to develop parsimonious multiscale<br/>representations of data that `lives' on a Riemannian manifold or<br/>Lie group. Such application areas are growing by leaps and bounds<br/>and cognate application problems are arising all the time.<br/>Diffusion tensor imaging and collaborative motion modelling are<br/>simple examples of new sensor types and deployments that give rise<br/>to massive volumes of data taking values in nonlinear manifolds.<br/>We believe that many more such methods are going to be seen in the<br/>future. The first proposed project allows a kind of<br/>multiscale representation of nonlinear data that does for such<br/>data what wavelets were able to do for images and signals. The<br/>resulted multiscale representations are the key to data<br/>compression, feature extraction, noise removal, fast search, and<br/>many other important problems that arise in exploiting such data.<br/>There is also an increasing need to extend the current subdivision<br/>methods to handle also functions, vector fields, 1-forms, etc. on<br/>2-D and 3-D manifolds of arbitrary topology. The second proposed project<br/>addresses part of these needs. The holy grail is to design<br/>numerical algorithms that, in an appropriate sense, respect the<br/>geometric or topological characteristics of the underlying<br/>problem. The third proposed project is motivated by the<br/>vast interests in nanotechnologies. It is speculated that<br/>computational nanoscience may gradually take the forefront of<br/>scientific computing in the same way that computational fluid<br/>dynamics was at the forefront of scientific computing for<br/>several decades. In this project we study a central method in<br/>electronic structure computation known as the Kohn-Sham<br/>functional minimization problem. A specific geometric structure is proposed to be studied. The ultimate goal is to take full advantage of the smooth manifold structure underlying the problem to come up with linear scaling methods that are more efficient, more robust and possess provable, well-understood convergence properties.<br/><br/>Our immediate goal of analysis and synthesis of many new types of data, especially those taking values in nonlinear manifolds, as well as functions, vector fields, and differential forms on free-form manifolds, fits right into the broad and fundamental goal of finding efficient ways to organize and manipulate enormous and complex volumes of high-dimensional geometric data. The need of such methods is ubiquitous in science and engineering, so the potential impact of the project is even wider. We also believe that our focused effort here will eventually find their way into large scale scientific and engineering simulation problems, as the fields of computer-aided geometric design and computer-aided engineering are currently converging to each other. In a different direction, we combine rigorous geometric and numerical ideas to attack a central<br/>problem in electronic structure calculations. The broader impact of this project is evident from the the world-wide interests in material sciences and nanotechnologies. These projects also provide interdisciplinary research and training opportunities for graduate students, and stimulates collaboration among computational mathematicians, engineers and scientists. The publicly available software implementation of our research results further facilitates such training and collaborations."
"1115421","Novel Discretization Schemes for Fully Nonlinear Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","08/01/2011","07/08/2011","Michael Neilan","LA","Louisiana State University","Standard Grant","Junping Wang","08/31/2012","$127,184.00","","neilan@pitt.edu","202 HIMES HALL","BATON ROUGE","LA","708030001","2255782760","MPS","1271","9150, 9263","$0.00","The aim of this project is to develop, analyze, and implement the finite element method for fully nonlinear second order partial differential equations (PDEs).  The research is based on a recent discovery of the PI that Lagrange finite element methods and discontinuous Galerkin methods can be used to approximate the Monge-Ampere equation, the prototypical fully nonlinear second order PDE.  As these methods are simple to implement, the computation of the highly nonlinear problem can be performed efficiently and accurately.  The project will expand on these results to obtain simple, efficient, yet accurate numerical schemes for a general class of fully nonlinear equations.  In addition, the PI will develop and analyze various discretization methods including mixed finite element methods, local discontinuous Galerkin methods, hybridizable Galerkin methods, and Petrov Galerkin methods.<br/><br/><br/><br/>Mathematical modeling plays a key role in the investigation and understanding of many phenomena occurring in the natural sciences, the social sciences and engineering.  Yet even for simple problems, closed form solutions are unavailable, and therefore their numerical approximations are the only viable option. As the problems become ever more complex, the need for novel computational methods and innovative analysis becomes imperative to put the United States in the forefront in science and engineering.  The class of problems studied in this project arise in numerous mathematical modeling applications including weather phenomena, determining the initial shape of the universe, optimal reflector design, differential geometry, optimal transport, mathematical finance, image processing, and mesh generation.  Despite their significance in the physical sciences and pure and applied mathematics, the numerical approximation of these problems remains a relatively untouched area.  Therefore, there is a growing need to develop accurate schemes for these types of equations.  As progress of solving any of these application problems largely depends on progress of solving their governing equations, and since numerical methods for these equations are still in their infancy, any progress in the design, implementation, and convergence analysis will have an immediate impact in advancing these application areas."
"1115616","Collaborative Research: Inversion of the Broken-Ray Radon Transform and Applications","DMS","COMPUTATIONAL MATHEMATICS","07/01/2011","07/01/2011","Vadim Markel","PA","University of Pennsylvania","Standard Grant","Junping Wang","06/30/2014","$162,944.00","","vmarkel@pennmedicine.upenn.edu","3451 WALNUT ST STE 440A","PHILADELPHIA","PA","191046205","2158987293","MPS","1271","9263","$0.00","This project assembles a team of applied and computational mathematicians and physicists to develop, analyze and implement reconstruction algorithms for the broken-ray Radon transform (BRT) and its generalizations. The BRT describes the propagation of single-scattered particles or waves. This situation is typical of x-ray imaging at clinical energies or optical imaging of nearly transparent tissues and model organisms. The intent of the proposed research is to provide theoretically, numerically justified and practically applicable reconstruction algorithms for the BRT with applications to both x-ray computed tomography and optical tomography in the weak-scattering regime. In particular, the investigators propose to derive and analyze BRT-based scanning protocols and corresponding inversion techniques to reconstruct the absorption and scattering coefficients. Associated scanning protocols, which provide the optimum balance between spatial resolution and stability to noise, are to be developed. In addition, questions of uniqueness and stability (in the scale of Sobolev spaces) are a concern. Techniques of microlocal analysis may be used to characterize the propagation of singularities.  Efficient numerical algorithms for inverting the BRT are to be implemented and tested using data derived from radiative transport forward solvers that account for both single- and multiple-scattering, hence connecting the research to the experimental regime. <br/><br/>One of the grand challenges in imaging is to address the problem of scattering. <br/>It is generally believed that only unscattered particles or waves carry useful information about the medium through which they have traveled. The Investigators aim to show that this is not the case. By making use of mathematical methods and computational approaches that exploit the presence of scattering, they seek to transform a variety of biomedical and security-related x-ray and optical imaging technologies. This research is a collaboration between applied and computational mathematicians and physicists and their work with three graduate students. Broad dissemination of the results of the research is anticipated through publications and generation of publicly available software."
"1065942","FRG: Collaborative Research: Dynamical Processes in Many-Body Systems: Analysis and Simulations","DMS","COMPUTATIONAL MATHEMATICS","07/01/2011","05/24/2016","Carlos Garcia-Cervera","CA","University of California-Santa Barbara","Standard Grant","Leland Jameson","06/30/2017","$516,674.00","","cgarcia@math.ucsb.edu","3227 CHEADLE HALL","SANTA BARBARA","CA","931060001","8058934188","MPS","1271","1616, 9263","$0.00","The quantum physics of many interacting electrons lies at the foundation of chemistry and condensed matter physics. A direct treatment of the many-electron problem is impossible due to its shear complexity: dealing with N interacting electrons requires solving partial differential equations in 3N dimensions. Equilibrium and non-equilibrium Density Functional Theories (DFT) are rigorous and formally exact theories which map the interacting N-electron problem into a non-interacting N-electron problem. The non-interacting electrons move in an effective potential that has a universal functional dependence on the total electron density. As a result, the problem is reduced to a problem in dimension 3, amenable for computation. In this proposal the PIs propose to study a number of dynamical problems in many-body quantum mechanics within an interdisciplinary environment of mathematicians and physicists. In particular, the PIs  propose to develop further the mathematical foundations of density-functional theory, for equilibrium as well as the time-dependent case. The mathematical structure of the theory and its solutions will be further investigated and the insight from this analysis will be used to develop efficient numerical simulations. Particular emphasis will be given to the treatment of the spin-orbit interaction, within the full relativistic formulations and in non-relativistic formulations that include relativistic corrections. The PIs also plan to establish the foundations of the Dissipative Time-Dependent Density Functional Theory, and to apply the theory to the problem of charge and spin transport in materials.<br/><br/>The present technological progress is in great part based on design and discovery of new materials. Nowadays, the design of advanced materials involves laboratory work and computer simulations. Enhancing the accuracy and efficiency of computer simulations will reduce the costs, broaden the array of interesting and potentially useful materials, and speed up the process of testing and characterization. This is the target of the proposed research. The plan is to combine rigorous mathematical analysis, the insights from physics, chemistry and computer simulations in order to push the boundaries of theoretical simulations of advanced materials such as nano-structured materials, topological insulators and molecular electronic devices. The proposed research could have significant technological impact in applications such as nano-science and other areas of interest such as solar cell devices and energy conversion and storage. The PIs propose to integrate research and education by involving undergraduate and graduate students, and post-doctoral associates, in an interdisciplinary environment. Special attention will be paid to the recruitment of women and students from other underrepresented groups through the utilization of a diverse number of programs at the participating institutions."
"1065894","FRG: Collaborative Research: Dynamical Processes in Many-Body Systems: Analysis and Simulations","DMS","COMPUTATIONAL MATHEMATICS","07/01/2011","05/17/2011","Weinan E","NJ","Princeton University","Standard Grant","Junping Wang","06/30/2014","$622,645.00","Roberto Car","weinan@princeton.edu","1 NASSAU HALL","PRINCETON","NJ","085442001","6092583090","MPS","1271","1616, 9263","$0.00","The quantum physics of many interacting electrons lies at the foundation of chemistry and condensed matter physics. A direct treatment of the many-electron problem is impossible due to its shear complexity: dealing with N interacting electrons requires solving partial differential equations in 3N dimensions. Equilibrium and non-equilibrium Density Functional Theories (DFT) are rigorous and formally exact theories which map the interacting N-electron problem into a non-interacting N-electron problem. The non-interacting electrons move in an effective potential that has a universal functional dependence on the total electron density. As a result, the problem is reduced to a problem in dimension 3, amenable for computation. In this proposal the PIs propose to study a number of dynamical problems in many-body quantum mechanics within an interdisciplinary environment of mathematicians and physicists. In particular, the PIs  propose to develop further the mathematical foundations of density-functional theory, for equilibrium as well as the time-dependent case. The mathematical structure of the theory and its solutions will be further investigated and the insight from this analysis will be used to develop efficient numerical simulations. Particular emphasis will be given to the treatment of the spin-orbit interaction, within the full relativistic formulations and in non-relativistic formulations that include relativistic corrections. The PIs also plan to establish the foundations of the Dissipative Time-Dependent Density Functional Theory, and to apply the theory to the problem of charge and spin transport in materials.<br/><br/>The present technological progress is in great part based on design and discovery of new materials. Nowadays, the design of advanced materials involves laboratory work and computer simulations. Enhancing the accuracy and efficiency of computer simulations will reduce the costs, broaden the array of interesting and potentially useful materials, and speed up the process of testing and characterization. This is the target of the proposed research. The plan is to combine rigorous mathematical analysis, the insights from physics, chemistry and computer simulations in order to push the boundaries of theoretical simulations of advanced materials such as nano-structured materials, topological insulators and molecular electronic devices. The proposed research could have significant technological impact in applications such as nano-science and other areas of interest such as solar cell devices and energy conversion and storage. The PIs propose to integrate research and education by involving undergraduate and graduate students, and post-doctoral associates, in an interdisciplinary environment. Special attention will be paid to the recruitment of women and students from other underrepresented groups through the utilization of a diverse number of programs at the participating institutions."
"1115568","Fast TV-Regularized Large-Scale and Ill-Conditioned Linear Inversion with Application to PPI","DMS","COMPUTATIONAL MATHEMATICS","09/15/2011","09/15/2011","William Hager","FL","University of Florida","Standard Grant","Junping Wang","08/31/2014","$241,579.00","Yunmei Chen","hager@ufl.edu","1523 UNION RD RM 207","GAINESVILLE","FL","326111941","3523923516","MPS","1271","9263","$0.00","The research of the PIs is focused on the development of new algorithms to generate images from data acquired through the emerging Magnetic Resonance (MR) technology known as Partially Parallel Imaging (PPI).  Several fast algorithms for obtaining TV (total variation) regularized images have already been developed, but for efficiency require that the underlying matrices satisfy specific properties, that do not hold for PPI acquired data. Algorithms which can be applied for a general matrix are too slow for real time practical application.  The goals of the PIs' research are to both study and compare recently developed fast methods, as well as to develop novel, fast and accurate algorithms suitable for general large-scale ill-conditioned inversion problems. Image reconstruction requires the fast solution of two problems, a sparsification problem known as the basis pursuit denoising problem, and a TV problem.  Efficiency for the basis pursuit denoising problem is achieved using active set techniques, while efficiency for the TV problem relies on splittings which reduce the original problem into subproblems that can be solved quickly. Convergence and statistical reliability of the algorithms will be established.  The PIs' research will also provide extensions of the algorithms for the solution of related TV-based problems for obtaining more general classes of images.<br/><br/>This research  has broad impact on Partially Parallel Magnetic Resonance imaging technology.  Magnetic resonance imaging is commonly used in radiology to non-invasively visualize the internal structure and function of the body. It provides better contrast between the different soft tissues than most other modalities.  Due to the time needed to acquire an image, the cost of this technology can be high. Also motion effects can lead to image degradation.  The algorithms to be developed by the PIs will reduce scan time, while improving the accuracy of the reconstructed images.  More generally, these algorithms have the potential for impact on applications which require the solution of large, ill conditioned, nonsmooth inversion problems."
"1057064","CAREER: Numerical Multilinear Algebra and Its Applications - From Matrices to Tensors","DMS","COMPUTATIONAL MATHEMATICS, Algorithmic Foundations","03/01/2011","01/13/2011","Lek-Heng Lim","IL","University of Chicago","Standard Grant","Leland Jameson","02/28/2017","$550,000.00","","lekheng@galton.uchicago.edu","5801 S ELLIS AVE","CHICAGO","IL","606375418","7737028669","MPS","1271, 7796","1045, 7933, 9263, OTHR","$0.00","The PI will extend extensive studies in numerical linear algebra to the numerical multilinear algebra setting, which complements and enriches the underlying linear framework.   The PI's prior work has laid foundations for this new subject via (1) mapping the boundary between the possible and impossible, the computable and non-computable; and (2) extending several matrix notions to tensors (e.g. eigenvalues, singular values, Schatten, Ky Fan norms, Perron-Frobeniuis theorem). This project takes the next step -- developing the requisite algorithms for problems that sit within these boundaries. While almost all 'algorithms' currently in use for tensor problems lack correctness and convergence guarantees, the ones developed for this project strive to be algorithms in the true sense of the word, i.e. meeting the basic requirement of convergence to a true solution and not just a stationary or fixed point. This is in general not possible but the PI will (i) identify large classes of interesting cases for which efficient, provably convergent algorithms exist; and (ii) exploit multilinearity and tap the existing rich collection of linear techniques. These design principles and goals will be applied to algorithmic development of all following problems: (a) Low rank tensor approximations; (b) eigenvalues and singular values for tensors; (c) systems of multilinear equations in the exact and least-squares sense. The PI will also demonstrate the utility of numerical multilinear algebra by proposing several new tools in telecommunications, bioinformatics, and neuroimaging.<br/><br/>Almost all engineering, scientific, and statistical computing problems may ultimately be reduced to a handful of standard problems in linear algebra. <br/>Therefore one may argue that computational linear algebra is the workhorse of computations in science and engineering. This project is about expanding this fundamental arsenal of tools by going from ""linear"" to ""multilinear"". To achieve this, one must first realize that while there are natural extensions of the aforementioned handful of linear problems, there are also subtle difficulties and even impossibilities associated with these multilinear analogues. The crux of the project is to carve out a substantial tractable subclass of problems that are nevertheless still useful in applications. The project would also examine three concrete applications to brain imaging, cellular phone communication, and analytical chemistry."
"1115097","Adaptive Finite Element Method for Interface Problems","DMS","COMPUTATIONAL MATHEMATICS","07/15/2011","05/07/2013","Xiu Ye","AR","University of Arkansas Little Rock","Continuing Grant","Leland Jameson","06/30/2015","$231,053.00","","xxye@ualr.edu","2801 S UNIVERSITY AVE","LITTLE ROCK","AR","722041000","5015698474","MPS","1271","9150, 9263","$0.00","The objective of the project is to develop and to analyze a robust adaptive finite element method for the Darcy-Stokes-Brinkman model with extremely variable or discontinuous parameters. The proposed research include:  developing a robust adaptive H(div) finite element method; conducting a priori error analysis; deriving efficiency and reliability bounds for a posteriori error estimators; proving convergence of adaptive mesh refinement procedures; developing a computer program for implementation of the method.<br/><br/>The Darcy-Stokes-Brinkman model has wide range of applications such as surface and sub-surface water interaction in geoscience, blood circulation in health science and, fuel cells, filtration problems in environment science. Solving these problems has attracted a lot of attention from mathematicians and engineers, and many works have been done in developing and analyzing numerical algorithms for Darcy-Stokes-Brinkman model. Majority of these works treat viscosity and permeability as either constant or near zero jump. However, for the practical relevant problems, these physical parameters are either discontinuous or highly variable. Singularity caused by the highly varied physical parameters creates tremendous difficulty in development of numerical algorithms. There is a great interest in obtaining efficient and robust numerical methods to simulate these real word problems."
"1114889","Hybrid Methods for the Time Domain Integral Equations of Computational Electromagnetics","DMS","COMPUTATIONAL MATHEMATICS","08/15/2011","08/12/2011","Daniel Weile","DE","University of Delaware","Standard Grant","Junping Wang","07/31/2015","$289,938.00","Peter Monk","weile@eecis.udel.edu","220 HULLIHEN HALL","NEWARK","DE","197160099","3028312136","MPS","1271","9150, 9263","$0.00","The project ""Hybrid methods for the time domain integral equations of electromagnetics"" advances a multidisciplinary program consisting of basic numerical analysis of time domain integral equations (TDIEs) and a two-fold program of hybridization.  The basic numerical analysis is devoted to issues of sparsification, quadrature error, error estimates and fast solvers for a new and exciting class of TDIE methods based on convolution quadrature (CQ-TDIE). The first prong of the hybridization work concerns combining CQ-TDIE with the volume finite element method.  Not only would this hybridization allow for the easy simulation of inhomogeneous and complex media, but it also raises the tantalizing prospect of a perfect time domain integral based boundary condition. The second, and more speculative, hybridization approach  combines CQ-TDIE with older Galerkin-based techniques with the aim of controlling dispersion and dissipation.  It is anticipated that the resulting hybrid methods have the stability and spatial accuracy of CQ, but with the greater efficiency and reduced dispersion associated with Galerkin approaches.  In particular, the technique would be ideally suited for the analysis of certain classes of modern technology involving long propagation distances through homogeneous regions (as occur in electromagnetic interference analysis) or mechanically moving parts (as necessary in many nanotechnology problems).<br/><br/><br/><br/>Numerical simulation of physical processes reduces business prototyping costs, enables the safe prediction of the outcome of dangerous experiments, and can even make scientific discoveries by illuminating internal processes difficult to examine in the laboratory.  In an era dominated by personal communication technology, the simulation of electromagnetic phenomena becomes especially crucial. ""Hybrid methods for the time domain integral equations of electromagnetics"" creates two new methods for the simulation of the interaction between electromagnetic fields and matter.  While computerized approaches to electromagnetic analysis already exist, the methods to be created by the investigators allow for more accurate and efficient simulation of problems involving biological tissue, long propagation distances (such as occur in communications simulations), and mechanically moving parts (as needed in nanotechnology simulations).  In addition to these benefits, the new method represents an important mathematical advance: it is based on a technique thought unstable for over three decades, which has only recently been made practical.  The investigators therefore expect that the advances made in the analysis of electromagnetic problems under the auspices of this work will be easily translated to other scientific areas including acoustics, solid mechanics, and fluid mechanics."
"1115632","Wick-type Stochastic Modeling: Algorithms and Applications","DMS","COMPUTATIONAL MATHEMATICS","07/01/2011","06/09/2011","Xiaoliang Wan","LA","Louisiana State University","Standard Grant","Junping Wang","06/30/2015","$100,211.00","","xlwan@math.lsu.edu","202 HIMES HALL","BATON ROUGE","LA","708030001","2255782760","MPS","1271","9150, 9263","$0.00","The goal of this project is to understand mathematically the effect of Wick product, as a generalization of Ito integral, in infinite dimensional space and to develop new algorithms to quantify the uncertainty in complex dynamical systems. Many stochastic models for physical and biological applications include ""noise"" terms to account for the uncertainty in the parameters or interactions of the system. To eliminate the singularity induced by the randomness, regularization or renormalization approaches are often required for stochastic modeling. Originating from the Euclidean quantum field theory as a renormalization technique, the Wick product has a direct and deep mathematical connection with many modern theories of stochastic analysis, such as the white noise analysis and Malliavin calculus. Furthermore, the Wick product has many favorable numerical properties, which give it the potential to deal effectively with problems of high random dimension. Hence, the Wick product formulation provides a rigorous mathematical foundation for analysis but also a promising candidate for developing efficient numerical algorithms for uncertainty quantification. More specifically, this project includes two important issues related to Wick-type stochastic modeling: (1) Stochastic elliptic modeling based on the Wick product; (2) Random perturbations of dynamical systems. For the first problem, the PI will develop new stochastic finite element methods based on a new modeling  strategy given by the Wick product; for the second problem, the PI will develop scalable parallel minimum action methods for random perturbations of high dimensional dynamical systems. <br/> <br/>The developed algorithms can be used in a wide range of physical, biological and engineering applications. The understanding of the Wick product may shed new light on modeling of porous media, and the related algorithms can be applied to engineering applications such as petroleum engineering, underground water,  etc. The effect of random perturbations of dynamical systems can be rare but profound. Typical problems include chemical reactions, bistable genetic toggle switch, nucleation events during phase transitions, regime changes in climate, instability in fluid mechanics, etc. Scalable parallel minimum action methods can help people understand better high dimensional configuration space, which is crucial to study the aforementioned phenomena through large-scale simulations. The PI will disseminate the codes as open source codes via existing external open source websites as soon as the algorithms are developed and tested."
"1115636","Numerical Methods for Free Boundary Problems: Two-Phase Flows and Contact Line Dynamics","DMS","COMPUTATIONAL MATHEMATICS","08/01/2011","07/01/2011","Shawn Walker","LA","Louisiana State University","Standard Grant","Junping Wang","07/31/2014","$90,657.00","","walker@math.lsu.edu","202 HIMES HALL","BATON ROUGE","LA","708030001","2255782760","MPS","1271","9150, 9263","$0.00","The proposed research will develop numerical methods for a variety of free boundary problems. The research will take advantage of variational/finite element methods, stability/energy estimates, and automatic meshing technology in analyzing multi-physics flow problems that exhibit free interfaces and moving contact lines. The project will push the theory of free boundary problems into new and challenging application areas. Specific objectives are: (A) investigate domain representation and deformation by variational front-tracking, level set methods, diffuse interface, or a combination of these approaches; (B) develop and analyze efficient discrete formulations of Electro-Wetting On Dielectric (EWOD) driven fluid droplets in 2-D (with contact line pinning) and explore well-posedness questions of the time-dependent interface motion; (C) explore reduced order modeling of the electric field in EWOD and higher fidelity models; (D) develop an adaptive phase-field method for electro-wetting in 3-D that couples electro-statics to multi-phase fluid flow with contact line pinning; (E) develop a model and numerical method for 2-phase droplets interacting with a solid substrate that accurately handles the fine-scale details of the moving contact line problem; and (F) advance multi-phase meshing technology to handle 3-D problems in a robust and automatic way with attention given to parallel implementation issues. This project will investigate well-posedness of time dependent domain-deforming problems and study mathematical properties of multi-phase flows with non-smooth dynamics (e.g. contact line pinning). <br/><br/>The broader impact of the work arises from its connection with many physical/industrial processes that involve moving boundaries/interfaces. Examples include industrial coating flows that apply a protective layer to a substrate; fluid flows in micro-fluidic devices driven by electric fields (important in the bio-medical field); motion of rigid bodies in a fluid (particulate flows); dynamics of lipid bio-membranes (applications in biology); the peeling of adhesive tape from a rigid support. The research will enable system level modeling and simulation at macroscopic length and time scales for a variety of applications, such as electrowetting 2-phase flow, droplet impacting processes (painting/cooling of surfaces), and coating of solids by films, which can include fine-scale fluid dynamics and chemistry. In addition, the project will create new methods for automatic grid generation of complex shapes that efficiently capture moving boundaries. One outcome of the research will be an automatic meshing tool (i.e. code) which will be made available to the public through the PI's web-site.  Finally, a course on shape optimization (with PDE-constraints) will be developed that gives graduate students expertise in optimization with continuum models."
"1115527","Collaborative Research: An Efficient Computational Approach for Wave and Surge Attenuation in Wetlands and Applications in Flood Risk Reduction","DMS","COMPUTATIONAL MATHEMATICS","10/01/2011","09/21/2011","Qin Chen","LA","Louisiana State University","Standard Grant","Junping Wang","06/30/2015","$154,016.00","","q.chen@northeastern.edu","202 HIMES HALL","BATON ROUGE","LA","708030001","2255782760","MPS","1271","9150, 9263","$0.00","This proposal develops an accurate and efficient method for modeling the interaction of fluid with numerous flexible plant stems (modeled as bendable cylinders) at a wide range of Reynolds numbers. Research activities include deriving new mathematics of kernel functions for bottom-clamped and bendable cylinders, verifying and validating model output, investigating the relation between the drag force and the bending angle and the link between the lateral clearance in a cylinder cluster and the effectiveness of wave and surge attenuation, and upscaling the model to infer macroscale parameters for large-scale simulations to test hypotheses of wetland resilience and flood risk reduction. Three educational programs: Summer Outreach, Minority Internship, and Graduate Student Exchange, provide opportunities for communities and minorities to participate in research and inter-university collaborations.<br/><br/>Continued climate change and sea level rise pose a major threat to coastal habitats and communities worldwide. The impact of sea level rise has caused increased coastal erosion and flooding. For example, owing to subsidence, sea level rise and human interventions, the Mississippi River Delta and the Louisiana coast lose one acre of wetland every 24 minutes, which accounts for 80% of the total annual loss of coastal wetlands in the continental United States. The chronic wetland loss in south Louisiana has considerably weakened the natural defense against catastrophic floods, such as Hurricanes Katrina and Rita (2005). Over 1,500 people lost their lives and several major coastal populations were crippled for months after the hurricanes passed. Mitigating flood damage and reducing the threat of storm surges are imperative. It has been recognized that vegetation in wetlands can effectively reduce the flow speed. Results from the proposed research will not only provide insight to wave and surge attenuation in coastal wet-lands for coastal engineers and managers, but also serve as useful references for mechanical, civil, environmental, and ocean engineering concerning interactions of fluid with structures and plant canopies. The developed simulation tools will benefit society in better protecting the coastal ecosystem from impacts of storms and sea level rise and reducing the risk of flooding. Knowledge gained from the research will be assimilated in multi-channel education to train two graduate students, to involve minorities in mathematical science, and to stimulate the interest of communities in computational mathematics. This project will educate the public about the gravity of coastal flooding and erosion in Louisiana."
"1115228","Analysis of Algorithms for Continuum Models of Complex Materials","DMS","COMPUTATIONAL MATHEMATICS","10/01/2011","09/14/2011","Noel Walkington","PA","Carnegie-Mellon University","Standard Grant","Junping Wang","09/30/2015","$299,883.00","","noelw@andrew.cmu.edu","5000 FORBES AVE","PITTSBURGH","PA","152133815","4122688746","MPS","1271","9263","$0.00","The focus of this project is the analysis of numerical schemes, and<br/>the development of algorithms, to simulate materials which exhibit<br/>intricate rheological behavior or mechanical response due to their<br/>microstructural makeup. Examples include polymers, liquid crystals,<br/>and blood, whose elastic molecules or cells influence the macroscopic<br/>properties at the macroscopic scale.  These materials are modeled by<br/>formidable systems of partial differential equations whose structural<br/>properties capture important properties and physical principles, and<br/>it is important to develop numerical schemes to faithfully inherit<br/>these. This project will bring together tools from partial<br/>differential equations, continuum mechanics, and numerical analysis,<br/>to analyze numerical schemes to simulate these systems. <br/><br/>The ability to simulate complex materials is a key technology required<br/>for the design and development of many next generation products such<br/>as micro-mechanical devices, ink jets, bio-materials, solar energy<br/>devices, and prosthetic organs.  Predicting material response is an<br/>essential tool needed to determine biological or physiological<br/>function; or to design and manufacture these materials; or for the<br/>design of the multitudes of devices which use their special<br/>properties. The research proposed here will result in improved<br/>understanding of the mathematical models and the computational tools<br/>used to accomplish these tasks."
"1115705","Collaborative proposal: Higher-Order Two-Fluid Methods for Simulations of Particle-Laden Flow","DMS","COMPUTATIONAL MATHEMATICS","09/01/2011","01/22/2014","Gustaaf Jacobs","CA","San Diego State University Foundation","Standard Grant","Leland Jameson","08/31/2014","$99,848.00","","gjacobs@mail.sdsu.edu","5250 CAMPANILE DR MC1947","SAN DIEGO","CA","921821901","6195945731","MPS","1271","9263","$0.00","In this effort the PIs and their student develop a high-order two-fluid method based on a new set of coupled two-fluid hyperbolic conservation PDEs and a Hybrid WENO-spectral method. The two-fluid model is unprecedented, obtained from first principles utilizing an Eulerian approach for the description of particles, which have been predominantly modeled through lower-order methods in the Lagrangian frame of the particle. In the Eulerian frame, the particle phase is modeled through a set of hyperbolic Eulerian transport equations governing the behavior of the Probability Density Function of particle properties. The equations are derived by a novel statistical method based on a method of moments via an averaged Liouville equation. The PIs propose to develop a method based on a high-order resolution, hybrid multidomain WENO-spectral method for the two-fluid model. The high- resolution method is projected to improve over existing lower- order method by capturing discontinuous interfaces and shocks sharply, while accurately resolving small scale, unsteady particle-laden flow features.  The focus of this proposal is on the development of a stable and consistent capturing of discontinuous particle-gas interfaces as well as a stable and consistent source coupling between the particle and gas phases. Another focus will be on the regularization of non- linear, singular and stiff source terms that couple the gas and particle PDEs. The two-fluid method will be assessed against published benchmarks, including a one-way coupled isotropic turbulence and two-way coupled shock particle interaction, computed with a more established Eulerian- Lagrangian method.<br/><br/>Explosions and combustion processes generate environments where fluid turbulence and shocks have an intimate and mutual interaction with particles. Various engineered systems and natural processes involve high speed particle dynamics, shock- turbulence interaction, and particle flow interactions; such phenomena play key roles in debris flow and contaminant spread due to explosions, controlling supersonic combustion, high- speed coating processes for high-performance aerospace and electronic components. The volcanic explosions in Iceland, for example, generated shocks, accelerated turbulent gas flows and micro-scale dust particles that were carried for hundreds of miles over several days not only polluting the environment but affecting air traffic for an extended period of time. The proposed research develops an advanced numerical tool that enables (improved) computation of these flows which will ultimately enhance understanding of a large class of engineering and environmental problems. This knowledge can be used directly in design improvements, control of pollution and the effects of explosion processes on society. This proposal, moreover, increases the number of students from underrepresented groups in STEM education by involving students in the Mathematics, Engineering, Science Achievement (MESA) program at SDSU."
"1115420","Collaborative Research: Stable and Efficient Convexity-splitting Schemes for Bistable Gradient PDEs","DMS","COMPUTATIONAL MATHEMATICS","07/15/2011","07/05/2011","Cheng Wang","MA","University of Massachusetts, Dartmouth","Standard Grant","Junping Wang","06/30/2015","$104,283.00","","cwang1@umassd.edu","285 OLD WESTPORT RD","NORTH DARTMOUTH","MA","027472356","5089998953","MPS","1271","9263","$0.00","The goal of this research is to design robust, efficient, and practical numerical methods for bistable gradient equations (BGEs).  These form a a special class of partial differential equations (PDEs) that describe important phenomena in materials, fluids, and biology research. For this work the PIs plan detailed investigations of the slope selection (SS), no slope selection (NSS), phase field crystal (PFC) and Cahn-Hilliard (CH) equations, which are important 4th or 6th-order BGEs that must typically be solved over large space and time scales.  Numerical solution of these equations (and BGEs in general) can pose enormous challenges.  In this work the PIs will develop convex splitting (CS) schemes for BGEs.  CS schemes are 1st or 2nd-order accurate in time and at least 2nd-order accurate in space.  They are simple, powerful, and particularly well-suited to studying large spatiotemporal morphological evolution accurately and efficiently.  1st-order  (in time) CS schemes have been known for about ten years; but, up to now, the underlying theory has been incomplete and their application, somewhat limited.  The proposed high-order CS schemes (2nd-order in time, 2nd-order and higher in space) are novel features of the PIs work.  All CS schemes have two important properties: they are unconditionally energy stable and unconditionally uniquely solvable.  The energy stability can often be exploited to prove various norm stabilities, as well as convergence.  The unique solvability follows from the fact that the schemes are derived as the gradients of strictly convex functionals.  As a result, practical solvers can always be crafted, since gradient descent methods will converge unconditionally.  A big challenge of this work is in designing truly efficient solvers for the potentially highly nonlinear CS schemes.  The PIs have had some early, important successes in this direction, having crafted nearly optimally efficient nonlinear multigrid solvers for the PFC and Cahn-Hilliard-Hele-Shaw (CHHS) equations.  In this work they will extend these achievements by deriving sophisticated, efficient, and time and space adaptive solvers for a variety of BGEs.  The PIs will apply their CS schemes and efficient solvers to study the complicated long-time dynamics of models for thin film coarsening, tumor growth and treatment, two-phase fluid flow, and crystal growth.<br/><br/>BGEs allow researchers to create models of a great number of physical and biological phenomena, and hence this work will have a direct impact on many scientific disciplines. The specific equations that the PIs will focus on (SS, NSS, PFC, and CH equations) are vital for understanding phase transformations of materials at the atomic and nanometer scales, the complex processes in biological growth and development, and the complicated topological change involved in two-phase flows.  For a specific example, the SS equation can be used model the formation of nano-scopic hills and valleys on the surfaces of certain materials, such as those used in semiconductor devices.  Knowing how these nano-structures form and move during device processing is critical for precise manufacture.  Mathematical modeling (using BGEs, for example) is often a more practical alternative to doing laboratory experiments to find ``optimal"" processing procedures.  However, in most practical situations, solutions to BGEs can only be approximated using computerized algorithms.  The primary goal of this research is to develop 2D and 3D algorithms that approximate the solutions as accurately, efficiently, and robustly as possible.  The computer algorithms and source codes created from this work will apply to even more general models than will be explored in this research and will therefore advance the field of computational science as a whole.  The PIs will make their software packages available in the public domain so that researchers will have direct access to their algorithms.  In addition to working toward their research goals, the PIs will help to build and reinforce the human resources pipeline in the field of computational sciences, which is one of the broader goals in STEM education in the US.  Both graduate and undergraduate students will receive training in high-performance scientific computing, numerical mathematics, and modeling; and their work is expected to form the bases of peer-reviewed publications, conference talks, technical reports, and theses.  As a major component of this effort, the PIs will continuously  support and mentor two UMass, Dartmouth undergrads through the CSUMS program.  These students will get hands-on training in algorithm and software development.  This type of training is rare in the typical undergraduate curriculum.  Using this research as a venue, the PIs will work to inspire students, especially undergraduates and those from traditionally underrepresented groups, to pursue careers in science and engineering."
"1115416","Discontinuous Galerkin Methods for Problems with Fractional Derivatives","DMS","COMPUTATIONAL MATHEMATICS","09/01/2011","08/27/2013","Johnny Guzman","RI","Brown University","Continuing Grant","Leland Jameson","08/31/2015","$310,941.00","","Johnny_Guzman@brown.edu","1 PROSPECT ST","PROVIDENCE","RI","029129127","4018632777","MPS","1271","9263","$0.00","In this effort the investigator and his student will consider developments of discontinuous Galerkin methods suitable for solving fractional differential equations. Motivated by a series of preliminary but very encouraging computational experiments, local discontinuous Galerkin methods for both fractional ordinary and partial differential equations will be considered. These initial computational observations supports a number of conjectures and these will guide the development and analysis of the proposed methods. While specific target applications are not considered detail, problems of a more practical character such as computational efficiency, multi-dimensional problems, and alternative formulations will be addressed in the latter part of the effort.<br/><br/>While the notion of fractional calculus is as old as that of classical calculus introduced by Newton, the development and analysis of fractional calculus and fractional equations is not nearly as mature. However, during the last few decades fractional calculus has emerged as a natural and important description for a broad range of non-classical phenomena in the applied sciences and engineering. Examples can be found anomalous transport processes, sub-diffusion, and problems dominated by memory effects. Applications of such models are found in wide range of areas such as porous, visco-elastic, or biological flows, flow of crude oil in reservoirs, fusion plasma problems, modeling of properties of complex materials, financial markets etc. The planned activities seek to develop efficient and accurate computational techniques to allow application scientists and engineers to more effectively solve this important class of models."
"1016150","Causality as a source of efficiency in numerical methods.","DMS","COMPUTATIONAL MATHEMATICS","02/15/2011","08/12/2013","Alexander Vladimirsky","NY","Cornell University","Continuing Grant","Leland Jameson","01/31/2016","$249,212.00","","vlad@math.cornell.edu","341 PINE TREE RD","ITHACA","NY","148502820","6072555014","MPS","1271","9263","$0.00","Iterative methods for large non-linear systems of coupled equations are often prohibitively expensive.  Such systems frequently result from discretizations of static nonlinear partial differential equations, presenting practitioners with a computational efficiency ""bottleneck"". <br/>However, in many applications (from robotic navigation to photolithography, seismic imaging, computational geometry, optics, differential games, and segmentation of images) the direction of ""information flow"" can be used to successively eliminate or at least significantly decrease the coupling of equations, resulting in efficient (often non-iterative) numerical methods.  The related notion of ""causality"" provides an a priori unobvious yet natural ordering of the elements of computation.  The primary investigator and his collaborators have previously introduced such causal algorithms for problems in anisotropic & hybrid deterministic control and for approximations of geometrically stiff invariant manifolds.  Currently, the primary investigator develops efficient algorithms for a wider class of ""structurally causal"" stochastic problems on graphs and in continuous domains.  This includes important special types of uncertainty & stochasticity as well as optimal control problems with multiple length scales.  The investigator and his colleagues also use approximations of Lagrangian manifolds to build efficient methods for recovering multivalued solutions of nonlinear first-order PDEs -- a problem of high practical importance in dispersive waves computations, multiple-arrival seismic imaging and tomography.<br/><br/>Real-time answers to many important practical questions depend on availability of robust and efficient numerical methods for the corresponding partial differential equations.  What is the minimum safe distance for the aircraft collision avoidance?  How should an ""idle"" ambulance be routed in between emergency calls?  Which trajectory is optimal for a rover traveling on the surface of Mars?  The prior numerical techniques help one answer these questions, but only under unrealistic/idealized conditions: a single criterion (e.g., energy-optimal trajectories only), a known terminal time, a single reliable map of the terrain, etc.  The PI's current work makes a difference in incorporating multiple criteria (e.g., time versus energy versus money) and uncertainty (when will the next emergency call be received?) into the decision making process without excessive computational costs."
"1115345","Collaborative Research: Reduced Order Model Approaches for Time Dependent Nonlinear PDE Constrained Optimization","DMS","COMPUTATIONAL MATHEMATICS","08/15/2011","07/01/2011","Matthias Heinkenschloss","TX","William Marsh Rice University","Standard Grant","Junping Wang","07/31/2015","$150,000.00","","heinken@rice.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","MPS","1271","9263","$0.00","This project develops, analyses and implements projection based reduced order models (ROMs) for optimization problems associated with nonlinear evolution partial differential equations (PDEs). These ROMs determine a subspace that  contains the essential (for the optimization) dynamics  of the nonlinear evolution PDEs and project these PDEs onto the subspace. If the subspace is small, the original nonlinear PDEs in the optimization problem can be replaced by a small system of ordinary differential equations and the resulting approximate optimization problem can be solved efficiently. The efficient generation of ROMs together with error estimates that can monitor the quality of the ROMs is challenging. This project expands and integrates ideas from goal oriented adaptive mesh refinement, proper orthogonal decomposition (POD), and model management approaches in optimization to overcome these challenges. Specifically, model management ideas from optimization are used determine at which optimization parameters the nonlinear evolution PDE needs to be solved to generate snapshots for the ROM. Furthermore, for the numerical solution of the PDE and generation of snapshots a combination of goal-oriented dual weighted based adaptive space-time finite element approximations of the PDE and discrete Galerkin-POD will be used. In particular, local-in-time and local-in-space dual weighted residuals for the control of the error in time and the error in space will be obtained that also provide a prediction of appropriate time steps at which snapshots are taken. The goal is the derivation of an a posteriori error estimator for the ROM error that gives us information about the number of reduced basis functions that need to be included. This novel approach will result in an Adaptive Discrete Galerkin-POD (ADGPOD) algorithm for an efficient and reliable ROM-based numerical solution of PDE constrained optimization. In addition the resulting ROMs will be demonstrated on several applications, including flow control/design problems and the optimal control of Asymmetrical-Flow Field-Flow-Fractionation processes for the fast separation of nanoparticles, proteins, and other macromolecules.<br/><br/><br/>The optimal design of processes and systems in engineering and life science applications often requires the optimal control/optimization of systems of nonlinear partial differential equations (PDE). The numerical solution of such problems typically amounts to the solution of large nonlinear algebraic systems requiring extensive storage and computational time. On the other hand, the design engineers are interested to run optimal designs on their PCs within a couple of minutes. This can be achieved only by a dramatic reduction of the dimension of the problem, i.e., by developing a reduced model for the underlying PDE system that captures the essential dynamics of the expensive high fidelity simulation. Although reduced order models have been shown to work well for a wide spectrum of applications, they not yet well understood from a theoretical point of view, especially for nonlinear problems. This project will provide a better theoretical foundation of reduced order models for nonlinear problems, it will develop novel algorithmic tools for the efficient generation of reliable reduced order models, and it will demonstrate the algorithms on important science and engineering applications."
"1105470","Geometry and Topology of Singular Structures with Applications to Computer Imaging","DMS","TOPOLOGY, COMPUTATIONAL MATHEMATICS","09/01/2011","08/25/2011","James Damon","NC","University of North Carolina at Chapel Hill","Standard Grant","Christopher Stark","08/31/2016","$118,686.00","","jndamon@math.unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275995023","9199663411","MPS","1267, 1271","9263","$0.00","Professor Damon has been investigating problems involving the geometry, topology and deformation properties of singular structures, including stratified sets, mappings, and nonisolated singularities, and the application of these results for developing geometric methods for problems in computer imaging. He proposes to further develop his work which applies to computer imaging and also continue his theoretical work, based on recent discoveries, on the properties of highly nonisolated singularities. He will extend the methods involving ""skeletal structures"", which he introduced to capture the shape of objects in any dimension, to obtain ""skeletal/medial linking structures"" for configurations of multiple objects in images. Such a linking structure will provide a mathematical structure which could be used for: the statistical analysis of medical images involving multiple physiological features, improved segmentation in images, and providing a rigorous unified mathematical framework for analyzing the interaction of positional and shape information in images. As well his work will develop new methods for studying highly nonisolated singularities whose topology has been beyond the reach of previous methods developed for isolated singularities. This involves determining the ""vanishing topology"" of the singularities as well as the topology of the complements and Milnor fibers for (highly singular) ""free divisors"" which naturally arise from representation theory of solvable linear algebraic groups.<br/><br/>The proposed investigations to be carried out under this grant will concern both theoretical work on singular spaces and its application to problems in medical imaging. Singular spaces, which are different from our usual image of smoothly bending objects, inevitably arise in the study of smooth objects. In the case of configurations of smooth objects, the investigator will develop appropriate singular structures which allow for the simultaneous analysis of the shapes of the individual objects and their positional relations. Such structures can be used for various imaging problems, such as for 3D medical images, where for treatment and diagnosis, the exact relative position and features of multiple physiological features must be determined. This will involve joint work with several groups of computer scientists. The investigator will also investigate the properties of these singular spaces when their structure is highly singular and cannot be understood using traditional methods. He is developing a new method for both simplifying the qualitative structure of such singularities and providing explicit algebraic methods for computing qualitative numerical invariants of the structures."
"1115297","Sparse Direct Methods on High-Performance Heterogeneous Architectures","DMS","COMPUTATIONAL MATHEMATICS, CI REUSE","08/15/2011","05/04/2015","Timothy Davis","FL","University of Florida","Standard Grant","Junping Wang","07/31/2015","$310,000.00","Sanjay Ranka, Timothy Davis","davis@tamu.edu","1523 UNION RD RM 207","GAINESVILLE","FL","326111941","3523923516","MPS","1271, 6892","7569, 9263","$0.00","Sparse direct methods form the backbone of many applications in<br/>computational science, but the methods are not keeping pace with advances<br/>in heterogeneous computing architectures.  High end systems can be built to<br/>contain multiple general-purpose CPU cores, coupled with one or more<br/>Graphics Processing Units (GPUs) each with hundreds of simple yet fast<br/>computational cores.  This project develops high-performance parallel<br/>sparse direct methods that can exploit GPU-based architectures to achieve<br/>orders of magnitude gains in computational performance.  The focus is<br/>single and multiple GPU algorithms for multifrontal sparse QR<br/>factorization.  QR factorization has wide applicability, is numerically<br/>very stable and is useful in many application areas.  The nonuniform and<br/>hierarchical structure of sparse QR factorization along with the unique<br/>features of the GPU  requires the development of novel algorithms.<br/>These include managing the simultaneous mix of regular computations inside<br/>the frontal matrix, and irregular computations in the assembly process<br/>between nodes in the computational tree and between concurrent subtrees.<br/><br/><br/>An efficient sparse QR factorization is an essential kernel in many<br/>problems in computational science.  It can be used to find solutions to<br/>sparse linear systems, sparse linear least squares problems, eigenvalue<br/>problems, rank and null-space determination, and many other mathematical<br/>problems in numerical linear algebra.  Application areas that can exploit<br/>the result of this research include structural engineering, computational<br/>fluid dynamics, electromagnetics, semiconductor devices, thermodynamics,<br/>materials, acoustics, computer graphics/vision, robotics/kinematics,<br/>optimization, circuit simulation, economic and financial modeling, chemical<br/>process simulation, text/document networks, and many other areas.  QR<br/>factorization is representative of many other sparse direct methods, with<br/>both irregular coarse-grain parallelism and regular fine-grain parallelism,<br/>and methodologies developed are very relevant for these other<br/>methods.  The work has broad impact on computational linear<br/>algebra, optimization, and related application areas.  The PI's research extends beyond these specific applications of numerical linear algebra, demonstrating how problems with a mixture of irregular and regular computation can be performed on the challenging yet promising landscape of GPU computing, and opens the door to many other kinds of applications.  The investigator and his colleagues plan on producing and distributing high-quality software as a result of this work, for which they have a 20-year track record."
"1115520","Eigenvalues problems, Krylov subspace methods, and subspace recycling","DMS","COMPUTATIONAL MATHEMATICS","08/15/2011","08/10/2011","Daniel Szyld","PA","Temple University","Standard Grant","Junping Wang","07/31/2014","$280,000.00","Fei Xue","szyld@temple.edu","1801 N BROAD ST","PHILADELPHIA","PA","191226003","2157077547","MPS","1271","9263","$0.00","The project concerns the development, analysis, refinement and testing of efficient numerical algorithms for the solution of algebraic eigenvalue problems and of systems of linear equations arising from a variety of applications. The PI's research is concentrated on the following two classes of problems: <br/>1. Interior eigenvalues of generalized non-Hermitian eigenvalue problems. These arise in many scientific and engineering applications, such as stability analysis of steady flows of incompressible fluid and evaluation of passivity in control systems and circuit networks. <br/>2. Sequences of linear systems of equations. These arise, e.g., in iterative methods for nonlinear problems, such as inexact Newton's method for Riccati equations, inexact eigenvalue algorithms, and interior-point methods for convex optimization.   <br/>A goal of the project is the development of rapidly convergent and robust Krylov subspace methods to efficiently solve both classes of problems. For the first class of problems, this entails the study of convergence properties, subspace expansion and extraction, and preconditioning techniques that take advantage of the structure of the problems. For the second problem class, the aim is to reduce the iteration counts and computational  effort needed for the solution of each linear system by using a properly recycled subspace obtained from the iterative solution of a preceding linear system in the sequence. The study of both problem classes also entails extensive computational experimentation on benchmark problems.<br/><br/><br/><br/>The problems to be studied in this project include the efficient  computation of a group of eigenvalues and the solution of sequences of linear systems. Eigenvalue calculations include analysis of vibration frequencies  in structures including buildings, to make sure, for example,  that they are far from the earthquake band.  Fast algorithms for generalized eigenvalue problems also contribute to the design and analysis of electronic integrated circuit and micro-electro-mechanical systems (MEMS), and the detection of potential presence of turbulent fluid flows. Efficient solution of a sequence of  linear systems facilitates modeling of fatigue and fracture via  finite element analysis, and the stability analysis of linear systems  through the solution of Riccati equations. The two problems mentioned are fundamental in the field of numerical  linear algebra as well as many relevant areas such as fluid and solid  mechanics, system and control theory, and numerical optimization.  Although numerical algorithms have been developed and studied for  some of these problems, efficient solution of large-scale applications  remains a major computational challenge. Development and refinement of these computational methods have potential broader impact in engineering and science."
"1115341","Computer simulations of giant fluctuations in mixing fluids","DMS","COMPUTATIONAL MATHEMATICS","07/01/2011","05/07/2013","Aleksandar Donev","NY","New York University","Continuing Grant","Leland Jameson","06/30/2014","$323,235.00","","ad139@nyu.edu","70 WASHINGTON SQ S","NEW YORK","NY","100121019","2129982121","MPS","1271","9263","$0.00","Thermal fluctuations in non-equilibrium systems exhibit remarkable<br/>behavior compared to equilibrium systems. Giant fluctuations in<br/>binary mixtures of miscible fluids have been observed, including<br/>in recent experiments in microgravity. Novel mathematical and<br/>computational challenges need to be addressed in order to include<br/>thermal fluctuations in traditional computational fluid dynamics in<br/>a way that is consistent with statistical mechanics. This proposal<br/>is concerned with the design, mathematical analysis, and computer<br/>implementation of finite-volume methods for fluctuating hydrodynamics<br/>of fluid mixtures, as well as applications to diffusively mixing<br/>fluids in gravity. The following research directions are proposed:<br/>(1) Multi-resolution numerical schemes for solving the compressible<br/>stochastic continuum equations; (2) Algorithms for incompressible,<br/>and (3) low Mach fluctuating hydrodynamics of miscible mixtures on<br/>staggered and collocated grids; (4) Simulations of giant fluctuations<br/>and comparisons to experiments; (5) Study of the contribution<br/>of advection by velocity fluctuations to transport in finite<br/>non-equilibrium systems.<br/><br/>Flows at micro and nano scales typical of new devices and biological<br/>systems are affected by thermal fluctuations. These effects are often<br/>assumed small and are not included in traditional computational<br/>fluid dynamics. However, giant fluctuations in the concentration<br/>of a polymer solution have been observed in recent experiments<br/>conducted in microgravity on a research space shuttle. Computer<br/>simulations are ideally suited for studying the details of this<br/>phenomenon and comparing the predictions of existing theory to<br/>the experimental findings. However, our community still lacks<br/>the appropriate computational tools, including both algorithms and<br/>large-scale parallel codes, to attack this problem. The investigator<br/>and his colleagues will develop such tools and use them to answer<br/>important scientific questions concerning fluctuations in fluids, in<br/>close collaboration with experimentalists. The developed algorithms<br/>will be implemented in a public domain code whose development is funded<br/>through a Software Infrastructure for Sustained Innovation NSF grant."
"1114827","Numerical methods for the moving contact line problem","DMS","COMPUTATIONAL MATHEMATICS","10/01/2011","07/14/2013","Weiqing Ren","NY","New York University","Standard Grant","Junping Wang","09/30/2015","$179,701.00","","weiqing@cims.nyu.edu","70 WASHINGTON SQ S","NEW YORK","NY","100121019","2129982121","MPS","1271","9263","$0.00","Contact lines arises as the intersection of fluid interfaces with solid <br/>surfaces. For a long time, this area of study has been plagued with <br/>conflicting theories and uncertainties regarding how the problem should be <br/>modeled. The main difficulty stems from the fact that classical hydrodynamics <br/>(specifically, the Navier-Stokes equation with the no-slip boundary condition) <br/>predicts a non-integrable singularity  for the viscous stress at the moving <br/>contact line. In this project, the moving contact line problem is to be <br/>systematically studied with the help of macroscopic thermodynamics, <br/>microscopic molecular dynamics, and numerical simulations. A ``first-<br/>principle'' contact line model is derived based on principles of <br/>thermodynamics and molecular dynamics simulations. Novel numerical methods <br/>will be developed for the contact line model, and will be applied to study <br/>problems of both practical and theoretical interests, including the contact <br/>line dynamics on heterogeneous surfaces. The asymptotic behavior of the <br/>contact line model as the slip length goes to zero will be investigated with <br/>the help of numerics and asymptotic analysis.<br/><br/>A contact line is the intersection of three phases, ofter two fluid phases and <br/>a solid phase. The two fluid phases can either be two immiscible fluids such <br/>as water and oil, or two phases of the same substance, such as the liquid and <br/>vapor phase of water. The solid phase is usually the container for the fluids. <br/>For this reason, the contact line is also the boundary of the interface <br/>between the two fluid phases, and is therefore an ubiquitous part of <br/>interfacial phenomena. Contact lines also arise in many applications such as <br/>coating, printing, oil production, and in many micro-fluidic devices. The main <br/>difficulty of the moving contact line problem stems from the fact that <br/>classical hydrodynamics predicts an infinite rate of energy dissipation which <br/>simply implies that contact lines cannot move. In this project, the PI will <br/>derive a first-principle contact line model based on thermodynamics principles <br/>and molecular dynamics simulations. Novel numerical methods will be developed <br/>and will be applied to study problems of practical interests, such as the <br/>contact line dynamics on heterogeneous surfaces."
"1115671","New Techniques on Reconstruction and Limiting for Numerical PDE","DMS","COMPUTATIONAL MATHEMATICS","10/01/2011","09/20/2011","Yingjie Liu","GA","Georgia Tech Research Corporation","Standard Grant","Junping Wang","09/30/2014","$170,955.00","","yingjie@math.gatech.edu","926 DALNEY ST NW","ATLANTA","GA","30332","4048944819","MPS","1271","9263","$0.00","The development of limiting techniques starts from high resolution capturing schemes for solving nonlinear conservation laws whose weak solutions contain discontinuities. These schemes do not trace discontinuities in a weak solution individually and automatically smear them into transition layers within a few mesh cells. They can achieve high order of accuracy if the solution is smooth and there is a nonlinear limiting mechanism to prevent spurious oscillations in the vicinities of discontinuities. The limiting techniques have since been developed for many other methods and applications, e.g., the Runge-Kutta discontinuous Galerkin methods with limiting, the moment limiter etc. Hierarchical reconstruction decomposes the job of limiting a high degree polynomial defined in a cell into a series of smaller jobs, each of which only involves the non-oscillatory reconstruction of a linear polynomial from cell averages. Therefore it only uses information from adjacent cells and can be naturally formulated on unstructured meshes in multi dimensions. It does not use local characteristic decomposition and thus is less dependent on the underlying equation to be solved. The principle investigator proposes several new improvements related to the hierarchical reconstruction in higher orders. The analytical study of the role of the remainder term in it could provide deeper understanding of the limiting mechanism. In particular, a compact, multi-step method is proposed to reconstruct a piecewise polynomial function of high degree from cell averages and sparsely located polynomial approximations. This property is novel. Its development and theoretical understanding is a new area to be explored.<br/><br/>More and more complex problems from science, engineering, business and daily life are handled by computers. However, only a finite amount of information can be stored and all numbers are truncated in a computer with a finite number of digits before and after being processed. Therefore a computer simulation is an approximation and is usually ""noisy"" as in the real world. In particular, non-smooth data tends to induce artifacts in computational solutions, making them less useful or completely useless. Non-smooth data is common in real applications. For example, the air pressure and density have jumps across a shockwave induced by a supersonic aircraft; the human body contains various jumps in density; in nanoscience, fuel cells, composite materials, material defect detection etc, non-smooth data originates from interfaces between different materials, irregular boundaries and cracks; in simulations in environmental science, ocean and atmosphere, non-smooth data comes from heterogeneous underground structures, irregular seafloor, seashore and ground surface, dynamic interfaces separating solid, liquid and gas etc. The project involves the development and analysis of a general method which eliminates as much computational artifacts as possible from the underlying solution without actually knowing it. The proposed limiting techniques are less problem dependent and can be useful in solving gas dynamics equations, magnetohydrodynamics equations and many other equations related to these applications. The new compact, multi-step reconstruction method could significantly reduce the memory cost of the discontinuous Galerkin methods enabling them to solve more complicated applications. It can also be formulated as a compact interpolation method and can be broadly used in computer graphics, image processing and many other scientific and engineering <br/>computations."
"1115269","Collaborative Research: Numerical approaches for incompressible viscous flows with high order accuracy up to the boundary","DMS","COMPUTATIONAL MATHEMATICS","09/01/2011","08/18/2011","Benjamin Seibold","PA","Temple University","Standard Grant","Leland Jameson","08/31/2014","$299,922.00","Prince Chidyagwai","seibold@temple.edu","1801 N. Broad Street","Philadelphia","PA","191226003","2157077547","MPS","1271","7569, 9263","$0.00","The research in this project focuses on the development, analysis, and implementation of efficient strategies to solve incompressible viscous flow problems with high order accuracy up to the boundary, with specific emphasis on the accurate calculation of stresses at the boundaries. To that end, Pressure Poisson Equation (PPE) reformulations of the time-dependent Navier-Stokes equations are considered. These reformulations are equivalent to the original equation, however, they yield explicit boundary conditions for the fluid pressure. As a consequence, numerical discretizations of PPE reformulations do not suffer from certain problems that traditional projection techniques incur, such as numerical boundary layers and inaccuracies in stresses at boundaries. The goal of this project is the exploitation of this fundamental advantage to develop effective, and high order accurate, implementations for incompressible viscous fluid flows in general domains, using various techniques such as finite elements, finite differences, and meshfree particle methods.<br/>Moreover, the numerical approximation of the actual Pressure Poisson Equations is a rich source of questions of interest to the numerical linear algebra community, and this project involves interactions with collaborators from that area.<br/><br/>In many applications in science and engineering, the accurate and efficient computation of forces and stresses at boundaries between fluids and solids is of crucial importance. Examples in which boundary forces (in the form of lift and drag) are key quantities of interest are the design of airplane wings, motor vehicles, and wind turbines, as well as the simulation of sedimentation in stratified fluids and bio-locomotion. The investigators are researching new methodologies and implementations of approaches that allow for a highly accurate computation of these boundary forces. This project relates developments in computational fluid dynamics with both theoretical aspects regarding the mathematical structure of the equations of incompressible flows, as well as fundamental questions that arise in the effective solution of large systems of equations. The involvement and training of graduate students is an important component of this project."
"1115392","Kernel Methods for Numerical Computation","DMS","COMPUTATIONAL MATHEMATICS","07/01/2011","07/01/2013","Fred Hickernell","IL","Illinois Institute of Technology","Continuing Grant","Junping Wang","06/30/2014","$320,000.00","Gregory Fasshauer","hickernell@iit.edu","10 West 35th Street","Chicago","IL","606163717","3125673035","MPS","1271","9263","$0.00","The PI's research provides a deeper understanding of kernel methods for multivariate function approximation problems. There are five main research thrusts. <br/>The first is to derive dimension-independent error bounds for kernel methods based on noisy and noiseless data. <br/>The second is to investigate which designs (arrangements of data sites) achieve these error bounds. <br/>The third is to use Green's functions to develop a better understanding of the inherent native spaces associated with the kernels used. <br/>The fourth is to use the kernel eigenfunction expansions to construct numerically stable evaluation algorithms for kernel approximation. <br/>The final thrust is to develop fast evaluation algorithms for kernel approximation, again using the eigenfunction expansions. <br/>The theoretical development provides practitioners in academia and industry insight and support for the development of numerical simulation algorithms in such application areas as materials engineering, complex fluid flow simulations, and nuclear reactor simulation. The investigators partner with software developers such as Matlab, NAG and JMP statistical software to have their algorithms included in future releases of these software packages. This research is being disseminated among the mathematics, statistical, and engineering communities to build bridges between them. In particular, the investigators are presenting tutorial courses on kernel methods to national and international audiences. The research findings are taught in several graduate courses that routinely draw students from applied mathematics, engineering and business. One key priority is to engage students in computational mathematics research as early as possible in the form of an REU experience and thereby develop a pipeline of young computational mathematicians for academia or industry. The investigators stress the inclusion of students from underrepresented minorities and from universities in the Chicago area that do not provide computational research opportunities to their students.<br/><br/>Computation is an indispensable tool for solving a variety of scientific, engineering, and societal problems.  However, accurate and timely answers require computational algorithms that are well understood and properly applied.  This research focuses on the fundamental problem of inferring the function that relates multiple inputs to an output, e.g., the way in which values of tens of engineering design parameters determine the temperature inside a nuclear reactor.  Kernel methods are flexible and accurate in certain settings, but their applicability for large numbers of inputs, as in the example just given, is not understood.  The PI's research addresses this issue.  Success means that the number of time-intensive computer simulations needed to understand complex processes can be reduced, and be replaced by a surrogate constructed via kernel methods.  This research shows how to plan the computer simulations for maximum accuracy.  Moreover, the methods for constructing this surrogate more quickly are developed.  Because of the fundamental nature of this research, the findings are expected to influence general purpose numerical computation packages used by many engineers and scientists involved in the fields of energy, manufacturing, and nanotechnology.  By including not only PhD students, but also MS and BS students, this research project is preparing the next generation of computational scientists, who are needed to support our continued technological and economic growth."
"1115963","Interior-point algorithms for conic optimization with sparse matrix cone constraints","DMS","COMPUTATIONAL MATHEMATICS","09/01/2011","06/06/2011","Lieven Vandenberghe","CA","University of California-Los Angeles","Standard Grant","Junping Wang","08/31/2015","$303,100.00","","vandenbe@ee.ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","MPS","1271","9263","$0.00","Conic optimization is an extension of linear programming in which the <br/>componentwise vector inequalities are replaced by inequalities with <br/>respect to nonpolyhedral convex cones.  The conic optimization model is  <br/>widely used in the recent literature on convex optimization and provides<br/>an elegant framework for extending interior-point algorithms from linear <br/>programming to convex optimization.  It is also the basis of popular <br/>modeling systems for convex optimization.  <br/>The research on algorithms for conic optimization has mainly focused on  <br/>three types of inequalities, associated with the nonnegative orthant, <br/>the second-order cone, and the positive semidefinite cone.  <br/>This restriction is motivated by symmetry properties that can be exploited <br/>to formulate symmetric primal-dual interior-point algorithms.<br/>However, large gaps in linear algebra complexity exist between the <br/>three types of conic constraints, and this can lead to inefficiencies when <br/>convex optimization problems are converted to the standard conic format.  <br/>This study considers approaches to improve the efficiency of conic optimization <br/>solvers by considering a larger class of conic constraints, <br/>defined by chordal sparse matrix cones, i.e., cones of positive <br/>semidefinite matrices with a given chordal sparsity pattern, <br/>and the associated dual cones of chordal sparse matrices that <br/>have a positive semidefinite completion.  These cones include as special <br/>cases the three standard cones, but also several interesting non-self-dual <br/>cones.  Moreover non-chordal sparsity patterns can often be efficiently <br/>embedded in chordal patterns and, as a consequence, sparse semidefinite <br/>programs can be solved as non-symmetric cone programs involving <br/>lower-dimensional cones than the positive semidefinite cone used in  <br/>semidefinite programming methods.  The choice for chordal matrix cones is  <br/>further motivated by the existence of fast algorithms for evaluating the <br/>associated barrier functions and their derivatives.<br/>The investigator and his collaborators study nonsymmetric <br/>interior-point algorithms for sparse matrix cones, building on techniques <br/>developed for large-scale sparse matrix computations, in particular, <br/>multifrontal and supernodal factorization algorithms and parallel sparse <br/>matrix algorithms.<br/><br/>A wide variety of practical problems in engineering and science can be  <br/>formulated as nonlinear convex optimization problems, and solved using <br/>algorithms developed over the last few decades.  <br/>The success of these techniques has created a demand for robust and <br/>efficient algorithms for very large convex optimization problems, <br/>especially for applications in machine learning, computer vision, <br/>electronic design automation, sensor networks, and combinatorial <br/>optimization.  The problem sizes that arise in these fields often <br/>exceed the capabilities of general-purpose solvers.  <br/>The work of the prinicipal investigator with his collaborators considers approaches to improve the scalability of interior-point<br/>algorithms, an important class of convex optimization algorithms.<br/>Freely available high-quality software implementations of the techniques developed in the<br/>project are a product of the research."
"1112593","Improved Methods for Incompressible Viscous Flow Simulation","DMS","COMPUTATIONAL MATHEMATICS","07/15/2011","07/07/2011","Leo Rebholz","SC","Clemson University","Standard Grant","Junping Wang","06/30/2015","$150,000.00","","rebholz@clemson.edu","230 Kappa Street","CLEMSON","SC","296340001","8646562424","MPS","1271","9150, 9263","$0.00","The objective of this work is to investigate four fundamentally new ideas, with high potential impact, for improving accuracy and efficiency in fluid flow simulations.  Each of these ideas is a fundamentally new approach to well-known challenges in flow simulation, is built from a solid mathematical foundation, and is motivated by the idea that more physically accurate models and numerical methods will produce more accurate results. The main ideas proposed for study are 1) development of the new velocity-vorticity-helicity formulation of the Navier-Stokes equations, 2) investigation of numerical methods for improving mass conservation in finite element methods that approximate velocity with piecewise continuous elements, 3) development of enhanced physics based schemes for flow problems that enforce discrete conservation laws in addition to energy (e.g. helicity in Navier-Stokes, cross-helicity in magnetohydrodynamics), 4) improving numerical methods for approximate deconvolution models of turbulence.<br/><br/>Simulating incompressible viscous fluid flow is an important subtask in most every engineering application involving the flow of water, oil, and/or most other liquids.  The ability to accurately and efficiently simulate these flows leads to improved engineering designs, improves turn-around time for designs, and also significant cost savings when testing is done on a computer model instead of a physical model.  However, modern computational methods for performing these simulations remain unreliable on many problems of interest.  This project will improve the state-of-the-art methods by developing/improving methods with a solid mathematical foundation, better enforcing the physical fidelity in simulations (i.e. avoiding non-physical solutions), and improving efficiency in the simulation techniques. Furthermore, the models and methods developed herein will have the potential to make an impact on the related systems of equations that govern atmospheric flow, oceanic flow, and climate modeling.  Broader impacts for this project includes training of graduate and undergraduate students in this field of research, the writing of a book on models for fluid simulation, and outreach to high school students."
"1112700","Algorithm Design and Analysis for High Order Numerical Methods","DMS","COMPUTATIONAL MATHEMATICS","08/01/2011","07/05/2011","Chi-Wang Shu","RI","Brown University","Standard Grant","Junping Wang","07/31/2015","$354,336.00","","chi-wang_shu@brown.edu","BOX 1929","Providence","RI","029129002","4018632777","MPS","1271","9263","$0.00","In this project, research in the algorithm design and analysis of high order numerical methods, including the finite difference and finite volume weighted essentially non-oscillatory (WENO) schemes and discontinuous Galerkin finite element methods, for solving hyperbolic and other convection dominated partial  differential equations, will be carried out.  While the emphasis of this project is on algorithm design and analysis, close attention will be paid to efficient parallel implementation and applications. The intellectual merit of the proposed activity lies in its comprehensive coverage of algorithm development, analysis, implementation and applications.  Problems in applications motivate the design of new algorithms or new features in existing algorithms; mathematics tools are used to analyze these algorithms to give guidelines for their applicability and limitations; practical considerations including parallel implementation issues are addressed to make the algorithms competitive in large scale calculations; and collaborations with engineers and other applied scientists enable the efficient application of these new algorithms or new featuresin existing algorithms.<br/><br/>The broader impacts resulting from the proposed activity will be a suite of powerful computational tools, suitable for various applications with involving convection dominated partial differential equations, in adaptive, multiscale and uncertain environments.  These tools are expected to make positive contributions to computer simulations of the complicated solution structure in these applications.  The application areas include (but are not limited to) computational fluid dynamics, traffic flow problems, semiconductor device simulations, and computational biology. Graduate students will be involved in this project, and will get training in performing mathematics research on problems closely related to applications.  Special attention will be paid to the recruitment and training of Ph.D. students from under-represented groups including women."
"1066045","Dynamical Processes in Many-Body Systems: Analysis and Simulations","DMS","COMPUTATIONAL MATHEMATICS","07/01/2011","05/17/2011","Emil Prodan","NY","Yeshiva University","Standard Grant","Junping Wang","06/30/2014","$331,314.00","","prodan@yu.edu","500 West 185th Street","New York","NY","100333201","2129605217","MPS","1271","1616, 9263","$0.00","The quantum physics of many interacting electrons lies at the foundation of chemistry and condensed matter physics. A direct treatment of the many-electron problem is impossible due to its shear complexity: dealing with N interacting electrons requires solving partial differential equations in 3N dimensions. Equilibrium and non-equilibrium Density Functional Theories (DFT) are rigorous and formally exact theories which map the interacting N-electron problem into a non-interacting N-electron problem. The non-interacting electrons move in an effective potential that has a universal functional dependence on the total electron density. As a result, the problem is reduced to a problem in dimension 3, amenable for computation. In this proposal the PIs propose to study a number of dynamical problems in many-body quantum mechanics within an interdisciplinary environment of mathematicians and physicists. In particular, the PIs  propose to develop further the mathematical foundations of density-functional theory, for equilibrium as well as the time-dependent case. The mathematical structure of the theory and its solutions will be further investigated and the insight from this analysis will be used to develop efficient numerical simulations. Particular emphasis will be given to the treatment of the spin-orbit interaction, within the full relativistic formulations and in non-relativistic formulations that include relativistic corrections. The PIs also plan to establish the foundations of the Dissipative Time-Dependent Density Functional Theory, and to apply the theory to the problem of charge and spin transport in materials.<br/><br/>The present technological progress is in great part based on design and discovery of new materials. Nowadays, the design of advanced materials involves laboratory work and computer simulations. Enhancing the accuracy and efficiency of computer simulations will reduce the costs, broaden the array of interesting and potentially useful materials, and speed up the process of testing and characterization. This is the target of the proposed research. The plan is to combine rigorous mathematical analysis, the insights from physics, chemistry and computer simulations in order to push the boundaries of theoretical simulations of advanced materials such as nano-structured materials, topological insulators and molecular electronic devices. The proposed research could have significant technological impact in applications such as nano-science and other areas of interest such as solar cell devices and energy conversion and storage. The PIs propose to integrate research and education by involving undergraduate and graduate students, and post-doctoral associates, in an interdisciplinary environment. Special attention will be paid to the recruitment of women and students from other underrepresented groups through the utilization of a diverse number of programs at the participating institutions."
"1056821","CAREER: Developing Mathematical Tools for Modeling Complex Materials Systems","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/01/2011","08/28/2015","Maria Emelianenko","VA","George Mason University","Continuing Grant","Leland Jameson","12/31/2017","$452,009.00","","memelian@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","MPS","1266, 1271","1045, 1187, 9263","$0.00","To increase materials strength and prevent failure, one needs to be able to gain control over material microstructure. The PI's research is focused on mathematical approaches to this problem. This research is designed to help make improvements to several stages of the materials process chain, from construction of phase diagrams to determination of growth rates and texture optimization. Her work features the interplay of modeling, simulation and analysis tools involving partial differential equations and stochastic processes. A combination of techniques from optimization, statistics and numerical analysis help this project substantially contribute to some of the field's long-standing challenges. The PI's plans include the creation of a mesoscopic theory of microstructure evolution which is focused on traditionally neglected disappearance events. Novel high-accuracy tools for multicomponent phase diagram calculation are achieved by fully utilizing modern sampling and constrained optimization techniques. Through a network of already established and newly formed collaborations with engineers in the US and abroad, the PI plans a comprehensive analysis of the impact of micro- and mesoscopic parameters on macroscopic materials properties. The Modeling Days conference organized by the PI and run together with the K-12 Mathematics Day workshop, brings students and senior researchers working in the field closer together and provides a unique career forum and networking opportunity for students from K-12 to postgraduate level, and helps to recruit and retain a talented workforce.<br/><br/>Microstructure degradation of components exposed to high temperature and high pressure has been linked to failure of components such as used in petrochemical plants, oil and gas transmission pipelines, offshore structures, ships, pharmaceutical plants, food processing equipment, and gas turbine engine components. The PI's research provides cost-effective solutions for predicting and preventing failure of materials due to environmental factors. This work has a direct impact on many practically important areas by advancing the synthesis of novel ""smart"" materials. These are highly sophisticated materials which possess very specific sets of properties targeted to particular applications. Close collaboration between mathematical and engineering communities on the global scale fostered by this project is crucial for accelerating the design and deployment of such materials. The project provides an unparalleled opportunity for involving students from high school to graduate level in a wide array of vertically-integrated research and educational activities focused on mathematical modeling and analysis of real-life systems. Such activities include short-term and long-term research projects, internships with industry, workshops and meetings with top scientists in the field. Special effort in the project is dedicated to the recruitment of women and minorities into STEM-related fields and outreach activities aimed at showcasing mathematics as a powerful tool for discovery."
"1068800","Conference on the Foundations of Computational Mathematics","DMS","APPLIED MATHEMATICS, TOPOLOGY, COMPUTATIONAL MATHEMATICS, ANALYSIS PROGRAM, Algorithmic Foundations","04/01/2011","03/24/2011","Agnes Szanto","NC","North Carolina State University","Standard Grant","Junping Wang","03/31/2012","$50,000.00","Michael Singer","aszanto@ncsu.edu","2601 Wolf Village Way","Raleigh","NC","276957514","9195152444","MPS","1266, 1267, 1271, 1281, 7796","7556, 9263","$0.00","This proposal  seeks support to increase the participation of  US researchers to the Conference on the Foundations of Computational Mathematics (FoCM)  which will be hosted by the Budapest University of Technology and Economics in Hungary between July 4-14, 2011.  The conference is the seventh in a sequence of international meetings organized by the Society for the Foundations of Computational Mathematics. The meetings are held every three years and the preceding ones have been held in different countries in North and South America and Europe. The NSF funding will cover the travel costs (airfare and partial subsistence support) for 30 conference participants who are US citizens/permanent residents, or work/study at a US institution. The supported  participants will be predominantly students and young researchers from the US, but the organizers expect to also cover the travel and subsistence expenses of some senior participants.  NSF funding to support travel and other participant costs for approximately 30 junior researchers and graduate students. The conference organizers have been traditionally and continue to be dedicated to attracting young participants and participants from under-represented groups and providing valuable opportunities for networking with the leaders of the disciplines. The conference will facilitate the flow of ideas between the theoretical computer science, computational and core mathematics communities.<br/><br/><br/>The research areas represented at the conference span a diverse array of topics on the broad interface  between mathematics and contemporary computation. The agenda of the conference includes 20 workshops on a broad array of topics including Approximation theory, Computational harmonic analysis, Computational algebraic geometry, Stochastic computation, Computational dynamics, Computational number theory, Combinatorics and intractability in computation, Discrete Optimization, Continuous Optimization, Learning theory, Information-based complexity, etc."
"1068187","Convexity, Topology, Combinatorics and beyond: An international conference","DMS","TOPOLOGY, COMPUTATIONAL MATHEMATICS, Combinatorics","03/01/2011","02/16/2011","Jesus De Loera","CA","University of California-Davis","Standard Grant","Tomek Bartoszynski","02/29/2012","$15,000.00","","deloera@math.ucdavis.edu","OR/Sponsored Programs","Davis","CA","956186134","5307547700","MPS","1267, 1271, 7970","7556, 9263","$0.00","The award will support an international workshop on the mathematics at the<br/>intersection of convex geometry, topology, and combinatorics, or convex<br/>topological combinatorics, for short. This is an important topic because<br/>convex geometric and topological techniques have become a main tool in<br/>discrete mathematics and theoretical computer science. In fact, convex<br/>topological combinatorics has had a impact in application areas such as<br/>algorithm design, computer graphics, mathematical programming, solid<br/>modeling, and computational biology. At the same time, topology and<br/>geometry have benefited from the study of combinatorial structures such as<br/>convex bodies, polyhedra, simplicial complexes, geometric graphs, etc.,<br/>because they appear naturally in relation to important algebraic and<br/>topological spaces such as Grassmanians, toric varieties, configuration<br/>spaces, and others.<br/><br/>This workshop will be the first large international conference in<br/>North-America on the topic of convex topological combinatorics. The event<br/>intends to bring together top international researchers to discuss<br/>developments in these intersecting fields. Besides specific mathematical<br/>research, the meeting will increase the cooperation between mathematical<br/>schools in the USA and Mexico, both of which have many strong researchers<br/>in convex topological combinatorics and a good number of Ph.D students<br/>doing research in these topics. Both groups will benefit from the<br/>interaction that the conference will bring."
"1115722","RUI: Theory and simulations of knotting in physical and biological systems ranging from proteins to glueballs","DMS","COMPUTATIONAL MATHEMATICS","09/01/2011","08/06/2013","Eric Rawdon","MN","University of St. Thomas","Continuing Grant","Junping Wang","08/31/2014","$176,198.00","","ejrawdon@stthomas.edu","2115 Summit Avenue","St. Paul","MN","551051096","6519626038","MPS","1271","9229, 9263","$0.00","Entanglement is seen at every scale in the physical world, from microscopic enzymes manipulating DNA to human-scale garden hoses to relativistic jets spanning light years in distance. The function of these entanglements is related to their physical form. In this proposed project, the PI, collaborators, and undergraduate students study the physical form of knotted tubes. Specifically, the proposed project has two main goals: 1) to model motions of thick tubes in contact with each other, and 2) to rigorously study knotting within open strands.  Knot configurations in a tight state have been used to model the relative speed of knotted DNA loops in gel electrophoresis, to predict the slope of the DNA double helix, and to classify the structure of the sub-atomic glueball states.  The PI and collaborators have written computer code to tighten knot configurations.  This code, and its corresponding theory, has led to a general model for handling the problem of self-contact of tube-like objects.  The PI and collaborators will extend the model so that it can be applied to other physical systems.  The second portion of the project concerns studying knotting in open chains.  The discovery of knotted proteins spurred the recent interest in classifying knotting within open chains.  The PI and collaborators will focus on the entanglement stability of the knotting within the chains, i.e. the resistance of the geometry of the configuration to change its knotting properties.  Protein chains will be compared to random chains to understand the role that knotting plays in the life of the proteins.<br/><br/>When one thinks of a knot, it is usually made out of rope.  The rope has physical properties, such as thickness, that limits how it can be manipulated.  For example, one cannot pass a rope through itself without cutting the rope.  When one ties a knot in a piece of rope and pulls it tight, the surface of the rope comes in contact with itself and the rope slides naturally along the contacts.  Modeling these motions along contacts is difficult but has applications in many fields, such as the study of elastic rods and computer graphics. The PI and collaborators have coded a knot tightening algorithm that deflects motions across self-contacts for rope-like materials in a mathematically sound, and physically intuitive fashion.  In the first portion of this project, this algorithm will be extended to study other physical systems with self-contact. Some possible applications include testing the effect of a bullet's impact on woven materials forming bullet-proof vests and analyzing the security of boating, fishing, and surgical knots.  The type of knots typically studied by mathematicians are closed loops with no free ends, in contrast to the knots we see in everyday life, such as in shoelaces and garden hoses, that have free ends.  However, the importance of studying knotting in objects with free ends is becoming increasingly clear.  For example, some proteins contain these types of knot, although the function of the knots is still being debated. Since proteins are involved in essentially every process in cells, knots would seem to be an unnecessary obstruction as the protein folds in and out of its active state.  Knotting in open strands is not well understood from a mathematical perspective, but should coincide with one's intuitive notion of what is and what is not ""knotted"".  A ""knotted"" strand should be stable so that, for example, a person's shoes do not come untied. The PI, collaborators, and undergraduate students will study notions of knotting in open strands and the relationship between the spatial structure of the strand and its stability.  Ultimately, this will lead to insights into knotting within proteins.  In addition to the scientific goals, this grant has broad educational objectives. Undergraduate students will be directly supported by the grant, gaining critical experience in the research process and presenting their results at professional conferences.  The PI will continue to be involved in connecting with students, non-specialists, and specialists from different fields through talks and organizing interdisciplinary conferences."
"1115887","High Order Model, Computation, and Stochastic Hybrid Coupling Continuum-Particle Algorithm with Application to Micro-propulsion","DMS","COMPUTATIONAL MATHEMATICS","10/01/2011","09/19/2011","Zhiliang Xu","IN","University of Notre Dame","Standard Grant","Leland Jameson","09/30/2015","$120,000.00","guang lin","zxu2@nd.edu","940 Grace Hall","NOTRE DAME","IN","465565708","5746317432","MPS","1271","9263","$0.00","Micro-domain multi-scale flow simulation is one of the most difficult and unresolved problems in today's computational mathematics. Simulating micro-propulsion generated by the plasma flow from the micro-pulsed plasma thruster (PPT) is one of the examples. Flow in a micro-PPT is partially ionized collisional plasma exhibiting transition from continuum to rarefied (or non-equilibrium) regime. To successfully simulate such multi-scale flow, a novel stochastic hybrid algorithm combining direct simulation Monte Carlo (DSMC) method suitable for highly non-equilibrium flow regime and continuum methods in the rest of the domain for efficiency is proposed. Using the new algorithm, the study will focus on numerical modeling the internal flow of the micro-thruster. To the end, stochastic simulations are planned to optimize performance characteristics of the thruster such as specific impulse and thrust. The intellectual merit of the proposed activity lies in the development and analysis of new numerical algorithms and application of these algorithms for large scale simulations of multi-scale flow problems. Moreover, one significance of the proposed research is to build a stochastic interface between kinetic and continuum methods to exchange the statistical distribution instead of the spatial-temporal average. Proposed tools will be applied to study the micro-thruster to order to improve their performance by optimizing their geometry.<br/><br/>    The proposed work will broadly extend the understanding of the behavior of multi-scale flows in many applications of current interest. It will assist in developing new micro-propulsion devices with improved efficiency, which is important for next generation micro-spacecrafts. Moreover, the methods to be developed can be applied to numerous applications in engineering, physics and biology including, but not limited to, hypersonic re-entry vehicles, thermo-fluids of fusion blankets and dissolution of a blood clot by ultrasound. Proposed work will continue and expand the PI?s educational outreach activities by building a strong collaboration between University of Notre Dame and Pacific Northwest National Laboratory and providing interdisciplinary training for students. An interdisciplinary training of undergraduate and graduate student training is planned."
"1115278","Collaborative Research: Numerical approaches for incompressible viscous flows with high order accuracy up to the boundary","DMS","COMPUTATIONAL MATHEMATICS","09/01/2011","08/18/2011","Rodolfo Rosales","MA","Massachusetts Institute of Technology","Standard Grant","Leland Jameson","08/31/2015","$119,998.00","","rrr@math.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","MPS","1271","9263","$0.00","The research in this project focuses on the development, analysis, and implementation of efficient strategies to solve incompressible viscous flow problems with high order accuracy up to the boundary, with specific emphasis on the accurate calculation of stresses at the boundaries. To that end, Pressure Poisson Equation (PPE) reformulations of the time-dependent Navier-Stokes equations are considered. These reformulations are equivalent to the original equation, however, they yield explicit boundary conditions for the fluid pressure. As a consequence, numerical discretizations of PPE reformulations do not suffer from certain problems that traditional projection techniques incur, such as numerical boundary layers and inaccuracies in stresses at boundaries. The goal of this project is the exploitation of this fundamental advantage to develop effective, and high order accurate, implementations for incompressible viscous fluid flows in general domains, using various techniques such as finite elements, finite differences, and meshfree particle methods.<br/>Moreover, the numerical approximation of the actual Pressure Poisson Equations is a rich source of questions of interest to the numerical linear algebra community, and this project involves interactions with collaborators from that area.<br/><br/>In many applications in science and engineering, the accurate and efficient computation of forces and stresses at boundaries between fluids and solids is of crucial importance. Examples in which boundary forces (in the form of lift and drag) are key quantities of interest are the design of airplane wings, motor vehicles, and wind turbines, as well as the simulation of sedimentation in stratified fluids and bio-locomotion. The investigators are researching new methodologies and implementations of approaches that allow for a highly accurate computation of these boundary forces. This project relates developments in computational fluid dynamics with both theoretical aspects regarding the mathematical structure of the equations of incompressible flows, as well as fundamental questions that arise in the effective solution of large systems of equations. The involvement and training of graduate students is an important component of this project."
"1102029","Special Meeting:  Discrete Geometry and Applications","DMS","COMPUTATIONAL MATHEMATICS","08/15/2011","08/03/2011","Robert Connelly","NY","Cornell University","Standard Grant","Junping Wang","07/31/2012","$50,000.00","Yinyu Ye, Herbert Edelsbrunner","connelly@math.cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","MPS","1271","7556, 9263","$0.00","The Fields Institute in Toronto will host and fund ($400,000 CAN) a Thematic Program on Discrete Geometry and its Applications, July-December 2011. This project shall provide support for two postdoctoral participants and a graduate student to the Fields thematic program. The goal of the program is to advance the understanding of discrete geometry and its relation to other parts of mathematics including packings and coverings of disks, expansive reconfigurations of spherical disks, visibility problems, optimization problems, algebraic geometry, topology, arrangements, polytopes, rigidity theory both local and global, rigidity and symmetry, geometric probability theory, and convexity as well as engineering problems related to the stability of structures, computational geometry, computational topology, computational structural biology, coding problems, and solid modeling to name a few. The common thread is the role that geometry plays and how a geometric viewpoint provides vital, often the critical insight, into the understanding of discrete structures. The program organizers have scheduled three roughly one-week focus workshops along with a Coxeter Lecture series and a Distinguished Lecture series. In addition, during July and August 2011, the Fields Institute will sponsor a program to introduce undergraduates, in the spirit of the Research Experiences for Undergraduates (REU), to many of the subjects that will be studied during the rest of the semester. Graduate courses will also be offered for students who will be attending during the semester. Significant numbers of senior and junior researchers and postdoctoral fellows will reside long-term with the program: others will make shorter visits.<br/><br/>This program capitalizes on the rapid development of several related areas in discrete geometry and comes at a time that is excellent for their interaction and common growth. The experienced and highly respected mathematicians, promising younger postdoctoral fellows and graduate students will have the diversity, creativity, and energy to make a significant impact on discrete geometry and its many applications for many years to come. This grant supports the training of two junior U.S. researchers and a graduate student by providing travel support and living expenses, making it possible for them to participate in the program. The participants will experience a wide range of activities including workshops, distinguished lecturer series, courses both specialized and for a general audience, day-to-day interactions for the people there, all connected with top researchers to provide guidance and direction for junior researchers and nonspecialists to provide synergy and excitement for all. The organizers, guided and overseen by the directorate of the Fields Institute will have a priority of making possible the participation and inclusion of qualified students, junior researchers, women, minorities, people with disabilities and under-represented groups. In addition, with the help of the Fields Institute infrastructure, the proposed activities will be communicated widely internationally."
"1111612","Workshop on Fluid-Structure Interaction Problems","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","06/15/2011","06/02/2011","Zhilin Li","NC","North Carolina State University","Standard Grant","Henry Warchall","05/31/2012","$25,284.00","","zhilin@math.ncsu.edu","2601 Wolf Village Way","Raleigh","NC","276957514","9195152444","MPS","1266, 1271","7556, 9263","$0.00","This award provides support for the workshop on Fluid-Structure Interaction Problems to be held at the National Center for Theoretical Sciences (NCTS) in Taiwan, May 26-29, 2011. The award will provide partial support for US participants, principally graduate students, post-doctoral researchers, and junior faculty. <br/><br/>The fluid-structure interaction problems arise in a variety of important applications in materials science, biological flows, and multi-phase flows among others. The workshop includes plenary lectures by international speakers on topics of current research interest in the area of fluid-structure interactions, including modeling and analysis, the related theory and analysis of partial differential equations, various numerical methods, and applications. It will provide a venue for the discussion of important recent advances and the current directions of research. The workshop encourages presentations by junior participants. It will serve to expose new research opportunities to young researchers and graduate students, and to facilitate the scientific collaborations between US scientists and their international counterpart. NCTS will support most of the expenses and logistics of the workshop.<br/><br/>Workshop web site: http://math.cts.nthu.edu.tw/Mathematics/FSIP2011.htm"
"1115469","Collaborative Research:  Proximity Algorithms for Optimization Problems Arising from Image Processing","DMS","COMPUTATIONAL MATHEMATICS","08/15/2011","08/08/2013","Charles Micchelli","NY","SUNY at Albany","Continuing Grant","Junping Wang","07/31/2015","$145,000.00","","charles_micchelli@hotmail.com","1400 Washington Ave MSC 312","Albany","NY","122220100","5184374974","MPS","1271","9263","$0.00","The restoration of degraded images is a fundamental and challenging problem in image processing. This problem is ill-posed. The total-variation regularization and its variants are commonly used to convert to a well-posed problem. The resulting regularized model usually has a non-differentiable objective functional, which together with the large dimension of the underlying image makes the minimization theoretically and numerically difficult. Typical numerical treatments for this minimization are indirect in the sense that the methods are developed for a smoothed or dual model of the original model. With this project, the principal investigators use tools from convex analysis to find the solution of the image restoration models directly under a unified framework. The PIs address more general mathematical challenges and computational difficulties associated with the obtained fixed-point formulation.  This project provides a fixed-point characterization for the solutions of models with  least squares and max norm fidelity terms combined with the total variation regularization term. The study considers images corrupted by Gaussian noise, impulsive Gaussian noise and Poisson noise, which are all of relevance for different applications. <br/> <br/>Restoring images from available data is required in a variety of applications including computer tomography; natural resources and pollution control via satellite imaging in environmental sciences; and fingerprint and face recognition in security identification. Advanced mathematical models and efficient computational algorithms for solving this problem are essential. The developed numerical schemes  support improved automatic image restoration for these applications. Furthermore, interdisciplinary approaches resulting from the projects enrich upper level undergraduate and graduate curriculum development and teaching activities."
"1201666","Image Processing Using PDE on Image Features and Image Databases","DMS","COMPUTATIONAL MATHEMATICS","08/01/2011","10/24/2011","Arthur Szlam","NY","CUNY City College","Standard Grant","Leland Jameson","06/30/2013","$58,681.00","","aszlam@courant.nyu.edu","Convent Ave at 138th St","New York","NY","100319101","2126505418","MPS","1271","0000, 9263, OTHR","$0.00","In recent years the heat equation on a weighted graph  has been used to attack problems in image processing, including denoising, segmentation, and inpainting.<br/>In many cases the data used to build the graph is the set of patches or feature responses from a single image; and even then, patches or filter responses are usually only compared with their spatial<br/>neighborhoods.   On the other hand, it has become practical to<br/>manipulate large collections of images, and using the statistics of large collections of images has become an important image processing<br/>tool.   The PI will investigate how to use larger databases of<br/>images and image features in a PDE framework. For some of the proposed work, it will be necessary to invent new theory to lift notions of the smoothness of a surface embedded in Euclidean space to maps from the discrete grid into a weighted graph; and perhaps further to maps from a more general weighted graph into a weighted graph.  Other proposed work will try to make use of (and improve) recent methods for sparse feature extraction, and solidify the theory underlying the NL-means method of Buades, Coll, and Morel.<br/><br/><br/>A large class of popular image processing techniques making use of the theory of partial differential equations operate locally; that is, the behavior of each step of these algorithms at a given pixel in an image is determined solely by the neighboring pixel values.<br/>In recent years, it has become possible to manipulate large databases of images; and such databases of images have become available from many sources, including the world wide web. The PI will work towards extending the local techniques to make use of these large databases. The long term goal is image processing techniques which understand and utilize the content and context of images; such techniques would have many important applications, for example in medical imaging, hperspectral imaging, and computer vision in general.<br/>"
"1115406","Collaborative Research: A Field Expansion Method for Acoustic Scattering from Topography: Extensions to Elasticity and the Inverse Problem","DMS","COMPUTATIONAL MATHEMATICS, Geophysics, OPPORTUNITIES FOR RESEARCH CMG","09/01/2011","08/01/2013","Alison Malcolm","MA","Massachusetts Institute of Technology","Continuing Grant","Junping Wang","08/31/2014","$149,983.00","","amalcolm@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","MPS","1271, 1574, 7215","1574, 7215, 9263","$0.00","This proposal initiates a new collaboration aimed at improving methods of waveform inversion by including topography in seismic wave modeling and reducing the reliance of these methods on data at extremely low-frequency.  The Principal Investigators propose to adapt and improve methods developed for simulating scattering from a diffraction grating. Their approach has extensions to linear elasticity and provides general improvements for solving the inverse problem.  Significant mathematical advances are required to develop robust and efficient techniques for this application. The Boundary Perturbation Method extends the Field Expansion approach to an arbitrary number of layers with independent topographies and allows for rapid and accurate simulation of acoustic wave propagation in two dimensions.  Extensions to three dimensions and to the general equations of elasticity are required. Moreover, the extension of frequency-independent discretizations based on Geometric Acoustics to multilayered elastic models is a significant and necessary mathematical advance.  Additionally, advances in the inverse problem are also necessary to make the technique truly applicable to the seismic imaging problem. The standard method of ""full-waveform inversion"" requires data at frequencies which are too low to record in practice.  The PIs' approach casts the forward problem as the application of a sequence of topography-dependent operators where the interface shapes appear rather explicitly.  A number of iteration schemes are proposed for the recovery of these shapes, using re-arrangements of the compositions coupled to standard regularizing techniques from the theory of ill-posed problems.  <br/><br/>The propagation properties of seismic waves in layers of sediment are crucial in many technologies including the determination of inner earth properties and structure, earthquake detection and prediction, and hydrocarbon (oil and gas) exploration.  In light of its many important applications, it is not surprising that a vast array of numerical and experimental techniques have been brought to bear upon this problem.  However, several gaps in understanding and capability still exist. The PIs' address some of these questions through sophisticated numerical simulations which will be validated against both laboratory experiments and field measurements from the Tibetan plateau."
"1115870","Alternatives to the tensor product in wavelet construction and beyond","DMS","COMPUTATIONAL MATHEMATICS","09/15/2011","07/01/2013","Youngmi Hur","MD","Johns Hopkins University","Continuing Grant","Junping Wang","08/31/2014","$188,870.00","","hur@jhu.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","MPS","1271","9263","$0.00","The principal investigator's research is focused on the study of alternatives to the tensor product for constructing multi-dimensional wavelet functions from one-dimensional wavelet functions. These alternative methods may overcome some limitations of the tensor product approach while also complementing the tensor product formulation. The tensor product concept is also prevalent in many other application areas, and thus new developments have the potential for broader impact. From the mathematical perspective, the research includes extending current efforts in developing the coset sum methodology, searching for alternative mechanisms to construct wavelet bases while assessing their distinguishing properties for certain applications, and studying systematic ways to construct multi-dimensional wavelet systems where the tensor product does not work.  <br/><br/><br/>Wavelets have been used in a wide range of applications including Image Compression. Examples where wavelets are a key tool include the JPEG 2000 digital image standard and fingerprint compression for data storage. This work concerns improvements in the construction of multi-dimensional wavelet systems focused toward specific application areas, and provides an opportunity for mathematics graduate students to study mathematics from an application perspective."
"1115668","Preconditioning, analysis, and applications of numerical algebraic geometry methods","DMS","COMPUTATIONAL MATHEMATICS","09/15/2011","09/08/2011","Daniel Bates","CO","Colorado State University","Standard Grant","Junping Wang","08/31/2015","$306,969.00","","bates@math.colostate.edu","601 S Howes St","Fort Collins","CO","805232002","9704916355","MPS","1271","9263","$0.00","Numerical algebraic geometry involves the use of numerical methods to extract <br/>data from ideals about the corresponding varieties or schemes.  This area has <br/>grown rapidly over the last 20 years and has found applications in many areas <br/>of science and engineering.  This grant is funding four projects in the area <br/>of numerical algebraic geometry.  First, the PI and his students will <br/>investigate several forms of preconditioning for homotopy continuation, <br/>including algorithms for finding (near-)optimal multihomogeneous and linear <br/>product start systems, as well as the use of dual bases to reduce the number <br/>of paths tracked to ""bad"" endpoints.  Second, the PI and several collaborators <br/>will work on three application areas:  exceptional mechanisms (via fiber <br/>products), software in Macaulay2 for algebraic geometry-related applications, <br/>and software for repeated parameter homotopies.  Third, the PI will work on <br/>analyzing the complexity of numerical algebraic geometry algorithms.  Finally, <br/>the PI and several collaborators will continue to work on methods to extract <br/>information about real algebraic sets both from standard continuation methods <br/>and from Khovanskii-Rolle continuation. <br/><br/>Polynomial systems of equations arise in many places throughout mathematics, <br/>science, and engineering. An entire mathematical field - algebraic geometry - <br/>grew out of the need to find solutions to these sorts of equations. Until the <br/>1960s, though, there was no known general technique for solving such systems <br/>of equations. The methods developed in that era require too much memory to be <br/>effective except for relatively small problems. More recently developed <br/>methods - the numerical methods of Sommese, Verschelde, Wampler, Li, and <br/>others, now collectively known as numerical algebraic geometry - allow for the <br/>solution of much larger polynomial systems, opening the application of <br/>algebraic geometry methods to a wider class of problems. However, there is <br/>still much to understand about these numerical methods. The goals of this <br/>project include addressing four open problems in this direction.  This work <br/>includes the development of techniques to streamline some of these <br/>computations, the implementation of valuable algorithms in popular and useful <br/>software packages, a careful analysis of the computational costs associated <br/>with the computational methods in this field, and the continued effort to <br/>extract useful real-world data from the data provided as output from these <br/>methods."
"1112656","Definite Integration:  Algorithms and Applications","DMS","COMPUTATIONAL MATHEMATICS","07/01/2011","07/21/2015","Victor Moll","LA","Tulane University","Continuing Grant","Leland Jameson","06/30/2016","$320,001.00","","vhm@math.tulane.edu","6823 ST CHARLES AVENUE","NEW ORLEANS","LA","701185698","5048654000","MPS","1271","9150, 9263","$0.00","The project is an effort to investigate the mathematical theory and <br/>algorithms associated with the symbolic evaluation of definite <br/>integrals. The first class of functions that will be considered is <br/>the family of hypergeometric functions. This class is characterized <br/>by satisfying a differential equation of second order with exactly <br/>three singular points. The PI will attempt to develop an automatic <br/>procedure based on the Barnes representation for these functions. <br/>The natural next step is the family of Heun functions that have four <br/>singular points.  The project also considers many topics that have risen from previous <br/>investigations by the PI. These include arithmetical properties of <br/>sequences coming from the iteration of integrals, questions of logconcavity <br/>of sequences appearing in the integration of rational functions and <br/>general questions on the p-adic properties of naturally occurring sequences. <br/>A general theory for these valuations will be developed.  A third component <br/>of the project is the implementation and justification of a heuristic method <br/>developed by the PI and his coworkers to evaluate integrals coming from <br/>Feynman diagrams. <br/><br/>Many problems in physics and engineering require the exact <br/>evaluation of definite integrals in terms of the parameters appearing <br/>in them. These integrals come up in the study of particle physics and <br/>classical mechanics. While it is not always possible to find such an <br/>expression, an efficient and robust symbolic software package should <br/>give the result in closed-form, or decide whether such expression is <br/>achievable. The goal of this project is to develop algorithms that will <br/>expand the capabilities of existing software packages that are <br/>widely used in industry and universities.  A second goal is to develop <br/>mathematical theories for theoretical questions that appear in the <br/>development of the previously mentioned algorithms."
"1115718","Collaborative Research: Development of High-Resolution Finite-Volume Methods for Systems of Nonlinear Time-Dependent PDEs","DMS","COMPUTATIONAL MATHEMATICS","10/01/2011","09/13/2011","Alexander Kurganov","LA","Tulane University","Standard Grant","Leland Jameson","09/30/2015","$118,621.00","","kurganov@math.tulane.edu","6823 ST CHARLES AVENUE","NEW ORLEANS","LA","701185698","5048654000","MPS","1271","9150, 9263","$0.00","The project is aimed at developing highly accurate, efficient and robust numerical methods for systems of nonlinear time-dependent PDEs, with particular reference to multidimensional hyperbolic systems of conservation/balance laws and related problems. The principal part of the proposed research will be focused on the development of new finite-volume methods that will provide an improved resolution of linear contact waves and incorporate new techniques for solving problems involving complicated nonlinear wave phenomena and blowing up/spiky solutions. The proposed methods will be applied to a variety of nonlinear problems, among which are systems of gas dynamics, nonlinear elasticity and acoustics systems, modern traffic flow models, several chemotaxis and bioconvection models, and others. These problems will be studied in the most challenging cases of high space dimensions, complex geometries and moving interfaces. For each problem, a high-resolution finite-volume scheme will be systematically derived in a way that the main properties satisfied by the underlying system of PDEs will be also satisfied on the discrete level. One of the key features of the new schemes will be their nonlinear stability, which will be ensured by ability of the scheme to preserve positivity of such physical quantities as density. To achieve this goal, several high-order positivity preserving techniques will be explored.<br/><br/>Besides providing the examples that corroborate the analytical approach, the foregoing applications are of a substantial independent value for a broad class of problems arising in today's science including geophysics, meteorology, astrophysics, semiconductors, traffic flows, image processing, financial and biological modeling and many other areas. Development of modern high-resolution finite-volume methods as well as of supplementary techniques is essential for solving many practically important problems, some of which are currently out of reach because the existing numerical methods are either inefficient/inaccurate or not applicable at all."
"1115950","Building Up the Optimization Algorithmic Infrastructure for Data-Driven Knowledge Discovery and Recovery","DMS","COMPUTATIONAL MATHEMATICS","07/01/2011","06/23/2011","Yin Zhang","TX","William Marsh Rice University","Standard Grant","Junping Wang","06/30/2015","$184,999.00","","yzhang@rice.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","MPS","1271","9263","$0.00","The investigator proposes to study a number of optimization models and algorithms <br/>that are broadly useful in data dimension reduction, latent information extraction<br/>and hidden knowledge discovery. The focus is on problems involving low-rank <br/>matrices of very large sizes, including the fundamental problem of computing <br/>principal singular value decompositions for unstructured dense matrices, as well as <br/>3D-image processing techniques with applications to hyperspectral data processing and <br/>wireless video networks.  The overall goal is to develop reliable algorithms that are <br/>much faster (by one order of magnitude or more on large problems) than those in use today. Since many of the proposed algorithms are extensions to the classic augmented Lagrangian alternating direction method (ALADM) originally designed for certain convex programs, a part of the project is devoted to a theoretical investigation on establishing a convergence theory for ALADM in more general settings.<br/><br/>Modern technologies, such as 4D CT-scans, satellite remote sensing and DNA microarrays, are creating an explosion of data made available in massive quantities and at fast rates. Mathematical and computational techniques play a crucial role in helping make sense out of such massive data sets in a timely fashion and with minimal human interventions. The PI's work involves studying and designing new algorithms for solving several classes of mathematical models designed to help discover and extract the most useful information buried or hidden in large amounts of data. New algorithms have the potential to run much much faster than today's state-of-the-art methods, thus providing more processing power and speed to numerous data-driven applications such as medical diagnoses, agriculture planning, environment surveillance or genetic research in biosciences."
"1115385","Matrix Functions, Rational Approximation, and Quadrature with Applications","DMS","COMPUTATIONAL MATHEMATICS","09/01/2011","06/27/2013","Lothar Reichel","OH","Kent State University","Continuing Grant","Junping Wang","08/31/2015","$180,000.00","","reichel@math.kent.edu","OFFICE OF THE COMPTROLLER","KENT","OH","442420001","3306722070","MPS","1271","9263","$0.00","This research project is concerned with the development and analysis of novel methods for the approximation of matrix functions and integrals defined by matrix functions. The research blends linear algebra and approximation theory. New rational Lanczos methods for Hermitian matrices with short recursion formulas are being developed. The existence of short recursion relations is of significant theoretical and practical interest. It speeds up the computations because each new rational Lanczos vector only has to be orthogonalized against a few of the most recently computed Lanczos vectors.  The number of required explicit orthogonalizations is bounded independently of the number of rational Lanczos steps. The recursion relations define the orthogonal projection of a given matrix onto a rational Krylov subspace. The projection is represented by a pentadiagonal matrix, which also has a block structure. This matrix is analogous to the symmetric tridiagonal matrix associated with a (standard) Gauss quadrature rule, and is the basis for new algorithms for the evaluation of rational Gauss, Gauss-Radau rules, and Gauss-Lobatto quadrature rules. The research is an extension of the very important work by Gene Golub, and his collaborators, on matrices, moments, orthogonal polynomials, and quadrature. There may be connections to the structured matrices, such as the CMV-matrices, which arise in the context of orthogonal polynomials and orthogonal rational functions on the unit circle, as well as to to semi- and quasi-separable matrices. When the given matrix is non-Hermitian, rational Arnoldi and rational non-Hermitian Lanczos processes can be applied. The projections onto the rational Krylov subspace again have a structure, the exploitation of which is an important topic in linear algebra. The need to estimate matrix functionals arises in many applications, including the investigation of social networks and in Tikhonov regularization of ill-posed inverse  problems.  <br/><br/>The principal investigator is studying developments of faster numerical methods for the evaluation, bounding or estimation of complicated nonlinear expressions that involve large symmetric or nonsymmetric matrices. The gain in speed is achieved by exploiting structure that until now has been ignored. The development of fast methods is important when solving large-scale problems of interest to scientists and engineers. These methods are applicable in the investigation of social networks, whose properties recently have received considerable attention, not only by scientists, but also by the New York Times. A major hurdle in the investigation of social networks is their large size. The research provides improved tools for investigating these kinds of networks. The methods can also be applied in solution methods for Maxwell's equation in three space-dimensions. Essentially, one has to compute the exponential of very large matrices. These matrices are much too large to allow the use of standard software. The methods to be developed within the framework of this proposal speed up the computations by exploiting inherent structure of these problems. Work on the problems of this proposal requires background in linear algebra, orthogonal polynomials and rational functions, approximation theory, and Gauss-type quadrature. Hence the research is well suited for doctoral students working on this project."
"1114546","Multiscale Computational Methods for Semiclassical Schrodinger Equations","DMS","COMPUTATIONAL MATHEMATICS","07/01/2011","08/12/2013","Shi Jin","WI","University of Wisconsin-Madison","Continuing Grant","Junping Wang","06/30/2015","$352,574.00","","shijin-m@sjtu.edu.cn","21 North Park Street","MADISON","WI","537151218","6082623822","MPS","1271","9263","$0.00","The proposer proposes to develop efficient numerical methods<br/>for several problems in quantum dynamics. Specifically, the following<br/>three topics are selected:  Semiclassical methods for quantumscattering, <br/>surface hopping,  and Bloch-decomposition based computational<br/>methods for quantum dynamics in periodic lattice. These are challenging<br/>computational issues that involve high frequency waves and<br/>quantum-classical coupling. Mathematical and computational<br/>methods can play important roles to enhance our understanding as well<br/>as our ability to simulate these problems.<br/><br/>These problems arise in solid state physics,  semiconductor device<br/>modeling, Bose-Eistein Condensations (BEC),  solar energy, and<br/>functional materials such as graphane, thus the developed computational<br/>methods will have a wide range of applications, some of which of<br/>significant national interests. Some of the research results will<br/>provide excellent additions for future graduate courses in applied<br/>mathematics and scientific computing, thus will help to<br/>improve the graduate curriculum in applied mathematics in order to<br/>better train future graduate students in modern applied mathematics."
"1114923","Probabilistic Methods in Computational Topology","DMS","COMPUTATIONAL MATHEMATICS","10/01/2011","09/14/2011","Thomas Wanner","VA","George Mason University","Standard Grant","Leland Jameson","09/30/2015","$180,000.00","","twanner@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","MPS","1271","9263","$0.00","Computational topological methods are increasingly and successfully being used to analyze and understand complex data, provided both from experimental sources and numerical simulations. Many of these topological methods use homology theory and the related Betti numbers to concentrate on essential topological information. Usually the objects of interest are discretized before their homology can be computed. This process of discretization can introduce artifacts which cause the resulting topological information to be incorrect. Uncertainty can also occur in experimental settings due to noise.<br/>In this project, the investigator and his colleagues develop two mechanisms for a quantitative assessment of the correctness of topological information.<br/>The first approach is based on the realization that most applied problems involve randomness, and it studies the accuracy of homology computations for random fields by providing explicit probability estimates which give a-priori information on suitable problem discretizations. The second mechanism develops a method for rigorous computational a-posteriori correctness based on randomized subdivisions. In addition, the investigators address two specific applications which are interesting in their own right. First, they develop a new method for finding isolating blocks in dynamical systems, which has a wide range of possible applications and provides a novel tool for studying dynamical properties of evolution equations. The second application focuses on pattern classification in materials science and leads to a classification of possible phase separation phenomena in multi-component alloys.<br/><br/>Recent advances in computational sciences have led to an immense increase in the amount of generated data, and the development of novel techniques to quickly and reliably extract essential information from this data has become a central issue. The project research develops probabilistic approaches for topological data analysis, including quantitative reliability assessments.<br/>The project has applications in the field of materials science, such as in the study of the properties of industrial level metal alloys and the design of new materials. Topological methods have already been shown to provide important insight into such materials studies, and the techniques developed in this project are applied in the context of materials characterization and design. This leads to a classification of phase separation phenomena in multi-component alloys and has the potential to lead to system-response-maps, which can then be used in the design of materials, such as for example the design of controlled drug-release coatings for arterial stents. The project also leads to a broader study of random fields using homology theory, which in the long term has applications in medical imaging. The project involves student research at both the undergraduate and graduate levels."
"1115682","Collaborative Research: Development of High-Resolution Finite-Volume Methods for Systems of Nonlinear Time-Dependent PDEs","DMS","COMPUTATIONAL MATHEMATICS","10/01/2011","09/13/2011","Alina Chertock","NC","North Carolina State University","Standard Grant","Leland Jameson","09/30/2015","$118,379.00","","chertock@math.ncsu.edu","2601 Wolf Village Way","Raleigh","NC","276957514","9195152444","MPS","1271","9263","$0.00","The project is aimed at developing highly accurate, efficient and robust numerical methods for systems of nonlinear time-dependent PDEs, with particular reference to multidimensional hyperbolic systems of conservation/balance laws and related problems. The principal part of the proposed research will be focused on the development of new finite-volume methods that will provide an improved resolution of linear contact waves and incorporate new techniques for solving problems involving complicated nonlinear wave phenomena and blowing up/spiky solutions. The proposed methods will be applied to a variety of nonlinear problems, among which are systems of gas dynamics, nonlinear elasticity and acoustics systems, modern traffic flow models, several chemotaxis and bioconvection models, and others. These problems will be studied in the most challenging cases of high space dimensions, complex geometries and moving interfaces. For each problem, a high-resolution finite-volume scheme will be systematically derived in a way that the main properties satisfied by the underlying system of PDEs will be also satisfied on the discrete level. One of the key features of the new schemes will be their nonlinear stability, which will be ensured by ability of the scheme to preserve positivity of such physical quantities as density. To achieve this goal, several high-order positivity preserving techniques will be explored.<br/><br/>Besides providing the examples that corroborate the analytical approach, the foregoing applications are of a substantial independent value for a broad class of problems arising in today's science including geophysics, meteorology, astrophysics, semiconductors, traffic flows, image processing, financial and biological modeling and many other areas. Development of modern high-resolution finite-volume methods as well as of supplementary techniques is essential for solving many practically important problems, some of which are currently out of reach because the existing numerical methods are either inefficient/inaccurate or not applicable at all."
"1125906","Early Career and Student Support for the XVIII Householder Symposium","DMS","COMPUTATIONAL MATHEMATICS","02/15/2011","02/14/2011","Ilse C.F. Ipsen","NC","North Carolina State University","Standard Grant","Junping Wang","01/31/2012","$20,000.00","Michael Overton","ipsen@ncsu.edu","2601 Wolf Village Way","Raleigh","NC","276957514","9195152444","MPS","1271","7556, 9263, OTHR","$0.00","This project supports the participation of U.S.-based early career scientists and Ph.D. students at the Householder Symposium XVIII on Numerical Linear Algebra, June 12-17, 2011, at the Granlibakken Conference Center in Tahoe City, California.  The Symposium is very informal, with the intermingling of early career and established researchers a high priority. Participants are expected to attend the entire meeting. The  Householder Prize for the best thesis in numerical linear algebra since January 1, 2008 is awarded at the  meeting.  Numerical linear algebra plays a central role in scientific computing.  For the 2011 Symposium the Householder Program Committee aims for a healthy balance of theoretical, computational and applied presentations.  There is an emphasis on broad relevance, in contrast to results that are of interest only in  a narrow subfield.  Since abstract submission is only 6 months in advance of the meeting date, the Symposium always features hot research topics and emerging areas.  The organizers anticipate a large number of  submissions on the following topics: Nonlinear eigenvalue problems, tensor algorithms and analysis, domain decomposition and multilevel methods, Krylov space methods for linear systems and eigenvalue problems, algorithms for structured matrices, computation of matrix functions, randomized algorithms, as well as application to optimization, differential equations, signal and image processing, control, electronic structure calculations, data analysis, information retrieval, bioinformatics, and structural, mechanical and aerospace engineering. <br/><br/>The support of this project ensures the attendance at the meeting of well qualified applied mathematics U.S. Ph.D. students from U.S. institutions, as well as early U.S. career scientists who received their Ph.D.'s after January 1, 2008.  Support of this group will have a positive impact on the continued strong competitiveness of the U.S. in this crucial discipline, with its connections to a large number of scientific computing topics. Individual benefits for early career researchers who have attended a Householder Symposium include: career advice from established researchers, enhanced visibility in the community, ideas for REU programs, and several NSF funded research projects that arose directly from collaborations established or advice received at the Householder Symposium. Funding for participants takes into consideration the participant diversity at the meeting."
