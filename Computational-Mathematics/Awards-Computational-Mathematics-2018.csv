"AwardNumber","Title","NSFOrganization","Program(s)","StartDate","LastAmendmentDate","PrincipalInvestigator","State","Organization","AwardInstrument","ProgramManager","EndDate","AwardedAmountToDate","Co-PIName(s)","PIEmailAddress","OrganizationStreet","OrganizationCity","OrganizationState","OrganizationZip","OrganizationPhone","NSFDirectorate","ProgramElementCode(s)","ProgramReferenceCode(s)","ARRAAmount","Abstract"
"1812693","Direct and Inverse Electromagnetic Scattering Problems for Complex Periodic Media","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","07/20/2018","Dinh-Liem Nguyen","KS","Kansas State University","Standard Grant","Yuliya Gorb","07/31/2022","$130,000.00","","dlnguyen@ksu.edu","1601 VATTIER STREET","MANHATTAN","KS","665062504","7855326804","MPS","1271","9150, 9263","$0.00","The interaction and scattering of light by periodic structures at the nanoscale <br/>is a topic of great significance in the area of nanophotonics and metamaterials <br/>technology. With the current rapid development of this enabling technology, there <br/>is a high demand on new mathematical theories and computational algorithms <br/>for both direct and inverse problems of the light scattering by periodic complex <br/>media or periodic metamaterials. This project aims to develop such theories <br/>and algorithms. Results from this project will advance knowledge, understanding <br/>and imaging techniques in the technology of nanophotonics and metamaterials. <br/>For instance, the mathematical theories and the computational algorithms developed <br/>for the direct problems are extremely useful for the simulation, fabrication and <br/>maintaining of optical devices. The imaging techniques developed for the inverse <br/>problems can be potentially of practical use for non-destructive tests, which help <br/>to detect and characterize discrete flaws in optical components and devices.<br/><br/>The project contains two main areas of study: the mathematical and numerical <br/>analysis for direct scattering problems, and the development of efficient inversion <br/>algorithms for inverse scattering problems. More precisely, for the direct problem, <br/>the PI and his colleagues will work on the following topics: 1) develop volume integral <br/>equation formulations for direct scattering problems for periodic complex media; 2) <br/>develop fast integral equation-based numerical solvers for the direct scattering problems; <br/>3) study interior transmission eigenvalues for periodic complex media; 4) study <br/>well-posedness of the scattering by chiral metamaterials. The proposed research <br/>for the inverse problem includes the topics: 1) develop sampling methods <br/>for imaging of periodic complex  media; 2) develop sampling methods for the detection <br/>of local defects in photonic crystals; 3) develop globally convergent methods for <br/>the identification of material parameters for photonic crystals.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819166","Fast and Reliable Hierarchical Structured Methods for More General Matrix Computations","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","06/21/2018","Jianlin Xia","IN","Purdue University","Standard Grant","Leland Jameson","07/31/2021","$199,148.00","","xiaj@purdue.edu","2550 NORTHWESTERN AVE STE 1900","WEST LAFAYETTE","IN","479061332","7654941055","MPS","1271","062Z, 9263","$0.00","Large matrix computations play a critical role in modern scientific computing tasks and engineering simulations. Realistic computations usually involve enormous amounts of data due to large dense matrices or dense intermediate matrix blocks, which makes classical matrix methods impractical. Hierarchical structured methods provide an effective and reliable way to compress and process large matrix data. In such methods, dense matrix blocks are approximated by compact structured forms that are convenient to handle. This research project aims to develop theoretical foundations for understanding multiple hierarchical structured techniques and for designing new hierarchical structured algorithms. These algorithms are expected to be applicable to more general matrix computations and challenging applications where usual structured methods are not suitable or effective.<br/><br/>Hierarchical structured methods exploit inherent structures in matrix computations to gain high efficiency while ensuring superior stability. This project is concerned with the design, analysis, and application of fast and reliable hierarchical structured methods for broad classes of challenging computations. A unified framework will be provided to understand multiple types of hierarchical structured methods, design new hierarchical methods with enhanced applicability, and analyze their accuracy and stability. State-of-the-art fast and stable solvers will be developed for tackling challenges such as large data sizes, ill conditioning, high frequencies, and multiple frequencies. The new solvers will be applicable to a wide range of matrix computations. Based on data sparsity and enhanced stability, the solvers will significantly improve the efficiency and reliability of many computations in PDE solution, large data analysis, network, machine learning, imaging, seismic modeling, electromagnetics, etc. The research will also make fast and stable structured solvers widely accessible to broader fields and industries. The data will be included in data repositories for unrestricted access. Open-source packages and educational/tutorial materials will be freely available. The multidisciplinary project will provide excellent opportunities for graduate and undergraduate students from diverse backgrounds to closely interact and to learn critical computational and mathematical skills from multiple fields.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1759877","US Participation at the Twenty-fifth International Domain Decomposition Conference","DMS","COMPUTATIONAL MATHEMATICS","01/01/2018","11/06/2017","Susanne Brenner","LA","Louisiana State University","Standard Grant","Leland Jameson","06/30/2019","$15,000.00","","brenner@math.lsu.edu","202 HIMES HALL","BATON ROUGE","LA","708030001","2255782760","MPS","1271","7556, 9150, 9263","$0.00","The 25th International Domain Decomposition Conference (DD25) will be held at the Memorial University of Newfoundland in St. John's, Newfoundland, Canada, during July 23-27, 2018. The conference website is http://dd25.math.mun.ca/index.html . The conference will be comprised of mini-symposia and contributed talks, along with thirteen invited talks.<br/><br/>Domain decomposition methods are fundamental to large scale high performance computing in the sciences and engineering. The International Domain Decomposition Conference, which has been held approximately every eighteen months since 1987, is the preeminent conference in domain decomposition methods that brings together mathematicians, engineers, and scientists to exchange information and ideas on the latest cutting-edge developments in the field. This funding will provide travel costs for young US participants, graduate students, and recent Ph.D. recipients, to learn about recent developments in domain decomposition and to interact with renowned international experts in computational engineering and computational sciences."
"1819002","Polyhedral Techniques for Fast Sparse Nonlinear Optimization and their Application to Nonsmooth Optimal Control","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","07/31/2018","William Hager","FL","University of Florida","Standard Grant","Leland Jameson","07/31/2021","$200,000.00","Anil Rao","hager@ufl.edu","1523 UNION RD RM 207","GAINESVILLE","FL","326111941","3523923516","MPS","1271","9263","$0.00","New computational algorithms are developed for solving sparse optimization problems. These are large, complex problems that arise in science, engineering, and industry where the goal is to operate a large interconnected system in an efficient way.  Applications range from power grids to air traffic control systems to the fabrication of computer chips. A target area in the project is optimal control, a technology which has a wide array of uses that include space flight maneuvers, the optimal design of aerodynamic shapes, the optimal design of manufacturing processes, and biotechnology; for example, the development of effective vaccination and treatment plans for a disease. The optimization algorithms are targeted to sparse problems which often arise when a dynamic process which evolves continuously in time, such as the motion of a robot's arm, is replaced by discrete movements that are computationally tractable.  The algorithms are faster and achieve greater accuracy than was previously possible. The research has impact on the development of human resources through the training of students with both gender and ethnic diversity. To maximize the impact of the research, high-quality software will be developed and made widely available.<br/><br/>A new framework will be developed for solving large-scale sparse constrained nonlinear optimization problems based on a new fast robust accurate solver for polyhedral constrained problems. At the same time that the new optimization framework is developed, it will be used in a new approach for solving optimal control problems based on hp-orthogonal collocation.  The optimization research will focus on the extension of techniques for solving polyhedral constrained optimization problems to the treatment of general nonlinear constraints. The solver will require only first-order information and will be built around a new tight bound for the error in a solution to an optimization problem in terms of the violation in the first-order optimality conditions.  Sparsity in the constraints will be exploited throughout the solution process.  Phase one of the solver seeks to identify active constraints, while phase two strives for superlinear convergence using a gradient-based method such as the conjugate gradient method.  The switch between the two phases is controlled by the error estimator.  The new optimization framework will be used to continue the development of hp-orthogonal collocation techniques for solving optimal control problems.  In particular, the fast and accurate optimization scheme is instrumental in the hp-techniques since better estimates for the error in the discrete approximation to the control problem yield a better choice for the mesh, and a much faster solution of the control problem. Mesh placement techniques, as opposed to mesh refinement techniques, will be used to further improve the mesh.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818467","High-Order Numerical Methods for Convection-Diffusion Equations with Unbounded Singularities","DMS","COMPUTATIONAL MATHEMATICS","09/01/2018","06/06/2018","Yang Yang","MI","Michigan Technological University","Standard Grant","Yuliya Gorb","08/31/2022","$236,978.00","","yyang7@mtu.edu","1400 TOWNSEND DR","HOUGHTON","MI","499311200","9064871885","MPS","1271","9263","$0.00","This project focuses on design of efficient and robust numerical methods to solve partial differential equations with unbounded singularities, with potential applications in astrophysics, biology, combustion, electrical engineering, and oil recovery. The numerical techniques under development can be extended to systems with multi-species fluid mixtures such as gaseous detonation and reacting flows. The project includes training of graduate students through involvement in the research. Research results will be integrated into new courses on numerical analysis and multidisciplinary computation.<br/><br/>The focus of this project is the study of high-order numerical methods for solving convection-diffusion equations with unbounded singularities. It contains two parts. The first part is to study the error behaviors of the numerical schemes and ensure the boundedness of numerical approximations before blow-up occurs (where the exact solutions are sufficiently smooth). The second part is to use high-order numerical methods to solve convection-diffusion equations involving delta-singularities and other blow-up solutions. Special bound-preserving techniques will be constructed to ensure that the numerical approximations are physically relevant. The strategies in this work do not depend on the maximum principle, and they ensure L1-stability of the numerical schemes. For problems with blow-up solutions, the blow-up criteria, blow-up locations, blow-up time, and blow-up rates will be studied. The project aims to develop a general approach to numerically approximate exact blow-up times and to elucidate the relationship between blow-up time and significant system parameters.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818757","A Solve-Then-Discretize Paradigm for Spectral Methods","DMS","COMPUTATIONAL MATHEMATICS, CDS&E-MSS","07/01/2018","06/22/2020","Alex Townsend","NY","Cornell University","Continuing Grant","Yuliya Gorb","06/30/2022","$300,000.00","","townsend@cornell.edu","341 PINE TREE RD","ITHACA","NY","148502820","6072555014","MPS","1271, 8069","9263","$0.00","Spectral methods are one of the big three technologies (along with finite differences and finite element methods) for the numerical solution of partial differential equations (PDEs) and are particularly powerful for fluid flow and airfoil simulations.  This research project aims to develop a new infinite-dimensional framework for solving PDEs to derive competitive computational algorithms that preserve the continuum structure of differential operators, promising to overcome many of the hard-and-fast computational barriers with spectral discretizations. We aim to produce a collection of adaptive, robust, and industrial-strength iterative solvers for spectral methods to allow for the accurate resolution of fluid flows. We will also develop tools for computing the pseudospectra and continuous spectra of differential operators, facilitating improved understanding of inelastic scattering. The results will help to demonstrate that spectrally-accurate methods, when done carefully, are flexible, general, and powerful numerical tools in computational mathematics and engineering.<br/><br/>The standard paradigm for solving a PDE is to first discretize the equation and then solve the resulting linear system. This approach has a number of drawbacks for spectral methods related to the design of preconditioners, the introduction of non-normality, and the perturbation of spectra. The infinite-dimensional framework under development in this project preserves the continuum structure of PDEs by avoiding the discretization of differential operators, and instead only discretizes smooth functions, such as the solution and the source terms of the PDE. Not working with finite sections of differential operators promises to enable us to develop robust Krylov-based iterative solvers, motivate preconditioners directly from the differential operator, compute the continuous part of the spectrum of operators, and develop a theoretical foundation for the adaptive resolution of solutions and eigenfunctions based on error analysis. We will apply these new tools to the numerical simulation of advection-dominated fluid flow as well as inelastic scattering.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818646","Symbolic Computation Meets Computational Geometry and Data Approximation","DMS","COMPUTATIONAL MATHEMATICS","06/15/2018","06/07/2018","Henry Schenck","IA","Iowa State University","Standard Grant","Leland Jameson","03/31/2021","$149,999.00","","hks0015@auburn.edu","1350 BEARDSHEAR HALL","AMES","IA","500112103","5152945225","MPS","1271","9263","$0.00","Modeling of functions and data approximation are two fundamental tools in computational geometry, computer graphics, and data analytics. For example, when an airplane wing is designed, rather than modeling the wing as one large object, the wing is conceptually broken into a number of small triangles, computations are performed on these small patches, and then the results are assembled back together into a coherent result. This research project studies this technique, and others like it, using tools from computational and symbolic algebra. Results of the research are expected to advance theoretical understanding of these approximations, as well as to provide potential speed-ups to computations used in computer graphics and industrial design.<br/><br/>This research focuses on analysis and implementation of three central methods in approximation theory and geometric modeling: generalized barycentric coordinates, multidimensional splines, and polynomial interpolation. These methods involve algebraic techniques; from the computational standpoint this means that tools of symbolic algebra are applicable. The goal in all these projects is to compute the dimension of some space of functions, generally in terms of combinatorial and geometric data, and if possible to find a basis for that space. The theoretical tools to be employed are homological algebra and algebraic geometry; the investigations also use computation as a vehicle for experiment. The project will result in development of specialized software, which will be integrated into the Macaulay2 software package.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818861","Structure-Preserving Numerical Methods for Strongly Nonlinear Elliptic Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","08/05/2020","Wujun Zhang","NJ","Rutgers University New Brunswick","Continuing Grant","Yuliya Gorb","07/31/2022","$250,000.00","","wujun@math.rutgers.edu","3 RUTGERS PLZ","NEW BRUNSWICK","NJ","089018559","8489320150","MPS","1271","9263","$0.00","The goal of this research project is to develop accurate and efficient numerical methods to solve strongly nonlinear elliptic partial differential equations (PDEs).  Nonlinear problems are ubiquitous in science and engineering and arise naturally from materials science, nonlinear elasticity, fluid dynamics and image processing. This proposal studies the analysis and design of efficient numerical algorithms which preserve essential properties of nonlinear PDEs. The project will provide efficient numerical algorithms for researchers in liquid crystal materials and shape design. In addition to the design of efficient algorithms, the project will also analyze the stability and rates of convergence of the methods. Compared with the vast literature on linear problems, the work on numerical analysis for strongly nonlinear elliptic problems are relatively few. The success of the project will provide insight in future development of numerical methods in studying nonlinear phenomena. <br/><br/>The project splits into three different parts, namely, numerical approximation of the Landau-De Gennes model of nematic liquid crystals, numerical approximation of the Monge Ampere PDEs, numerical optimal transportation problem. The specific goal of the project includes (i) construction of novel numerical methods based on piecewise linear or nodewise functions to preserve discrete maximum principle, an essential property of these problems, (ii) combination of robust lower order method with accurate higher order methods and development of  a posteriori error estimation and adaptivity to improve the accuracy and efficiency of the methods, (iii) analysis of these methods based on discrete version of nonlinear PDE tools, such as Gamma convergence and discrete Alexandroff maximum principle, (iv) applying these methods in simulating liquid crystal materials and antenna design.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819220","Novel Computational Mathematics for Aperiodic Multilayers","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","06/01/2018","Paul Cazeaux","KS","University of Kansas Center for Research Inc","Standard Grant","Yuliya Gorb","06/30/2022","$81,446.00","","cazeaux@vt.edu","2385 IRVING HILL RD","LAWRENCE","KS","660457552","7858643441","MPS","1271","7237, 8037, 9150, 9263","$0.00","The recent discovery of a whole family of atomically thin layers has led to much interest in the fields of materials science and nanotechnology. In principle, many desired electronic, optical, and thermal material properties can be obtained by stacking vertically a number of such layers to form so-called two-dimensional weakly-bonded integrated multilayers. Such structures are generally non-periodic. This leads to interesting geometrical properties such as moire patterns, but also results in the breakdown of the traditional (periodic) description of materials that is essential to the computer simulation of materials from first principles. The broad goal of this project is to exploit the mathematical structure that arises in quantum models of two-dimensional multilayer materials to enable the efficient and reliable predictions by computer simulations that are required to explore the vast range of design possibilities and to guide or validate experimental studies.<br/><br/>This project aims to develop and analyze novel discretization techniques and algorithms based on the C*-algebra formulation of the quantum electronic transport phenomena. This novel class of numerical techniques will implement directly the noncommutative framework for aperiodic multilayer geometries and enable fast and robust ab-initio computations of electronic properties in two-dimensional multilayer materials. Numerical analysis and theory-based numerical experiments will be developed to optimize and certify the resulting computations. Beyond the case of two-dimensional weakly-bonded integrated multilayers, this new prediction and design tool will also allow the investigation of mechanical or photonic meta-materials by engineering artificial incommensurate geometries.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819157","Multigrid Methods and Machine Learning","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","08/09/2019","Jinchao Xu","PA","Pennsylvania State Univ University Park","Continuing Grant","Yuliya Gorb","06/30/2022","$350,000.00","Ludmil Zikatanov","xu@math.psu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271","079Z, 9263","$0.00","The goal of this project is to merge advanced tools from multigrid (MG) methods and machine learning (ML) towards the development of a novel class of numerical techniques targeting the data intensive applications emerging in physical, biological and social sciences.  Multigrid methods, including both geometric and algebraic multigrid (GMG and AMG) methods, are effective tools for solving linear as well as nonlinear algebraic system of equations arising from scientific and engineering computing.  On the other hand, there is a significant advancement in machine learning (ML) techniques, especially convolutional neural networks (CNN), which have successful applications in many areas such as image classification and processing.  The proposed project is to explore the resemblances and differences between these two different technologies so that more efficient multigrid methods as well more efficient deep learning models are developed.  The existing rich theory of multigrid method is expected to shed new light to the theoretical understanding of deep neural networks whereas the numerous empirical techniques used in the vast and ever-growning deep learning literature can be used to design general multigrid methods with wider range of applications.  This interdisciplinary research project is expected to have a direct impact to both the scientific computing community and the artificial intelligence industry.<br/><br/>More specifically, MG and CNN are similar for the use of multilevel hierarchy and the use of many technical components such as smoothers (MG) versus convolutions (CNN), restriction (MG) versus convolution with stride (CNN). But they also have some major differences: CNN has multiple channels of convolutions to be trained whereas MG often has one single smoother given a priori. Such relationships motivate the design of new multigrid methods with more general smoothers and restrictions that are subject training in different ways and, as a result, multigrid methods will become more adaptive and robust in its application to different practical problems.  The well-understood MG structure and theory can be adapted to understand and improve the existing deep learning model such as residual neural networks.  Furthermore, multilevel iterative techniques used in MG will also be investigated to speed up the stochastic gradient descent method that is now the standard training algorithm for most deep neural networks in machine learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1901567","Conference on Fast Direct Solvers","DMS","COMPUTATIONAL MATHEMATICS","12/01/2018","11/29/2018","Jianlin Xia","IN","Purdue University","Standard Grant","Yuliya Gorb","11/30/2021","$10,000.00","","xiaj@purdue.edu","2550 NORTHWESTERN AVE STE 1900","WEST LAFAYETTE","IN","479061332","7654941055","MPS","1271","7556","$0.00","The 2018 Conference on Fast Direct Solvers will be held at Purdue University in November 9-11, 2018. The purpose of the conference is to bring together researchers from different mathematical and application fields to exchange ideas on the latest developments of fast direct solvers, discuss potential strategies for tackling the current challenges, stimulate new multidisciplinary collaborations, and disseminate relevant ideas to broader communities. Researchers, students, and practitioners from all relevant fields are encouraged to attend the conference and/or to give talks. The conference will provide a multidisciplinary platform for junior and senior researchers, students, and practitioners to discuss and to establish new collaborations. The activities will help to attract students and junior researchers from diverse background to join the field and also stimulate student interest in mathematics. This grant will be used to partially support the travel and lodging of junior researchers and students.<br/><br/>In scientific computing, data analysis, and engineering simulations, solving large linear systems is typically a key computational component. Direct solvers do not need iterations, are very robust, and have various other attractive features. However, classical direct solvers are typically expensive for large sparse systems because of the loss of sparsity. In the past 15 years or so, the scientific computing community has witnessed quick developments of the so-called fast direct solvers, which exploit structures and can achieve significantly better efficiency than classical direct solvers, sometimes by orders of magnitude. This conference will bring together researchers, students, and practitioners from diverse fields that actively involve the design, study, and application of fast direct solvers. The invited and contributed talks will help to supply new tools and identify new research directions for direct solvers. The conference is expected to be an effective event to both advance the development of fast direct solvers and benefit more general numerical computations.<br/><br/>Website: http://www.math.purdue.edu/~xiaj/FastSolvers2018/<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819131","A General and Efficient Framework for Computational Shape Analysis Through Geometric Distributions","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","06/06/2018","Nicolas Charon","MD","Johns Hopkins University","Standard Grant","Leland Jameson","10/31/2020","$215,032.00","","charon@cis.jhu.edu","3400 N CHARLES ST","BALTIMORE","MD","212182608","4439971898","MPS","1271","062Z, 9263","$0.00","The analysis of shapes and their variability has become an increasingly central problem in multiple areas of data science. In the field of computer vision, shape recognition and classification is often a crucial component of machine learning systems such as self-driving cars. In natural sciences, the recent development of computational anatomy, that is the automatic analysis of anatomical structures by numerical algorithms, provides a fruitful approach in understanding and diagnosing a wide range of pathologies and disorders. Along these different scientific questions, the amount and variety of available data has never ceased to grow. As a result, the concept of shape itself has considerably expanded and may refer to various types of geometric objects, which poses the important challenge of constructing and computing relevant similarity metrics between shapes across all these different modalities. The purpose of this research project is to develop an integrated mathematical model and associated numerical pipeline that allows for morphological analysis of geometric structures in a flexible and efficient way, and explore its possible applications to computational anatomy and computer vision. It will also include a substantial educational component with the training of a graduate student, support for presentations in conferences and workshops, and dissemination of an open-source code to the scientific community.<br/><br/>The primal challenge of statistical shape analysis is the rather non-standard and disparate mathematical spaces in which objects belong, whether the shapes in question are raw images, manually or automatically extracted landmarks, curves, surfaces, vector fields or multi-modal objects. While the seminal model proposed by Grenander introduced the idea of comparing any two shapes through the estimation of an optimal deformation (measured by a metric on a certain diffeomorphism group), this model's generality falls short in many real applications where a certain amount of residual dissimilarity is necessary to account for other sources of variability (like noise). This project intends to fill this current gap by introducing a flexible approach to quantify shape similarity which relies on a unified embedding of shape spaces as generalized distributions, following the principles of geometric measure theory. Beyond the past success of these representations for curve and surface registration problems, the objective will be to demonstrate on a mathematical and computational level how it extends to a much wider class of geometric data structures and allows for cross-modality analysis, while pushing the scope of applications to other problems like clustering, classification and sparse representations on shapes. Fast numerical methods for this new framework is also an important aspect of the project, with the objective of making implementations scalable to the current dimensionality of datasets e.g. in medical imaging.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1852876","Regularized Adaptive Methods for Classes of Nonlinear Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","06/28/2019","Sara Pollock","FL","University of Florida","Continuing Grant","Leland Jameson","07/31/2021","$92,662.00","","s.pollock@ufl.edu","1523 UNION RD RM 207","GAINESVILLE","FL","326111941","3523923516","MPS","1271","8012, 9263","$0.00","Nonlinear diffusion equations appear often in simulations of physical processes such as heat conduction, groundwater flow, and flow in porous media. Such equations appear in environmentally relevant modeling problems describing the distribution of subsurface contaminants. In these nonlinear problems, the diffusion coefficient is dependent on the solution and possibly its coordinates; as such, a numerical solution to the model cannot be determined by direct means. Generally, solutions can only be found by solving a sequence of simpler approximate problems, and making successive improvements to the solution. Convergence of the scheme may fail however if this is carried out in a standard way, and current numerical simulations can be limited by the failure of these standard iterative techniques. The focus of this work is on the mathematically rigorous development of stable and convergent iterative numerical algorithms to efficiently solve nonlinear diffusion equations, addressing a substantial problem in scientific computing for realistic physical modeling.<br/><br/>The technical goal of this project is to develop efficient and robust simulation technology for classes of nonlinear diffusion equations. Finite element solutions for nonlinear diffusion problems are known to have good approximation properties in the asymptotic regime, but a sound methodology to compute those discrete solutions has yet to be developed.  Regularized adaptive methods will be developed within the framework of adaptive finite element methods, for which (1) the iterates converge to discrete solutions; and (2) the discrete solutions converge to the solution of the partial differential equation, as the mesh is selectively refined.  One of the aims of this work is to develop guiding principles for the regularization of the induced discrete problems in concert with error indicators to determine the mesh refinement.  The combination of the regularization and error indicators should both allow the computation of a discrete solution, and guarantee the convergence to a correct solution from a theoretical standpoint.  Computational methods backed up by sound mathematical theory will be developed for representative classes of model problems, and the developed methods will be extended to larger, computationally-demanding simulations, for example to model the distribution of C02 injected into the earth's subsurface as a potential means for long-term storage. It is expected that the technical advances made in the course of this project will advance the realization of  efficient and accurate numerical simulation tools that allow the practical modeling of problems with realistic physical attributes."
"1747624","The Midwest Numerical Analysis Day","DMS","COMPUTATIONAL MATHEMATICS","04/01/2018","01/28/2021","Xuemin Tu","KS","University of Kansas Center for Research Inc","Standard Grant","Leland Jameson","03/31/2022","$7,200.00","Erik Van Vleck, Weizhang Huang, Hongguo Xu, Agnieszka Miedlar","xtu@math.ku.edu","2385 IRVING HILL RD","LAWRENCE","KS","660457552","7858643441","MPS","1271","7556, 9150, 9263","$0.00","This award provides  support for 24 regional participants to attend ""The Midwest Numerical Analysis Day"", which will be held on April 14 to 15, 2018, on the campus of the University of Kansas, in Lawrence, Kansas. Funds will provide support for women, underrepresented minorities, and young participants (graduate students, postdoctoral fellows, and junior faculty). Scientific computing is a rapidly growing multidisciplinary field and has become a common tool for using advanced computing capabilities to  construct mathematical models for complex problems, to develop quantitative analysis techniques, and to understand and solve the scientific problems arising from different disciplines. Numerical analysis is the core of scientific computing, an area that develops and studies algorithms of obtaining the numerical solutions of the mathematical models of real world problems. With the increasing power of modern computers, large scale and complex simulations become possible, which in turn requires collaboration among numerical analysts, algorithm designers, and exports in applied sciences and engineering. Such an interdisciplinary collaboration has increased significantly and become a new norm in last decades.<br/><br/>This conference will bring  groups  of researchers  in mathematics and applied sciences and engineering who are interested in scientific computation and related applications. It will facilitate a transfer of knowledge among different disciplines and promote the collaborations. The conference will provide an excellent opportunity for regional researchers in all stages of their careers, especially for young faculty members, postdocs, and graduate students, to present their research results,  have the opportunities to exchange the ideas with people from different disciplines, and gain experience and improve their skills in communication and presentation.  Moreover, the conference will invite, encourage, and support people from underrepresented groups.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1753203","CAREER: Adapting the Fluid Projection Method to Model Elasto-plastic Materials","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","07/05/2022","Christopher Rycroft","MA","Harvard University","Continuing Grant","Yuliya Gorb","06/30/2024","$400,000.00","","rycroft@wisc.edu","1033 MASSACHUSETTS AVE 5TH FL","CAMBRIDGE","MA","021385369","6174955501","MPS","1271","1045, 9263","$0.00","There are two main ways that materials deform under an applied force. The deformation can be elastic, so that when the force is removed the material recovers its original shape. Alternatively, the deformation can be plastic, whereby the material undergoes irreversible changes that may subsequently lead to breakage. Many materials of technological importance exhibit a combination of these two types of deformation depending on the applied force, and are called elasto-plastic. One example are bulk metallic glasses (BMGs), which are alloys that have an amorphous atomic arrangement in contrast to most metals. BMGs have desirable properties, such as the ability to be processed like plastics, making them attractive candidates for many applications (e.g. next-generation smartphone cases) due to considerable improvements in manufacturing efficiency. However, experimental measurements of BMG breakage properties show wide variations, limiting their usage. To overcome these limitations, it is essential to develop predictive theoretical and computational models of BMG elasto-plasticity. This project is based on a surprising similarity between the equations for elasto-plastic materials and the equations for incompressible fluids. Using this similarity, computational approaches that were originally developed for fluid flow will be translated to elasto-plasticity. These computational methods will be used in collaboration with theorists and experimentalists to study the fracture properties of BMGs. The ultimate aim is to provide a practical engineering tool for predicting when elasto-plastic materials will break, and how to best design structures using them. This work will be undertaken as part of an integrated program of research, teaching, and mentorship, and will involve outreach activities in New England, including a local library lecture series.<br/><br/>The projection method of Chorin (1968) is a well-established approach for simulating the incompressible Navier-Stokes equations for fluid flow. This proposal is based on a surprising mathematical correspondence between fluids in the incompressible limit and elasto-plastic solids in the quasi-static limit (when inertia can be neglected). In this proposal, this correspondence is harnessed to translate several modern numerical approaches derived from Chorin's projection method to quasi-static elasto-plasticity, resulting in a practical and powerful set of new simulation tools for a different class of physical problem. Compared to existing techniques, the resultant numerical methods are likely to be especially well-suited to problems involving large plastic deformations. An example type of elasto-plastic material are the bulk metallic glasses (BMGs), which are alloys with many favorable properties such as excellent strength and wear resistance. The numerical methods developed here will be used in a collaboration with theorists and experimentalists to study the fracture toughness properties of BMGs, with the aim of predicting BMG toughness over a wide range of experimental conditions. The PI plans to expand the graduate curriculum in numerical methods to address a pressing need in this area. Open source software will be released as part of this project, and the PI will train students in best practices to make software accessible to a broad audience.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818946","Computational Framework  for Optimization with Perspective Functions and Applications to Data Analysis","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","06/01/2018","Patrick Combettes","NC","North Carolina State University","Standard Grant","Yuliya Gorb","06/30/2023","$372,644.00","","plc@math.ncsu.edu","2601 WOLF VILLAGE WAY","RALEIGH","NC","27607","9195152444","MPS","1271","062Z, 9263","$0.00","Data analysis is ubiquitous in modern science, essential in areas such as information technology, environmental sciences, medicine, biology, and homeland security. The mathematical formulations arising in modern data analysis pose new mathematical and computational challenges, both because of the sophistication of their formulations and their potentially very large size. In this context, it is essential to exploit structures that may be present in a system, with the dual objectives of simplifying the analysis and constructing efficient and flexible optimization algorithms that need only to perform basic tasks at each iteration. This research project aims to address these issues by developing new mathematical tools and algorithms structured around a class of so-called perspective functions that will facilitate handling of a broad range of data analysis questions.<br/><br/>This research concerns mathematical and computational issues pertaining to perspective functions, a powerful concept that permits the extension of a convex function to a jointly convex one in terms of an additional scale variable. While perspective functions are implicitly or explicitly present in many variational formulations, especially in data analysis, few efforts have been devoted to the study of their mathematical properties and the development of computational methods that can solve them efficiently. Thus, no synthetic variational model is available to unify classes of optimization problems involving perspective functions. In addition, on the algorithmic side, there exists no principled strategy to solve such problems. In particular, the proximity operators of perspective functions are known only in limited cases, which precludes the use of powerful proximal splitting algorithms. It is the objective of this project to fill these gaps. The project aims to lay out theoretical and computational foundations for the analysis and the numerical solution of minimization problems involving perspective functions and generalizations thereof, and to apply these findings to problems in data analysis that are beyond the reach of current methods. The research methodology hinges on unifying structured variational models that are recast in product spaces and solved via proximal splitting algorithms as well as duality-driven strategies. Applications to several fields of data analysis are planned.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819233","Mathematical Analysis and Numerical Methods for Peridynamics and Nonlocal Models","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","06/29/2018","Xiaochuan Tian","TX","University of Texas at Austin","Standard Grant","Yuliya Gorb","09/30/2020","$119,644.00","","xatian@ucsd.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271","9263","$0.00","Improvements in computer technology are fueling the development of more realistic mathematical models for complex applications, including nonlocal models that are more realistic than conventional local models for studying various phenomena from physics and biology to materials and social sciences. An example is the peridynamics model, a spatially nonlocal mechanics theory, which has been successfully used to model material defects and predict dynamics of crack formation in various engineering applications. Although new nonlocal models have been gaining popularity in various applications, the study of mathematics behind them is still at the nascent stage, impeding the further development of computational tools. The goal of this project is to develop efficient and reliable numerical methods for simulating nonlocal models and establish related mathematical analysis as part of the rigorous validation and verification process. It aims to improve the effectiveness and robustness of nonlocal modeling while retaining modeling accuracy. On the educational side, this project will provide training to students in both mathematics and computational mechanics. <br/><br/>This project aims to develop state-of-the-art multiscale modeling techniques to improve computational efficiency while retaining the accuracy of nonlocal models for predicting dynamic fractures, with new theoretical methodologies built to study the analytic properties of the models.  Three specific methods of multiscale modeling will be addressed, in which the treatment of boundary traces and interfacial conditions plays pivotal roles. The first is the seamless coupling of nonlocal and local models via heterogeneous localization of nonlocal interactions at the interface. A novel nonlocal trace theorem is used to ensure the well-posedness of the coupling. The goal is to treat the interface as a free boundary based on the development of the solution. The second is a quasi-nonlocal coupling method inspired by the atomistic-to-continuum coupling method. It is aimed at building a bridge between the discrete atomistic model and continuous nonlocal model. The third is to design appropriate nonlocal boundary conditions to reduce the computational cost for problems on unbounded domains. A new notion of nonlocal Neumann boundary condition will be introduced, which will shed light on domain decomposition methods and the coupling of nonlocal models.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818941","Collaborative Research: Construction and Analysis of Numerical Methods for Stochastic Inverse Problems with Application to Coastal Hydrodynamics","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","07/26/2018","Troy Butler","CO","University of Colorado at Denver-Downtown Campus","Standard Grant","Yuliya Gorb","07/31/2022","$175,000.00","","butler.troy.d@gmail.com","1380 LAWRENCE ST STE 300","DENVER","CO","802042055","3037240090","MPS","1271","9263","$0.00","As observed in past hurricanes such as Katrina (2005), Ike (2008), Sandy (2012), and the sequence of hurricanes over the 2017 season, flooding due to storm surge and rainfall causes tremendous damage to coastal communities. Preparing for future hurricane impacts requires the ability to predict characteristics of inland flooding due to surge, most importantly water levels, currents, and extent of inundation. Accurate predictions of surge require determining critical inputs to models related to the physical characteristics of coastal regions that are expensive to obtain and evolve in time. This research project focuses on quantifying and reducing uncertainties in these critical inputs using novel mathematical techniques to both extract information from existing data and aid in the design of future data collection efforts.<br/><br/>More specifically, this project focuses on the construction, analysis, and implementation of numerical methods for a stochastic inverse problem defined by the melding of observational data and high-fidelity mathematical models to perform scientific and engineering inference and prediction for complex physical systems. This research applies broadly to complex, time-evolving physical systems depending on high dimensional parameter spaces. Mathematical areas utilized in this research include computational measure theory, differential geometry, functional analysis, probability theory, and numerical analysis. Dissemination of results to the broader scientific community will be accomplished in part by the development and implementation of computational algorithms in public domain code that are applied to a state-of-the-art storm surge model.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1817542","Accurate Prediction of Fluid Motion","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","05/23/2018","William Layton","PA","University of Pittsburgh","Standard Grant","Yuliya Gorb","06/30/2022","$319,497.00","","wjl+@pitt.edu","4200 FIFTH AVENUE","PITTSBURGH","PA","152600001","4126247400","MPS","1271","9263","$0.00","Accurate prediction of fluid motion and materials thereby transported is essential for many critical engineering and scientific applications. As two examples, flow predictions are key to limiting damage of hurricanes to human life and to the economy (the latter estimated to be hundreds of billions of dollars in 2017) and to energy efficiency optimization (85% of US energy is generated by combustion for which accurate simulation of turbulent mixing is critical). Unfortunately, fundamental barriers to accurate, efficient and reliable prediction of fluid flow exist in these and other applications addressed in the proposed research. Accurate prediction with uncertain data requires reliable and efficient ensemble simulations. The cost of current methods limits prediction accuracy by limiting ensemble sizes. Further improvement requires new computational tools with a fundamental decrease in simulation cost and memory requirements. Algorithms which address these needs will be developed in this project. <br/><br/>Artificial compression methods are by far the most efficient per time step but little used due to low time accuracy, restrictive time step conditions, stability problems, ill-conditioning and nonphysical acoustic waves. Their resolution will resurrect artificial compression methods into accurate, reliable and efficient methods for the prediction of fluid motion, expanding ensemble simulations and coupled flow prediction markedly beyond their current limitations. Artificial compression methods exhibit parasitic pressure waves that become resonant at higher Reynolds numbers. This research will develop a method dependent Lighthill theory of flow generated sound and apply it to design time filters to suppress parasitic acoustics. Time accuracy will be achieved by development of a new family of variable step, variable order methods. Variable step, variable order method have proven to be the most efficient, accurate and reliable methods to solve smaller systems of ordinary differential equations.  However, previous variable step, variable order methods have limited penetration into computational fluid dynamics practice due partially to their implementation complexity and increased cost per step. The new methods have (to leading order) the same cognitive and computational complexity as the fully implicit method. Uncoupling of velocity and pressure in artificial compression methods introduces an extra grad-div term in the velocity solve, decreasing sparsity and increasing ill conditioning. Thus, the efficiency of artificial compression methods is lost with increased storage and solver cost per step. The research will develop a new realization, modular Grad-Div, reducing storage and turnaround time by a factor of 30 in preliminary tests. While each development has independent interest, they will be integrated into an ensemble, artificial compression method and tested on problems of compelling interest. The proposed research develops expertise of PhD students in analysis, numerical analysis and application areas while working on compelling mathematics problems of broad impact advancing the accurate prediction of fluid motion. It is carefully integrated with the development of the PI's PhD students and undergraduate researchers. Within the project, each PhD student can develop their own research agenda and collaborate at the points of contact among the research problems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818769","Homotopy Methods for Computing Bifurcations and Multiple Solutions of Nonlinear Partial Differential Equations with Biological Applications","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","06/24/2021","Wenrui Hao","PA","Pennsylvania State Univ University Park","Standard Grant","Yuliya Gorb","01/31/2022","$128,408.00","","wxh64@psu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271","102Z, 9263","$0.00","Many mathematical models of natural phenomena, e.g., biology, physics and materials science, involve nonlinear systems of partial differential equations (PDEs). Traditional numerical methods focus on the unique time-marching solution and are very hard to capture these solution structures such as bifurcations, multiple steady states, and the structural stability. This project aims to address these challenges by developing efficient computational methods to explore bifurcations and multiple solutions of nonlinear PDEs.<br/><br/>The aim of this project is to develop efficient numerical methods to study the bifurcations and multiple solutions of nonlinear systems of PDEs. Two novel numerical techniques are proposed to study nonlinear systems of PDEs. First, an adaptive homotopy tracking with bifurcation detection algorithm will be designed for computing bifurcation points and bifurcation solution branches based on adaptive tracking, endgame technique, and inflation process. Second, a homotopy method with optimal basis approximation will be developed to compute multiple solutions of nonlinear systems by optimizing the solution basis in order to minimize the size of the discretized polynomial system. Homotopy method will be employed to solve this bootstrapped discretized polynomial system. The project will also focus on demonstrating and verifying efficiency/reliability of these proposed numerical methods on the real biological problems which have attracted extensive mathematical studies since the models were proposed.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818842","Algorithm Development and Analysis for Non-Newtonian Fluids Interacting with Elastic and Poroelastic Structures","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","05/23/2018","Hyesuk Lee","SC","Clemson University","Standard Grant","Leland Jameson","06/30/2022","$233,348.00","","hklee@clemson.edu","201 SIKES HALL","CLEMSON","SC","296340001","8646562424","MPS","1271","9150, 9263","$0.00","This research concerns the development and rigorous analysis of stable and efficient numerical schemes for non-Newtonian fluid - structure interactions (FSI). The study will be focused on partitioning schemes of an implicit type for the coupled model systems that allow each subproblem to be solved independently using existing local solvers in a fixed/moving domain setting. Stability and accuracy properties of numerical methods will be investigated using non-Newtonian fluid and poroelastic/elastic structure models. The theoretical investigation will provide a solid foundation and guidance to the further development of numerical algorithms.  Because of the many important biological and engineering processes involving non-Newtonian fluid flows, there is a great demand for mathematical support in these applications. This research will provide an underlying mathematical foundation for non-Newtonian flows in a multiphysical setting.<br/> <br/> <br/>The technical goal of this project is to develop algorithms and analyze numerical schemes for two coupled systems: (a) quasi-Newtoinan fluid - poroelastic structure and (b) viscoelastic fluid - elastic structure. For system (a) the PI will focus on the development and analysis of a nonlinear operator, where a solution to the operator equation yields subsystem solutions satisfying interface conditions of the whole coupled system. Advantages of this approach over the previously developed optimization approach are the flexibility to choose a nonlinear solver and that no extra coding effort is needed as the adjoint system is no longer involved in a solution process. Since it is expected that the linearized operator is not self-adjoint, the linear operator equation should be solved by an iterative solver for a non-self-adjoint problem. When a partitioned scheme is considered for simulating viscoelastic FSI, extra difficulty is encountered due to the lack of information on the stress along the moving boundary and movement of inlet and outlet boundaries along the interface of two subsystems. The PI will investigate various choices for a stress boundary value and their effect on a solution of FSI.  Another issue with the viscoelastic FSI is the size of the fluid problem to be solved in each time step (or in each internal iteration), which may require an operator splitting based on a temporal discretization scheme such as a fractional time step method. To tackle this, the PI will investigate various time stepping schemes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819042","Flexible Krylov Subspace Projection Methods for Inverse Problems","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","06/14/2018","James Nagy","GA","Emory University","Standard Grant","Yuliya Gorb","06/30/2022","$306,589.00","","jnagy@emory.edu","201 DOWMAN DR","ATLANTA","GA","303221061","4047272503","MPS","1271","9263","$0.00","In many scientific and engineering applications, it is necessary to<br/>solve an inverse problem; that is, to determine quantities defining an<br/>object or a system through indirect measurements.  The mathematics<br/>used to produce images in devices such as X-Ray Computed Tomography<br/>(CT) and Magnetic Resonance Imaging (MRI) are excellent examples.  The<br/>mathematical models describing an inverse problem are often so<br/>complicated that it is not possible to find an exact analytical<br/>solution, and it is necessary to use an approximation based on a set<br/>of simpler equations.  However, many equations may be needed; in<br/>medical imaging, for example, it is not unusual to compute<br/>approximations by solving millions of equations.  Additional<br/>complications arise because an inverse problem may have infinitely<br/>many solutions, or the solutions may change dramatically if there are<br/>small errors in the indirect measurements.  Thus, additional<br/>constraints and mathematical tools (often referred to as<br/>regularization) are needed to narrow the search to a set of<br/>appropriate feasible solutions, and to stabilize the computations.<br/>The type and amount of regularization is problem dependent, requiring<br/>the algorithms to be able to easily adapt to user and/or problem<br/>specifications.  The aim of this project is develop a flexible and<br/>adaptable computational platform that can be used for this important<br/>class of problems, which arise in many application areas, including<br/>space object identification, geophysics, microscopy and medical<br/>imaging. Thus advancements made from this project have the potential to<br/>benefit national defense, energy exploration, and human health.<br/> <br/>Efficient iterative methods to compute regularized solutions of<br/>large-scale discrete ill-posed inverse problems will be developed.<br/>The approach will use flexible Krylov subspace iterative methods, and<br/>will exploit low-rank structure of data, solutions and operators. The<br/>approach will allow to incorporate a variety of regularization<br/>techniques, including sparse and low-rank constraints on the solution.<br/>The methods developed in this project can be used as tools to obtain<br/>approximate solutions of ill-posed inverse problems, and optimized<br/>implementations will be included in a new MATLAB package called IR<br/>Tools (Iterative Regularization Tools).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819251","Extraction of Information from Scientific Simulations","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","07/09/2020","Stephen Becker","CO","University of Colorado at Boulder","Continuing Grant","Yuliya Gorb","07/31/2022","$149,993.00","","stephen.becker@colorado.edu","3100 MARINE ST","BOULDER","CO","803090001","3034926221","MPS","1271","9263","$0.00","Numerical simulations are a cornerstone of the modern scientific process, and considerable expense and energy, both literally and figuratively, is put into simulations. The two objectives of this project are to (1) shorten simulation time, and (2) ask new questions of the data given the output of an existing simulation (but not its full history) in order to avoid running a new simulation.  To shorten simulation time, a naive approach leads to less accurate estimates of certain variables that are used for both prediction of new material properties and for validation of numerical models against known properties. This program investigates super-resolution methods that do not suffer this loss of accuracy. The second objective records appropriate randomized snapshots or ""sketches"" from simulations.  Because it may not be known in advance which variables should be directly calculated, this program develops techniques to use the sketches to estimate variables that were not originally calculated. The technique is designed to ""future-proof"" simulations, and gives datasets a second chance at being useful without requiring a new simulation to be run. Achieving either or both objectives in this project will lead to fewer unnecessary computer simulations, saving energy and reducing impact on the environment.<br/><br/>This project brings together ideas from physical chemistry, high-performance computing, optimization, machine learning, digital signal processing, and time-series statistics. More specifically, the first objective is to estimate spectral variables from a shortened simulation. Shortening the time range usually has the effect of broadening the spectral lines. Under appropriate assumptions on the spectra, recent advances in harmonic analysis show that by solving a semi-definite program, one can super-resolve the spectral lines. These advances have been limited to signal-processing applications, and with appropriate modification, they will have a great impact on spectral estimation from simulations.  The project will develop efficient algorithms to tackle this problem, as well as show how it can be adapted to the situation of scientific computing, and theoretically extended to correctly handle uncertainty. The second objective is compressive parameter estimation, which has only recently been explored and mainly in the context of digital signal processing. The project will develop particular estimators for given statistics, as well as explore a general approach to apply to a broad class of statistics. The approach for storing snapshots of data will be applied primarily to magnetohydrodynamic (MHD) simulations of solar convection, a field of great importance due to the effect of the sun's weather on cosmic rays and photons incident on Earth.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1752116","CAREER: Sparse Model Selection for Nonlinear Evolution Equations","DMS","COMPUTATIONAL MATHEMATICS","06/01/2018","06/27/2022","Hayden Schaeffer","PA","Carnegie-Mellon University","Continuing Grant","Yuliya Gorb","06/30/2023","$400,000.00","","hayden@math.ucla.edu","5000 FORBES AVE","PITTSBURGH","PA","152133815","4122688746","MPS","1271","1045, 9263","$0.00","Extracting information from stationary and/or dynamic data is an important task in many scientific and industrial problems; including but not limited to, machine learning, data mining, image processing, and automated analysis of scientific data. This project focuses on learning the underlying process that generates observational data, in a sense, ""reverse-engineering"" models from data. These models are often used to gain insights on the data (for example, determining mathematical principles from experimental observations) or to make data-enabled decisions (for example, trend prediction). This is a challenging mathematical and computational problem, since one often has limited information on the process beforehand and real data is often noisy and/or incomplete. The research objective is to construct efficient computational methods for learning generating functions. This will involve a variety of mathematical techniques centered around optimization and sampling theory. The educational objective is to provide advanced training to undergraduate and graduate students in order to prepare them for the U.S. STEM workforce. In particular, students will be mentored and trained through mathematical and computational research projects, collaborative summer programs, working groups, and advanced courses that integrate education and research.<br/><br/>The goal is to develop computational methods for model learning, data analysis, and other machine learning tasks.  The overall objectives include: (i) the construction of optimization models that use sparsity, smoothness, and randomness to supplement the learning, (ii) the design of efficient and provably convergent numerical methods, (iii) the development of methods that are robust to sample size and outliers, and (iv) the creation and implementation of activities for undergraduate and graduate students that integrate education and research.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818772","Partial Differential Equation Constrained Optimization:  Algorithms, Numerics, and Applications","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","07/26/2018","Harbir Antil","VA","George Mason University","Standard Grant","Leland Jameson","07/31/2021","$199,999.00","","hantil@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","MPS","1271","9263","$0.00","The state of the art in modeling of the physical processes in science and engineering confronts us with solving increasingly complex optimization problems in the presence of constraints.  Think of designing the wing of an aircraft where it is essential that it can withstand a tremendous amount of pressure. This is just one of the example of an optimization problem with constrains. Such problems are inherently nonlinear due to constraints. This makes the development and analysis of algorithms and numerical techniques for the solution of these problems extremely challenging but rewarding. This project will create new optimization algorithms that allows us to incorporate constraints in a systematic and robust fashion. The targeted applications range from next generation micro- and nano-scale lab-on-chip devices to novel material and structural designs. Open source software will be created so that the research can be easily used by scientists working in other research areas.<br/> <br/>The applications under consideration can be modeled using partial differential equations (PDEs). These PDEs are  nonlocal (fractional); nonsmooth (contact problems); geometric, nonlinear, multiscale with an unknown domain, i.e. free boundary problems (FBPs). This project focuses on optimization problems with such PDE constraints - the so-called PDE constrained optimization problems. It aims to create new optimization schemes that will enable the solution of currently intractable optimization problems with nonsmooth features, including: optimization problems with nonlinear inequality constraints, contact problems, and risk-averse PDE constrained optimization. The resulting optimization algorithms will provide new insights into nonconvex nonsmooth problems. Optimization problems with surface tension is a new research field with great potential to enhance our understanding at the micro and nano-scales where surface effects dominate bulk effects. This will impact the design of next generation lab-on-chip, forensics and liquid lenses in astronomical telescopes. Open source software will be developed, which will not only benefit scientists in optimization, FBPs, and nonlocal problems but also scientists in nonlinear PDEs and data driven optimization problems. The results will be disseminated via two special topics courses on (i) PDE constrained optimization under uncertainty; (ii) Deep learning and PDE constrained optimization. One female student will get her PhD.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818775","Advanced Discretizations and Domain Decomposition Algorithms for Multiphysics Couplings of Fluid Flows and Solid Mechanics","DMS","COMPUTATIONAL MATHEMATICS","07/15/2018","08/14/2019","Ivan Yotov","PA","University of Pittsburgh","Continuing Grant","Leland Jameson","06/30/2021","$250,000.00","","yotov@math.pitt.edu","4200 FIFTH AVENUE","PITTSBURGH","PA","152600001","4126247400","MPS","1271","9263","$0.00","A computational framework will be developed for modeling coupled physical processes. It will be applied to geoscience and biomedical problems of societal importance. The research will investigate coupled subsurface and surface flows to model interactions between contaminated aquifers, rivers, lakes, and wetlands. The project will model flows in fractured and deformable reservoirs to provide predictive simulations of hydraulic fracturing and carbon sequestration, including surface subsidence, wellbore collapse, and fault activation. The project will further model flow in arteries, accounting for flow within the arterial wall. This has an effect on the blood velocity in the lumen and the speed of the pressure wave, as well as low density lipoproteins (LDL) transport and drugs filtered into the tissue. The research will lead to the development of simulation tools that advance drug delivery as well prevention, detection, and therapy of cardiovascular diseases such as atherosclerosis.  <br/><br/>The objective of this project is mathematical and computational modeling of multiphysics systems of coupled flow and mechanics problems with multiscale input parameters.  The simulation domain is decomposed into a union of subdomains, each one associated with a physical, mathematical, and numerical model. Physically meaningful interface conditions are imposed on the discrete level via mortar finite elements or penalty methods. The formulation provides great flexibility for multiphysics and multinumerics couplings. Furthermore, when combined with coarse scale mortar elements, it provides a multiscale approximation and an efficient way to solve the coarse grid problem in parallel.  The project will develop 1) Mathematically rigorous and physically meaningful multiphysics models; 2) Robust, accurate and efficient multiscale discretization techniques; 3) Efficient parallel domain decomposition solvers and preconditioners; 4) Efficient non-iterative time-partitioned algorithms. Two main components of the proposed research are A) mixed elasticity formulations and discretizations, and their coupling with mixed flow discretizations in the multiphysics framework; B) space-time multidomain variational formulations and discretizations allowing for different time stepping in different subdomains. A computational framework will be developed and applied to geoscience and biomedical problems. The research will develop variational formulations of Partial differential Equations systems coupling free and porous media fluid flows with deformations of the porous solids. Free fluid models such as Stokes, Brinkman, or Navier-Stokes equations will be coupled through physically meaningful interface conditions with Darcy flow. Regions with Darcy flow through deformable porous media will be modeled by the Biot system of poroelasticity. Nonlinear models for non Newtonian fluids, as well as reduced-dimension fracture models will also be investigated. An emphasis will be placed on mixed elasticity formulations coupled with mixed Stokes and Darcy formulations. The PI will study well-posedness of the variational formulations and will develop stable and accurate discretizations. Novel cell-centered mixed finite element methods for elasticity and poroelasticity will be investigated. The essential-type interface conditions will be imposed on a coarse scale via mortar finite elements. The PI will carry out stability and a priori multiscale error analysis. the PI will develop efficient parallel non-overlapping domain decomposition algorithms for the solution of the resulting algebraic systems by reducing the global problem to a coarse scale interface problem. The PI will analyze the condition number of the interface operator and will develop efficient preconditioners for speeding up the interface iteration. The PI will also study penalty methods, such as the Nitsche's coupling method, to impose interface conditions, resulting in loosely coupled formulations amendable to efficient non-iterative time-partitioned algorithms. The PI will study the stability and accuracy of the methods, as well as their properties as preconditioners for monolithic schemes. The PI will further develop multidomain space-time variational formulations and discretizations for the multiphysics models, coupling spatial non-overlapping domain decomposition methods with  Galerkin-type approximations in time, allowing for different time steps associated with different regions and different types of physics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819094","Collaborative Research: Improved Boundary Element Methods for Electrostatics of Interacting Proteins in Solvent","DMS","COMPUTATIONAL MATHEMATICS","07/15/2018","07/12/2018","Robert Krasny","MI","Regents of the University of Michigan - Ann Arbor","Standard Grant","Yuliya Gorb","06/30/2022","$245,000.00","","krasny@umich.edu","1109 GEDDES AVE, SUITE 3300","ANN ARBOR","MI","481091079","7347636438","MPS","1271","9263","$0.00","Protein molecules are basic components in all forms of life, and electrostatic effects play a key role in determining protein structure and function. However studying these effects experimentally is difficult, and there is great interest in using computer simulations to advance this area of biochemical research. This project will contribute by developing new mathematical algorithms to improve the accuracy and efficiency of these simulations. Potential biomedical applications include (1) protein-ligand binding, which is important for synthetic drug design, and (2) protein folding, which is important for understanding how misfolding causes disease. The investigators will collaborate with bioscientists, and the software developed in the project will be made available in open source format for use by the scientific community. The project results will be disseminated through conference and seminar presentations, and publications in scientific journals. The project will develop the national workforce in computational mathematics by training junior personnel at the postdoctoral, graduate student, and undergraduate student levels.<br/><br/> <br/>Biochemical simulations of charged particle systems are often limited by the cost of computing long-range electrostatic interactions. To address this issue the PIs have developed a treecode-accelerated boundary integral (TABI) method to solve the Poisson-Boltzmann (PB) equation for the electrostatic potential of a solvated protein. In this project the PIs will extend the TABI solver to the challenging case of interacting proteins in solvent, focusing on subtle dielectric and ionic structural effects. The work entails advances in modeling, improvements in treecode and boundary element methods, and applications in molecular biochemistry including the following topics: (1) The TABI code will be extended to compute the binding energy of a solvated protein-protein complex. (2) The treecode will be adapted to accelerate computations of the total correlation function in the Reference Interaction Site Model (RISM) which provides a physically accurate description of the water structure near the solute/solvent interface. (3) Explicit ion simulations will be carried out to validate the PB and RISM simulations, and to investigate the effect of finite ion size on the interfacial charge structure. (4) The treecode will be improved by implementing a more effective multipole acceptance criterion, and parallel CPU and GPU implementations of the treecode will be developed. (5) A new method for computing electrostatic PB forces will be tested for application in molecular dynamics simulations of interacting proteins in solvent. (6) Efficient computation of pH-dependent effects in solvated proteins will be demonstrated using TABI.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819257","Parallel, Adaptive Cartesian Grid Algorithms for Natural Hazards Modeling","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","06/25/2018","Donna Calhoun","ID","Boise State University","Standard Grant","Stacey Levine","06/30/2023","$315,587.00","","donnacalhoun@boisestate.edu","1910 UNIVERSITY DR","BOISE","ID","837250001","2084261574","MPS","1271","9150, 9263","$0.00","Geophysical hazards such as flooding, tsunamis, debris flows, landslides, storm surges and potential dam failures threaten communities across the United States and globally.  This project develops computational tools that can efficiently simulate these hazards, enabling a diverse group of researchers and emergency planners to develop hazard maps of areas most likely to be impacted by these disasters.  For efficiency, the computational framework uses adaptive, ""depth-averaged"" mathematical models that only require two dimensional planar grids, rather than  fully three dimensional meshes.  A primary goal of the project is to correct our depth-averaged model to capture localized waves that may spill over flood barriers or overtop harbor breakwaters.   These correction terms will give  current users of the computational framework critical additional capabilities for modeling shallow geophysical hazards and allow them to create more robust hazard maps.  The computational tools can also take full advantage of emerging hardware trends available on desktop workstations, moderate sized compute clusters, as well as massively parallel computing facilities available at NSF funded supercomputing sites.  The project also provides users with tools for visualizing results using open source software such as the Google Earth browser.  Ultimately, computational modeling can aid responders in predicting how to distribute emergency resources in the event of unavoidable hazards and serve to inform developers, legislative representatives, and citizenry of potential risks in their communities.<br/><br/>The research will focus on the implementation of a direct solver for variable coefficient elliptic problems on adaptively refined quad-tree meshes.  The targeted solver is the Hierarchical Poincare Steklov (HPS) solver, developed by A. Gillman and P. Martinsson.  Satisfying four crucial properties, this solver (1) has the ease of use of matrix-free methods, (2) can solve nearby systems quickly, (3) has optimal O(N) efficiency, and (4) provides parameters that can be tuned to reduce computational cost in proportion to accuracy requirements.   Furthermore, the method uses low rank approximations to compress dense matrices and accelerate matrix computations.   In the proposed work, the PI will modify the original HPS solver for use with second order, finite volume schemes and implement the solver in ForestClaw, the parallel, patch-based Cartesian adaptive quad-tree code.  The PI will also report on the scalability and parallel efficiency of the implementation of the HPS method. Two technical challenges that will arise are to develop effective procedures for merging Dirichlet-to-Neumann maps across processor boundaries and incrementally updating the solver factorization for dynamically evolving meshes.  The targeted application is the solution to the Serre-Green Naghdi equations for modeling dispersive corrections to the shallow water wave equations.  These corrections will be included in the GeoClaw extension of ForestClaw.  GeoClaw (D. George, R. J. LeVeque, M. J. Berger) is a widely used software package for solving depth-averaged flow equations. The addition of these correction terms to the GeoClaw extension will provide GeoClaw users with critical capabilities for modeling  tsunamis, flooding, debris flows, storm surges and other shallow geophysical flows.  Ultimately, the proposed solver can be used within the ForestClaw framework as a general purpose elliptic solver for a variety of physical flow phenomena.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818592","Parallel Semiclassical Methods for Seismic Wave Propagation, Inversion, and Data Analysis","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","07/18/2018","Xu Yang","CA","University of California-Santa Barbara","Standard Grant","Yuliya Gorb","07/31/2022","$199,928.00","","xuyang@math.ucsb.edu","3227 CHEADLE HALL","SANTA BARBARA","CA","931060001","8058934188","MPS","1271","9263","$0.00","Predicting seismic events, locating hidden resources and deepening our understanding of our planet's internal complexity require overcoming challenges from multi-interdisciplinary sciences including mathematics and geophysics. The proposed research will initiate projects to develop parallel semiclassical methods for seismic wave propagation, inversion and data analysis, with results computed, visualized and explored to create three-dimensional imaging of inner Earth structure. Specifically, the projects include development of the frozen Gaussian approximation (FGA) to handle elastic wave propagation in high-contrast, heterogeneous media, inversion of background velocity using full waveform inversion by constructing a surrogate model based on FGA to enlarge the search-function spaces used in the particle swarm method, and application of developed mathematical theory and associated computer programs to collected seismic data.<br/> <br/>The projects will develop semiclassical approaches for seismic wave propagation, inversion and data analysis, leading to quantitative imaging of our Earth's whole inner structure, and provide deep understanding of seismic activities. The research introduces a mathematically systematic way of attacking requests on reducing time of simulation in seismic tomography and inversion processes. More broadly, these new methods and models will provide fundamental advances in computational mathematics, leading to practical benefit in the field of geophysics, which plays such significant roles in responsible use of resources. The expected results will find applications in other emerging science and engineering fields such as spin-transfer torque in materials science and E. coli chemotaxis in biology, some of the problems the PI has also been working on.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1839457","International Conference on Mathematics of Data Science","DMS","COMPUTATIONAL MATHEMATICS","11/01/2018","10/29/2018","Yuesheng Xu","VA","Old Dominion University Research Foundation","Standard Grant","Stacey Levine","10/31/2019","$15,000.00","Hideaki Kaneko, Fang Hu, Katherine Smith","y1xu@odu.edu","4111 MONARCH WAY","NORFOLK","VA","235082561","7576834293","MPS","1271","7556","$0.00","Data science is an emerging interdisciplinary field of science and technology. It aims at developing theory, methods and techniques for extraction of useful knowledge or insights from raw data in various structured or unstructured forms such as signal, radar, sounds, images, videos and texts to make smart decisions. Data science employs theories and methods drawn from many fields within the broad areas of mathematics, statistics, information science, and computer science. Mathematics plays an indispensable role in data science. To bring together active researchers in various fields related to data science and practitioners in industry to identify mathematical and statistical challenges in data science, the International Conference on Mathematics of Data Science is being held on the campus of Old Dominion University on November 3-4, 2018. The conference website is http://icmds2018.org. The conference invited speakers are internationally known researchers in the field of data science and will address critical mathematical issues of the field. The conference will promote research collaboration among different areas, cultivate research partnership between academia and industry and, in particular, encourage young talents to work in the field of data science. The funds will solely be used to support junior researchers and graduate students in related fields at US universities and research institutions to attend the conference. This supports the recruitment of young talent to the field of data science and preparation of the next generation researchers to meet the scientific challenges in the big data era. Special efforts are made to recruit graduate students from underrepresented groups such as African American students and female students for the conference participants.<br/><br/>The conference will cover mathematical topics crucial to data science. In the field of data science, mathematics has provided functional spaces to represent data sets, approximation approaches to characterize similarity and difference of data sets, optimization methods to extract information from raw data, and analytical, geometrical tools to describe insightful relationships among various concepts in data and their statistical analysis. Further development of data science demands that mathematics play a leading role. For example, it is not yet fully understood that why deep learning is very efficient for certain applications while less efficient in other scenarios. This requires mathematical understanding of the fundamental issues in deep learning. All these issues will be the focus of the conference. Specifically, its scope covers sparse representation of big data sets, functional spaces suitable for big data analysis, mathematical foundation of machine learning, signal image processing, statistical analysis for big data, convex or non-convex sparse optimization for data analysis, scalable algorithms for big data and applications of data science. Scientific and societal broader impacts of this project lie in the aspects that the conference will promote interaction of mathematics, statistics, computer science, engineering and industrial applications, which support the interdisciplinary field of data science, and it will provide a platform for young scholars to learn about and discuss challenging mathematical issues in the field.<br/><br/>Website: https://sites.wp.odu.edu/icmds2018/<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1751636","CAREER: A Flexible Optimal Control Framework for Efficient Training of Deep Neural Networks","DMS","COMPUTATIONAL MATHEMATICS","06/01/2018","07/06/2022","Lars Ruthotto","GA","Emory University","Continuing Grant","Yuliya Gorb","05/31/2024","$400,000.00","","lruthotto@emory.edu","201 DOWMAN DR","ATLANTA","GA","303221061","4047272503","MPS","1271","1045, 9263","$0.00","One of the most transformative technologies of our time is deep learning, a form of machine learning that uses neural networks containing many hidden layers. Recent success has led to breakthroughs in applications such as speech and image recognition, nourishing public interest. However, more theoretical insight is needed to create a rigorous scientific basis for designing and training deep neural networks, increasing their scalability, and providing insight into their reasoning. This project develops a new mathematical framework that simplifies designing, training, and analyzing deep neural networks. Due to the broad applicability of deep learning, advances made in this project will benefit a wide range of technologies of high economic and societal impact, e.g., driverless cars, drug discoveries, and web searches. The mathematical theory supporting the new algorithms will increase the acceptance of deep learning for delicate tasks, e.g., cancer prediction and cyber-security. <br/><br/>This project develops a new mathematical framework for deep learning based on the interpretation of deep learning as a dynamic optimal control problem involving nonlinear time-dependent differential equations. This interpretation offers a new way to analyze the successes and failures of deep learning. Advances in deep learning will be made by adapting the wide array of tools available for related optimal control problems, including numerical optimization, partial and ordinary differential equations, inverse problems theory, and parallel processing. Using these currently untapped resources provides rigorous new ways to design and train very deep neural networks that generalize well. Advances in optimal control will be achieved through new hybrid regularization methods, adaptive time discretizations, and large-scale splitting-based optimization.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1752202","CAREER: Variational and Geometric Methods for Data Analysis","DMS","COMPUTATIONAL MATHEMATICS, Division Co-Funding: CAREER","07/01/2018","07/05/2022","Braxton Osting","UT","University of Utah","Continuing Grant","Yuliya Gorb","06/30/2024","$400,002.00","","osting@math.utah.edu","201 PRESIDENTS CIR","SALT LAKE CITY","UT","841129049","8015816903","MPS","1271, 8048","1045, 9263","$0.00","This project will use tools from applied mathematics to develop and analyze scalable methods for large-scale data analysis, especially for the problems of clustering, geometry processing, image analysis, and analyzing high-order interactions in data. One specific end-goal is to use N-direction fields to create quad meshes, which are provably high-quality, and have immediate applications in finite element simulations for engineering. The PI plans to attract, involve, and educate students at both the undergraduate and graduate levels at the University of Utah through research seminars and student programs. Students will benefit from exposure to this interdisciplinary field and be an integral part of the research, participating at regular group meetings and discussions, and given the opportunity to present their research findings at conferences. The proposed education plan includes the development of two courses, Introduction to Optimization and Introduction to Data Science, which will serve students throughout the University of Utah's Schools of Science and Engineering. A new course on Data analysis as part of the University of Utah's ACCESS program, a seven-week intensive summer program for incoming female undergraduates, will foster study of STEM disciplines for this underrepresented group.<br/><br/>This project will develop and analyze new computational methods based on geometry, variational principles, and partial differential equations for data analysis. Due to associated variational characterizations and stochastic processes, these methods are geometrically and/or physically interpretable and have provable properties, complementing and extending traditional data analytic methods from statistics and computer science. The proposed research plan has three primary goals. The first goal is to study foundational questions related to the Cheeger formulation of the graph partitioning problem and connections to graph curvature and Merriman-Bence-Osher (MBO) diffusion generated motion. In particular, a new probabilistic interpretation of the MBO method will lead to efficient algorithms that systematically balance partition components. The second goal is to use a generalization of vector fields, called N-direction fields or cross fields when N=4, for a variety of tasks in geometry processing and image analysis. This work is well-motivated by recent progress of the PI and his graduate student on the generation of boundary-aligned quadrilateral meshes based on the Ginzburg-Landau theory. In part, this will involve the extension of the MBO algorithm and associated Lyapunov function to approximate harmonic maps with image in generalized sets. The third goal is to develop efficient methods for analyzing simplicial complexes, generalizing and extending methods for analyzing graphs. To overcome the inherent computational costs due to the non-local and multi-scale nature of simplicial complexes, the PI will develop efficient sparsification algorithms based on preserving the spectrum of associated generalized Laplacian operators.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819041","Novel Finite Element Methods for Three-Dimensional Anisotropic Singular Problems","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","06/14/2018","Hengguang Li","MI","Wayne State University","Standard Grant","Yuliya Gorb","07/31/2022","$198,991.00","","li@wayne.edu","5700 CASS AVE STE 4900","DETROIT","MI","482023692","3135772424","MPS","1271","9263","$0.00","Elliptic partial differential equations can possess singular solutions in various practical models. The efficacy of numerical simulation highly depends on smoothness and can severely deteriorate in the presence of singularities. The development of effective finite element methods (FEMs) for singular partial differential equations has been a central focus in computational mathematics; however, most of the established methods are for two-dimensional problems. The design of effective three-dimensional (3D) methods is more technically involved and less explored, largely due to the constraints imposed by the 3D geometry and by anisotropic structure in singularities. Existing 3D algorithms are usually tetrahedron-based and sensitive to the domain geometry and to the degree of polynomials, which limits their applications in practical computing. This project aims to develop a novel mesh algorithm that is well-structured, flexible with different 3D elements, and simple in implementation.  The new algorithm is expected to significantly improve the effectiveness of 3D numerical simulations in areas where anisotropic solutions frequently occur, including mathematical models in aerospace engineering (e.g., aircraft design), in mechanical engineering (e.g., crack propagation in civil infrastructure), in fluid mechanics, and in electromagnetism.<br/><br/>This research project has two main components. (1) Innovative numerical algorithms. The investigator plans to develop a new family of anisotropic meshes that facilitate optimal FEMs approximating 3D anisotropic singular solutions. The mesh construction follows a simple, explicit, and unified approach and applies to four basic 3D elements: the tetrahedron, hexahedron, wedge, and pyramid. With unconventional but implementation-friendly features, these algorithms have shown effectiveness in early numerical tests. (2) Rigorous theoretical investigations and applications. The investigator plans to devise new analytical tools to justify and broaden the applications of the new FEMs, especially when the mesh is anisotropic. This includes (i) optimal error analysis; (ii) new regularity estimates for 3D anisotropic problems; (iii) fast numerical solvers for linear systems from anisotropic meshes; and (iv) efficient implementations in high-performance computing environments.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1753031","CAREER: A Local-Nonlocal Coupling Framework for Tissue Damage in Fluid-Structure Interaction","DMS","COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY, Division Co-Funding: CAREER","08/01/2018","07/06/2022","Yue Yu","PA","Lehigh University","Continuing Grant","Yuliya Gorb","07/31/2024","$402,451.00","","yuy214@lehigh.edu","526 BRODHEAD AVE","BETHLEHEM","PA","180153008","6107583021","MPS","1271, 7334, 8048","1045, 9263","$0.00","This project aims to develop a new mathematical framework and the corresponding high-performance open source software for addressing fundamental open questions on multiscale and multiphysics modeling of soft tissue damage process, with the ultimate goal of improving the understanding of heart valve damage mechanisms. The resultant framework will have substantial impacts in heart valve operation and research, and will potentially contribute towards more rigorous interventional and surgical procedures. The computational tool and the methodology developed in this project can also be used efficiently in a wide range of physical and biological problems. For the educational component, this project will provide an excellent research and outreach platform for promoting female and under-represented groups in Science, Technology,  Engineering and Mathematics (STEM) fields in a range of educational levels from middle school to young researchers post graduate school. These activities include (1) introducing a heart function module in a summer outreach program to expose middle school girls to science and engineering, (2) providing research opportunities for undergraduate students from primarily undergraduate institutions to promote the students' engagement in scientific studies, and (3) organizing an annual high-performance computing (HPC) workshop and a multiscale/multiphysics modeling topical workshop to promote the participation of female students and researchers in the areas of applied mathematics and scientific computing.<br/><br/>Technically, a central theme of the research component is the development of a computational approach which models the physically realistic process of heart valve degradation under long-term cyclic hemodynamic loading with the objective of understanding tissue fatigue mechanisms. Emphasis will be placed on modeling the fiber-level tissue damage induced by cyclic hemodynamic loading and its long-term progression. Specifically, the computational domain is composed of three subregions: the fluid (blood) simulated as incompressible Newtonian flow, the fracture thin structure (damaged heart valves) modeled by the nonlocal peridynamic shell theory, and the thin structure (undamaged heart valves and aortic walls) described by a classical hyperelastic shell model. These three subregions will be numerically coupled to each other with proper interface boundary conditions. Novel constitutive models and corresponding numerical schemes will be developed, and new local-nonlocal coupling strategies will also be designed. A powerful computational open source software will be developed, which not only will contribute to advance the knowledge of soft tissue damage, but also will increase the range of capabilities for computer simulation of problems in long-term materials and manufacturing damage progression in general.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819193","Collaborative Research: Improved Boundary Element Methods for Electrostatics of Interacting Proteins in Solvent","DMS","COMPUTATIONAL MATHEMATICS","07/15/2018","07/12/2018","Weihua Geng","TX","Southern Methodist University","Standard Grant","Yuliya Gorb","06/30/2022","$155,000.00","","wgeng@smu.edu","6425 BOAZ LANE","DALLAS","TX","75205","2147684708","MPS","1271","9263","$0.00","Protein molecules are basic components in all forms of life, and electrostatic effects play a key role in <br/>determining protein structure and function. However studying these effects experimentally is difficult, <br/>and there is great interest in using computer simulations to advance this area of biochemical research. <br/>This project will contribute by developing new mathematical algorithms to improve the accuracy and <br/>efficiency of these simulations. Potential biomedical applications include (1) protein-ligand binding, <br/>which is important for synthetic drug design, and (2) protein folding, which is important for <br/>understanding how misfolding causes disease. The investigators will collaborate with bioscientists, and <br/>the software developed in the project will be made available in open source format for use by the <br/>scientific community. The project results will be disseminated through conference and seminar <br/>presentations, and publications in scientific journals. The project will develop the national workforce in <br/>computational mathematics by training junior personnel at the postdoctoral, graduate student, and <br/>undergraduate student levels.<br/> <br/>Biochemical simulations of charged particle systems are often limited by the cost of computing long-<br/>range electrostatic interactions. To address this issue the PIs have developed a treecode-accelerated <br/>boundary integral (TABI) method to solve the Poisson-Boltzmann (PB) equation for the electrostatic <br/>potential of a solvated protein. In this project the PIs will extend the TABI solver to the challenging case <br/>of interacting proteins in solvent, focusing on subtle dielectric and ionic structural effects. The work <br/>entails advances in modeling, improvements in treecode and boundary element methods, and <br/>applications in molecular biochemistry including the following topics: (1) The TABI code will be <br/>extended to compute the binding energy of a solvated protein-protein complex. (2) The treecode will <br/>be adapted to accelerate computations of the total correlation function in the Reference Interaction <br/>Site Model (RISM) which provides a physically accurate description of the water structure near the <br/>solute/solvent interface. (3) Explicit ion simulations will be carried out to validate the PB and RISM <br/>simulations, and to investigate the effect of finite ion size on the interfacial charge structure. (4) The <br/>treecode will be improved by implementing a more effective multipole acceptance criterion, and <br/>parallel CPU and GPU implementations of the treecode will be developed. (5) A new method for <br/>computing electrostatic PB forces will be tested for application in molecular dynamics simulations of <br/>interacting proteins in solvent. (6) Efficient computation of pH-dependent effects in solvated proteins <br/>will be demonstrated using TABI.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818684","Collaborative Research: Structure Preserving Numerical Methods for Hyperbolic Balance Laws with Applications to Shallow Water and Atmospheric Models","DMS","COMPUTATIONAL MATHEMATICS","09/01/2018","06/11/2018","Alina Chertock","NC","North Carolina State University","Standard Grant","Yuliya Gorb","08/31/2023","$250,000.00","","chertock@math.ncsu.edu","2601 WOLF VILLAGE WAY","RALEIGH","NC","27607","9195152444","MPS","1271","9263","$0.00","This project will significantly contribute toward development of computational methods for shallow water and related models and will provide considerably more powerful tools for studying a variety of water waves and atmospheric phenomena. Special attention will be paid to applications arising in oceanography, atmospheric sciences, hydraulic, coastal, civil engineering, in which rapid changes in the bottom topography, Coriolis forces, friction, multiscale regimes, and uncertain phenomena factor heavily. The studied problems will include shallow water flows in multi-connected river channel systems, tsunami wave propagation and low Froude regime shallow water models, dynamics models of tropical cyclones and clouds with uncertain data.The newly developed tools may have a great potential in designing coastal protection systems and investigating the effects of sediment transport on shelf drilling platforms as well as contributing to a better prediction of tropical cyclones trajectories and tsunami wave propagation and on-shore arrival.<br/><br/>The project focuses on development of new structure preserving numerical methods for hyperbolic balance laws with applications to shallow water equations and related models. Shallow water models are systems of time-dependent partial differential equations (PDEs) that are derived using physical properties such as conservation of mass and momentum, and hydrostatic or barotropic approximations. Naturally, these applications, especially in cases of high space dimensions, require development and implementation of special numerical methods that are not only consistent with the governing system of PDEs, but also preserve certain structural and asymptotic properties of the underlying problem at the discrete level. The development of new numerical techniques will be based on high-order shock-capturing finite-volume schemes, asymptotic preserving, adaptive moving mesh and stochastic Galerkin methods utilizing major advantages of each one of these methods in the context of studied problems. Besides providing examples that corroborate the numerical approach, the foregoing applications are of a substantial independent value for a broad class of problems arising in today's science.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818833","Fast Algorithms for Simulating the Collective Swimming of Microorganisms","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","07/18/2018","Minghao Rostami","NY","Syracuse University","Standard Grant","Yuliya Gorb","07/31/2022","$176,045.00","","mwrostam@syr.edu","900 S CROUSE AVE","SYRACUSE","NY","132440001","3154432807","MPS","1271","9263","$0.00","Hydrodynamic interactions play a crucial role in the collective dynamics of microorganisms. The main goal of this project is to explore and develop efficient algorithms for simulating the collective swimming of a large group of microorganisms in a three-dimensional viscous fluid. The computational methods resulting from this project will provide new tools to understand how micro-swimmers such as sperm and cilia collectively perform various physiological functions inside the human body. They will also help shed new light on how and why microorganisms such as bacteria and algae aggregate and form colonies. Microorganisms often have to navigate through elastic structures such as mucus and polymers; their motility in a non-Newtonian fluid has attracted significant interest in recent years. The proposed methods can be extended to study the collective swimming of microorganisms inside a viscoelastic network. Besides hydrodynamic interactions, steric and chemical interactions also have profound impacts on the collective behaviors of microorganisms. This project lays a foundation for the development of more comprehensive mathematical models for collective dynamics that incorporate a variety of interactions.<br/><br/>At high enough density, micro-swimmers, such as bacteria, cilia, sperm and algae, exhibit remarkable collective motions which bear significant biological implications. For example, sperm swim both competitively and collaboratively to reach the egg, and cilia in the airways beat collectively to propel mucus and foreign particles out of the lung. These phenomena can be modeled by several methods, all of which entail solving equations of fluid-structure interaction. Among them, the method of regularized Stokeslets and the Rotne-Prager-Yamakawa tensor have the advantage of not requiring a 3D Eulerian grid and using the fundamental solutions to the underlying equations instead. However, the computations required by both methods entail the use of dense matrices, and they tend to be large and very costly to work with for practical models in which the number of micro-swimmers is large. In addition, patterns can take a long time to emerge and develop in swimming microorganisms, making the simulation even more challenging. The project has the following three objectives:<br/>1.Develop fast algorithms for computing matrix-vector products and for solving linear systems with the aforementioned large, dense matrices;<br/>2.Employ these algorithms to investigate (a) the collective swimming of a large group of sperm confined by a surface, (b) the flow field induced by a dense mat of beating cilia, and (c) the flow field induced by a large number of free micro-swimmers;<br/>3.Accelerate the time-dependent simulation of collective swimming by implementing parallel-in-time methods; and compare the efficiency of spatial and temporal parallelization when hundreds of computer cores are used.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1821145","Data-Driven Computation of Lagrangian Transport Structure in Realistic Flows","DMS","COMPUTATIONAL MATHEMATICS, CDS&E-MSS","06/15/2018","06/30/2020","Traian Iliescu","VA","Virginia Polytechnic Institute and State University","Continuing Grant","Christopher Stark","05/31/2021","$200,000.00","Shane Ross","iliescu@vt.edu","300 TURNER ST NW","BLACKSBURG","VA","240603359","5402315281","MPS","1271, 8069","9263","$0.00","Forecasting the spread of contaminants in the ocean, floodwaters, or atmosphere in a timely manner is of critical importance.  Accurate prediction of the contaminant location at a later time requires a realistic model of the underlying fluid flow, as well as knowledge of where the contaminant was initially located.  Furthermore, to aid decision-makers, the fluid simulations must proceed sufficiently rapidly. The movement of the ocean and atmosphere, like that of other fluids, creates certain patterns whose shape is influenced by special regions, known collectively as the Lagrangian transport structure, or LTS (named after the mathematician and fluid mechanist Joseph-Louis Lagrange). LTS is a template that organizes how the fluid moves: some structures are surfaces that attract nearby fluid, some repel nearby fluid, and some form meandering jet pathways or vortex-like structures.  Focusing on the LTS helps alleviate the dependence of contaminant forecast on its initial location, as contaminants tend to follow these key organizing features.  Furthermore, incorporating these structures into a faster, approximate model, the fluid simulation itself can be sped up.  However, despite its potential usefulness -- to predict the spread of hazardous material, debris, or missing individuals in a search-and-rescue scenario -- LTS is not currently used because of the high computational cost.  This project aims to develop a new framework to make possible real-time, robust LTS computation on mobile platforms, to inform real-time decision-making (for instance, directly onboard the manned or autonomous vehicles doing reconnaissance and sensing).  Such effective, timely computations for realistic aquatic and atmospheric environments can provide information to prevent the loss of lives, mitigate environmental damage, and avoid enormous financial cost.<br/><br/>This project studies a novel Lagrangian data-driven reduced-order modeling and spatial filtering framework for fluid transport simulation.  This new framework in intended to decrease the computational cost of current algorithms by orders of magnitude and yield LTS approximations that are accurate and robust with respect to the numerical inaccuracies that are inherent in realistic flows. Progress will be made by developing several intertwined approaches in computational fluid mechanics and nonlinear dynamics -- the mathematical theory underlying chaos theory. The main novelty of the project is bridging Eulerian algorithms (used in the velocity field computation) and Lagrangian algorithms (used in the LTS computation). This makes possible the development of novel Lagrangian data-driven reduced-order models (ROMs) and spatial filters. The new Lagrangian data-driven ROM is based on a novel Lagrangian inner product that makes possible the accurate and efficient approximation of average LTS.  In contrast, standard Eulerian ROMs produce inaccurate LTS results. A novel Lagrangian data-driven spatial filter for LTS computation on coarse realistic meshes is also studied. This new filter is stable, accurate, efficient, and robust with respect to the numerical inaccuracies that are inherent in realistic flows. While the work will focus on environmental flows, the results are expected to apply to a wide variety of fluid applications.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819229","RUI: Robust Feasibility and Robust Optimization using Algebraic Topology and Convex Analysis","DMS","COMPUTATIONAL MATHEMATICS","08/15/2018","08/13/2018","Bala Krishnamoorthy","WA","Washington State University","Standard Grant","Yuliya Gorb","07/31/2022","$200,000.00","","bkrishna@math.wsu.edu","240 FRENCH ADMINISTRATION BLDG","PULLMAN","WA","991640001","5093359661","MPS","1271","9229, 9263","$0.00","Solving systems of equations and optimizing a function over such systems are ubiquitous in computational mathematics. The functions or equations being nonlinear and/or nonconvex often make these tasks challenging. Further, uncertainty in problem parameters adds to the problem complexity. A crucial part of modern society where such problems are prevalent is power systems. Two central computations in power systems operations are power flow (PF) studies and optimal power flow (OPF). PF studies ensure the power grid state (i.e., voltages and flows across the network) will remain within acceptable limits in spite of contingencies (e.g., loss of a generator or a transmission line) and other uncertainties (e.g., shifting demand or renewable sources of power such as wind and solar). OPF seeks further to choose values for controllable assets in the system (e.g., generators whose rate of power production could be controlled) so as to meet demand at minimum cost. These problems have inherent nonlinearities and nonconvexities, making them hard to solve in their natural form. This project uses ideas from algebraic topology and nonlinear analysis to develop efficient algorithms for robust feasibility and robust optimization.  In particular, the investigator will develop a framework to derive mathematically rigorous guarantees for robust feasibility and optimization in nonlinear systems using scalable algorithms.  The investigator will employ these algorithms to characterize the effects of uncertainties in nonlinear models of power systems.  The investigator will also demonstrate the efficacy of the framework by testing it on large scale OPF problems.<br/><br/>The rapid adoption of renewable energy sources such as wind and solar energy is creating increased uncertainty in modern power systems. In this project, the investigator will take a robust viewpoint of uncertainty: the worst-case impact of the uncertainty on feasibility and optimization problems will be quantified. To this end, the investigator will use ideas from algebraic topology and nonlinear analysis -- specifically Borsuk's theorem (a generalization of the intermediate value theorem) and topological degree theory -- to develop efficient algorithms for robust versions of the PF and OPF problems. On the computational side, the investigator will develop efficient implementations of these algorithms capable of scalably solving large instances of PF and OPF problems. The novel framework will combine rigorous guarantees, efficient algorithms, and the ability to handle nonlinearities. Such a framework is critical for operating modern power systems with significant uncertainty. While power systems are used as the main application area, the methods to be develop are fairly general, and could be applied to problems in other domains as well, e.g., gas distribution networks. More broadly, this project could have a direct impact on how complex and large scale infrastructure systems are handled, especially under increasing uncertainties created by the environment.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819252","Developing Efficient and Accessible Computational Tools for Poroelasticity Problems","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","07/26/2018","Jiangguo Liu","CO","Colorado State University","Standard Grant","Yuliya Gorb","07/31/2022","$149,941.00","","liu@math.colostate.edu","601 S HOWES ST","FORT COLLINS","CO","805212807","9704916355","MPS","1271","9263","$0.00","Poroelasticity problems arise from a broad range of real world problems, in which fluid flows through a porous medium that can deform due to the fluid pressure.  For example, convection-enhanced drug delivery to tumor sites, functioning of knee meniscus, and CO2 sequestration all involve this type of interaction between solid (displacement) and fluid (pressure).  Mathematical modeling and computer simulations will provide valuable tools to enhance our ability in understanding, predicting, and controlling these complicated physical processes.  This research project aims at developing a family of novel accurate, efficient, and robust numerical methods for poroelasticity problems.<br/>    <br/>The focus of this project is on design, analysis, implementation, and applications of a family of novel finite element methods for poroelasticity problems.  Based on the displacement-pressure two-field formulation, weak Galerkin finite element methods will be developed for approximating both solid displacement and fluid pressure.  Conditions for stable coupling of these sub-problem solvers will be investigated.  The new methods will be applied to an engineering problem on knee meniscus. These new methods will also be implemented as Matlab and C++ code modules (on deal.II platform) that are openly accessible to the scientific computing community. The efficient and robust computational tools developed in this project can be applied to many real world problems that involve poroelasticity such as drug delivery to tumor sites, food processing, reservoir engineering, and tissue engineering.  These will have further economic impact on better use of natural resources or cures for diseases.  The methodology developed in this project can be applied to a large class of scientific computing tasks that deal with multiple physical processes.  This project will also provide hands-on training opportunities for both graduate and undergraduate students.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818969","A Two-Way Research Street: Geometric Algorithms in Optimization and Computer-Based  Discrete Geometry","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","07/01/2018","07/12/2021","Jesus De Loera","CA","University of California-Davis","Standard Grant","Yuliya Gorb","06/30/2023","$366,736.00","","deloera@math.ucdavis.edu","1850 RESEARCH PARK DR, STE 300","DAVIS","CA","956186153","5307547700","MPS","1253, 1271","079Z, 1253, 1515, 9263","$0.00","At the foundation of the progress in artificial intelligence and data science that is changing society (e.g., driverless cars) is the mathematical theory of optimization. For example, convex and non-linear optimization is the engine at the core of the very successful deep neural-networks. The first part of the project develops the mathematics necessary to solve optimization theory challenges (e.g., larger amounts of data, uncertain data) and to create faster, more accurate optimization algorithms. Computers are changing the nature of mathematical research and discovery too. For instance, computers can derive formulas and proofs automaticaly, computers can search for examples, and now they can more easily extract patterns thanks to machine learning. The second part of the project investigates the use of algorithms from artificial intelligence and algorithms to attack problems in mathematics, especially in geometry.<br/><br/>This project in computational mathematics has two interacting components: The first component is to apply methods from convex geometry, algebraic geometry, geometry of numbers, and combinatorics to develop new algorithms for mixed-integer optimization problems arising in data science, especially the clustering of data with special conditions. The project also studies augmentation (primal) algorithms for integer and mixed-integer variables, these are algorithms that generalize the pivoting used for the simplex method. The second component of the project investigates geometric and combinatorial problems amenable to be investigated with computers. The computation of a number of fundamental combinatorial quantities in convex geometry, including the exact value of integer Caratheodory numbers for cones, quantitative Helly numbers, and integral Radon-Tverberg numbers, will be emphasized. The project presents a computer-based approach to prove or disprove several theorems in<br/>discrete geometry.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819011","Stochastic Constitutive Models for Nano-Scale Heat Transport","DMS","COMPUTATIONAL MATHEMATICS","09/01/2018","06/11/2018","Xiantao Li","PA","Pennsylvania State Univ University Park","Standard Grant","Leland Jameson","08/31/2021","$200,000.00","","xli@math.psu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271","7237, 9263","$0.00","At the nano-mechanical scale, heat conduction processes exhibit a wide variety of phenomena that are different from macroscopic observations.  Conventional models, such as the Fourier's law,  are inadequate. In addition, there are overwhelming observations that suggest that heat conduction properties depend critically on the system size and geometry, creating a unique challenge for the portability of the mathematical models. This project aims to bridge the modeling gap by developing a first-principle based approach that leads to a hierarchy of generalized models. The new models have the potential capabilities to describe various important behavior of heat conduction processes, including the wave propagation characteristic, fluctuation, delay, and more. <br/><br/>The proposed approach will derive new constitutive models from first-principle, and mathematically, the models are obtained from a microscopic many-particle description with three levels of reductions: A spatial reduction that eliminates atomic-level details and singles out the dynamics of the average energy, a temporal reduction that removes the nonlocality in time, and a statistical reduction that efficiently samples scale-dependent, statistical noises. Such a first-principle based approach derives its benefit from its combination of mathematical transparency, robustness, and amenability to error estimates. Unlike conventional theories, the current approach yields a stochastic constitutive model. Combined with energy balance, the constitutive models lead to stochastic partial differential equations, for which there is a wealth of interesting mathematical and computational issues.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1760374","FRG: Collaborative Research: Randomization as a Resource for Rapid Prototyping","DMS","STATISTICS, COMPUTATIONAL MATHEMATICS","08/01/2018","04/26/2023","Ilse C.F. Ipsen","NC","North Carolina State University","Standard Grant","Yuliya Gorb","07/31/2024","$366,109.00","","ipsen@ncsu.edu","2601 WOLF VILLAGE WAY","RALEIGH","NC","27607","9195152444","MPS","1269, 1271","1616, 9263","$0.00","A principled foundation for fast prototyping data analysis methods will be developed.  The main approach will be to use fast randomized matrix algorithms, as developed within the research area known as Randomized Numerical Linear Algebra (RandNLA).  Prior work has shown that these RandNLA algorithms come with strong theory and that they perform well for many practical data science and machine learning problems.  The foundation will develop novel uses of randomization to combine complementary algorithmic and statistical perspectives. The statistical viewpoint attributes randomness to an inherent and desirable property of the data, while the algorithmic viewpoint claims randomness as a computational resource to be exploited.  The coupling of these complementary approaches poses challenging mathematical problems to be investigated in the proposed work.<br/><br/>The proposed work will establish the foundations for fast prototyping in two directions: A Multi-Pronged Direction to bring RandNLA to the next level and explore what is technically feasible; and an overarching Synergy Direction that fuses the results for prototyping. The Multi-Pronged Direction includes the following topics: (i) Matrix perturbation theory, to bridge the gap between traditional worst-case bounds for asymptotically small perturbations on the one hand; and perturbations caused by stochastic noise, and missing or highly corrupted matrix entries on the other hand. (ii) Implicit versus explicit regularization, where randomness as a computational resource for speeding up algorithms additionally contributes to implicit statistical regularization, thereby improving statistical and numerical robustness. (iii) Krylov space methods for fast computation of good warm-starts and computation of surrogate models in the form of low-rank approximations, and specifically a better understanding of these methods in an algorithm-independent setting. (iv) Randomized basis construction methods that use matrix factorizations to compute low-rank approximations at low to moderate levels of accuracy. The Synergy Direction will explore topics like ultra-low accuracy matrix computations in machine learning applications, where merely a correct sign or exponent is sufficient. As a group, the PIs possess unrivaled and complementary expertise in applying fundamental mathematical tools to numerical applications in machine learning, data mining and scientific computing.  Importantly, the proposed methods will have significant impact in big data analysis, scientific computing, data mining and machine learning, where matrix computations are of paramount importance. The proposed work is fundamentally interdisciplinary and will enable fast, yet user-friendly extraction of insight from large-scale data these societally-important scientific domains.  Specifically, the proposed work will (i) create a numerically reliable and robust footing for fast prototyping; (ii) advance mathematics at the interface of computer science and statistics, one of the objectives being a synergy of numerical and statistical robustness; and (iii) advance the development of an interdisciplinary community with RandNLA as a pillar for the mathematics of data. The award will allow the investigators to increase their active engagement in reaching out to undergraduate and graduate students, and research communities in numerical linear algebra, theoretical computer science, machine learning, and scientific domains such as astronomy, materials science, and genetics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1745654","RTG: Randomized Numerical Analysis","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, WORKFORCE IN THE MATHEMAT SCI","08/15/2018","07/17/2023","Pierre Gremaud","NC","North Carolina State University","Continuing Grant","Pedro Embid","07/31/2024","$2,140,000.00","Arvind Saibaba, Alen Alexanderian, Ralph Smith, Carl Kelley, Ilse C.F. Ipsen","gremaud@math.ncsu.edu","2601 WOLF VILLAGE WAY","RALEIGH","NC","27607","9195152444","MPS","1266, 1271, 7335","7301, 9263","$0.00","Classical methods from scientific computing were designed with the natural goal of finding exact answers to exact questions. Such methods cannot address most of today's large and complex computational models. This research training group focuses on the development of methods which aim instead at providing approximate answers to approximate questions thereby opening up the door for new generations of numerical tools well adapted to 21st century problems. The program provides training opportunities for undergraduate, graduate, and postdoctoral participants who benefit from their integration in vertically structured working groups. It is important for Science, Technology Engineering and Math (STEM) students to have professional skills extending beyond technical expertise; they must be able to communicate their results to non-technical audiences in clear, compelling and engaging ways. Through its emphasis on multi-layered working groups, the program offers a prime training ground for its participants to gain the communication skills necessary to bridge disciplinary divides, as is required for work addressing most of society's grand challenges. The program also involves the development of new course material, both online and on campus, that reflects and addresses challenges in present-day scientific computing.<br/><br/>The paradigm of numerical analysis as the study of algorithms for the problems of continuous mathematics needs to be updated. An increasing number of data intensive applications are better described through discrete mathematics in terms of graphs or networks rather than through the smooth manifolds of continuous mathematics. Additionally, current computational models are often neither well-posed nor well-conditioned; new approaches are needed. The program addresses this pressing need by using randomization as the key scientific tool. The research is organized around three complementary thrusts in numerical linear algebra, nonlinear solvers and global sensitivity analysis. By analyzing the effect on numerical solutions of perturbations caused by randomization, or corrupted data, the first two thrusts fill a critical gap in the theoretical foundation to numerical analysis under large perturbations and low accuracy: even the notion of numerical solution has to be revisited. The third thrust aims at reducing model complexity through novel sensitivity analysis methods and the use of surrogate models; this thrust both capitalizes on and contributes to the previous two.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819006","International Congress on Mathematical Software (ICMS 2018)","DMS","COMPUTATIONAL MATHEMATICS","07/15/2018","07/16/2018","Jonathan Hauenstein","IN","University of Notre Dame","Standard Grant","Leland Jameson","06/30/2019","$20,000.00","","hauenstein@nd.edu","940 Grace Hall","NOTRE DAME","IN","465565708","5746317432","MPS","1271","7556, 9263","$0.00","The International Congress on Mathematical Software (ICMS) consists of a diverse community in the broadly defined area of computational sciences including researchers and practitioners in computational mathematics, algorithms and complexity, and software engineering.  This National Science Foundation award provides support for the 2018 meeting of the International Congress on Mathematical Software (ICMS 2018) to be held July 24-27, 2018 at the University of Notre Dame in Indiana.  ICMS 2018 is the 6th meeting of ICMS and the first to be hosted in the United States.  This conference, as with the 5 previous meetings of ICMS, will bring together a wide range of computational scientists along with practitioners to discuss recent progress and current challenges in software, algorithms, complexity, and applications in computational mathematics and computational science.  This conference provides an opportunity for cross-fertilization between the mathematical sciences and other areas of science and engineering through software development and utilization.  The plenary speakers for this conference are Folkmar Bornemann (TU Munich), Thomas Hales (University of Pittsburgh), and William Stein (SageMath, Inc.).  This award will support travel grants for graduate students, post-doctoral researchers, young faculty members, members of under-represented groups, and researchers without federal support to attend ICMS 2018 to meet with leaders in software development for mathematics, science, and engineering applications, and interact with each other who will be the next generation of leaders in this area.<br/><br/>ICMS 2018 is an international meeting for interaction between computational mathematicians, scientists, engineers, and software developers.  This creates a unique atmosphere for sharing ideas and discussing new trends and challenges in computational mathematics and software development. For example, plenary speaker William Stein will provide attendees of ICMS 2018 insights into successes and challenges of open-source mathematical software development.  Apart from the plenary speakers, all talks and posters at ICMS 2018 are selected from responses to an open call for submissions which are organized into sessions.  ICMS 2018 features 18 sessions such as machine learning for mathematical software, software for mathematical reasoning, computational algebraic geometry, post-quantum group-based cryptography, and management of mathematical software, mathematical knowledge, and research data.  ICMS 2018 also includes a poster session which is scheduled for the first day of the conference.  The conference website is http://icms-conference.org/2018/.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819115","Reduced-Order and Low-Rank Methods for Parameter-Dependent Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","07/16/2018","Howard Elman","MD","University of Maryland, College Park","Standard Grant","Leland Jameson","01/31/2022","$200,000.00","","elman@cs.umd.edu","3112 LEE BLDG 7809 REGENTS DR","College Park","MD","207420001","3014056269","MPS","1271","9263","$0.00","The goal of this study is to develop new computer algorithms to be used to simulate engineering models and physical phenomena, with the aim of predicting behavior of systems in the physical world.  Examples of the use of these techniques include modeling of the flow of pollutants in groundwater, assessing the stability of structures such as airplane wings in the face of stresses such as high temperatures or pressures, and simulating the effects of magnetic fields on performance of semiconductors or reactions in nuclear fusion.  Such algorithms help engineers and scientists to make good decisions about construction and use of new technology, but they are only practically useful if demonstrated to be efficient (that is, use modest amounts of computer time and memory) and accurate.  The aim of this work is to advance the development of efficient algorithms of this type and to demonstrate their utility for models of transient phenomena such as fluid flows and stability of physical structures.<br/><br/>The technical goals of the project are to study solution algorithms for parameter-dependent partial differential equations by constructing approximate solutions of low-rank structure.  Parameterized problems of this type arise when underlying terms figuring in the differential operators of the system depend on a set of unknown or random parameters.  Examples include unknown permeabilities in models of diffusion or velocity fields that are affected by temperatures.  In this scenario, the solutions sought also depend on parameters, but they can often be approximated well in a space of low dimension, i.e., solutions for all parameter values can be represented as a linear combination of a small finite set of functions.  Such a reduced representation offers the prospect of significant reduction of costs required to compute solutions.  The project will explore the utility this approach for two types of problems: (i) dynamical systems, for which the dependence on time requires new methods to develop reduced-order models that are accurate over long time periods, and (ii) eigenvalue problems, with emphasis on techniques for stability analysis of dynamical systems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1749707","CAREER: Primal-Dual Weak Galerkin Finite Element Methods","DMS","COMPUTATIONAL MATHEMATICS, Division Co-Funding: CAREER","07/01/2018","05/21/2018","Chunmei Wang","TX","Texas State University - San Marcos","Continuing Grant","Leland Jameson","09/30/2018","$58,852.00","","chunmei.wang@ufl.edu","601 UNIVERSITY DR","SAN MARCOS","TX","786664684","5122452314","MPS","1271, 8048","1045, 9263","$0.00","Partial differential equations (PDEs) are an important mathematical tool for modeling many scientific problems and the most common approach for solving these equations usually involves numerical methods.  The goal of this project is to extend the theory and develop novel numerical methods of one such method known as the PD-WG algorithm. The resulting computational codes will be made publicly available. In addition, the PI will apply the new methods to several problems in biology and physical sciences.  One exciting application is the mathematical modeling of ion channels which are proteins with a hole down their middle, and which serve an important function as gatekeepers for cells. The project also has an educational component that integrates the PI's research activities with training of students at all levels, from K-12, undergraduate, to graduate students, with a focus on serving underrepresented minorities.<br/><br/>The goal of this project is to develop novel numerical methods through a coupling of the original/primal governing equations and their dual. The resulting numerical methods are known as ""Primal-Dual Weak Galerkin (PD-WG) finite element methods"". The main research of this CAREER project will be focused on five primary areas: (1) developing robust numerical schemes by using PD-WG techniques for various PDE problems including the elliptic Cauchy problem, convection dominated convection-diffusion equations, and general linear or nonlinear PDEs; (2) establishing stability and mathematical convergence (including superconvergence) theory for the newly developed PD-WG methods by developing new mathematical tools; (3) numerical simulations for biological problems modeled by the nonlinear Poisson-Nernst-Planck (PNP) equations; (4) devising new concepts in numerical PDEs by integrating key ideas of optimization with WG methods; and (5) developing application-oriented software packages using the PD-WG methods.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1905195","Innovative Weak Galerkin Finite Element Methods with Application in Fluorescence  Tomography","DMS","COMPUTATIONAL MATHEMATICS","10/05/2018","03/26/2019","Chunmei Wang","TX","Texas Tech University","Standard Grant","Leland Jameson","03/31/2019","$583.00","","chunmei.wang@ufl.edu","2500 BROADWAY","LUBBOCK","TX","79409","8067423884","MPS","1271","8990, 9263","$0.00","Fluorescence tomography (FT) is an emerging three-dimensional optical imaging modality that uses in vivo noninvasive depth-resolved localization and quantification of fluorescent-tagged inclusions. FT techniques have been extensively employed in early cancer detection, guidance of tumor resection, and drug monitoring and discovery. This research project aims to develop new numerical methods for computational problems arising in FT imaging. Besides fluorescence tomography, the numerical methods can be applied to solve partial differential equations that arise in various other disciplines. The models, theory, and computational methods under development in this project will be of great value in the fields of digital image processing, medical imaging, and numerical analysis, with direct applications in broad areas such as digital image and even construction industries. Students will be trained in this project.<br/><br/>The goal of this research project is to develop and analyze efficient numerical methods -- weak Galerkin (WG) finite element methods -- to address challenges posed by fourth-order problems arising in fluorescence tomography theory. The research will explore algorithmic advancements, new convergence theory, and imaging technology improvement, by: (1) developing robust finite element methods for a fourth order partial differential equation in the primal variable formulation for which no existing method works; (2) establishing a stability and convergence, including superconvergence, theory for the newly developed finite element methods; (3) validating and verifying the methods through collaboration with domain-specific researchers; (4) analyzing a new weak Galerkin mixed finite element method for a fourth order partial differential equation; and (5) developing application-oriented software packages, tested and validated with collaborators in the area of FT."
"1849483","CAREER: Primal-Dual Weak Galerkin Finite Element Methods","DMS","COMPUTATIONAL MATHEMATICS, Division Co-Funding: CAREER","08/01/2018","04/28/2020","Chunmei Wang","TX","Texas Tech University","Continuing Grant","Leland Jameson","07/31/2021","$228,908.00","","chunmei.wang@ufl.edu","2500 BROADWAY","LUBBOCK","TX","79409","8067423884","MPS","1271, 8048","1045, 9263","$0.00","Partial differential equations (PDEs) are an important mathematical tool for modeling many scientific problems and the most common approach for solving these equations usually involves numerical methods.  The goal of this project is to extend the theory and develop novel numerical methods of one such method known as the PD-WG algorithm. The resulting computational codes will be made publicly available. In addition, the PI will apply the new methods to several problems in biology and physical sciences.  One exciting application is the mathematical modeling of ion channels which are proteins with a hole down their middle, and which serve an important function as gatekeepers for cells. The project also has an educational component that integrates the PI's research activities with training of students at all levels, from K-12, undergraduate, to graduate students, with a focus on serving underrepresented minorities.<br/><br/>The goal of this project is to develop novel numerical methods through a coupling of the original/primal governing equations and their dual. The resulting numerical methods are known as ""Primal-Dual Weak Galerkin (PD-WG) finite element methods"". The main research of this CAREER project will be focused on five primary areas: (1) developing robust numerical schemes by using PD-WG techniques for various PDE problems including the elliptic Cauchy problem, convection dominated convection-diffusion equations, and general linear or nonlinear PDEs; (2) establishing stability and mathematical convergence (including superconvergence) theory for the newly developed PD-WG methods by developing new mathematical tools; (3) numerical simulations for biological problems modeled by the nonlinear Poisson-Nernst-Planck (PNP) equations; (4) devising new concepts in numerical PDEs by integrating key ideas of optimization with WG methods; and (5) developing application-oriented software packages using the PD-WG methods.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912703","Approximation of Functions with Parameter-Dependent or Stochastic Shock Locations Arising from Hyperbolic Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","08/29/2018","12/07/2018","Gerrit Welper","FL","The University of Central Florida Board of Trustees","Standard Grant","Yuliya Gorb","07/31/2022","$60,000.00","","gerrit.welper@ucf.edu","4000 CENTRAL FLORIDA BLVD","ORLANDO","FL","328168005","4078230387","MPS","1271","9263","$0.00","Many mathematical models of scientific or engineering problems are influenced by design parameters and random parameters. An example is the modeling of flow around an airfoil. A design parameter is its shape, and random parameters include, for example, perturbations in the air before a plane travels through it. These parameters pose some natural questions for engineers and the mathematical models they use: What is the best possible shape? Can we compute safety tolerances of the wing and limit the probability of failure? With increasing computational power, such questions attracted considerable attention in recent years. However, for physical phenomena with sharp transitions, only brute-force approaches are available, which quickly become challenging even with advanced computer hardware. In the wing example, one such transition is the sonic boom, a rapid change in the pressure around the wing at high speed. This project aims to develop new algorithms that can handle such rapid transitions in parametric models, far more efficiently than currently. The method under development will be applicable to a range of other engineering problems as well, such as environmental questions in groundwater flows or the simulation of bio-molecules.<br/><br/>The goal of the project is the development of new approximation schemes for functions with parameter-dependent jumps or kinks, motivated by solutions of parametric and stochastic hyperbolic partial differential equations. These singularities pose serious challenges by deteriorating the convergence rates for established methods such as reduced basis methods, proper orthogonal decomposition, or polynomial chaos expansions. Recent work offers a new method to approximate functions with jump discontinuities and achieves super-polynomial convergence rates for many problems. It serves as a proof of principle that high-order methods are advantageous, but it needs to be developed further to make it practical: In most realistic problems, jumps not only move but they also interact, and parameter spaces are typically high-dimensional. Addressing these issues is the goal of this project. The new algorithms will be tested numerically, in particular regarding the convergence rates that can be achieved. In addition, the investigator plans to prove convergence rates for model classes of parametric functions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1752934","CAREER: Geometry and Learning for Manifold-Structured Data in 3D and Beyond","DMS","COMPUTATIONAL MATHEMATICS, Division Co-Funding: CAREER","07/01/2018","07/05/2022","Rongjie Lai","NY","Rensselaer Polytechnic Institute","Continuing Grant","Yuliya Gorb","06/30/2023","$403,633.00","","lai249@purdue.edu","110 8TH ST","Troy","NY","121803522","5182766000","MPS","1271, 8048","1045, 8091, 9263","$0.00","With the advance of modern technology and computing power, processing and analyzing of data in three and higher dimensions becomes a ubiquitous task in diverse fields such as medical imaging, computational chemistry, computational biology, social networks and many others. For many problems in practice, data is commonly associated with certain coherent and nonlinear structure. Mathematically, this allows us to model data sets as points sampled on manifolds usually of low dimensions embedded in a high dimensional ambient space. Different from image and signal processing which handle functions on flat domains with well-developed tools for processing and learning, manifold-structured data is far more challenging due to their complicated geometry. For example, the same geometric object can take very different coordinate representations due to the variety of embeddings, transformations or representations (imagine the same human body shape can have different poses as its nearly isometric embedding ambiguities). These ambiguities form an infinite dimensional isometric group and make higher-level tasks in manifold-structured data analysis and learning even more challenging. To overcome these challenges, it becomes increasingly important to develop new tools in both theoretical and computational point of views for processing manifold structured data. <br/><br/>This project proposes to investigate analyzing and learning of manifold-structured data by bridging connection from geometric partial differential equations (PDEs) and learning theory to intrinsic data analysis. The major objectives of this project contain three components. The first part is to investigate a framework of geometric-PDEs-based methods to a data structure for manifolds represented as incomplete inter-point distance. The second part is to overcome the challenge of poor performance using intrinsic descriptors to handling not nearly isometric manifolds. In the third part, a new method of defining geometric convolution on manifolds is considered. This provides a building block of constructing the proposed geometric convolutional neural network for conducting deep learning on manifold-structured data. By collaborating with biomedical engineers, applications such as human brain mappings will also be explored. The new methodologies and research findings resulting from the proposed work will lead to new ways of tackling problems in manifold-structured data analysis and will be integrated into my future teaching and course projects in appropriate ways. The education plan is to provide unique opportunities to train undergraduate and graduate students interested in exploring geometry and learning on manifold-structured data, and to reach out the general public.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818783","Collaborative Research: Models, Algorithms, and Simulations for Two-Phase Ferrofluid Flows in Contact with a Solid Surface","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","07/27/2018","XIAOFENG YANG","SC","University of South Carolina at Columbia","Standard Grant","Yuliya Gorb","07/31/2022","$57,185.00","","xfyang@math.sc.edu","1600 HAMPTON ST # 414","COLUMBIA","SC","292083403","8037777093","MPS","1271","9150, 9263","$0.00","Being controllable by applied magnetic fields, two-phase ferrofluid flows have found diverse applications in various science and engineering fields. Flows of two-phase ferrofluid mixtures usually involve the coupling of hydrodynamics, interface motion, intrinsic particle spins, magnetization field, and induced magnetic field. It is expected that the proposed research will not only lead to reliable well-posed models, efficient numerical algorithms for the two-phase ferrofluid system, but also extend the applicability of mathematical models, analyses and codes to various physical problems of current interest through numerical simulations.  The proposed research will produce efficient, optimally convergent, easily implemented, energy stable numerical algorithms, as well as publicly available finite element codes. It will provide ample and valuable opportunities for undergraduate and graduate students to receive multidisciplinary training in the areas of mathematical modeling, computational mathematics, and mechanical engineering, and to develop state-of-the-art mathematical models and numerical algorithms for science and engineering applications. Starting from this collaborative work, the investigators plan to disseminate the developed models, methods and software packages to more engineers and scientists for solving their realistic problems, present the research in professional conferences and colloquia, and organize special sessions/minisymposiums in domestic/international conferences for related works.<br/><br/><br/>The intellectual merit of this project lies in the challenge to develop suitable mathematical models and design efficient and accurate schemes for the highly nonlinear two-phase ferrofluid system, which couples free interfaces, hydrodynamics, magnetization field, induced magnetic field, and intrinsic particle spins. Very few efforts have been made to address the induced modeling/numerical challenges of the two-phase ferrofluid system due to the complicated nonlinear couplings among these constituents. The proposed models are thermodynamically consistent and thus preserve the energy dissipation laws. With strengths of the finite element methods in dealing with the complex boundary, the proposed numerical schemes are efficient, accurate, easily implemented, and energy stable with some discrete energy dissipation laws which have advantages of allowing the large time step and controlled error bound to capture the interfacial singularities accurately. In addition, the models, numerical algorithms and simulations will contribute to better understandings of various physical problems of practical interests, such as new materials based on ferro fluids.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1760353","FRG: Collaborative Research: Randomization as a Resource for Rapid Prototyping","DMS","STATISTICS, COMPUTATIONAL MATHEMATICS","08/01/2018","06/16/2023","Petros Drineas","IN","Purdue University","Standard Grant","Yuliya Gorb","07/31/2024","$343,223.00","","pdrineas@purdue.edu","2550 NORTHWESTERN AVE STE 1900","WEST LAFAYETTE","IN","479061332","7654941055","MPS","1269, 1271","1616, 9263","$0.00","A principled foundation for fast prototyping data analysis methods will be developed.  The main approach will be to use fast randomized matrix algorithms, as developed within the research area known as Randomized Numerical Linear Algebra (RandNLA).  Prior work has shown that these RandNLA algorithms come with strong theory and that they perform well for many practical data science and machine learning problems.  The foundation will develop novel uses of randomization to combine complementary algorithmic and statistical perspectives. The statistical viewpoint attributes randomness to an inherent and desirable property of the data, while the algorithmic viewpoint claims randomness as a computational resource to be exploited.  The coupling of these complementary approaches poses challenging mathematical problems to be investigated in the proposed work.<br/><br/>The proposed work will establish the foundations for fast prototyping in two directions: A Multi-Pronged Direction to bring RandNLA to the next level and explore what is technically feasible; and an overarching Synergy Direction that fuses the results for prototyping. The Multi-Pronged Direction includes the following topics: (i) Matrix perturbation theory, to bridge the gap between traditional worst-case bounds for asymptotically small perturbations on the one hand; and perturbations caused by stochastic noise, and missing or highly corrupted matrix entries on the other hand. (ii) Implicit versus explicit regularization, where randomness as a computational resource for speeding up algorithms additionally contributes to implicit statistical regularization, thereby improving statistical and numerical robustness. (iii) Krylov space methods for fast computation of good warm-starts and computation of surrogate models in the form of low-rank approximations, and specifically a better understanding of these methods in an algorithm-independent setting. (iv) Randomized basis construction methods that use matrix factorizations to compute low-rank approximations at low to moderate levels of accuracy. The Synergy Direction will explore topics like ultra-low accuracy matrix computations in machine learning applications, where merely a correct sign or exponent is sufficient. As a group, the PIs possess unrivaled and complementary expertise in applying fundamental mathematical tools to numerical applications in machine learning, data mining and scientific computing.  Importantly, the proposed methods will have significant impact in big data analysis, scientific computing, data mining and machine learning, where matrix computations are of paramount importance. The proposed work is fundamentally interdisciplinary and will enable fast, yet user-friendly extraction of insight from large-scale data these societally-important scientific domains.  Specifically, the proposed work will (i) create a numerically reliable and robust footing for fast prototyping; (ii) advance mathematics at the interface of computer science and statistics, one of the objectives being a synergy of numerical and statistical robustness; and (iii) advance the development of an interdisciplinary community with RandNLA as a pillar for the mathematics of data. The award will allow the investigators to increase their active engagement in reaching out to undergraduate and graduate students, and research communities in numerical linear algebra, theoretical computer science, machine learning, and scientific domains such as astronomy, materials science, and genetics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1834756","2018 Gene Golub SIAM Summer School: Inverse Problems: Systematic Integration of Data with Models under Uncertainty","DMS","COMPUTATIONAL MATHEMATICS","06/15/2018","06/19/2018","Noemi Petra","CA","University of California - Merced","Standard Grant","miao-jung ou","05/31/2019","$20,000.00","","npetra@ucmerced.edu","5200 N LAKE RD","MERCED","CA","953435001","2092012039","MPS","1271","7556","$0.00","This award supports the participation of US-based PhD students in the 2018 Gene Golub Society for Industrial and Applied Mathematics (SIAM) Summer School entitled ""Inverse Problems: Systematic Integration of Data with Models under Uncertainty,"" taking place June 17-30, 2018 in Breckenridge, Colorado. The fundamental question addressed by this two-week summer school is: How do we optimally learn from data through the lens of models? And how do we do so when the data and models are uncertain (as they usually are)? These questions have become central with the massive explosion of data volumes across all areas of science, engineering, technology, medicine, and the social sciences. The summer school aims to introduce graduate students to the mathematical and computational aspects of such inverse problems, particularly modern developments that emphasize the quantification of uncertainty in the inverse solution within the framework of Bayesian inference. <br/><br/>The summer school brings graduate students together with experts in foundational areas of Bayesian inverse problems. The lectures feature an integrated format that begins with ill-posedness and regularization, develops the ideas and tools for deterministic inversion via numerical optimization, and elaborates formulations and solution methods for the modern Bayesian perspective, building on several of the deterministic tools. The focus throughout the lectures is on methods that can scale to inverse problems governed by complex forward models, such as partial differential equations. Morning lectures are complemented by afternoon hands-on laboratory sessions using open-source software (hippylib and MUQ) that implements state-of-the-art deterministic and Bayesian inversion methods, and the school concludes with student project presentations. The summer school aims to augment existing academic curricula with instruction in Bayesian inverse problems that reflects the relatively recent emergence of the mathematical and computational foundations of the field, the need to integrate concepts from inverse theory, partial differential equations, optimization, probability, statistics, and computing, and the need to develop supporting software. This perspective is critical to maximizing the information gained from data when interpreted via models.<br/><br/>More information can be found at<br/>https://www.siam.org/students/g2s3/index.php<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819052","Close Evaluation of Layer Potentials","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","03/07/2022","Camille Carvalho","CA","University of California - Merced","Standard Grant","Yuliya Gorb","09/30/2022","$200,000.00","Arnold Kim, Shilpa Khatri, Camille Carvalho","ccarvalho3@ucmerced.edu","5200 N LAKE RD","MERCED","CA","953435001","2092012039","MPS","1271","9263","$0.00","This research project addresses several outstanding questions in the numerical solution of boundary value problems using boundary integral equation methods. In addition to advancing knowledge within the field of computational mathematics, this research aims to lead to innovations that will provide an efficient and accurate research computing platform complementing ongoing experimental research in fluid mechanics and electromagnetics. The project includes an interdisciplinary, team-based approach with graduate training and education components that will also serve as recruiting tools to further promote women and underrepresented minority graduate students in science and engineering fields.<br/><br/>The purpose of this project is to introduce, analyze, and implement new high-order numerical methods for the close evaluation of layer potentials. Layer potentials are used to represent solutions of linear elliptic partial differential equations in boundary integral equation methods. The close-evaluation problem refers to large errors incurred by high-order quadrature rules when evaluating layer potentials at points near the boundary of the domain despite being highly accurate elsewhere in the domain. Addressing the close-evaluation problem is important for many applications, including Stokes flow problems and the field of plasmonics. A current challenge is to develop efficient, easily-implementable methods that address the close-evaluation problem in three dimensions. This project will address the challenge by identifying and analyzing the nearly-singular behavior of these integral operators using asymptotic analysis. The main objectives of this project are to (1) develop new methods to address the close-evaluation problem, (2) analyze the error and investigate efficiency and computational issues, and (3) extend the methods to other linear elliptic partial differential equations. Results from this project are expected to enable development of novel, accurate, and efficient computational methods that address the close-evaluation problem.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1903420","Multiscale computational methods in kinetic theory and optimal transport","DMS","COMPUTATIONAL MATHEMATICS","10/12/2018","10/25/2018","Li Wang","MN","University of Minnesota-Twin Cities","Continuing Grant","Leland Jameson","06/30/2020","$83,789.00","","wangli1985@gmail.com","200 OAK ST SE","MINNEAPOLIS","MN","554552009","6126245599","MPS","1271","9263","$0.00","Kinetic equations with multiple scales arise in diverse applications such as rarefied gas dynamics, plasma physics, semiconductors, and biology; they often introduce severe numerical challenges due to the stiffness that comes from the small scales. Optimal transport plays a fundamental role in image registration, video restoration, urban transport, kinetic theory and many others. However, numerical methods for it have not reached their full capacity to meet the most demanding practical applications. This project aims at both advancing the multiscale computational methods - particularly the asymptotic preserving (AP) schemes - in new prospects for kinetic equations including multi-stage and fractional asymptotic limit, and developing fast parallelizable algorithms for optimal transport via advanced optimization technique. <br/><br/>Specifically, the following topics will be investigated in this project: (1) theoretically study the AP schemes for semiconductor Boltzmann equation with two-scale collisions at a deeper depth and generalize them to implicit/high order schemes and to capture the hierarchy of macroscopic models; (2) extend the AP scheme for kinetic equation with fractional diffusion limit to a broader scope including anisotropic scattering, degenerate collision, and Levy-Fokker-Planck interaction (applications to nonclassical photon transport in clouds will be addressed); (3) develop efficient algorithms for optimal transport problems and conduct convergence analysis and apply it to practical problems especially for human crowd dynamics in panic situations. With increasing interest in multiscale kinetic equations and optimal transport, the computational methods developed here will impact beyond the particular applications in this proposal. The dynamics of electron transport in semiconductor devices are one of the main concerns in physics and engineering; the developed methods from this proposal will be equally applicable in a broader context such as gas discharges and multi-group radiative transfer. Nonclassical transport that leads to a fractional diffusion has attracted much attention in plasma physics and economy; it has now been applied in climate science to model the photon transport in clouds as well as in criminology to model the hotspots in residential burglaries. Optimal transport has become a useful tool in image processing, urban transport, computer vision and etc; the development of fast parallelizable algorithms will substantially advance these areas and the application in modeling human crowds is crucial for better preparation of safe mass events."
"1819222","Collaborative Research: Geometric Analysis and Computation for Generative Models","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","06/21/2018","Alexander Cloninger","CA","University of California-San Diego","Standard Grant","Yuliya Gorb","06/30/2022","$195,869.00","","acloninger@ucsd.edu","9500 GILMAN DRIVE","LA JOLLA","CA","920930021","8585344896","MPS","1271","062Z, 9263","$0.00","Research in unsupervised learning and generative models is concerned with uncovering structure and relationships in data with the intent of being able to generate new, as yet unseen, examples of the data set. Generative models learn the distribution of a data set from finite samples and provide an efficient sampler of the approximated density, rather than relying on labels for supervision. These models are a powerful tool for analyzing large volume, high-dimensional data in an unsupervised way. While generative models are an active research topic in machine learning, many theoretical and computational questions for such models remain unclear. This collaborative research project will study generative models from a geometric perspective, focusing on both performance guarantees and efficient implementations. The ability to efficiently create new data points that are guaranteed to be similar to the existing data has important implications in a variety of applications, including medical data analysis and privacy, bioinformatics, modeling of image and audio signals, and general high-dimensional data analysis in which it is difficult to collect labeled data for supervised algorithms.<br/><br/>The ideas and approaches in this research project center around the techniques that have evolved in the manifold learning field over the past decade. These mathematical tools, in particular local neighborhood preserving maps, approximation analysis in terms of intrinsic dimensionality, and construction of global coordinate systems based upon local affinity, have natural applications in the study of generative models. The project is comprised of four fundamental questions that arise in the field: (a) What are the types of distributions that generative networks are capable of learning efficiently, and how does the intrinsic dimensionality of the distribution affect convergence? (b) How can non-parametric generative models be created for dimension-reduced representations that arise in manifold learning, and which only depend on the intrinsic geometry of the data? (c) How can efficiently-computed metrics be defined between high-dimensional distributions for use in assessing the validity of various generative models? (d) How can these metrics be used to examine the various paths generative models take through the parameter space while being trained, and what clusters of starting points give optimal generators? The project will focus on both mathematical and computational aspects of these problems, aiming at resolving fundamental questions about these tools that are widely used in various data analysis and signal processing applications in science and industry.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1836035","The 4th Annual Meeting of SIAM Central States Section","DMS","COMPUTATIONAL MATHEMATICS","10/01/2018","08/09/2022","Ying Wang","OK","University of Oklahoma Norman Campus","Standard Grant","Yuliya Gorb","09/30/2023","$20,000.00","Alexander Grigo","wang@ou.edu","660 PARRINGTON OVAL RM 301","NORMAN","OK","730193003","4053254757","MPS","1271","7556, 9150, 9263","$0.00","The SIAM Central States Section (SIAM CSS https://www.siam.org/sections/central/) was formed in 2014 to serve SIAM members in Arkansas, Colorado, Iowa, Kansas, Mississippi, Missouri, Nebraska, and Oklahoma. The 4th Annual Meeting of SIAM Central States Section will be held 10/5-10/7, 2018 on the Norman campus of the University of Oklahoma. The url for the conference website is http://www.math.ou.edu/conferences/siam2018 .<br/><br/>The theme of this conference will be centered around applied and computational Mathematics. This award will be used solely to support junior researchers (students/postdocs/early career faculty), minorities, people with disability and colleagues from 4-year colleges. Our long-term goal is to build a stronger computational and applied Math program throughout all the central states. The SIAM CSS annual conference series provides a very important platform for computational and applied mathematicians to exchange knowledge and network with experts from all over the U.S. and other countries. This conference will give ample opportunity for people to interact at discussions during the breaks, between talks, as well as after the talks. In particular we expect participants from the central states (that may or may not present at the conference) to have the opportunity to establish interactions with researchers that they would not often have a chance to meet in this part of the country.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1752709","CAREER: Mathematical Analysis and Numerical Methods for the Underground Oil Recovery Models","DMS","COMPUTATIONAL MATHEMATICS, Division Co-Funding: CAREER","06/15/2018","07/07/2022","Ying Wang","OK","University of Oklahoma Norman Campus","Continuing Grant","Yuliya Gorb","05/31/2024","$400,054.00","","wang@ou.edu","660 PARRINGTON OVAL RM 301","NORMAN","OK","730193003","4053254757","MPS","1271, 8048","1045, 9150, 9263","$0.00","This CAREER award supports a coordinated set of research and educational activities with the goals of elucidating the modeling and computation of underground oil recovery and stimulating the environment for research and study in applied analysis and computation at the University of Oklahoma. The project involves the Oklahoma Applied Analysis & Computing Group, a team consisting of undergraduate and graduate students, postdoc researchers,  University of Oklahoma faculty, and faculty from Oklahoma's network of universities and colleges.<br/><br/>Accurate mathematical analysis and efficient numerical methods play a more and more important role in studying partial differential equation (PDE) models in the petroleum industry. The goal of this project is to perform research in the mathematical analysis and high order accuracy numerical methods design for the PDE models describing the water-drive secondary underground oil recovery. The PI will combine mathematical analysis, numerical scheme design and computational techniques in our proposed research. The mathematical analysis is based on PDE theory, and the numerical methods proposed are based on state-of-the-art discontinuous Galerkin (DG) schemes. Furthermore, the obtained results will be cross-validated using data from laboratory experiments provided by the PI's academic collaborator, and oil reservoir simulation provided by the PI's industry collaborator. The interdisciplinary nature of this project will provide an environment of communication and collaboration, as well as provide an opportunity for students at different levels and with diverse background to apply mathematical and computational tools to investigate the underground oil recovery models.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1817691","Finite Element Approximations of Bending Actuated Devices","DMS","COMPUTATIONAL MATHEMATICS","10/01/2018","07/13/2020","Andrea Bonito","TX","Texas A&M University","Continuing Grant","Yuliya Gorb","09/30/2022","$272,414.00","","bonito@math.tamu.edu","400 HARVEY MITCHELL PKY S STE 30","COLLEGE STATION","TX","778454375","9798626777","MPS","1271","8037, 9263","$0.00","The ability to generate complex deformations from relatively small energies has tremendous applications in micro-engineering and biomedical science. This research focuses on developing and implementing mathematical algorithms able to predict and optimize the deformation of elastic films, chosen for their potential in the production of robust and light-weight micro-scale devices. The deformations considered are triggered by exposing to external stimuli either polymers with different expansion characteristics or manufactured gels with residual stresses. Devices based on these technologies are, for instance, employed as drug delivery vesicles,  cell encapsulation devices, sensors, bio-muscles and as proxies for tissue growth.  In addition to these applications in biomedical science, the development of autonomous foldable structures such as self-deployable sun sails in spacecraft or deployable aircrafts,  photovoltaic devices, actuators, micromotors, microgrippers, microvalves, microswimmers are very popular interests in the engineering community this research is likely to have impact on.<br/><br/>The proposed study focuses on thin devices where bending is the principal mechanism for, possibly large, deformations.  The mathematical models are derived as the two dimensional limit of thin three dimensional hyper-elastic solids. They are characterized by energy densities dominated by bending, expressed geometrically as the film's second fundamental form. In addition to the difficulties inherent in the non-divergence form of this fourth order system, fully non-linear geometrical constraints must be taken into account in the context of large deformations. The aim of this research is to derive mathematical models when not available for the targeted application, and to design, analyze and implement finite element based algorithms for their approximations. The entire process from the mathematical analysis to the actual highly parallel implementation of finite element algorithms is covered. Hence, analytical tools borrowed from differential geometry and calculus of variation are blended with numerical analysis and delicate computational efforts to achieve efficient and practical algorithms. The ability to generate complex deformations from relatively small energies has tremendous application in micro-engineering and biomedical science. The algorithms resulting from the proposed research - and in particular their relatively effortless implementations - are likely to have impact in these areas. To mention a few applications, devices based on bilayers of polymers or prestrained films are employed as drug delivery vesicles,  cell encapsulation devices, sensors, bio-muscles and as proxies for tissue growth. In addition to these applications in biomedical science, the development of autonomous foldable structures such as self-deployable sun sails in spacecraft or deployable aircrafts,  photovoltaic devices, engineered scaffolds, actuators, micromotors, microgrippers, microvalves, microswimmers are very popular research interests in the engineering community.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1750488","CAREER: Applicable Kinetic Computation with Boundaries and Rough Media","DMS","COMPUTATIONAL MATHEMATICS, Division Co-Funding: CAREER","09/01/2018","07/05/2022","Qin Li","WI","University of Wisconsin-Madison","Continuing Grant","Yuliya Gorb","08/31/2024","$400,000.00","","qinli@math.wisc.edu","21 N PARK ST STE 6301","MADISON","WI","537151218","6082623822","MPS","1271, 8048","1045, 9263","$0.00","Kinetic theory describes the dynamics of a large number of particles in a statistical manner. The theory is central to statistical mechanics and naturally connects the micro-world described by Newton's law and the macro-world described by the Navier-Stokes equations. Its applications arise from aerospace engineering, mechanical engineering, nuclear engineering, and atmospheric science. In all these engineering fields, rarified gas, photons, neutrons, and many other types of particles are modeled by kinetic equations. This research project aims to advance kinetic theory in both abstract and practical ways, developing novel theory that is widely applicable to systems of central interest in science and engineering.<br/> <br/>This research project concentrates on three main questions in kinetic theory: 1. theoretically and numerically understanding particles' interactions with boundaries/interfaces, with the focus placed on understanding the boundary layer behavior; 2. analytically and numerically relaxing homogeneity assumptions for the media, with both highly oscillatory and rough media considered; 3. studying uncertainties and sensitivities of the problem in both forward and backward manner, that is, tracing the propagation of perturbations in the forward setting to understand how error gets enlarged in the associated inverse problem. Due to the multi-scale multi-physics nature of kinetic theory, the theoretical results will largely be obtained from performing asymptotic analysis on the formal level and regularity theory on the rigorous level. To tackle the challenges in computation, the PI intends to incorporate solution structure given by partial-differential-equation analysis, and to explore randomized solvers that have seen success in data science and compressed sensing. Throughout the project, the PI intends to collaborate with engineers to ensure the techniques under development are truly applicable.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818747","Advances in Numerical Methods for Wave Propagation in Inhomogeneous Media","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","05/23/2018","Lise-Marie Imbert-Gerard","MD","University of Maryland, College Park","Standard Grant","Leland Jameson","12/31/2020","$268,940.00","","lmig@math.arizona.edu","3112 LEE BLDG 7809 REGENTS DR","College Park","MD","207420001","3014056269","MPS","1271","9263","$0.00","The scientific thrust of this project is devoted to the creation of methods for the numerical simulation of wave propagation in complicated materials with variable material properties. Generalized Plane Wave functions, introduced by the PI during her PhD, have already been proven to lead to be efficient tools for simple problems. Analyzing the corresponding methods will be a central focus of our work, with application to noise reduction in turboreactors.  The proposed work is expected to enable noticeable improvements in the numerical methods used to study acoustic effects in an air flow around a turboreactor. As recently reported by the Washington Post, airplanes have a huge impact on noise pollution. Taking into account noise reduction in the design of future aircrafts is very challenging, and will impact public health and policy.<br/><br/>Although GPW-based schemes represent a very promising numerical tool, little is known analytically about their performance. Sharper and more detailed estimates are necessary, however, to increase their impact on the community. This proposal focuses on the numerical simulation of wave propagation problems in inhomogeneous media, modeled by variable coefficients, in two and three dimensions. The principal application targeted is wave propagation in aeroacoustics in collaboration with Airbus SAS, where the source of inhomogeneity is the non-uniform flow, but the methods considered in this project will also apply to other variable material properties such as permittivity or sound speed. Novel mathematical and computational challenges need to be addressed in order to avoid the numerical error introduced a priori by a piece-wise constant approximation of the coefficients. Trefftz methods rely, in broad terms, on the idea of approximating solutions to PDEs using basis functions which are exact solutions, making explicit use of information about the ambient medium. This project is concerned with the design, mathematical analysis and computer implementation of numerical methods adapted to variable coefficients via Generalized Plane Wave (GPW) basis functions. The following research directions are proposed: (1) construction of GPWs for the convected Helmholtz equation, (2) h-version of convergence analysis, corresponding to refining the mesh, (3) p-version of convergence analysis, corresponding to increasing the number of basis functions with a fixed mesh, (4) implementation of a prototype GPW-Trefftz code for performance comparison with other methods.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818777","Collaborative Research: Construction and Analysis of Numerical Methods for Stochastic Inverse Problems with Application to Coastal Hydrodynamics","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","07/26/2018","Donald Estep","CO","Colorado State University","Standard Grant","Leland Jameson","07/31/2021","$81,044.00","","donald.estep@colostate.edu","601 S HOWES ST","FORT COLLINS","CO","805212807","9704916355","MPS","1271","9263","$0.00","As observed in past hurricanes such as Katrina (2005), Ike (2008), Sandy (2012), and the sequence of hurricanes over the 2017 season, flooding due to storm surge and rainfall causes tremendous damage to coastal communities. Preparing for future hurricane impacts requires the ability to predict characteristics of inland flooding due to surge, most importantly water levels, currents, and extent of inundation. Accurate predictions of surge require determining critical inputs to models related to the physical characteristics of coastal regions that are expensive to obtain and evolve in time. This research project focuses on quantifying and reducing uncertainties in these critical inputs using novel mathematical techniques to both extract information from existing data and aid in the design of future data collection efforts.<br/><br/>More specifically, this project focuses on the construction, analysis, and implementation of numerical methods for a stochastic inverse problem defined by the melding of observational data and high-fidelity mathematical models to perform scientific and engineering inference and prediction for complex physical systems. This research applies broadly to complex, time-evolving physical systems depending on high dimensional parameter spaces. Mathematical areas utilized in this research include computational measure theory, differential geometry, functional analysis, probability theory, and numerical analysis. Dissemination of results to the broader scientific community will be accomplished in part by the development and implementation of computational algorithms in public domain code that are applied to a state-of-the-art storm surge model.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818748","A Novel Computational Method for Diffuse Interface Models of Implicit Solvation of Biomolecules","DMS","COMPUTATIONAL MATHEMATICS","09/01/2018","08/05/2020","Zhan Chen","GA","Georgia Southern University Research and Service Foundation, Inc","Continuing Grant","Yuliya Gorb","08/31/2022","$112,109.00","","zchen@georgiasouthern.edu","261 FOREST DR","STATESBORO","GA","304586724","9124785465","MPS","1271","9263","$0.00","In the past two decades, implicit solvent models are of tremendous importance to the biomolecular<br/>modeling community with thousands of exemplary applications in the literature due to their low<br/>computational cost and relatively high accuracy. The accuracy of implicit solvent models depends<br/>on the geometric description of the solute-solvent interface and the solvent dielectric profile that<br/>is defined near the molecules. Successful implementations of the proposed model in this project with<br/>realistically generated solute-solvent smooth boundaries will greatly improve the accuracy and<br/>efficiency of these implicit solvent models. This investigation will be directly integrated into existing<br/>implicit solvent software and visualization packages to ensure extensive usages by an established<br/>user community of researchers in chemistry, physics, and biology. Moreover, the proposed work will  present <br/>an unconventional computational method for diffuse interface models applied to spatial multiscale modeling <br/>in mathematical biology. Successful development of the proposed work will become a valuable computational<br/>tool for studying the transition between regions described by discrete and continuum models. <br/>The outcome will have potential impacts across a wide range of scientific fields such as multiscale<br/>modeling in cancer research and drug design. <br/><br/><br/>The goal of this project is to develop a novel computational method for diffuse interface models of<br/>implicit solvation of biomolecules. The computational approach will be mathematically rigorous and<br/>computationally efficient to generate physically realistic solute-solvent smooth boundaries by free<br/>energy minimization. To this end, an innovative construction is proposed to transform a variational<br/>problem subject to bounded admissible functions into an equivalent unconstrained problem so<br/>that the traditional Euler-Lagrange Equation can be applied directly. This new computational<br/>formulation will be implemented with advanced computational algorithms to ensure their accuracy,<br/>stability, and efficiency, and it will be validated by several common biomolecular modeling tasks.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818886","Iteratively Regularized Broyden-Type Algorithms for Nonlinear Inverse Problems","DMS","COMPUTATIONAL MATHEMATICS","09/01/2018","07/18/2018","Alexandra Smirnova","GA","Georgia State University Research Foundation, Inc.","Standard Grant","Yuliya Gorb","08/31/2021","$100,000.00","Xiaojing Ye","asmirnova@gsu.edu","58 EDGEWOOD AVE NE","ATLANTA","GA","303032921","4044133570","MPS","1271","9263","$0.00","The goal of this project is to tackle major computational challenges faced by scientists and engineers in their quest to improve the accuracy and efficiency of numerical algorithms for solving large-scale inverse problems. This is a scenario where direct measurements of the unknown quantities are not feasible, and one needs to identify ""cause from effect"" by using (generally nonlinear) mathematical and statistical models. The resulting problems are notoriously ill-posed (or unstable), in a sense that even small measurement errors in the input data may give rise to a substantial noise propagation in the recovered solution, to the extent that this solution gets entirely destroyed. For this reason, special techniques called ""regularization"" must be combined with high-speed optimization procedures, so that reliable information on the unknown effect could be obtained from the available data. The key areas of application include imaging and sensing technology, machine learning, gravitational sounding, ocean acoustics, and data sciences.<br/><br/>This project aims at the development of iteratively regularized Broyden-type numerical algorithms for solving nonlinear ill-posed inverse problems in either finite or infinite dimensional spaces. A family of new regularization methods will be designed to solve large-scale unstable least squares problems, where the Jacobian of a discretized nonlinear operator is difficult or even impossible to compute. To overcome this obstacle, PIs consider a family of Gauss-Newton and Levenberg-Marquardt algorithms with the Frechet derivative operator recalculated recursively by using Broyden-type single rank updates. To balance accuracy and stability, the pseudo-inverse for the derivative-free Jacobian is regularized in a problem-specific manner at every step of the iteration process. A variety of filters will be investigated, yielding greater flexibility in the use of qualitative and quantitative a priori information available for each particular applied problem. The proposed iteratively regularized methods will be studied in both deterministic and stochastic settings. For stochastic processes, the minimization functionals are evaluated subject to stochastic errors due to inexact computations to lower per-iteration cost, and/or unavoidable environmental noise and fluctuations. In the framework of the proposed research, PIs will conduct comprehensive convergence analysis of the new algorithms, including convergence rates and optimal policies for the selection of regularization parameters and step sizes. In addition to the theoretical investigation, a significant component of this project is to evaluate the proposed algorithms using extensive numerical experiments on real-world nonlinear inverse problems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818977","Uncertainty Quantification for Machine Learning","DMS","COMPUTATIONAL MATHEMATICS","06/15/2018","06/07/2018","Andrew Stuart","CA","California Institute of Technology","Standard Grant","Yuliya Gorb","05/31/2022","$250,000.00","","astuart@caltech.edu","1200 E CALIFORNIA BLVD","PASADENA","CA","911250001","6263956219","MPS","1271","9263","$0.00","Computers are increasingly making decisions that impact on each and every one of us, in scenarios as wide-ranging as deciding credit card limits, flying aircraft, predicting weather and recommending products via the internet. The algorithms which perform these tasks are complex and their intricacies cannot be fully appreciated by all the people who rely on them. The goal of this project is to equip these decision-making algorithms with measures of uncertainty so that, where appropriate, human or further computer intervention can be used to ensure fair and safe outcomes. The junior researchers involved in the program will also engage in outreach programs, organized through Cal Tech. These outreach programs are aimed at high school students, and designed in particular to impact on a diverse range of high school students; this outreach work will be enhanced by experience with the research about equipping everyday algorithms with measures of uncertainty.<br/><br/>The purpose of this project is to obtain a deeper understanding of machine learning algorithms. This will be achieved by formulating and solving the problems in a statistical fashion in which uncertainty in both the mathematical models used for learning, and the data used to train them, is tracked and quantified. The objectives are twofold: (i) to improve existing algorithms by allowing them to be cognizant of their own uncertainties, or by allowing humans to interact with them in an informed fashion; (ii) to use knowledge of uncertainties to study the predictive power of the algorithms and identify laws or rules implicitly encoded within them. A Bayesian formulation of a number of machine learning tasks will be adopted, with focus on neural networks, and related issues arising in graph-based semi-supervised learning. Recent advances in the development of Monte Carlo Markov chain (MCMC) samplers in high dimensions will be deployed to make empirical studies of uncertainty. Various parameter limits (including large data volume, data in high dimensional spaces, and small data noise) will be used to develop mathematical theories which quantify uncertainty in the predictions made by machine learning algorithms.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1852597","Collaborative Research: Algorithm and Theory for Interface Computations","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","05/27/2022","Lingxing Yao","OH","University of Akron","Standard Grant","Yuliya Gorb","09/30/2022","$95,247.00","","lyao@uakron.edu","302 BUCHTEL COMMON","AKRON","OH","443250002","3309722760","MPS","1271","9263","$0.00","Phenomena in which a fluid interacts with an immersed elastic structure abound in nature and in everyday life. Such fluid-structure interaction (FSI) problems include the swimming of microorganisms, the flying of birds, blood flow in the heart, and the deformation of leaves in the wind. One powerful way to understand such FSI problems is through computer simulation. Many FSI problems lead to challenging computational problems that call for significant improvements over currently available algorithms. The immersed boundary (IB) method is a popular computational method for FSI problems, and one major goal of this project is to understand the mathematical properties of the IB method to aid in the development of faster and more robust numerical algorithms. Another goal is to adapt the IB method so that it can handle problems in which fluid (water) can flow through an elastic structure. Such problems are particularly important for the understanding of movement and shape changes of biological cells. This cell-biological aspect of the work will be performed in collaboration with experimental biophysicists. The project will train undergraduate and graduate students in the mathematical and computational sciences through research on these problems.<br/><br/>This project consists of two major aims in theory and algorithmic development for computational problems with moving membrane interfaces. On the theoretical side, the PIs will establish a convergence theory for the immersed boundary (IB) method. The IB method is a widely used numerical method for fluid structure interaction problems, but despite its popularity, its convergence properties are poorly understood. Convergence analysis for the IB method will be one of the first to be established for a fluid structure interaction algorithm in which a dual grid is used; one for the fluid and another for the elastic structure. Such an analysis will clarify the effect of grid and time discretization parameters on the stability properties of the IB method. On the algorithmic side, the PIs will develop a numerical scheme to handle electrodiffusion of ions and transmembrane water flow in the presence of deformable elastic membranes. A novel feature of the osmotic water flow problem in contrast to conventional fluid structure interaction problems is that the interfacial membrane does not move with respect to the local fluid velocity and that this slip velocity is controlled by the jump in concentration of a diffusing chemical across the membrane interface. The fluid structure interaction will be treated with the IB method whereas chemical diffusion will be treated using a Cartesian embedded boundary method. This algorithm will be applied to study the interplay between electrophysiology/osmotic water flow and cell mechanics, an area that is poorly explored theoretically but whose importance is becoming increasingly clear."
"1818716","Collaborative Research: Stochastic Methods for Complex Systems","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","07/26/2018","Gideon Simpson","PA","Drexel University","Standard Grant","Yuliya Gorb","07/31/2022","$98,134.00","","grs53@drexel.edu","3141 CHESTNUT ST","PHILADELPHIA","PA","191042816","2158956342","MPS","1271","9263","$0.00","This project addresses computational challenges in materials science, chemistry, uncertainty quantification, and related fields.  Quantities of interest such as chemical reaction rates, strength of alloys, and more, can be estimated using a common mathematical modeling framework that computes mean values and provides quantification of the variance about the means.  Estimating these quantities by computer simulation can be particularly challenging when the property that one wishes to study is rare and many repeated computer simulations would be required to estimate the mean value and the variance.  While this challenge is somewhat alleviated by growth in computing power, some simulations, including chemical reaction rates, cannot be addressed via brute force computation.  Rather than rely on raw computing power, the investigators intend to develop novel computer algorithms and approximations that will allow for more efficient and more accurate predictions.  This includes the use of interacting copies of mathematical models, which communicate information between one another, resulting in higher quality estimates.  These algorithms and approximations will allow more faithful prediction of quantities of interest and access to bigger models (such as larger, more complicated molecules).  Mathematically the project will provide a rigorous understanding of the computer algorithms, providing confidence to scientists in a variety of fields. <br/> <br/>Multiscale distributions appear in a variety of applications, including materials science, chemistry, and uncertainty quantification.  Given efficient sampling strategies, one can compute a variety of quantities of interest, including ensemble averages, mean first passage times, and probabilities of rare events.  However, multiscale distributions in high number of dimensions are particularly challenging to sample.  One example is the Boltzmann distribution induced by an energy landscape containing superbasins.  Such a landscape features clusters of local minima that correspond to close groupings of modes in the distribution.  This project will investigate four sampling algorithms: weighted ensemble sampling, parallel replica dynamics, local entropy smoothing, and piecewise deterministic Markov processes.  Weighted ensemble sampling partitions state space into bins and then elects to sample within those bins in an optimal way.  The project will investigate the choice of the sample allocation strategy and consider both finite and infinite system size limits for the method.  Parallel replica dynamics also involves using an ensemble of samples, but, in contrast to weighted ensemble, it uses the replicas to efficiently find first exits out of one metastable region and into another.  Local entropy smoothing removes the superbasin features of the energy landscape by performing local ensemble sampling and averaging.  Finally, the investigators will use piecewise deterministic Markov processes to perform rejection free sampling without requiring estimates of gradients.  These algorithms will be rigorously analyzed, and they will be tested on a variety of realistic high-dimensional problems including chemical reaction networks and stochastic molecular dynamics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819144","Novel Multiple-Shooting Algorithms for Optimization Governed by Time-Dependent Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","06/07/2018","Matthias Heinkenschloss","TX","William Marsh Rice University","Standard Grant","Yuliya Gorb","06/30/2022","$319,192.00","","heinken@rice.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","MPS","1271","9263","$0.00","Mathematical optimization plays a crucial role in the optimal design of engineering systems and in their efficient operation. For example, management of oil reservoirs requires the injection of, e.g., water into wells to push oil reserves through complex geological structures to production wells with the goal to maximize revenue. Systems like this are modeled by time-dependent partial differential equations (PDEs) and involve many design or decision variables, such as injection rates that vary among wells and over time, that need to be determined. This research develops new mathematical optimization algorithms for such time-dependent problems.  <br/> <br/>Specifically, this research aims to develop new algorithms for the efficient application of direct multiple shooting (MS) formulations to optimal control and optimal design problems governed by time dependent PDEs, and demonstrates the performance of these algorithms to applications in flow control. Direct MS formulations decompose the underlying PDEs into equations on shorter time subintervals and couple these at the time interval boundaries. These coupling conditions must be satisfied at the solution, but not during the iteration of an optimization algorithm. This is exploited to achieve substantial improvements in the numerical solution of such problems through superior stability properties of sub-problems, enhanced convergence properties of solution algorithms, and introduction of parallelism. However, MS formulations have a price: The auxiliary initial data at time interval boundaries are additional optimization variables and the coupling conditions are additional constraints. For problems governed by (discretized) PDEs this leads to huge increases in the number of optimization variables and constraints. Because of these increases, existing optimization approaches that have been successfully applied to MS formulations of problems governed by ordinary differential equations are practically infeasible in the PDE setting. The goals of this research are to 1) inject MS formulations into first-order gradient optimization algorithms to expand their applicability to problems where the solution of the underlying PDE may be numerically unstable and 2) develop new second-order iterative methods based on model reduction to substantially reduce the computational cost of solving large quadratic-programs that arise in conventional sequential quadratic programming approaches. Convergence analysis of the new methods will be provided and these methods will be demonstrated on applications in flow control.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818998","Multiscale and Hybridizable Discontinuous Galerkin Methods for Dispersive Equations and Systems","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","06/01/2018","Bo Dong","MA","University of Massachusetts, Dartmouth","Standard Grant","Yuliya Gorb","06/30/2022","$269,185.00","","bdong@umassd.edu","285 OLD WESTPORT RD","NORTH DARTMOUTH","MA","027472356","5089998953","MPS","1271","9263","$0.00","This project concentrates on the development of novel computational methods for efficiently solving dispersive equations and systems, including the time-independent Schrodinger equations and Korteweg-de Vries (KdV) type equations in multidimensional spaces and systems.  Schrodinger equations play a central role in the study of quantum mechanical systems and are widely used in the simulation of quantum transport in nanoscale semiconductor devices. The proposed multiscale method for Schrodinger equations will have a positive impact in the study of quantum mechanics and great potential in applications to ultrafast, low consumption and high functionality nanoscale semiconductor devices. KdV type equations and systems have wide applications in various fields such as fluid mechanics, nonlinear optics, acoustics, plasma physics, and Bose-Einstein condensates. The proposed method for KdV type equations and systems will help understand theoretically unresolved issues and provide accurate and efficient numerical tools for simulation of nonlinear waves in applications. <br/> <br/>The proposed research includes the following topics, (1) development and analysis of multiscale discontinuous Galerkin (DG) methods for Schrodinger equations in 1D, system, and 2D for the simulation of nanoscale semiconductor structures on coarse meshes, (2) design and error analysis of hybridizable discontinuous Galerkin (HDG) methods for solving multidimensional KdV type equations and KdV type systems, and (3) design of IMEX HDG-DG schemes for efficiently solving KdV type nonlinear equations and systems. To efficiently resolve highly oscillatory solutions of Schrodinger equations on coarse meshes, the multiscale DG methods will incorporate the oscillatory nature of the solutions and thus the multiple scales into the non-polynomial basis functions. For KdV type equations in multi-dimensions and systems, the PI will devise new HDG methods, study their convergence and conservation properties, and combine them with other DG methods in IMEX scheme to achieve high-order solutions both in time and in space and avoid overly small time-step sizes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1821342","Learning Geometry for Inverse Problems in Imaging","DMS","COMPUTATIONAL MATHEMATICS, CDS&E-MSS","07/01/2018","05/16/2023","Karl Wimmer","PA","Duquesne University","Standard Grant","Christopher Stark","06/30/2024","$116,803.00","","wimmerk@duq.edu","600 FORBES AVENUE","PITTSBURGH","PA","152820001","4123961537","MPS","1271, 8069","9251, 9263","$0.00","The quantity of digital image data our society relies on for medical, military, and a wide range of engineering and scientific applications continues to increase, yet digital images still typically exhibit some level of degradation during formation, transmission, and storage, often obscuring vital information. Despite significant advances in the fields of image processing and computer vision, this problem still persists due to the difficulty in accurately modeling random degradations such as noise, pixel loss, and blur. The main objectives for this project are to learn critical geometric and higher order image features for accurately solving a variety of inverse problems in imaging, including image denoising, image deblurring, image inpainting (filling in of missing data), and super-resolution.  The new algorithms developed in this project are expected to yield improvements over existing algorithms in the form of standard image quality metrics as well as in the preservation of accurate, fine details, a feature missing from many current state of the art image processing algorithms, yet vital for automatically interpreting this image data in practice.<br/> <br/>In recent work the PI and collaborators have developed several frameworks for image denoising that attempt to recover an image from a denoised geometric feature of the image. These approaches have successfully improved upon existing state of the art denoising algorithms, providing information in the reconstruction that has been elusive using alternate approaches. The challenge in working with this geometric data is that while it is very robust in practice, mathematically sound mechanisms developed for handling natural image data do not necessarily apply to their geometric features. This project involves learning geometric descriptors from image data that have suffered from some combination of the aforementioned random and/or linear degradations for the purpose of aiding in image reconstruction, analysis, and interpretation. Preliminary analyses and experiments indicate that the benefits of this approach could be significant, yet computationally intensive experiments are required to explore how best to exploit these benefits in practice. Theoretical analyses of these models will be an important part of this project as well, in order to better to understand when these models are guaranteed to be reliable in practice.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819161","Inexact Optimization Methods for Structured Nonlinear Optimization","DMS","COMPUTATIONAL MATHEMATICS","07/15/2018","07/12/2018","Hongchao Zhang","LA","Louisiana State University","Standard Grant","Yuliya Gorb","06/30/2022","$200,000.00","","hozhang@math.lsu.edu","202 HIMES HALL","BATON ROUGE","LA","708030001","2255782760","MPS","1271","9150, 9263","$0.00","New efficient computational algorithms will be developed for solving large-scale optimization problems with particular structure. Structured nonlinear optimization has played a central role in various modern applications ranging from image processing, optimal control to stochastic learning in big data area. The algorithms developed in the project will provide solutions in a more robust and faster way, and will be made publicly available to benefit both optimization and computational data science community. The student supported in this project will have excellent opportunities for interdisciplinary research.<br/><br/>The current methods for solving structured optimization problems often need to solve a sequence of subproblems according to the problem structure. This project aims to develop efficient methods and software that allow to solve their subproblems inexactly while still theoretically guarantee the global convergence and maintain the same or almost the same computational complexity of the corresponding methods that require exact solve of the subproblems. In particular, the investigator will develop (I) a framework of inexact alternating direction methods of multipliers for separable convex optimization, where the subproblem is solved to the accuracy relative to the whole problem KKT error; (II) inexact stochastic gradient methods for the composite optimization, which combines the(accelerated) proximal gradient methods and stochastic variance reduction techniques; (III) inexact active-set algorithms for polyhedral constrained nonlinear optimization.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818754","A Computational Study of the Nudging Approach to Data Assimilation","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","06/11/2020","Michael Jolly","IN","Indiana University","Continuing Grant","Yuliya Gorb","06/30/2022","$149,999.00","","msjolly@indiana.edu","107 S INDIANA AVE","BLOOMINGTON","IN","474057000","3172783473","MPS","1271","9263","$0.00","This work develops and tests new approaches to assimilating data into mathematical models to achieve more accurate prediction, for example in weather forecasts.  The novelty is to consider data that is (a) concentrated in a small region (as over a metropolitan area), (b) moving (as from satellites, commercial airplanes, cars, even cell phones), and (c) from easily-measured quantities, such as atmospheric pressure. Numerical experiments will be supported by rigorous mathematical analysis.<br/><br/>This work involves computational projects that tie together data assimilation, determining forms, and turbulence. The data assimilation is by nudging, an approach that has proven to be conducive to rigorous mathematical analysis but has undergone much less computational testing than have Kalman filters. Nudging is closely related to determining forms, ordinary differential equations in trajectory spaces that capture the global attractors of systems such as the Navier-Stokes equations of fluid flow. Such systems are expected to display turbulent behavior, which raises a particular set of computational issues addressed by this research.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819110","Efficient Algorithms for Optimal Control of Time-Periodic and Nonlinear Systems","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","07/30/2018","Serkan Gugercin","VA","Virginia Polytechnic Institute and State University","Standard Grant","Yuliya Gorb","07/31/2022","$279,913.00","Christopher Beattie, Jeffrey Borggaard","gugercin@math.vt.edu","300 TURNER ST NW","BLACKSBURG","VA","240603359","5402315281","MPS","1271","9263","$0.00","Fluids often exhibit cyclical motion, either due to external periodic forces (e.g., lunar tides) or due to internal forces that naturally arise through interaction with the environment (e.g., air buffeting through a slightly opened car window or the eddies that develop from a river current interacting with a bridge pillar).  The control of such flows is of great interest since in many cases small changes in a flow profile can produce either dramatic benefits or catastrophic costs.  Stabilizing and tuning cyclic flow patterns to a given frequency can be useful in the design of wind farms and wave energy converters, for example, while in other circumstances eliminating oscillatory motion altogether may help reduce fatigue loads placed on critical support structures.  This project specifically addresses the modeling and control of oscillatory phenomena through the development of new mathematical algorithms for simulation and control that integrate underlying periodic system behavior into the core modeling framework, thus promising both improved accuracy and reduced computational costs.  This research will result in improved understanding of mathematical models of systems with periodic behavior as well as the development of new simulation and modeling tools, which will have an immediate bearing on a wide range of applications found in biology (e.g., circulatory and respiratory systems) and energy (e.g., wind turbines and power grid dynamics).<br/><br/>Simulation and control of periodic flow structures require methods specialized to the task. The Floquet transformation has long been a theoretical tool for such problems, allowing for a change in system representation that effectively shifts the periodic time dependence out of the internal dynamics into the input/output ports. Only recently has it been practical to use this approach for small to medium scale problems.  The initial focus of this research will be on the development of scalable, numerically effective algorithms for large-scale Floquet transformations, enabling the high-fidelity reduced models for time-varying periodic flow dynamics. By combining operator splitting approaches with optimal model reduction methods for quadratic systems, new capabilities for input-independent model reduction for nonlinear dynamics will be developed and analyzed.  The model reduction framework that is proposed here offers improved numerical efficiency and greater accuracy at modest cost. Fundamental to this approach will be the integration of an accurate representation of dynamics into reduced-order models, better respecting the properties of the underlying optimal control problem.  Robust computational tools aiding the simulation and modeling of large-scale oscillatory dynamics will be developed and provided to the science and engineering community.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819097","New Preconditioned Solvers for Large and Complex Eigenvalue Problems","DMS","COMPUTATIONAL MATHEMATICS","07/15/2018","07/12/2018","Fei Xue","SC","Clemson University","Standard Grant","Yuliya Gorb","06/30/2022","$200,000.00","","fxue@clemson.edu","201 SIKES HALL","CLEMSON","SC","296340001","8646562424","MPS","1271","9150, 9263","$0.00","This project aims to develop new algorithms that will help enable large-scale eigenvalue-related modeling and simulations in many scientific and engineering areas, including linear stability analysis of dynamical systems, mechanics of materials, optimization of acoustic emissions, study of superconductivity, vibrations under conditions of uncertainty, and many more. Certain methods are also of significance to other areas; for example, a fast exponential matrix-vector product is essential to the exponential integrator for solving stiff time-dependent differential equations that are difficult to tackle by traditional methods. New textbook writing and graduate student mentoring will help cultivate qualified researchers and industrial professionals to generate further impact in future.<br/><br/>Eigenvalues and closely related mathematical tools (e.g., pseudospectra) are fundamentally descriptive in many areas of applied mathematics and scientific computing. This project concerns systematic development and analysis of innovative preconditioned solvers for several important classes of large-scale and complex eigenvalue-related problems. For large linear symmetric eigenproblems, variants of preconditioned eigensolvers have been thoroughly investigated and widely used with great success in many applications. The plan is to show that the preconditioning and the solver framework can both be generalized significantly and integrated with great flexibility to solve a much broader class of challenging eigenvalue-related problems. The methods to be developed will be reliable, efficient and flexible. The specific research topics include (i) preconditioning (spectral filtering) with matrix functions, (ii) solving nonlinear eigenproblems, and (iii) computing spectra and pseudospectra of large structured matrices.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818821","Smart Data Approaches for the Inverse Design of Soft Materials","DMS","COMPUTATIONAL MATHEMATICS","07/15/2018","07/06/2020","Hector Ceniceros","CA","University of California-Santa Barbara","Continuing Grant","Yuliya Gorb","06/30/2022","$200,001.00","","hdc@math.ucsb.edu","3227 CHEADLE HALL","SANTA BARBARA","CA","931060001","8058934188","MPS","1271","8037, 9263","$0.00","The traditional approach to the design of new, smart materials requires costly experimentation to explore a vast combination of parameters.  This process can be accelerated in a ""virtual lab"" with computer simulations but it requires a non-traditional approach. Until recently, the focus of computer simulations has been the forward problem: given values of the parameters such as molecular architecture, composition, etc., find the material properties. But the inverse problem in which given a desired set of material properties we seek values of the parameters that give rise to those properties, is more critical for accelerating the design and advancement of new materials. This inverse design problem, which is an extraordinarily challenging, high-dimensional global optimization problem, is one of the main thrusts of this project.  The envisioned mathematical and computational framework will be broadly applicable to a wide variety of materials such as block copolymers and nano-structured soft materials. This project will have a substantial impact in education with an increased participation of students from underrepresented groups and undergraduates<br/> <br/>Traditionally, computer simulations are performed for some educated choices of the model parameters. Each simulation is in general costly so that, even with state of the art computing resources, only a limited number of simulations is feasible for realistic models. This is a particularly serious problem when the parameter space is moderate to high dimensional and is impossible to fully explore that space. In this project, the principal investigator will develop a probabilistic approach to solve the inverse design problem, to design superior methods for the forward problem, and to perform statistical inference for the construction of computationally more efficient, coarse-grained models. This is a smart-data approach, in which the use of prior belief about the objective function to be optimized or to be inferred (based prior evaluations) to guide the sampling of the parameter will be explored for the first time in the context of field-theoretic models of multi-block copolymers.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818948","Numerical Spectral Study of Elliptic Operators","DMS","COMPUTATIONAL MATHEMATICS","06/01/2018","06/04/2018","Chiu-Yen Kao","CA","Claremont McKenna College","Standard Grant","Yuliya Gorb","05/31/2022","$86,150.00","","ckao@claremontmckenna.edu","500 E 9TH ST","CLAREMONT","CA","917115929","9096077085","MPS","1271","8037, 9263","$0.00","Since Lord Rayleigh conjectured more than a century ago that the disk should minimize the first Laplace-Dirichlet eigenvalue among all shapes of equal area, spectral study of elliptic operators has been an active research topic with applications including mechanical vibration, optical resonators, photonic crystals, and population dynamics. In mechanical vibration, for example, it is interesting to explore what shapes or what density distributions can generate minimal fundamental frequency; in photonic crystals, one seeks to design semiconductor structures with a periodic variation of refractive index to maximize photonic bandgap in which the propagation of light is forbidden. This project aims to advance numerical approaches to these kinds of questions for classes of eigenvalue problems that arise in design of containers to minimize fluid sloshing and in vibration control. Researchers have turned their attention to these questions with a renewed interest due to surprising recent discoveries, which include symmetry structure found in the optimizer of Steklov eigenvalue problems, optimal density arrangements in thin plates, and localization of vibration induced by interior clamped points. The project will explore a range of related open questions and aims to develop numerical approaches to solve them. The project also provides opportunities for mentoring students and engaging interested scientists, including those from underrepresented groups.  Results are expected to have important potential application in systems that reduce liquid sloshing in missiles and other vessels, in noise and vibration control, and in medical and geophysical imaging.<br/>   <br/>This project aims to develop numerical approaches to solve Steklov and biharmonic eigenvalue problems and study their related shape and topology optimization problems. The forward solvers for this project are based on boundary integral methods, finite element methods, and spectral methods. The optimization solvers are based on shape/topology derivatives and rearrangement methods. The investigator will study a wide range of problems arising from applications in liquid sloshing and plate vibrations, including (1) computation of the k-th Steklov eigenvalue problem and its optimization among star-shaped domains in three dimensions, (2) computation of principal eigenvalue of mixed Steklov eigenvalue problems and its related shape optimization, (3) Steklov eigenvalue problems on general manifolds, (4) spectral study of buckled plate eigenvalue problems, (5) localization of eigenfunctions induced by clamped points, and (6) multiphase shape optimization problems involving biharmonic operators.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818926","High-Order Accurate Partitioned Algorithms for Fluid-Structure Interactions and Conjugate-Heat Transfer","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","06/25/2018","William Henshaw","NY","Rensselaer Polytechnic Institute","Standard Grant","Yuliya Gorb","06/30/2022","$384,035.00","Donald Schwendeman","henshw@rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","MPS","1271","9263","$0.00","Fluid-structure interaction (FSI) problems are important in many areas of engineering and applied science, such as modeling of blood flow, flow-induced vibrations of structures, and wave energy devices, among others, and there is significant interest in numerical simulation tools for such problems.  Conjugate heat transfer (CHT) also plays an important role in many FSI simulations, such as the cooling of turbine blades, heat exchangers, nuclear reactors, semiconductor devices, and more.  In this project the PIs aim to build upon their recent achievements to develop stable partitioned algorithms for new classes of FSI problems that also include CHT effects.  The PIs will address the development of high-order accurate schemes for these FSI-CHT problems.  High-order schemes are especially useful for wave-dominated regimes such as high-Reynolds number turbulent flows and propagation of elastic waves.  At the same time, achieving high-order accurate interface coupling approaches for partitioned schemes presents numerous intellectual and numerical challenges.<br/><br/>The proposed research is concerned with the development and analysis of new high-order accurate algorithms for a wide range of complex and challenging FSI-CHT problems, such as those involving incompressible or compressible flows, with possible free surfaces, coupled to rigid bodies and deforming bulk solids with heat transfer.  These new partitioned algorithms will use novel interface coupling conditions to treat both the FSI and CHT interface conditions.  The FSI interface  conditions will be based on principles we have developed for our Added-Mass Partitioned (AMP)schemes. The CHT domain coupling will extend the recently devised CHAMP interface conditions that combine ideas from optimized Schwarz iterations for domain-decomposition with compatibility interface conditions. The resulting interface couplings will provide schemes that remain provably stable for a wide range of material parameters (e.g. for light solids when added-mass effects are large).  A primary focus will be on algorithms for incompressible flows and incompressible solids. New high-order accurate fractional-step solvers will be developed for both incompressible elastic solids and the incompressible Navier-Stokes equations.  Complex moving and deforming geometry will be handled with deforming composite grids. Fast, efficient and scalable multigrid algorithms and automatic mesh generation algorithms will be developed as key components of the FSI-CHT solvers.  The new high-order accurate and stable AMP algorithms will complement the ones already developed by the PIs and collaborators for FSI problems, and together they will provide a suite of solvers readily available in open-source software.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818374","Graph-Based Regularization Techniques and Their Applications","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","06/12/2018","Jing Qin","MT","Montana State University","Standard Grant","Leland Jameson","08/31/2019","$186,006.00","","jing.qin@uky.edu","216 MONTANA HALL","BOZEMAN","MT","59717","4069942381","MPS","1271","062Z, 9150, 9263","$0.00","The rapid development of science and technology ushers in a new era of big data that requires developing specialized algorithms to process a large amount of data. Signal processing and other related techniques aim to recover signals of interest or some of their properties; this goal can be reduced to an optimization question. Due to physical limitations of hardware, the size of the acquired data is in general much smaller than that of the underlying signal, resulting in an ill-posed problem for signal recovery with infinitely many solutions. Regularization techniques have been developed to address this inherent ill-posedness. Despite being widely applied in low-dimensional signal processing, regularization has seen limited use in processing high-dimensional data sets, especially those best represented by graphs, that is, networks with sophisticated connections. This project aims to further develop graph-based regularization techniques, with potential to revolutionize imaging and data analysis technologies in many areas of data science.<br/><br/>This project aims to develop a useful graph-based regularization framework for various signal processing problems, to address major theoretical and computational challenges for its applications, to provide new interpretations of low-dimensional regularization techniques, and to demonstrate its capability for handling large-scale data sets. The research has three objectives: (1) Develop novel graph-based regularization techniques along with rigorous theoretical guarantees to handle the more challenging signal processing problems and related inverse problems; (2) Develop efficient numerical algorithms to solve the corresponding optimization problems; and (3) Conduct numerical experiments in imaging applications to demonstrate the advantages of the proposed approaches in terms of accuracy and efficiency. The research aims to improve data processing techniques and to infuse new insights into mathematical signal and image processing, with a variety of applications such as medical imaging and remote sensing.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1817272","Understanding Semidefinite Programming Duality Using Elementary Reformulations","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","07/18/2018","Gabor Pataki","NC","University of North Carolina at Chapel Hill","Standard Grant","Yuliya Gorb","07/31/2022","$150,000.00","","gabor@unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275995023","9199663411","MPS","1271","9263","$0.00","Semidefinite programs (SDPs) are some of the most versatile, useful, and interesting  optimization problems to emerge in the last few decades. They find uses in engineering, economics, and machine learning, to name just a few areas. In the last few decades thousands of papers have been published on SDPs. However, SDPs are often pathological: they may not attain their optimal values, and/or their optimal value may differ from that of their dual. Such SDPs  often defeat even  the best SDP solvers, which fail or report an incorrect solution.  Can we understand these pathologies using something as simple as row operations inherited from Gaussian elimination? The project aims to answer this question affirmatively and lead to both theoretical and computational advances in semidefinite programming, and more broadly, in convex optimization. The PI will broadly disseminate the results, both in international and domestic conferences, and by training doctoral students. <br/> <br/>A linear system of equations can be pathological in the sense that it may not have a solution. We can understand this pathology by  transforming the system into a standard form that contains an impossible equation. The transformation is based on elementary row operations. The proposed project aims to use the same operations to transform SDPs into a canonical form, from which their pathology  (say positive duality gap) is easy to see. Thus, on the theoretical side  the project will show that elementary row operations - a staple tool in linear algebra - are useful to understand a much more general class of problems, SDPs, and even more broadly, convex optimization problems. On the computational side the project will develop a useful problem library to test SDP solvers, and other conic optimization solvers. Thus, besides developing theory, the project will contribute to the development of solution methods.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1720342","RUI: Entanglements in Proteins and Other Macromolecular Chains","DMS","COMPUTATIONAL MATHEMATICS","08/15/2018","08/03/2018","Eric Rawdon","MN","University of St. Thomas","Standard Grant","Yuliya Gorb","07/31/2022","$100,000.00","","ejrawdon@stthomas.edu","2115 SUMMIT AVE","SAINT PAUL","MN","551051096","6519626038","MPS","1271","9229, 9263","$0.00","Proteins are molecular chains which perform many of the cellular processes that sustain life.  For a protein to perform its function, the protein must ""fold"" into what is called its ""native state"".  While the folding process is not directly observable, modern experimental techniques make it possible to observe the 3D structure of proteins in their native states.  Researchers have found knots (like knots in one's shoes), links (like the Olympic rings), and other types of entanglements in the native states of many proteins.  Furthermore, it has been shown that the entanglements in these proteins have resisted evolution, suggesting that the entanglements are critical to the function of the proteins and not just a cosmic accident.  It is unclear why entanglements (which add complexity to the folding process) would be advantageous to proteins, especially since the consequences of misfolding a protein can be devastating.  For example, misfolded proteins are believed to be related to diseases such as Alzheimer's disease, Parkinson's disease, and Creutzfeldt-Jakob disease (the human analogue of Mad Cow Disease).  In addition, proteins linked to HIV, whooping cough, obesity, and other ailments have been shown to contain entanglements.  The goal of this project is to develop computational tools and run simulations to gain a deeper understanding of the types of entanglements seen in proteins and other molecular chains.  A clear understanding of protein entanglement, and the relationship between entanglement and protein function, will provide insights into human ailments and could be central to the design of the next generation of drugs to battle the ailments.<br/><br/>The PI, a multi-disciplinary group of collaborators, and undergraduate researchers will leverage their unique skill set towards two main objectives.  First, a number of different techniques have been proposed previously to classify the type of knotting in open curves (such as proteins).  In this project, these different methods will be compared, and new efficient algorithms created, to measure the types of knotting in these curves.  Second, physical properties of molecular chains affect the structure of entanglements that can be created.  For example, molecular chains are often modeled as having some thickness, i.e. there is a thin impenetrable tube about the chain.  The group will study how the types of knots and their structures change with differing thickness values.  Together, these projects aim to efficiently classify the entanglements in proteins, pinpoint their location, and determine how some physical properties affect the entanglements observed.  In addition to the scientific goals, this grant has broad educational objectives. Undergraduate students will be trained by the PI and contribute to the projects, gaining both content knowledge and experience in the research process. The students will participate in professional meetings and disseminate their findings in talks and posters. These research experiences are essential in training the next generation of STEM educators, researchers, and practitioners.  To reach a wide audience, the PI will continue to be active in giving presentations to students, non-specialists, and multidisciplinary groups, both domestically and internationally. The results will be published in mathematics and science journals. The PI will organize interdisciplinary conference sessions to bring together scientists from traditionally disparate fields and create new interdisciplinary collaborations with researchers across the world. Furthermore, the research results, data, and software generated as a part of this grant will be made publicly available via the world wide web.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1760316","FRG: Collaborative Research: Randomization as a Resource for Rapid Prototyping","DMS","STATISTICS, COMPUTATIONAL MATHEMATICS","08/01/2018","08/02/2018","Michael Mahoney","CA","University of California-Berkeley","Standard Grant","Stacey Levine","07/31/2023","$790,668.00","Ming Gu","mmahoney@icsi.berkeley.edu","1608 4TH ST STE 201","BERKELEY","CA","947101749","5106433891","MPS","1269, 1271","1616, 9263","$0.00","A principled foundation for fast prototyping data analysis methods will be developed.  The main approach will be to use fast randomized matrix algorithms, as developed within the research area known as Randomized Numerical Linear Algebra (RandNLA).  Prior work has shown that these RandNLA algorithms come with strong theory and that they perform well for many practical data science and machine learning problems.  The foundation will develop novel uses of randomization to combine complementary algorithmic and statistical perspectives. The statistical viewpoint attributes randomness to an inherent and desirable property of the data, while the algorithmic viewpoint claims randomness as a computational resource to be exploited.  The coupling of these complementary approaches poses challenging mathematical problems to be investigated in the proposed work.<br/><br/>The proposed work will establish the foundations for fast prototyping in two directions: A Multi-Pronged Direction to bring RandNLA to the next level and explore what is technically feasible; and an overarching Synergy Direction that fuses the results for prototyping. The Multi-Pronged Direction includes the following topics: (i) Matrix perturbation theory, to bridge the gap between traditional worst-case bounds for asymptotically small perturbations on the one hand; and perturbations caused by stochastic noise, and missing or highly corrupted matrix entries on the other hand. (ii) Implicit versus explicit regularization, where randomness as a computational resource for speeding up algorithms additionally contributes to implicit statistical regularization, thereby improving statistical and numerical robustness. (iii) Krylov space methods for fast computation of good warm-starts and computation of surrogate models in the form of low-rank approximations, and specifically a better understanding of these methods in an algorithm-independent setting. (iv) Randomized basis construction methods that use matrix factorizations to compute low-rank approximations at low to moderate levels of accuracy. The Synergy Direction will explore topics like ultra-low accuracy matrix computations in machine learning applications, where merely a correct sign or exponent is sufficient. As a group, the PIs possess unrivaled and complementary expertise in applying fundamental mathematical tools to numerical applications in machine learning, data mining and scientific computing.  Importantly, the proposed methods will have significant impact in big data analysis, scientific computing, data mining and machine learning, where matrix computations are of paramount importance. The proposed work is fundamentally interdisciplinary and will enable fast, yet user-friendly extraction of insight from large-scale data these societally-important scientific domains.  Specifically, the proposed work will (i) create a numerically reliable and robust footing for fast prototyping; (ii) advance mathematics at the interface of computer science and statistics, one of the objectives being a synergy of numerical and statistical robustness; and (iii) advance the development of an interdisciplinary community with RandNLA as a pillar for the mathematics of data. The award will allow the investigators to increase their active engagement in reaching out to undergraduate and graduate students, and research communities in numerical linear algebra, theoretical computer science, machine learning, and scientific domains such as astronomy, materials science, and genetics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819203","Computational Filtering Methods for Time-Varying Parameter Estimation in Nonlinear Systems","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","06/07/2018","Andrea Arnold","MA","Worcester Polytechnic Institute","Standard Grant","Yuliya Gorb","06/30/2023","$220,458.00","","anarnold@wpi.edu","100 INSTITUTE RD","WORCESTER","MA","016092247","5088315000","MPS","1271","9263","$0.00","Many applications in modern science involve unknown system parameters that must be estimated using little to no prior information.  In mathematical models to analyze and predict the behavior of such systems, the problem of estimating and quantifying uncertainty in model parameters remains a challenge.  This is particularly true for systems where knowledge of parameter values is critical in obtaining trustworthy model output, as in patient-specific models for personalized medicine, for example.  A subset of these problems includes parameters of the type that are known to vary with time but do not have known evolution models.  Examples include the seasonal transmission parameter in modeling the spread of infectious diseases and the external voltage parameter in modeling the spiking dynamics of neurons.  In certain cases, the parameters may have some known structural characteristics (such as periodicity) that can be utilized in and maintained throughout the estimation process. However, the main challenge in estimating time-varying parameters lies in accurately accounting for their time evolution without detailed information regarding their temporal dynamics.  The goal of this project is to design and analyze novel computational methods for estimating such time-varying parameters.<br/><br/>The aim of this study is to design and analyze novel computational methods for estimating time-varying parameters through use of nonlinear filtering.  Leveraging the strengths of the Bayesian statistical filtering framework, where prior beliefs are naturally incorporated, this work will involve developing models for parameter evolution that take into account prior knowledge relating to the structure or behavior of the parameter over time without defining explicit functions to describe the dynamics.  Methods will also be developed for more difficult problems where there may not be any parameter structural characteristics known a priori.  The algorithms and computational tools developed in this study will be applied to data for a variety of nonlinear systems, which may further inspire new directions for methodological advancement.  Specific areas of application include engineering and the life sciences, with particular application to surgical robotics involving tissue thermal response to laser-based microsurgery.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1814592","Inverse Problems Arising in Novel Modalities of Biomedical Imaging","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","08/01/2018","08/01/2018","Leonid Kunyansky","AZ","University of Arizona","Standard Grant","Pedro Embid","06/30/2022","$300,425.00","","leonk@math.arizona.edu","845 N PARK AVE RM 538","TUCSON","AZ","85721","5206266000","MPS","1266, 1271","9263","$0.00","Computerized tomography plays a central role in biomedical imaging. Since the invention of computer-aided tomography in the 1960s, numerous imaging modalities have been introduced and became indispensable for diagnostic instruments in biology and medicine. Recently, the quest for more sensitive and more reliable techniques has led to such promising coupled-physics modalities as Thermoacoustic and Photoacoustic Tomography (TAT and PAT), and Magnetoacoustoelectric Tomography (MAET). These imaging methods combine high resolution of ultrasound with the sensitivity of electromagnetic waves to optical absorption and conductivity of the tissues. Sharp abnormalities in the latter physical parameters are good markers of breast cancer, thrombosis, ischemia, and other medical conditions. Thus, these new techniques overcome limitations of classical tomography, and deliver otherwise unavailable, potentially life-saving diagnostic information - at a lesser cost and with less harm to a patient. The images in these modalities are obtained by complex mathematical procedures, rather than through direct acquisition. The mathematics of these methods is, mostly, at very early stages of development. The investigator and his collaborators work to resolve the central theoretical problems and to develop efficient numerical techniques for PAT, TAT, MAET and other hybrid techniques. A graduate student and a postdoc are playing a significant role in the project, gaining exposure to the exciting area at the junction of exact sciences, medicine, and biology. The results will be disseminated through publications in high quality research journals, presentations at national and international conferences, and series of lectures at various major venues.<br/><br/>The mathematics underlying and enabling such modalities as PAT, TAT, MAET and several novel techniques based on Compton scattering, contains a number of challenging open problems, important from both the theoretical and applied points of view. The investigator and his collaborators aim to gain a theoretical understanding and to develop algorithmic foundations for these modalities. In particular, they work on (1) deriving exact inversion formulas for the problem of TAT/PAT reconstruction from the sets of data reduced both in time and in space; (2) developing efficient reconstruction algorithms for different MAET data acquisition schemes, including MAET with loss of low frequencies, and MAET of objects with anisotropic conductivity; (3) devising efficient numerical techniques for congregating strongly over-determined Compton data sets, and processing them using attenuation compensation techniques previously developed for Single Photon Emission Computed Tomography. In addition, the newly developed theoretical and algorithmic tools will be used to process real MAET data obtained by the PI in experimental MAET research done jointly with the researchers from the Medical Imaging Department at the University of Arizona.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818751","Analysis and Recovery of High-Dimensional Data with Low-Dimensional Structures","DMS","COMPUTATIONAL MATHEMATICS","06/15/2018","06/26/2020","Wenjing Liao","GA","Georgia Tech Research Corporation","Continuing Grant","Yuliya Gorb","05/31/2021","$215,385.00","","wliao60@gatech.edu","926 DALNEY ST NW","ATLANTA","GA","30332","4048944819","MPS","1271","9263","$0.00","Nowadays massive, high dimensional data sets arise in many fields of contemporary science and introduce new challenges. In machine learning, the well-known curse of dimensionality implies that, in order to achieve a fixed accuracy in prediction, a large number of training data is required. In image and signal recovery, a large number of measurements are needed to recover a high-dimensional vector, unless further assumptions are made. Fortunately, many real-world data sets exhibit low-dimensional geometric structures due to rich local regularities, global symmetries, repetitive patterns, or redundant sampling. The PI will explore low-dimensional geometric structures in data sets for feature extraction, data prediction and signal recovery. Dimension reduction and function approximation given a set of training data are of central interest in machine learning and data science. When data are concentrated near a low-dimensional set or the function has low complexity, the PI will develop new and fast machine learning algorithms whose performance depends on the complexity of the data or the function, instead of the dimension of the data sets.  In image and signal recovery, an interesting problem is to recover a high-dimensional, sparse vector from a small number of structured measurements. This problem is challenging since sensing matrices arising from imaging and signal processing are often deterministic, structured and highly coherent (some columns are highly correlated), which does not allow one to apply standard theory and algorithms. The PI will utilize the structures of sensing matrices, develop efficient algorithms, and prove performance guarantees. The theory and fast algorithms developed in this project can be applied to a wide range of problems in data compression, image analysis, computer vision, and signal recovery.<br/> <br/> <br/>High dimensional data arise in many fields of contemporary science and introduce new challenges. Fortunately, many real-world data sets exhibit low-dimensional geometric structures. This project focuses on exploiting these low-dimensional geometric structures of the data sets, and developing novel methods for dimension reduction, function approximation, and signal recovery. The PI will work on two sets of problems. In the first one, a data set is modeled as point clouds in a D-dimensional space but concentrating near a d-dimensional manifold, where d is much smaller than D. She plans to exploit the geometric structures of the data sets to build low-dimensional representations of data and approximate functions on data. Function approximations in Euclidean spaces have been well studied; however, classical estimators converge to the true function extremely slowly in high dimensions. When data are concentrated near a d-dimensional manifold, or the function has low complexity, the PI aims at constructing estimators that converge to the true function at a faster rate depending on the intrinsic dimension d. The proposed approach is based on the PI's recent work on adaptive geometric approximations for intrinsically low-dimensional data, where a data-driven, fast and robust scheme was developed to construct low-dimensional geometric approximations of data. The second set of problems arise from imaging and signal processing where the goal is to recover a high-dimensional, sparse vector from its noisy low-frequency Fourier coefficients. It is related with super-resolution in imaging, as the missing high-frequency Fourier coefficients correspond to the high-resolution components of the vector. Many existing methods fail since some columns in the sensing matrix are highly correlated. The PI will utilize the structure of the sensing matrix, develop efficient algorithms and prove performance guarantees. A mathematical theory will be developed to explain the fundamental difficulty of super-resolution, as well as the resolution limit of superior subspace methods, such as MUSIC, ESPRIT, and the matrix pencil method.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1929568","Randomized Algorithms for Matrix Computations","DMS","COMPUTATIONAL MATHEMATICS","09/01/2018","03/28/2019","Per-Gunnar Martinsson","TX","University of Texas at Austin","Standard Grant","Leland Jameson","08/31/2020","$120,749.00","","pgm@ices.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271","9263","$0.00","This project will develop mathematical techniques for accelerating computational tasks such as simulating electromagnetic scattering,  medical imaging, extracting useful information from large datasets, machine learning, and many others. In all these computations, the step that tends to be the most time-consuming, and which therefore limits how large problems can be solved, concerns the manipulation of large square or rectangular arrays of numbers, called ""matrices"". Many of the matrices that arise in practical applications have redundancies, and can be compressed to enable them to be stored using less space. Using the compressed format, computations involving the matrix can also be greatly accelerated. The problems that will be addressed are deterministic in nature, but the algorithms that will be developed are probabilistic. It turns out that by exploiting certain mathematical properties of large ensembles of independent random numbers, one can build algorithms for compressing matrices that are much faster than traditional deterministic techniques. The new randomized algorithms can in theory fail, but the likelihood of failure can be shown to  be lower than 1 time out of 10,000,000,000 runs in typical applications. Randomized algorithms of this type have recently attracted much interest due to the fact that they perform  particularly well on emerging computing platforms such as mobile computing (where conserving energy is the key priority), computing using graphical processor units (where the vast numbers of computational cores create challenges), and distributed memory parallel computers. The methods also perform very well when applied  to massively large datasets that must be stored on hard drives, or on large server farms. The project will train one doctoral student, and will lead to the release of a publicly available software package that implements the methods that will be developed. <br/><br/>From a technical point of view, the objective of the project is to develop efficient algorithms for factorizing matrices and for solving large linear systems of algebraic equations. The algorithms will be based on randomized sampling, and will exploit remarkable mathematical properties of random matrices and random orthogonal projections. Such randomized algorithms require less communication  than traditional methods, which makes them particularly attractive for modern applications involving multicore processors, distributed computing, out-of-core computing, etc. Specifically, the project will address the following problems: (1) Computing full matrix factorizations (e.g. the so called ""column pivoted QR factorization"") which are core building blocks in scientific computing. Preliminary numerical experiments demonstrate speed-ups of close to an order of magnitude compared to state-of-the-art software packages. (2) Solving linear systems involving many unknowns and many equations. We expect to achieve substantial practical acceleration, and are cautiously optimistic about the possibility to develop solvers with substantially better asymptotic complexity than the cubic complexity achieved by standard techniques. (3) Developing randomized methods for accelerating computational simulations of phenomena such as electro-statics, composite materials, biochemical processes, slow fluid flows, Gaussian processes in 2 and 3 dimensions, etc. Technically, this will be achieved by developing randomized methods for compressing so called ""data-sparse"" or ""rank-structured"" matrices."
"1819101","The Discontinuous Petrov Galerkin Method with Optimal Test Functions for Compressible Flows and Ductile-to-Brittle Phase Transitions","DMS","COMPUTATIONAL MATHEMATICS","07/15/2018","07/12/2018","Leszek Demkowicz","TX","University of Texas at Austin","Standard Grant","Leland Jameson","06/30/2022","$250,000.00","","leszek@oden.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271","9263","$0.00","The project aims at a further development of the Discontinuous Petrov Galerkin (DPG) Finite Element (FE) method with optimal test functions introduced by Jay Gopalakrishnan and Leszek Demkowicz in 2009. The DPG methodology represents a breakthrough in the Finite Element simulations of challenging Engineering and Science processes. The proposed research directions are: the solution of 2D and 3D compressible flow problems, the modeling of ductile to brittle phase transitions using Phase Fields theories. The method will have a lasting impact on the construction of software for difficult applications requiring high accuracy. Application areas targeted in this project include aerospace (transonic flows) and high energy density electrical motors (insulation failure), building on collaborations with Boeing and the Navy.<br/><br/>The DPG method minimizes residuals in the dual norm corresponding to a specified test norm. Computation of the residual requires inversion of the Riesz operator in the test space. With the use of broken test spaces and localizable test norms, the inversion can be done element-wise using standard Galerkin and ""enriched"" spaces. With the error of inverting the Riesz operator controlled locally, i.e. on the element level, the method automatically guarantees discrete stability for any well-posed linear problem in a Hilbert setting, in the sense of the classic theory of closed operators. The methodology leads to uniform stability for singular perturbation problems and, being a minimization method, does not suffer from any preasymptotic instabilities. The residual is computed rather than estimated and provides a basis for automatic adaptivity. Optimality in the L2-norms does not preclude the Gibbs phenomenon and this project aims at extending the DPG technology to Banach spaces. The first focus area deals with a difficult classical subject, namely compressible Navier-Stokes equations with applications to flow around a three-dimensional wing model and its simplified model, the full potential equation. The second line of research aims at modeling ductile-to-brittle phase transitions in polymers using Phase Field theories, with applications to understanding damage and crack initiation in polymer insulation. In both application areas above, solutions experience strong boundary or/and internal layers. The proposed work includes both analysis and software development in a joint computational effort with Cracow University of Technology, Boeing, and collaborators at the University of Texas at Austin.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818847","Collaborative Research: Construction and Analysis of Numerical Methods for Stochastic Inverse Problems with Application to Coastal Hydrodynamics","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","07/26/2018","Clinton Dawson","TX","University of Texas at Austin","Standard Grant","Yuliya Gorb","07/31/2022","$100,000.00","","clint@ices.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271","9263","$0.00","As observed in past hurricanes such as Katrina (2005), Ike (2008), Sandy (2012), and the sequence of hurricanes over the 2017 season, flooding due to storm surge and rainfall causes tremendous damage to coastal communities. Preparing for future hurricane impacts requires the ability to predict characteristics of inland flooding due to surge, most importantly water levels, currents, and extent of inundation. Accurate predictions of surge require determining critical inputs to models related to the physical characteristics of coastal regions that are expensive to obtain and evolve in time. This research project focuses on quantifying and reducing uncertainties in these critical inputs using novel mathematical techniques to both extract information from existing data and aid in the design of future data collection efforts.<br/><br/>More specifically, this project focuses on the construction, analysis, and implementation of numerical methods for a stochastic inverse problem defined by the melding of observational data and high-fidelity mathematical models to perform scientific and engineering inference and prediction for complex physical systems. This research applies broadly to complex, time-evolving physical systems depending on high dimensional parameter spaces. Mathematical areas utilized in this research include computational measure theory, differential geometry, functional analysis, probability theory, and numerical analysis. Dissemination of results to the broader scientific community will be accomplished in part by the development and implementation of computational algorithms in public domain code that are applied to a state-of-the-art storm surge model.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1838576","Collaborative Proposal: Strong Stochastic Simulation of Stochastic Processes Theory and Applications","DMS","COMPUTATIONAL MATHEMATICS, CDS&E-MSS","06/01/2018","06/12/2018","Jose Blanchet","CA","Stanford University","Standard Grant","Leland Jameson","08/31/2020","$200,871.00","","jose.blanchet@stanford.edu","450 JANE STANFORD WAY","STANFORD","CA","943052004","6507232300","MPS","1271, 8069","9263","$0.00","High performance computing of continuous random structures arises in a large body of scientific and engineering investigations. For example, these structures are used in environmental models for floods in different geographical areas, which are subject to random measurement errors. They are also used in the prediction and mitigation planning of potential disasters. However, these random structures are impossible to capture in a computer without incurring bias, due to their continuous nature. This research project investigates a new framework for the numerical analysis of continuous random structures. It achieves stronger error control, compared to current state-of-the-art methods, at basically the same computational cost. If successful, the framework and algorithms to be investigated will facilitate analysis and performance evaluation of fundamental random structures of interests to a broad community of scientists and engineers. To enhance the broader impact, the Principal Investigators will train graduate students through research and integrate the results from this research into new graduate courses in scientific computing. <br/><br/>This project investigates a new Monte Carlo framework for continuous stochastic structures (such as differential equations and random fields). The main innovative feature of the framework is the ability to approximate a continuous random object by a fully simulatable (typically piece-wise constant) object with a uniform error bound in the path space with 100% certainty. The error bound is user-specified and can be sequentially refined. Research projects involve developing simulation algorithms for fundamental random structures of interests. These include: Gaussian random fields, Levy processes, fractional Brownian motion, max-stable fields, etc. The algorithms are scalable in the sense of being easily extendable to more complex models by applying the continuous mapping principle with quantifiable error analysis. An important aspect of the methodology is the connection established between Monte Carlo simulation and the theory of rough paths in the setting of stochastic analysis."
"1818867","Simulation and Numerical Analysis in Elastodynamics","DMS","COMPUTATIONAL MATHEMATICS","09/01/2018","07/10/2020","Francisco Sayas","DE","University of Delaware","Continuing Grant","Yuliya Gorb","08/31/2022","$325,000.00","","fjsayas@math.udel.edu","220 HULLIHEN HALL","NEWARK","DE","197160099","3028312136","MPS","1271","9150, 9263","$0.00","The numerical simulation of transient elastic waves has the overall goal of developing robust and reliable computational tools to handle the study of deformation and stress in solids. The results of this project could impact a wide range of applications, including inverse problems in geophysics (seismic imaging with applications in earthquake simulation and oil exploration), magnetic resonance elastography for medical applications, control of electromechanical systems (the use of solid deformation to control electric fields or viceversa), and fracture detection in solids. The understanding of the computational approximations to complex model equations describing the interaction of varied physical phenomena (solid deformation, electromagnetism, acoustic propagation, and thermal diffusion) is of great importance to assess the quality and validity of the proposed simulations.<br/><br/>The project focuses on the numerical analysis and computation of transient elastic waves, including their interaction with acoustic waves. The proposal addresses multiple physical models where elastodynamics is involved, with an emphasis on viscoelastic behavior, piezoelectric effects, and fully coupled thermoelasticity. The project proposes to unify and simplify the treatment, theoretical and numerical, of several of these models. The numerical approximation will be handled using Finite Element Methods and Hybridizable Discontinuous Galerkin schemes for the space variables, and high order time-stepping tools disguised as Convolution Quadrature methods. The expected outcomes of this proposed research range from stability and convergence analysis for the fully discrete methods to practical implementation in three dimensional geometries.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818924","High Order Multi-Scale Numerical Methods for All-Mach Number Flows","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","05/23/2018","Jing-Mei Qiu","DE","University of Delaware","Standard Grant","Yuliya Gorb","07/31/2022","$262,410.00","","jingqiu@udel.edu","220 HULLIHEN HALL","NEWARK","DE","197160099","3028312136","MPS","1271","9150, 9263","$0.00","The primary goal of this project is the design of highly accurate and multi-scale numerical methods for all-speed flow simulations. To the best of our knowledge, highly accurate multi-scale solvers for all-Mach number flows are still underdeveloped. The proposed work is expected to establish close connections on existing state-of-art computational tools for compressible flow (with shock capturing techniques) and incompressible flows (with projection and divergence cleaning techniques). Successful methodology developments for all-speed flow simulations will have a broad impact for a wide range of computational fluid dynamics (CFD)-related applications. The proposed research work in algorithm design and analysis will promote/benefit from the demands from CFD applications fields. Further impact comes from the multidisciplinary nature of the proposed research, publications, participation and organization of mini-symposium sections in conferences, as well as the training of students.<br/><br/>High order multi-scale solvers for all-Mach number flows are proposed. The PI seeks to develop a uniform framework to build up high order solvers that could effectively capture shocks without numerical oscillations for the compressible Euler system, and would successfully approximate the incompressible solutions of the system with proper divergence cleaning steps for low Mach flows without the need in resolving acoustic waves. In particular, the main focus would be finite difference schemes with weighted essentially non-oscillatory (WENO) reconstructions coupled with proper implicit-explicit (IMEX) Runge Kutta (RK) treatments with the following properties:  (1) the schemes can robustly capture shock fronts in the compressible regime when the Mach number is of order 1; (2) the schemes automatically become high order, stable and consistent solvers for the incompressible Euler system when the Mach number approaches 0; (3) the schemes are high order accurate in both space and in time both when the acoustic waves are well-resolved and are under-resolved. Along this direction, the PI develops a thorough plan in methodology development, stability and asymptotic preserving analysis, as well as extensive benchmarked tests for all-Mach number flows. Further extensions to the Navier-Stokes system with additional consideration of viscous terms and special focus on boundary conditions will be explored.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818945","Collaborative Research: Geometric Analysis and Computation for Generative Models","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","06/21/2018","Xiuyuan Cheng","NC","Duke University","Standard Grant","Yuliya Gorb","06/30/2022","$100,000.00","","xiuyuan.cheng@duke.edu","2200 W MAIN ST","DURHAM","NC","277054640","9196843030","MPS","1271","062Z, 9263","$0.00","Research in unsupervised learning and generative models is concerned with uncovering structure and relationships in data with the intent of being able to generate new, as yet unseen, examples of the data set. Generative models learn the distribution of a data set from finite samples and provide an efficient sampler of the approximated density, rather than relying on labels for supervision. These models are a powerful tool for analyzing large volume, high-dimensional data in an unsupervised way. While generative models are an active research topic in machine learning, many theoretical and computational questions for such models remain unclear. This collaborative research project will study generative models from a geometric perspective, focusing on both performance guarantees and efficient implementations. The ability to efficiently create new data points that are guaranteed to be similar to the existing data has important implications in a variety of applications, including medical data analysis and privacy, bioinformatics, modeling of image and audio signals, and general high-dimensional data analysis in which it is difficult to collect labeled data for supervised algorithms.<br/><br/>The ideas and approaches in this research project center around the techniques that have evolved in the manifold learning field over the past decade. These mathematical tools, in particular local neighborhood preserving maps, approximation analysis in terms of intrinsic dimensionality, and construction of global coordinate systems based upon local affinity, have natural applications in the study of generative models. The project is comprised of four fundamental questions that arise in the field: (a) What are the types of distributions that generative networks are capable of learning efficiently, and how does the intrinsic dimensionality of the distribution affect convergence? (b) How can non-parametric generative models be created for dimension-reduced representations that arise in manifold learning, and which only depend on the intrinsic geometry of the data? (c) How can efficiently-computed metrics be defined between high-dimensional distributions for use in assessing the validity of various generative models? (d) How can these metrics be used to examine the various paths generative models take through the parameter space while being trained, and what clusters of starting points give optimal generators? The project will focus on both mathematical and computational aspects of these problems, aiming at resolving fundamental questions about these tools that are widely used in various data analysis and signal processing applications in science and industry.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818642","Collaborative Research: Models, Algorithms, and Simulations for Two-Phase Ferrofluid Flows in Contact with a Solid Surface","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","07/27/2018","Xiaoming He","MO","Missouri University of Science and Technology","Standard Grant","Yuliya Gorb","07/31/2022","$160,000.00","Cheng Wang","hex@mst.edu","300 W 12TH ST","ROLLA","MO","654096506","5733414134","MPS","1271","9150, 9263","$0.00","Being controllable by applied magnetic fields, two-phase ferrofluid flows have found diverse applications in various science and engineering fields. Flows of two-phase ferrofluid mixtures usually involve the coupling of hydrodynamics, interface motion, intrinsic particle spins, magnetization field, and induced magnetic field. It is expected that the proposed research will not only lead to reliable well-posed models, efficient numerical algorithms for the two-phase ferrofluid system, but also extend the applicability of mathematical models, analyses and codes to various physical problems of current interest through numerical simulations.  The proposed research will produce efficient, optimally convergent, easily implemented, energy stable numerical algorithms, as well as publicly available finite element codes. It will provide ample and valuable opportunities for undergraduate and graduate students to receive multidisciplinary training in the areas of mathematical modeling, computational mathematics, and mechanical engineering, and to develop state-of-the-art mathematical models and numerical algorithms for science and engineering applications. Starting from this collaborative work, the investigators plan to disseminate the developed models, methods and software packages to more engineers and scientists for solving their realistic problems, present the research in professional conferences and colloquia, and organize special sessions/minisymposiums in domestic/international conferences for related works.<br/><br/><br/>The intellectual merit of this project lies in the challenge to develop suitable mathematical models and design efficient and accurate schemes for the highly nonlinear two-phase ferrofluid system, which couples free interfaces, hydrodynamics, magnetization field, induced magnetic field, and intrinsic particle spins. Very few efforts have been made to address the induced modeling/numerical challenges of the two-phase ferrofluid system due to the complicated nonlinear couplings among these constituents. The proposed models are thermodynamically consistent and thus preserve the energy dissipation laws. With strengths of the finite element methods in dealing with the complex boundary, the proposed numerical schemes are efficient, accurate, easily implemented, and energy stable with some discrete energy dissipation laws which have advantages of allowing the large time step and controlled error bound to capture the interfacial singularities accurately. In addition, the models, numerical algorithms and simulations will contribute to better understandings of various physical problems of practical interests, such as new materials based on ferro fluids.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818700","Advancing Fractional Combinatorial Optimization: Computation and Applications","DMS","COMPUTATIONAL MATHEMATICS","09/01/2018","07/20/2018","Andres Gomez","PA","University of Pittsburgh","Standard Grant","Leland Jameson","04/30/2021","$150,000.00","Oleg Prokopyev","gomezand@usc.edu","4200 FIFTH AVENUE","PITTSBURGH","PA","152600001","4126247400","MPS","1271","9263","$0.00","Single- and multiple-ratio fractional combinatorial optimization problems naturally arise in diverse application contexts when modeling trade-offs such as maximizing return/investment, maximizing profit/time, minimizing cost/time or minimizing wasted/used material.  For example, risk-adverse decision-makers are often interested in solutions that provide a good trade-off between the expected return and risk, which can be modeled naturally as the ratio function. Also, fractional objectives can be used for feature selection and clustering in data mining as well as for solving isoperimetric problems on graphs that can be applied for error-correcting codes and image segmentation. There are no adequate solution approaches for these classes of optimization problems if they involve integrality and/or combinatorial restrictions (constraints). Therefore, if successful, the proposed research will substantially enhance the ability to solve these hard classes of optimization problems and can lead to a more widespread use of single- and multiple-ratio fractional measures in existing and emerging applications.<br/><br/>The project's main goal is to develop computational approaches with the solid underlying theoretical foundation, that deliver provably good solutions and can be used to solve realistically sized instances of single- and multiple-ratio fractional combinatorial optimization problems. In order to do so, the investigators propose to systematically exploit the combinatorial structure of the feasible region and structural properties of the ratio functions to construct strong convex relaxations of the fractional combinatorial optimization problems. The investigators will also explore single- and multiple-ratio fractional combinatorial optimization problems under parameter uncertainty. The proposed research, unlike most of previous work in the related literature, does not enforce restrictive simplifying assumptions on either the combinatorial structure induced by the constraint set or the number of ratios. Furthermore, the research does not rely on assuming that the functions in the numerators and denominators of the ratios are affine. The proposed approaches draw ideas and will contribute to the literature of mathematical optimization, particularly conic, fractional and discrete optimization, combinatorics, and algebraic graph theory.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1760991","Seventh International Conference on Computational Harmonic Analysis","DMS","COMPUTATIONAL MATHEMATICS","01/01/2018","12/04/2017","Alexander Powell","TN","Vanderbilt University","Standard Grant","Leland Jameson","12/31/2018","$15,000.00","Emanuel Papadakis","alexander.m.powell@vanderbilt.edu","110 21ST AVE S","NASHVILLE","TN","372032416","6153222631","MPS","1271","7556, 9263","$0.00","The Seventh International Conference on Computational Harmonic Analysis (ICCHA7) will take place at Vanderbilt University in Nashville, TN during May 14-18, 2018, in conjunction with the 33rd Annual Shanks Conference and Lecture. The conference website https://my.vanderbilt.edu/iccha7 contains a list of the conference plenary speakers and other conference information.  Computational harmonic analysis is a fundamental tool for analyzing and representing information, and is especially motivated by modern applications where data has complex structure and massively high dimension.  Applications of computational harmonic analysis include many areas of national technological interest such as data science, neural networks and artificial intelligence, medical imaging, radar signal processing, coding theory, and quantum computing.  The conference will discuss the most recent theoretical breakthroughs, practical advances, and emerging directions in computational harmonic analysis.  The plenary speakers include a diverse assortment of experts, and female and early career scientists are well-represented.  An important broader impact of the conference is to support the participation of students, early career scientists, and underrepresented minorities; the conference will make a particular effort to invite and provide travel support to members of these groups.  Travel support will be strongly prioritized to those without other sources of travel funding, so as to make the conference accessible those who would not otherwise be able to attend.  This will contribute to expanding and diversifying the nation's talent pool and workforce in the mathematical sciences by contributing to the training of underrepresented groups in STEM fields.<br/><br/>Specific technical topics addressed at the conference will include, but are not limited to: compressed sensing, phase retrieval, convolutional neural networks, wavelets and multiscale transforms, frame theory, graph-based signal processing, time-frequency analysis, analog-to-digital conversion, signal and image processing, quantum computation, and mathematical learning theory.  A main intellectual merit of the conference is to provide a venue to disseminate recent advances in computational harmonic analysis.  The conference will consist of plenary talks, as well as shorter talks and minisymposia in parallel sessions.  There will be numerous opportunities for mathematical interaction and collaboration among the participants.  The conference will provide an interdisciplinary link between mathematicians, engineers, and scientists from other fields who are working on computational harmonic analysis."
"1819059","Energetic Phase-Field Methods and Biological Cell Modeling","DMS","COMPUTATIONAL MATHEMATICS","08/15/2018","08/01/2018","Xiaoqiang Wang","FL","Florida State University","Standard Grant","Yuliya Gorb","07/31/2021","$99,999.00","","wwang3@fsu.edu","874 TRADITIONS WAY","TALLAHASSEE","FL","323060001","8506445260","MPS","1271","9263","$0.00","The phase field concept has recently been popularized by many researchers and is well on its way to becoming one of the methods of choice for studying many scientific and engineering problems. The specific settings the investigator focuses on in this project are its applications in cell biology, e.g., cell blebbing and cytokinesis, epithelial morphogenesis. The modeling, analytical, and computational issues are very complex and challenging. The investigator's prior research experience in studying phase field methods and its applications in biology makes him very well prepared to conduct the project. The proposed investigation will offer new insights into a number of outstanding theoretical issues leading to innovation in computational algorithms for many important applications and a better understanding of a number of fundamental biological processes. This project will offer a unique educational opportunity for both graduate and undergraduate students with interests in applied/computational mathematics, biology, and engineering by having them participate in an interdisciplinary research program that combines mathematics, biology, computer science and engineering. The investigator will provide research experience for underrepresented undergraduate students through ""FSU Teach"" and ""Directed Individual Studies"" programs. Each undergraduate will participate in each and every aspect of the research project. Because they will be teaching students at the high- and middle-school levels, involving them in the proposed project will produce a broader impact on training scientists of the next generation. The investigator will actively disseminate his research results and software not only to researchers in the area but also to a much broader community through publications, attending meetings, maintaining an informative web-site. The investigator will make electronic projection slides and movies from the numerical simulations to present in local elementary and middle schools to stimulate interest in science among younger students.<br/><br/>During recent years, the energetic phase field approach has emerged as a successful modeling and simulation method having many advantages in the study of micro structure evolution, including but not limited to solidification, grain growth and coarsening, thin film micro structure, crack propagation, crystal growth, dislocation-solute interactions, dislocation dynamics, and electromigration. The idea of phase field methods is to introduce a set of phase field variables to implicitly track the moving surfaces of micro structures, which can be very complex and nonlinear. In the past few years, the investigator and his collaborators have successfully applied phase field methods to study biological micro structures, especially cell membranes. These studies also extended the theory of phase field methods. A series of efforts have been carried out on modeling, numerical methods and theoretical analysis. The proposed project is mainly concerned with further studies on phase field methods and the broadening of applications for the cell biology; phase field methods and related concepts can be used as a basis for more convenient and/or efficient treatments. In the next few years, the investigator will investigate some theoretical and algorithmic problems on phase field methods that still remained unsolved or are partly unsolved today. Those new algorithms have the potential to dramatically lower the computational cost and thus make phase field method a state-of-art technique for solving complex biology problems. The investigator will also perform phase field modeling on membrane interaction with membrane proteins, acto-myosin driven cell blebbing, cell cytokinesis during mitosis, and epithelial morphogenesis. Those are very challenging problems. Phase field methods have the advantages in handling those problems compared to surface tracking or surface evolving methods, especially for cells with complex shape changes. The investigator's numerical simulations together with his collaborator's lab experiments will help us gain insight into the principles behind various biological phenomena.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1720377","Approximation of Functions with Parameter-Dependent or Stochastic Shock Locations Arising from Hyperbolic Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","08/01/2018","Gerrit Welper","CA","University of Southern California","Standard Grant","miao-jung ou","01/31/2019","$60,000.00","","gerrit.welper@ucf.edu","3720 S FLOWER ST FL 3","LOS ANGELES","CA","900074304","2137407762","MPS","1271","1271, 9263","$0.00","Many mathematical models of scientific or engineering problems are influenced by design parameters and random parameters. An example is the modeling of flow around an airfoil. A design parameter is its shape, and random parameters include, for example, perturbations in the air before a plane travels through it. These parameters pose some natural questions for engineers and the mathematical models they use: What is the best possible shape? Can we compute safety tolerances of the wing and limit the probability of failure? With increasing computational power, such questions attracted considerable attention in recent years. However, for physical phenomena with sharp transitions, only brute-force approaches are available, which quickly become challenging even with advanced computer hardware. In the wing example, one such transition is the sonic boom, a rapid change in the pressure around the wing at high speed. This project aims to develop new algorithms that can handle such rapid transitions in parametric models, far more efficiently than currently. The method under development will be applicable to a range of other engineering problems as well, such as environmental questions in groundwater flows or the simulation of bio-molecules.<br/><br/>The goal of the project is the development of new approximation schemes for functions with parameter-dependent jumps or kinks, motivated by solutions of parametric and stochastic hyperbolic partial differential equations. These singularities pose serious challenges by deteriorating the convergence rates for established methods such as reduced basis methods, proper orthogonal decomposition, or polynomial chaos expansions. Recent work offers a new method to approximate functions with jump discontinuities and achieves super-polynomial convergence rates for many problems. It serves as a proof of principle that high-order methods are advantageous, but it needs to be developed further to make it practical: In most realistic problems, jumps not only move but they also interact, and parameter spaces are typically high-dimensional. Addressing these issues is the goal of this project. The new algorithms will be tested numerically, in particular regarding the convergence rates that can be achieved. In addition, the investigator plans to prove convergence rates for model classes of parametric functions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818820","Fast Algorithms for Special Functions","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","05/25/2021","James Bremer","CA","University of California-Davis","Standard Grant","Leland Jameson","12/31/2021","$150,000.00","","bremer@math.ucdavis.edu","1850 RESEARCH PARK DR, STE 300","DAVIS","CA","956186153","5307547700","MPS","1271","9263","$0.00","The importance of the numerical simulation of physical phenomena by computers cannot be overstated.  Such computations have become an essential tool both in scientific research and in industrial applications.  The computer codes for these simulations are usually constructed from basic building blocks, including algorithms that carry out calculations involving so-called ""special functions."" Broadly speaking, special functions are nothing more than functions which cannot be expressed in terms of elementary operations (e.g., addition, subtraction, and the computation of square roots) and which arise frequently enough in mathematical calculations to warrant a name.  This project seeks to build more efficient and comprehensive libraries for a class of special functions which are solutions of  equations known as second order differential equations.  One of the principal uses of these special functions is in representing the solutions of much more complicated equations which model physical phenomena.<br/><br/>To be more precise, this project seeks to develop fast algorithms for families of special function satisfying second order differential equations whose coefficients are nonoscillatory.  There are no viable O(1) algorithms for evaluating many such families.  Moreover, only in a few cases are asymptotically optimal algorithms for the corresponding special function transforms available, and many of those are not readily applicable in parallel computing environments.  This is unfortunate given the many applications of extremely large-scale special function transforms, especially large-scale spherical harmonic transforms, which are widely used in astronomy and geophysics.  The methods to be developed in this project are based on the fact that essentially all second order differential equations with nonoscillatory coefficients admit nonoscillatory phase functions. This not only provides a mechanism for the O(1) evaluation of special functions defined by second order differential equations, it also implies that the associated special function transforms are Fourier integral operators.  Such operators can be applied in asymptotically optimal time by combining modern butterfly algorithms with algorithms for the O(1) evaluation of special functions.  One of the key advantages of this methodology is that it is well-suited to parallel computing environments and large-scale computations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818438","Study on Localized Exponential Time Differencing Methods for Evolution Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","06/06/2018","Lili Ju","SC","University of South Carolina at Columbia","Standard Grant","Leland Jameson","07/31/2021","$150,000.00","","ju@math.sc.edu","1600 HAMPTON ST # 414","COLUMBIA","SC","292083403","8037777093","MPS","1271","9150, 9263","$0.00","Many important physical phenomena are modeled by semilinear or fully nonlinear evolution partial differential equations. The overall goal of the project is to enhance the efficiency and scalability of exponential integrator-based methods for solving these equations by designing and analyzing highly scalable localized exponential time differencing methods and to apply them to numerically simulate and investigate a wide range of related application problems in science and engineering. The proposed work is of practical interest with significant influences as the developed methods are highly scalable on modern supercomputer systems, and can serve as an efficient, accurate and stable computational tool for simulations of these stiff problems. Direct and transformative innovations resulting from the project will greatly improve modeling and computational capabilities for many fields, such as design of new materials and oil recovery from fractured oil reservoirs. In addition, this project will also offer a unique educational opportunity for graduate students with interests in computational and applied mathematics by having them participate in an interdisciplinary research environment.<br/><br/>Direct parallelization of global exponential time differencing methods is often very hard to be scalable on massively distributed systems due to the intensive data communications needed by fast Fourier transform or by Krylov subspace-based calculations for products of matrix exponentials and vectors. On the other hand, domain decomposition approaches have been well established for many classic time integration methods, but not enough attention and work have been devoted to exponential integrators. This project involves a thorough study on the development and analysis of iterative and noniterative localized exponential time differencing methods based on domain decomposition, with a family of time-dependent scalar diffusion equations as the prototype problem. The PI will also apply the developed methods to study some phase field models for multi-component and multi-phase systems arising from materials science and petroleum engineering. This project would offer new insights through numerical investigations to the understanding of the macroscopic properties and reliability of alloys and the physical phenomena (such as liquid droplets, gas bubbles, and capillary pressure) of hydrocarbon fluids.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1822316","Recent Advances in Numerical Wave Propagation","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","08/02/2018","Yassine Boubendir","NJ","New Jersey Institute of Technology","Standard Grant","Victor Roytburd","07/31/2019","$19,999.00","Lou Kondic, Cyrill Muratov","boubendi@njit.edu","323 DR MARTIN LUTHER KING JR BLV","NEWARK","NJ","071021824","9735965275","MPS","1271","7556, 9263","$0.00","FACM 2018 represents the fifteen meeting in a series on ""Frontiers in Applied and Computational Mathematics""  at the New Jersey Institute of Technology and will focus on ""Recent Advances in Numerical Wave Propagation"".  Wave scattering problems are important in a variety of engineering and industrial applications such as the design of antennas and stealth aircraft; imaging and tomography; electromagnetic compatibility; and many others in particular in the aeronautic industry.  This workshop is a great occasion for researchers in this field to  present their most recent and effective work on industrial applications. The diversity of the methods presented in this meeting and its medium size will provide a unique opportunity to discuss limitations and advantages of each technique.  It is therefore expected that  the proposed 2018  conference will permit the development of  new collaborations in order to efficiently deal with difficult wave propagation problems. Substantial funds will be devoted to support the participation of graduate students, postdoctoral fellows, beginning faculty, and under-represented minorities. For students and postdocs in particular, FACM 2018 conference will provide a major learning and networking experience that will help them to develop their research and career paths. All plenary talks will be open to the public; see  https://m.njit.edu/Events/FACM18/ <br/><br/><br/>The FACM 2018 conference will be a two and a half day single-track session comprised of plenary lectures and standard workshop presentations in the field of numerical wave propagation problems.  Experts mainly on finite and boundary elements methods,  high frequency techniques, and domain decomposition algorithms will  present their most recent contributions.  The plenary presentations in the workshop will overview the state-of-the-art of the numerical techniques currently used to deal with wave propagation problems. This is an ideal occasion  for the participants to develop new methodologies for the ongoing challenging high-frequency problems in complex media, as well as new algorithms that couple numerical techniques using iterative solvers and high performance computing tools.  In addition, graduate students, postdocs, and junior researchers will be introduced to difficult problems motivated by industrial applications, and to the most widely used numerical solvers for wave propagation problems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1833601","SIAM TX-LA Section Meeting","DMS","COMPUTATIONAL MATHEMATICS","08/15/2018","08/08/2018","Robert Lipton","LA","Louisiana State University","Standard Grant","Leland Jameson","07/31/2019","$20,000.00","","lipton@lsu.edu","202 HIMES HALL","BATON ROUGE","LA","708030001","2255782760","MPS","1271","7556, 9150, 9263","$0.00","Basic and engineering science can deliver game changing advances in the way we live and the disciplines of computational and applied mathematics are increasingly central to these developments. The Texas and Louisiana SIAM Section spans a geographical region including 13 Universities and several Medical and Industrial Research Centers. Motivated by this exciting synergy the Society for Industrial and Applied Mathematics Texas-Louisiana Section Meeting will be held from 10/5/2018 through 10/7/2018 at Louisiana State University in Baton Rouge Louisiana. The Meeting  offers a special opportunity for increasing diversity and breadth of participation by actively engaging a much broader base of younger applied mathematicians than in more standard symposium formats. This symposium format allows undergraduate students, graduate students and young investigators to directly interact with the greater research community on interdisciplinary problems coming from the frontiers of science and applied mathematics. This feature increases diversity and full participation of women, persons with disabilities, and underrepresented minorities in STEM fields. It exposes undergraduate students, graduate students, and early career applied mathematicians to contemporary and fundamental theoretical problems challenging science; enabling future breakthroughs through interdisciplinary collaboration. One of the outcomes of this Meeting to provide a unique and valuable experience in the research education of next the generation of investigators and educators. This Meeting is intended to foster collaboration and synergy between the applied mathematics community and the basic and engineering science community and to facilitate interaction and collaboration between the Society for Industrial and Applied Mathematics (SIAM) and the Universities and Research Centers in the Texas - Louisiana region. <br/><br/>The scientific goals of the Society for Industrial and Applied Mathematics Texas-Louisiana Section Meeting are:  To foster new scientific collaborations between applied and computational mathematicians and researchers in the basic and engineering sciences in order to address contemporary problems at the frontiers of science. Mini symposia include Mathematics in Gulf of Mexico offshore oil and gas production, Modeling, analysis, and computation in mathematical biology, Computational methods for waves in complex media, High-order accurate numerical methods for multi-physics problems, Numerical PDE/ODE and high performance computing applications, Mathematics in oil and gas exploration and production, Spectral theory of differential operators, Multiscale methods and uncertainty quantification for porous media, Numerical approximation of fractional differential equations, Mathematical and computational aspects of fracture, Nonlinear partial differential equations and applications, Numerical Geometric PDE, and Nonlinear modeling of disease dynamics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1834686","A High Order Discontinuous Galerkin Multi-Scale Approach for Kinetic-Hydrodynamic Simulations","DMS","COMPUTATIONAL MATHEMATICS","01/16/2018","04/26/2018","Jing-Mei Qiu","DE","University of Delaware","Standard Grant","Leland Jameson","08/31/2019","$137,612.00","","jingqiu@udel.edu","220 HULLIHEN HALL","NEWARK","DE","197160099","3028312136","MPS","1271","7237, 9263","$0.00","This research project will develop novel numerical methods for simulation of the dynamics of rarefied gas.  Compared with the widely used Monte Carlo approach, the algorithm under development will be able to more accurately capture complicated solution structures in long-time simulations. Moreover, physically conserved quantities such as mass, momentum, and energy can be exactly preserved at the discrete level. The new algorithm also has the potential to be extended to a broader class of applications such as plasma physics, astrophysics, and semi-conductor device simulation.  Students will be trained through involvement in the research project.<br/><br/>This project aims to develop a very high order mesh-based multi-scale numerical approach to modeling rarified gas dynamics between the kinetic and hydrodynamic regimes. The approach is based on the so-called micro-macro formulation of the kinetic equation, which involves a natural decomposition of the problem into equilibrium and non-equilibrium parts. The high order spatial accuracy is achieved by a nodal discontinuous Galerkin (DG) finite element approach, and the high order temporal accuracy is achieved by globally stiffly accurate implicit-explicit Runge-Kutta methods.  Due to deliberate design and considerations of the hydrodynamic asymptotics, the scheme under development becomes a DG method with explicit RK time discretizations for the Euler system in the zero limit of the Knudsen number, and a local DG discretization of the Navier-Stokes equations for a simplified BGK collision operator in a formal asymptotic analysis. Such a local DG method is similar in spirit to classical approaches based on a mixed formulation of the equations. The new scheme will be tested on problems at kinetic-hydrodynamic scales and compared with the results from the simplified BGK model, its ellipsoidal statistical (ES-BGK) extension, as well as with results from the macroscopic hydrodynamic models. The project will also study numerically the boundary layer for kinetic simulations when a diffusive hydrodynamic limit is considered."
"1821211","Data-Driven Stochastic Model Reduction and Its Applications in Data Assimilation","DMS","COMPUTATIONAL MATHEMATICS, CDS&E-MSS","07/01/2018","06/29/2020","Fei Lu","MD","Johns Hopkins University","Continuing Grant","Christopher Stark","11/30/2021","$160,142.00","","flu15@jhu.edu","3400 N CHARLES ST","BALTIMORE","MD","212182608","4439971898","MPS","1271, 8069","062Z, 9263","$0.00","With data routinely available, many applications in science and engineering call for timely and accurate predictions that are constantly updated. In data assimilation, such predictions are made by combining data with mathematical dynamical models. To quantify the uncertainty in predictions, the dynamical models need to be repeatedly solved for many initial conditions in a timely manner. This rules out the use of first-principles dynamical models that are computationally expensive and time-consuming to solve, and prompts the need to construct effective statistical-dynamical reduced models. This project will address this issue by developing data-informed stochastic reduced models based on theories and tools in statistical inference, stochastic processes, dynamical systems, and partial differential equations. The research lies at the foundation of data-informed computational modeling and simulation, and aims at developing new mathematical and statistical theories and tools to address the challenges in data-informed predictive modeling of complex systems. The research plan is complemented by educational objectives to prepare and train students through interdisciplinary research. <br/><br/>The goal of this project is to develop and analyze efficient algorithms to construct statistically-dynamically effective stochastic reduced models from data for complex systems, and to obtain timely predictions through data assimilation using these reduced models. The investigator plans to infer discrete-time non-Markovian reduced models from data by (i) parametrizing projections of invariant manifolds of dissipative systems, and (ii) approximating the effects of the unresolved variables on the resolved variables by nonparametric inference methods for general unknown systems. The investigator also plans to develop novel data assimilation methods for these non-Markovian reduced models and apply these methods to address the grand challenge of model reduction from noisy partial data. The work is expected to have applications in climate modeling, geophysics, fluid mechanics, and other data-informed computational modeling problems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1720146","Algorithms for Arithmetic Groups","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","07/28/2018","Alexander Hulpke","CO","Colorado State University","Standard Grant","Leland Jameson","07/31/2021","$79,957.00","","hulpke@colostate.edu","601 S HOWES ST","FORT COLLINS","CO","805212807","9704916355","MPS","1271","9263","$0.00","The objects, called arithmetic groups, considered in this project are  sets of matrices (representing symmetries of a space) whose entries can be considered as integral coordinates in a geometrical object. They lie at the intersection of Algebra, Geometry and Number Theory.  If a number of such matrices are given, we consider the subset that can be formed by combining these matrices that is applying the symmetries in turn.  It is called the subgroup (generated by the matrices).  A natural question now arises on whether finitely many translated copies of such a given subgroup amount to the whole set, in this case the subgroup is called arithmetic. This question has come up in many concrete examples brought up by researchers in number theory or geometry but so far the only solution approach have been ad-hoc methods for small cases.  The PI will design new algorithms for answering this question on a computer and provide an open-source implementation of this algorithm.  The project will also train a graduate student in the development of mathematical software.<br/><br/>The PI will develop new algorithms for calculations with classes of arithmetic groups, in particular developing methods that may determine whether a subgroup given by generating matrices is itself arithmetic. Practical implementations of these algorithms will be made available as a package for the computer algebra system GAP.  By utilizing state-of-the art techniques for finite matrix groups, developed only in the last years, this project will make significant progress on algorithmic questions for infinite integral matrix groups, extending current methods that have been mostly restricted to the case of finite groups.  The approach envisioned will intermesh calculations with finitely presented groups and with matrix groups in a novel way. Several subtasks require the development of new algorithms for finite groups, as well as for coset enumeration, and thus contribute to the algorithmic theory of finite and finitely presented groups.  The software developed as part of the project will be of use to investigators in the many areas encountering arithmetic groups -- geometry, number theory, theoretical physics, and others.  The project will contribute to the development of the open-source computer algebra system GAP (and thus also to the system SAGE) that is used by a multitude of researchers world-wide, has been cited in over 2000 refereed publications, and also has seen use as a tool in undergraduate abstract algebra classes.  Integrating research and education this project will contribute to the training of a graduate student in developing mathematical software and utilizing standard open-source software development tools.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818726","Collaborative Research: Stochastic Methods for Complex Systems","DMS","COMPUTATIONAL MATHEMATICS","08/01/2018","07/26/2018","David Aristoff","CO","Colorado State University","Standard Grant","Leland Jameson","07/31/2021","$99,970.00","","aristoff@rams.colostate.edu","601 S HOWES ST","FORT COLLINS","CO","805212807","9704916355","MPS","1271","9263","$0.00","This project addresses computational challenges in materials science, chemistry, uncertainty quantification, and related fields.  Quantities of interest such as chemical reaction rates, strength of alloys, and more, can be estimated using a common mathematical modeling framework that computes mean values and provides quantification of the variance about the means.  Estimating these quantities by computer simulation can be particularly challenging when the property that one wishes to study is rare and many repeated computer simulations would be required to estimate the mean value and the variance.  While this challenge is somewhat alleviated by growth in computing power, some simulations, including chemical reaction rates, cannot be addressed via brute force computation.  Rather than rely on raw computing power, the investigators intend to develop novel computer algorithms and approximations that will allow for more efficient and more accurate predictions.  This includes the use of interacting copies of mathematical models, which communicate information between one another, resulting in higher quality estimates.  These algorithms and approximations will allow more faithful prediction of quantities of interest and access to bigger models (such as larger, more complicated molecules).  Mathematically the project will provide a rigorous understanding of the computer algorithms, providing confidence to scientists in a variety of fields. <br/> <br/>Multiscale distributions appear in a variety of applications, including materials science, chemistry, and uncertainty quantification.  Given efficient sampling strategies, one can compute a variety of quantities of interest, including ensemble averages, mean first passage times, and probabilities of rare events.  However, multiscale distributions in high number of dimensions are particularly challenging to sample.  One example is the Boltzmann distribution induced by an energy landscape containing superbasins.  Such a landscape features clusters of local minima that correspond to close groupings of modes in the distribution.  This project will investigate four sampling algorithms: weighted ensemble sampling, parallel replica dynamics, local entropy smoothing, and piecewise deterministic Markov processes.  Weighted ensemble sampling partitions state space into bins and then elects to sample within those bins in an optimal way.  The project will investigate the choice of the sample allocation strategy and consider both finite and infinite system size limits for the method.  Parallel replica dynamics also involves using an ensemble of samples, but, in contrast to weighted ensemble, it uses the replicas to efficiently find first exits out of one metastable region and into another.  Local entropy smoothing removes the superbasin features of the energy landscape by performing local ensemble sampling and averaging.  Finally, the investigators will use piecewise deterministic Markov processes to perform rejection free sampling without requiring estimates of gradients.  These algorithms will be rigorously analyzed, and they will be tested on a variety of realistic high-dimensional problems including chemical reaction networks and stochastic molecular dynamics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818882","Stable and Convergent Computational Algorithms for Current Density Imaging","DMS","COMPUTATIONAL MATHEMATICS","08/15/2018","08/08/2018","Alexandre Timonov","SC","University of South Carolina at Columbia","Standard Grant","Yuliya Gorb","07/31/2021","$59,997.00","","altim@pdmi.ras.ru","Sponsored Awards Management","COLUMBIA","SC","292080001","8037777093","MPS","1271","9150, 9263","$0.00","Coupling together two distinct physical fields in medical and geophysical imaging is capable of enhancing both the space and contrast resolution of imaging modalities. This project concerns one of such a modality - Current Density Imaging (CDI) that couples the magnetic and radio-frequency electromagnetic fields used in Magnetic Resonance Imaging (MRI) with the electric field used in Electrical Impedance Tomography (EIT). Such a coupling is resulted in images of the electrical conductivity with significantly higher quality and accuracy than those obtained by the routine medical imaging modalities.  The general aim of this project is to develop the computationally efficient and robust algorithms for CDI.<br/> <br/>The proposed research is in the field of coupled physics (hybrid) inverse problems whose distinctive feature is utilizing the interior data available in new imaging modalities in order to reconstruct material parameters of an object to be investigated. Speaking about the possible applications of such inverse problems, it should be particularly emphasized medical diagnostics and marine controlled source electromagnetic sounding due to their importance for early detection of cancer, minimizing the rate of false diagnoses, more efficient treatment of diseases, etc., and for geophysical exploration of hydrocarbon deposits on a shelf. The innovation of this project is that it is concerned with the development of computational tools for CDI by utilizing an initial boundary value problem for the weighted mean curvature flow equation. In order to achieve the general aim, the principal investigator will: (1) analyze the level set formulation of motion by the weighted mean curvature associated with the Dirichlet problem for the weighted 1-Laplacian, which is considered as a mathematical model of CDI, (2) develop the stable and convergent computational algorithms, and (3) conduct the numerical convergence study in order to demonstrate in numerical experiments the effectiveness of computational algorithms and quality of reconstruction. The approach developed in this project is expected to advance understanding of the geometrical features of CDI. One undergraduate student will be involved in the project and trained in numerical methods for the inverse problems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819012","Numerical Methods and Analysis for Multiscale Kinetic Equations with Uncertainties","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","11/09/2018","Shi Jin","WI","University of Wisconsin-Madison","Continuing Grant","Leland Jameson","08/31/2018","$36,983.00","","shijin-m@sjtu.edu.cn","21 North Park Street","MADISON","WI","537151218","6082623822","MPS","1271","9263","$0.00","Kinetic models provide the bridges between microscopic and macroscopic descriptions for physical systems; they have a wide range of applications, including astronautics, nuclear engineering, plasma physics, and semiconductor device modeling. These models often involve multiple time and spatial scales, which pose tremendous difficulties in numerical simulations.  Moreover, since kinetic models arise from approximations, there are intrinsic uncertainties in the equations employed and the data (initial conditions and boundary values) used.  This project aims to develop efficient numerical methods and to conduct analysis for multiscale and uncertain kinetic equations.  The questions under study concern fundamental issues in scientific and engineering computation in the modern age -- multiscale modeling and simulation and uncertainty quantification. Some of the research results are expected to provide excellent additions for graduate courses in applied mathematics and scientific computing, thus contributing to training of the future generation of researchers in modern applied mathematics and scientific computing.<br/><br/>The project aims to develop and analyze numerical methods for multiscale kinetic equations with uncertainties. The work addresses the numerical challenges of multiple time and spatial scales as well as intrinsic model uncertainties in collision kernels, scattering coefficients, initial and boundary data, forcing and source terms, etc. The investigator plans to tackle these numerical challenges via several computational and analytical tools: asymptotic-preserving schemes to deal with multiple scales; polynomial chaos expansion and stochastic Galerkin (and other non-intrusive) methods for the random uncertainties; and hypocoercivity theory to study the regularity, stability, sensitivity, and long-time behavior of these methods. The hypocoercivity analysis provides new numerical analysis tools to study a wide class of physically important nonlinear partial differential equations in mathematical physics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1817603","Numerical Methods for Parametric Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","05/31/2018","Ronald DeVore","TX","Texas A&M University","Standard Grant","Leland Jameson","06/30/2021","$369,192.00","Guergana Petrova","rdevore@math.tamu.edu","400 Harvey Mitchell Pkwy South","College Station","TX","778454375","9798626777","MPS","1271","9263","$0.00","One of the most significant scientific challenges of this century is the accurate description and computation of complex processes such as climate change, contaminant flow, genomics, and even social media and finance. While one can create a mathematical model for these processes, the large number of parameters in the model inhibits the use of traditional computational tools for fast and reliable predictions. In addition, there is the question of the efficacy of the mathematical model. The proposed research puts forward new mathematical ideas, based primarily on model reduction, to determine the importance of the various parameters and derive simpler models that still faithfully describe the underlying process. This, in turn, leads to more accurate and less costly computational models that can be implemented within today's existing  computing resources.  The project also investigates how to quantify uncertainty in both the model and the parameters from data observations of the process.<br/><br/>This project investigates three demanding computational tasks in parametric partial differential equations (PDEs). The first of these, called the forward problem, seeks the creation of fast and accurate online solvers for the PDE when given a parameter query. Such online solvers are used in a myriad of applications that seek to optimize performance through parameter selection. The second seeks optimal methods to compute the state of the PDE from observational data. Related to this is the third problem of estimating the parameters of the PDE from observational data. Because of the large number of parameters, traditional numerical methods for such high dimensional problems face the so-called ""curse of dimensionality"", i.e., they cannot obtain the desired accuracy of computation in a reasonable computational time. The proposed research circumvents this difficulty by developing novel methods of model reduction based on sparsity ad highly nonlinear approximation such as n-term dictionary approximation. Foundational results will also be established for inverse parameter estimation that prove Lipschitz smoothness for the forward and inverse maps under minimal smoothness conditions on the parameters. These foundational results are then coupled with reduced modeling to create numerical methods for parameter estimation and model verification.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1748357","The Ninth Annual Graduate Student Mini-conference in Computational Mathematics","DMS","COMPUTATIONAL MATHEMATICS","01/01/2018","11/07/2017","Zhu Wang","SC","University of South Carolina at Columbia","Standard Grant","Leland Jameson","12/31/2018","$7,280.00","Lili Ju","wangzhu@math.sc.edu","Sponsored Awards Management","COLUMBIA","SC","292080001","8037777093","MPS","1271","7556, 9150, 9263","$0.00","This awards supports ""The Ninth Annual Graduate Student Mini-conference in Computational Mathematics"", held at University of South Carolina at its Columbia campus on February 17-18, 2018. The conference webpage is at http://imi.cas.sc.edu/events/ninth-annual-graduate-student-mini-conference-computational-mathematics/. The conference will promote the progress of science by bringing together a wide group of students and researchers working at the frontier of computational mathematics. Topics include recent advances in the theory and implementation of numerical solutions to partial differential equation models for, but not limited to, materials science, turbulence, biomedical flows, climate simulation, and data rich phenomena. The conference series has established a unique role as a comfortable forum for culturally diverse graduate students and recent Ph.D.s to present their work, learn of recent advances, form collaborations, and network to advance their career opportunities. The Ninth Annual Graduate Student Mini-conference will continue this tradition. The conference organizers are committed to supporting the participation of graduate students, recent Ph.D.s, and researchers from underrepresented groups. <br/><br/>The organizing committee anticipates approximately 55 participants in attendance, to include 1 senior and 1 junior plenary speakers, 30 graduate students (10 from USC), and their advisors (5 from USC). The conference consists of 2 forty-five-minute-long plenary talks, approximately 16 fifteen-minute-long contributed talks, and 1 two-hour-long discussion session. In particular, one plenary talk will be given by a senior computational scientist from Argonne National Laboratory, the other will be presented by a junior postdoc fellow at USC; all the contributed talks will be given by graduate students, and the discussion session will focus on the career development for graduate students and postdocs. The student speakers will be selected from attendees based on their CVs and by consulting with their advisors about their research achievements."
"1818666","Collaborative Research: Structure Preserving Numerical Methods for Hyperbolic Balance Laws with Applications to Shallow Water and Atmospheric Models","DMS","COMPUTATIONAL MATHEMATICS","09/01/2018","08/09/2019","Alexander Kurganov","LA","Tulane University","Standard Grant","Leland Jameson","06/30/2019","$0.00","","kurganov@math.tulane.edu","6823 ST CHARLES AVENUE","NEW ORLEANS","LA","701185698","5048654000","MPS","1271","9150, 9263","$0.00","This project will significantly contribute toward development of computational methods for shallow water and related models and will provide considerably more powerful tools for studying a variety of water waves and atmospheric phenomena. Special attention will be paid to applications arising in oceanography, atmospheric sciences, hydraulic, coastal, civil engineering, in which rapid changes in the bottom topography, Coriolis forces, friction, multiscale regimes, and uncertain phenomena factor heavily. The studied problems will include shallow water flows in multi-connected river channel systems, tsunami wave propagation and low Froude regime shallow water models, dynamics models of tropical cyclones and clouds with uncertain data.The newly developed tools may have a great potential in designing coastal protection systems and investigating the effects of sediment transport on shelf drilling platforms as well as contributing to a better prediction of tropical cyclones trajectories and tsunami wave propagation and on-shore arrival.<br/><br/>The project focuses on development of new structure preserving numerical methods for hyperbolic balance laws with applications to shallow water equations and related models. Shallow water models are systems of time-dependent partial differential equations (PDEs) that are derived using physical properties such as conservation of mass and momentum, and hydrostatic or barotropic approximations. Naturally, these applications, especially in cases of high space dimensions, require development and implementation of special numerical methods that are not only consistent with the governing system of PDEs, but also preserve certain structural and asymptotic properties of the underlying problem at the discrete level. The development of new numerical techniques will be based on high-order shock-capturing finite-volume schemes, asymptotic preserving, adaptive moving mesh and stochastic Galerkin methods utilizing major advantages of each one of these methods in the context of studied problems. Besides providing examples that corroborate the numerical approach, the foregoing applications are of a substantial independent value for a broad class of problems arising in today's science.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
