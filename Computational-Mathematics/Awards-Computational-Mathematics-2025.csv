"AwardNumber","Title","NSFOrganization","Program(s)","StartDate","LastAmendmentDate","PrincipalInvestigator","State","Organization","AwardInstrument","ProgramManager","EndDate","AwardedAmountToDate","Co-PIName(s)","PIEmailAddress","OrganizationStreet","OrganizationCity","OrganizationState","OrganizationZip","OrganizationPhone","NSFDirectorate","ProgramElementCode(s)","ProgramReferenceCode(s)","ARRAAmount","Abstract"
"2535465","Conference: 2nd SIAM Northern and Central California Sectional Conference (NCC25)","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","10/01/2025","08/14/2025","Lin Lin","CA","University of California-Berkeley","Standard Grant","Hailiang Liu","09/30/2026","$40,000.00","James Sethian, Per-Olof Persson","linlin@math.berkeley.edu","1608 4TH ST STE 201","BERKELEY","CA","947101749","5106433891","MPS","126600, 127100","075Z, 079Z","$0.00","The second annual conference of the Northern and Central California Section of SIAM (SIAM-NCC) will be held October 27?28, 2025, at Lawrence Berkeley National Laboratory. This event brings together researchers from academia, industry, national laboratories, and government to strengthen regional collaboration in applied and computational mathematics. The conference aims to: (1) create an opportunity for scientific researchers to meet, network, and share the innovations and recent developments in their fields; (2) attract and energize students and researchers working in applied and computational mathematics and related fields; (3) offer SIAM members from all institutions in the NCC region the opportunity to attend a local meeting of the community; (4) provide early career researchers the access and opportunities to connect with others who are at similar career stages; (5) inspire the next generation of applied and computational mathematicians to get involved in the community and to innovate through research and education.<br/><br/>Conference themes align with SIAM Activity Groups and include mathematical analysis, optimization, inverse problems, experimental design, high-performance computing, uncertainty quantification, scientific machine learning, AI, and digital twins. The program will feature two plenary talks, eight thematic sessions, two panels, two poster sessions with blitz presentations, a mentoring event, a CV/interviewing workshop, and guided tours of the National Energy Research Scientific Computing Center (NERSC) and the Advanced Light Source (ALS). The presenters will come from academia, industry, and national laboratories, representing many scientific backgrounds, career stages, and institutional affiliations. The themes and speakers for each thematic session will be selected via an open call and coordinated by the Technical Program Committee. More information is available at the conference: https://siamncc25.lbl.gov.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2524699","Conference: The 10th SIAM Central States Section Annual Meeting at the University of Arkansas, October 11-12, 2025","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","10/01/2025","06/30/2025","Jiahui Chen","AR","University of Arkansas","Standard Grant","Jodi Mead","09/30/2026","$24,000.00","Zachary Bradshaw, Chen Liu","jiahuic@uark.edu","1125 W MAPLE ST STE 316","FAYETTEVILLE","AR","727013124","4795753845","MPS","126600, 127100","9150, 075Z, 9263, 7556, 079Z","$0.00","The 10th Annual Meeting of the Society for Industrial and Applied Mathematics Central States Section (SIAM-CSS) will be held at the University of Arkansas, Fayetteville, on October 11?12, 2025. By convening applied and computational mathematicians from Arkansas, Colorado, Iowa, Kansas, Mississippi, Missouri, Nebraska, Oklahoma, and beyond, the meeting promotes the progress of science and strengthens regional and national research capacity. Participants will share cutting-edge advances, receive professional mentoring, and form collaborations that translate mathematical innovation into technological, biomedical, and economic benefits.<br/><br/>T?he SIAM-CSS conference will feature plenary lectures by distinguished scientists and a series of minisymposia spanning numerical analysis, partial differential equations, optimization, scientific computing, data-driven modeling, and interdisciplinary applications such as engineering and life sciences, to name just a few. Interactive poster sessions will showcase emerging methods such as structure-preserving algorithms, high-performance computing strategies, and machine-learning?enhanced simulation. By disseminating new theories, algorithms, and open-source software, the meeting will accelerate discovery and identify research directions of strategic importance to the computational and applied mathematics community. The conference website is https://siam.uark.edu/.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2529361","Collaborative Research: MATH-DT Dynamical Models and Statistical Guarantees for Sparse Sensing in Nuclear Digital Twins","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS, MSPA-INTERDISCIPLINARY","09/15/2025","08/05/2025","Krithika Manohar","WA","University of Washington","Standard Grant","Jodi Mead","08/31/2028","$370,000.00","","kmanohar@uw.edu","4333 BROOKLYN AVE NE","SEATTLE","WA","981951016","2065434043","MPS","125300, 127100, 745400","9263, 160Z","$0.00","Digital Twin technology aims to align the physical behavior of complex systems with online computational models, enabling real-time monitoring, prediction, and informed decision-making. Raw data gathered by sensors is often challenging to integrate into a model due to the sparsity of sensors. The sparse sensing problem is the central focus of this project. Along with developing theory and computational methods, the project focuses on applications to components of nuclear reactors. Open-source community software will be developed within the frameworks RAVEN, PySensors, and the Nuclear Data Research System.  The project will involve traineeships, software carpentry, and open-source educational curricula. Curricula will be published using the University of Washington's Lightboard filming studio.  The project aligns with the Presidential priorities in artificial intelligence and nuclear energy, and will enhance national leadership in these areas.<br/><br/>Sparse sensors establish the critical bidirectional flow of information between virtual models and safety-critical decision-making in physical nuclear energy subsystems. These sensors are essential for estimating high-dimensional temperature fields, pressure gradients, and accident scenarios. However, in nuclear applications, sensor design, placement, and budgets are extremely constrained, making strategic design and budgeting of sensors crucial. This project develops fundamental theory, algorithms, and guarantees for sparse sensing optimization in nuclear subsystems. Control and information theory, statistical mechanics, and uncertainty quantification will be leveraged to develop robust, high-dimensional estimation methods with guaranteed performance. To achieve this, there are three major thrusts: 1) dynamical models and information theory of sparse sensing, 2) optimal regularization and uncertainty quantification using statistical mechanics, and 3) multi-objective decision-making in nuclear digital twins. Validation and verification of the methods and models will focus on high-dimensional estimation, anomaly detection and prediction within the transient water irradiation system at Idaho National Laboratory (INL).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513865","High-order energy-stable embedded boundary method for compressible viscous flows","DMS","COMPUTATIONAL MATHEMATICS, MSPA-INTERDISCIPLINARY","09/15/2025","08/05/2025","Nek Sharan","AL","Auburn University","Standard Grant","Yuliya Gorb","08/31/2028","$290,000.00","","nsharan@auburn.edu","321-A INGRAM HALL","AUBURN","AL","36849","3348444438","MPS","127100, 745400","9263, 9150","$0.00","Accurate computations of compressible (high-speed) flows in practical domains are crucial in numerous scientific and engineering applications, e.g., bridge/building vibration in hurricanes, wing flutter in aircraft, human speech/phonation, etc. These computations are challenging because handling complicated boundaries often leads to numerical errors that compromise the accuracy of the predictions. Moreover, setting up these computations (which involves meshing or grid generation) for complex domains can be time-consuming. This project will develop computational approaches (and a theory to evaluate and improve the numerical properties of those approaches) to eliminate the need for complex grid generation, while ensuring high-fidelity flow predictions. It will enable accurate simulations of fluid-structure interactions in flow situations that have been intractable so far, helping uncover the physical mechanisms that drive the interactions and devise strategies to control them. The research tasks will be paired with instructional plans to train undergraduate and graduate students in leveraging computational tools for scientific investigations. Additionally, summer research opportunities focused on flow visualization tools and algorithms will be provided to encourage undergraduate research participation.<br/> <br/>Embedded boundary (EB) methods simplify the handling of practical geometries; however, they have been restricted to low (first/second) order of accuracy when non-dissipative interior schemes are used because of EB instabilities and small-cell issues. This project will address several key challenges associated with the application of EB methods to compressible Navier-Stokes equations. First, a stability theory will be developed for the construction of high (fourth and higher) order energy stable EB schemes for multi-dimensional compressible flow equations. Second, the theory will be extended to derive shock-capturing EB schemes that are provably stable. Finally, the derived schemes will be implemented to simulate the flow-induced vibrations of an airfoil/wing in supersonic flows. The theoretical (energy or time) stability will be proven by utilizing the dimensionally-split structure of the proposed schemes, which allows the multi-dimensional scheme to be written and analyzed as combinations of one-dimensional schemes in individual directions. No-slip wall boundary conditions will be enforced via penalty terms at the EB to satisfy the energy stability constraints. The small-cell issue, commonly encountered in existing EB methods, will be addressed by constructing a dual grid, containing separate solution and flux points, where the flux-point (or cell) spacings will be constrained to remain finite when the solution point spacings vanish near the EB.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2529362","Collaborative Research: MATH-DT Dynamical Models and Statistical Guarantees for Sparse Sensing in Nuclear Digital Twins","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS, MSPA-INTERDISCIPLINARY","09/15/2025","08/05/2025","Andrei Klishin","HI","University of Hawaii","Standard Grant","Jodi Mead","08/31/2028","$300,000.00","","aklishin@hawaii.edu","2425 CAMPUS RD SINCLAIR RM 1","HONOLULU","HI","968222247","8089567800","MPS","125300, 127100, 745400","160Z, 9150, 9263","$0.00","Digital Twin technology aims to align the physical behavior of complex systems with online computational models, enabling real-time monitoring, prediction, and informed decision-making. Raw data gathered by sensors is often challenging to integrate into a model due to the sparsity of sensors. The sparse sensing problem is the central focus of this project. Along with developing theory and computational methods, the project focuses on applications to components of nuclear reactors. Open-source community software will be developed within the frameworks RAVEN, PySensors, and the Nuclear Data Research System.  The project will involve traineeships, software carpentry, and open-source educational curricula. Curricula will be published using the University of Washington's Lightboard filming studio.  The project aligns with the Presidential priorities in artificial intelligence and nuclear energy, and will enhance national leadership in these areas.<br/><br/>Sparse sensors establish the critical bidirectional flow of information between virtual models and safety-critical decision-making in physical nuclear energy subsystems. These sensors are essential for estimating high-dimensional temperature fields, pressure gradients, and accident scenarios. However, in nuclear applications, sensor design, placement, and budgets are extremely constrained, making strategic design and budgeting of sensors crucial. This project develops fundamental theory, algorithms, and guarantees for sparse sensing optimization in nuclear subsystems. Control and information theory, statistical mechanics, and uncertainty quantification will be leveraged to develop robust, high-dimensional estimation methods with guaranteed performance. To achieve this, there are three major thrusts: 1) dynamical models and information theory of sparse sensing, 2) optimal regularization and uncertainty quantification using statistical mechanics, and 3) multi-objective decision-making in nuclear digital twins. Validation and verification of the methods and models will focus on high-dimensional estimation, anomaly detection and prediction within the transient water irradiation system at Idaho National Laboratory (INL).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2529212","Collaborative Research: MATH-DT: Digital Twin for Laboratory Science (DTLS) - Application to Liquid Sodium Experiments in Geosciences","DMS","COMPUTATIONAL MATHEMATICS, MSPA-INTERDISCIPLINARY","09/15/2025","08/25/2025","Paul Fischer","IL","University of Illinois at Urbana-Champaign","Standard Grant","Yuliya Gorb","08/31/2028","$432,001.00","","fischer@mcs.anl.gov","506 S WRIGHT ST","URBANA","IL","618013620","2173332187","MPS","127100, 745400","079Z, 9263","$0.00","The Earth?s magnetic field is critical for sustaining our planet?s habitability, deflecting harmful solar radiation. However, the processes generating this field deep within the Earth?s core remain mysterious, hindering our ability to predict its future behavior ? a concern given recent observations of relatively rapid changes in the field. This project addresses this fundamental challenge by developing a ?digital twin? system for a large-scale laboratory experiment that mimics conditions inside the Earth. The digital twin will allow researchers to operate and optimize complex experiments remotely, explore scenarios inaccessible through physical experimentation alone, and ultimately improve our understanding of the forces shaping the geodynamo ? the engine driving Earth?s magnetic field.  By creating extensible tools for laboratory science, this research advances computational mathematics, supports training for a new generation of scientists and engineers, and has potential benefits for diverse fields including medical device design and external aerodynamics.<br/> <br/>This translational science collaborative project between University of Maryland (UM) and University of Illinois creates a digital twin consisting of the 3-meter liquid sodium geodynamo experiment at UM, coupled with advanced numerical modeling schemes based on high-order spectral element methods (Nek5000/RS) and data assimilation techniques including Ensemble Kalman Filters. The research team will develop Reduced Order Models ROM incorporating Deep Learning Neural Networks to enhance predictive capabilities and enable flow control strategies. By synchronizing the model with experimental observations, researchers aim to achieve a 1:1 correspondence between geometry changes and simulation results, ultimately allowing for bidirectional interaction between the physical experiment and its digital counterpart. This work will leverage high-performance computing resources to advance computational mathematics and provide a framework extensible to other laboratory science domains.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2529112","Collaborative Research: MATH-DT: Computationally efficient hypercomplex variable-based sensitivity methods for rapid Digital Twin model updating","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS, MSPA-INTERDISCIPLINARY","09/15/2025","08/05/2025","Robert Kirby","UT","University of Utah","Standard Grant","Dmitry Golovaty","08/31/2028","$444,202.00","Shandian Zhe, Jacob Hochhalter","kirby@cs.utah.edu","201 PRESIDENTS CIR","SALT LAKE CITY","UT","841129049","8015816903","MPS","125300, 127100, 745400","9263","$0.00","A Digital Twin (DT) is a representation of a real-world system that continuously exchanges data between digital models and their physical counterparts, allowing them to simulate, monitor, and predict the behavior of real-world systems in real-time. As such, DTs hold transformative potential across critical sectors including manufacturing, infrastructure, energy, and defense. However, existing methods for updating the digital models with real-world data are often too slow for real-time use. To overcome this barrier, this research introduces a novel mathematical and computational framework to dramatically accelerate digital model calibration, enabling faster and more accurate digital twin applications. The potential benefits of this work are far-reaching, advancing capabilities in predictive maintenance, process optimization, and risk mitigation, directly supporting the US economic productivity, public safety, technological innovation, and competitiveness. The project also fosters the next generation of scientists and engineers through interdisciplinary training and hands-on research experiences for graduate and undergraduate students. Together, these contributions lay the groundwork for a new generation of scalable, real-time Digital Twin systems with wide-reaching impact across science, industry, and education.<br/> <br/>Digital Twins require continuous two-way communication between physical systems and high-fidelity digital models. However, the cost in time and resources to update the digital models with real-world data is often prohibitive. To address this technical challenge, this project explores a fundamentally new approach for DT model updating centered on the efficient computation and exploitation of high-order derivatives obtained via a new class of hypercomplex algebras. These derivatives will serve as the foundation for a new derivative-informed Bayesian updating method that dramatically reduces the number of required model evaluations while preserving accuracy. The project is structured around three interconnected aims. Aim 1 develops hypercomplex algebras specifically formulated to compute arbitrary-order derivatives efficiently and accurately, even in high-dimensional settings. Aim 2 computes and applies the new hypercomplex algebras to accurately and efficiently obtain sensitivities of high-fidelity digital models. Aim 3 develops a derivative-informed Bayesian updating strategy that utilizes the derivatives to reduce the cost of model updating while maintaining high accuracy. The anticipated outcomes include faster and more accurate model calibration, improved uncertainty quantification, and reduced operational costs, enabling scalable, real-time DT systems across high-impact domains such as aerospace, defense, infrastructure, and healthcare.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2529316","Collaborative Research: MATH-DT: Reduced order modeling and data assimilation for wave-dominated systems with applications to digital twins in ultrasonics","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS, MSPA-INTERDISCIPLINARY","09/01/2025","08/08/2025","Thomas Hagstrom","TX","Southern Methodist University","Standard Grant","Yuliya Gorb","08/31/2028","$354,485.00","","thagstrom@smu.edu","6425 BOAZ ST RM 130","DALLAS","TX","752051902","2147684708","MPS","125300, 127100, 745400","9263","$0.00","Millions of patients each year rely on medical procedures that use sound waves to break apart kidney stones or target diseased tissues without surgery. As these technologies advance, so does the need for greater precision, safety, and adaptability in treatment. This project contributes to the development of digital twins ? real-time computer models that simulate how sound waves interact with the body and, based on imaging as the procedures unfold, help guide the process. By enabling more accurate and responsive treatments, such models could significantly improve clinical outcomes and reduce costs in noninvasive medicine. Beyond the immediate medical application, the project addresses a broader national need: the development of fast, reliable computational tools for predicting and controlling complex physical systems in real time. These methods are broadly applicable to technologies that rely on wave-based sensing and actuation, including systems in biotechnology, nondestructive materials testing, environmental monitoring, and national defense. The project will also serve as a multidisciplinary training ground for graduate students working at the intersection of applied mathematics, computation, and engineering.<br/><br/>The research aims to develop fast, accurate algorithms that simulate how high-frequency waves, such as shock waves or focused ultrasound, propagate through complex, heterogeneous materials. The key technical challenge is that, in many real-world systems, waves must be tracked over hundreds of wavelengths, making traditional computational methods too slow for real-time use, especially when repeated simulations are needed to account for uncertainty or to estimate unknown parameters. To address this, the project will construct reduced-order models that capture the essential dynamics of wave propagation between source and target, while drastically reducing computational cost. These models will be designed to adapt in real time based on measurements from the system, enabling rapid prediction, control, and decision-making. The algorithms will be validated through comparison with full-scale simulations and, where possible, experimental data from laboratory-scale models of therapeutic ultrasound. The work is expected to lead to new strategies for real-time modeling and control in complex wave-driven systems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513117","Collaborative Research: Acceleration and Preconditioning Methods for Deep Learning","DMS","COMPUTATIONAL MATHEMATICS","09/01/2025","07/01/2025","Yousef Saad","MN","University of Minnesota-Twin Cities","Standard Grant","Ludmil T. Zikatanov","08/31/2028","$255,237.00","","saad@umn.edu","2221 UNIVERSITY AVE SE STE 100","MINNEAPOLIS","MN","554143074","6126245599","MPS","127100","9263, 075Z, 079Z","$0.00","The remarkable progress of Artificial Intelligence (AI) in recent years is starting to greatly influence research across a wide range of disciplines. As Numerical Linear Algebra plays a crucial role in Deep Learning models, this trend presents unprecedented opportunities for experts in numerical analysis and linear algebra to contribute to ongoing AI research. This proposal represents a step toward capitalizing on this opportunity. The focus of the proposed work is not on applying AI to solve a specific problem, but rather on enhancing AI methods themselves by exploiting insights from numerical methods to optimize the Deep Learning process. This process is time-consuming, energy-intensive, resource-demanding, and overall very costly. Therefore, any improvements that can speed up the process are likely to have a significant impact. The investigators will leverage their experience in numerical methods to develop a number of techniques for accelerating the training of large AI models.<br/><br/>The project aims to develop techniques that exploit both accelerators and preconditioners to speed up iterative procedures used in training deep learning models.  The same combination of preconditioning and acceleration techniques is central to the effectiveness of iterative solution methods for linear systems. Acceleration methods such as Anderson/Pulay mixing or the Reduced Rank Extrapolation method, among others, have had immense success across various fields of science and engineering. However, in the context of deep learning, these methods face challenges, particularly since they were not developed for stochastic sequences common in deep learning.  The team will investigate the relationship between mini-batching, a technique used for sampling subfunctions in stochastic methods, and its impact on both the convergence speed and the accuracy of the resulting models. Simple diagonal preconditioning methods have already been incorporated into optimization techniques in deep learning.  The research team will explore more advanced preconditioning methods based on various approximations to the Fisher information matrix, a matrix that measures the amount of information that the observed data provides about the parameters. It has been shown that replacing the Hessian in second order methods by the Fisher matrix yields a more meaningful form of scaling of the variables, leading to better convergence and generalization. The investigating team will consider various methods for obtaining inexpensive approximations of the Fisher matrix and for combining them with accelerators. The proposed work is expected to benefit research in ""scientific machine learning"" by promoting participation of numerical linear algebra specialists in AI research. The PIs plan on several specific activities to promote the dissemination of knowledge in machine learning, such as writing a book on the topic of numerical methods in machine learning or offering tutorials and short courses. These activities will stimulate the interest of students in a field of increasing importance and that it will help with the immersion of those students from other areas, e.g., mathematics, into data-related disciplines.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2512644","Graph-based semi-supervised techniques for machine learning tasks at low label rates","DMS","COMPUTATIONAL MATHEMATICS","09/01/2025","06/11/2025","Ekaterina Rapinchuk","MI","Michigan State University","Standard Grant","Jodi Mead","08/31/2028","$379,999.00","","merkurje@msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","127100","075Z, 079Z, 9263","$0.00","Machine learning is a type of artificial intelligence that enables a machine to learn from data. The success of machine learning is dependent upon a sufficient amount of labeled data samples. A key limitation of most machine learning methods is their reliance on large labeled sets. Labeled data is scarce for many applications. Obtaining enough labeled data is often difficult because it is time-consuming and expensive, especially when experts are required for the labeling task. This project develops novel strategies for machines to effectively learn in limited labeled data scenarios. The foundation of the new strategies lies in data analysis and algorithm development and the project involves the training of graduate and undergraduate students in these areas through mentoring and curriculum development.  User-friendly software packages will be made available to the community to ensure the results from the project can be used by other researchers who use machine learning. <br/> <br/>To address the challenge of data with limited labeled samples, and to develop computationally tractable methods for machine learning tasks such as data classification, the PI will incorporate a graph-based semi-supervised learning framework. Specifically, one of the main advantages of semi-supervised learning is its ability to make use of the important information from the vastly available unlabeled data without the additional cost of external interaction; moreover, the graph-based framework provides information about the extent of similarity between the data elements and the overall structure of data. In particular, the proposed research encompasses the following three aims:  (1) development of graph-based similarity-driven auction dynamics learning methods (2) development of graph-based similarity-driven neural network methods (3) development of graph-based similarity-driven maximum-flow learning methods. Although all three aims involve developing graph-based approaches for learning tasks using semi-supervised techniques, each of the aims will formulate procedures with their own advantages. Overall, this proposal will develop computationally tractable semi-supervised graph-based methods for machine learning tasks that will require less labeled data for accurate predictions, which is crucial due to the scarcity of labeled data.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513966","Effective Computational Methods for Training of Neural Networks via Exploration-Exploitation-Determination Framework","DMS","COMPUTATIONAL MATHEMATICS","09/01/2025","07/17/2025","Yeonjong Shin","NC","North Carolina State University","Standard Grant","Jodi Mead","08/31/2028","$307,266.00","","yeonjong_shin@ncsu.edu","2601 WOLF VILLAGE WAY","RALEIGH","NC","276950001","9195152444","MPS","127100","075Z, 079Z, 9263","$0.00","This project addresses one of the fundamental challenges in artificial intelligence (AI): training of neural networks (NNs). NNs are a core component of modern AI models and are widely used in numerous applications across science, engineering, and industry. Training refers to a learning process of AI models. It is notoriously challenging due to the nonlinear and nonconvex nature of NNs. The state-of-the-art methods frequently fail to produce satisfactory results and exhibit unstable behaviors, limiting the accuracy and reliability of AI models. This project will develop effective training methods that significantly improve the training performance over the state-of-the-art, overcoming the current limitations. The broader impacts include creating educational opportunities for undergraduates through a summer research program, developing professional training for K-12 educators on computational mathematics for AI, and establishing public engagement through interactive demonstrations and online resources, all of which will broaden participation in computing and improve public understanding of the role of mathematics in AI.<br/><br/>The project develops a novel exploration-exploitation-determination (EED) framework for training neural networks that uniquely combines both local and nonlocal information. Four objectives are: (1) establishing the EED framework for two-layer neural networks by utilizing mathematical analysis of gradient flow dynamics and nonlocal effects; (2) developing a layer-wise training strategy for deep neural networks that sequentially trains each hidden layer; (3) extending the framework to handle noisy and corrupted data through l1-norm minimization; and (4) validating the methods through applications to scientific machine learning tasks including operator learning for PDEs and flow map learning for data-driven discovery of dynamical systems. The computational methods will be rigorously analyzed mathematically, and the resulting algorithms will be made publicly available to enhance reproducibility and maximize impact across multiple scientific disciplines.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513795","NSF MPS/DMS-EPSRC: A novel theory-based framework for coarse-graining and simulating stochastic differential equations for crystalline materials","DMS","GVF - Global Venture Fund, COMPUTATIONAL MATHEMATICS","09/01/2025","07/23/2025","Xingjie Li","NC","University of North Carolina at Charlotte","Standard Grant","Yuliya Gorb","08/31/2028","$270,000.00","","xli47@uncc.edu","9201 UNIVERSITY CITY BLVD","CHARLOTTE","NC","282230001","7046871888","MPS","054Y00, 127100","5946, 9263, 022Z","$0.00","Computer simulations have revolutionized materials discovery, allowing scientists to test thousands of possibilities digitally before conducting expensive laboratory experiments, which accelerates innovation while dramatically reducing costs. There are critical national challenges that require advanced materials that perform under extreme conditions. Examples include next-generation computer chips essential for AI and quantum computing, and nuclear energy infrastructure materials that can withstand extreme radiation and heat in reactors. This project develops new mathematical tools and simulation methods enabling more efficient, accurate, and reliable materials modeling, accelerating breakthroughs in national nanotechnologies, clean energy systems, and resilient infrastructure. In addition, the project strengthens the U.S. scientific workforce by training students in advanced mathematical techniques that span multiple disciplines. Through international collaboration with the University of Warwick in the UK, both graduate and undergraduate students will engage in hands-on research experiences, inspiring them to pursue careers in science, technology, engineering, and mathematics. Overall, this project bridges mathematics, engineering, and computing to address real-world challenges in designing advanced materials, while supporting federal priorities in technological leadership, energy security, infrastructure resilience, and fostering the next generation's STEM talent pipeline.<br/><br/>This project establishes a new theoretical framework and methodologies for coarse-grained dynamics and numerical simulation to model materials defect evolution. The central intellectual merit lies in developing rigorous mathematical foundations for coarse-graining strategies that capture spatiotemporal correlations and in creating novel algorithms for efficient and robust computing. The research delivers three key contributions: (1) a robust theoretical framework for selecting coarse-graining variables, quantifying model deviations, and addressing non-Markovian effects while incorporating high-dimensional phase space geometry; (2) numerical methods ensuring stability and accuracy of large time-step integrators, investigating scheme ergodicity, and optimizing parameters to balance error sources; and (3) a software package applying these findings to real computational materials science problems. The proposed methods will improve accuracy and efficiency in modeling lattice vacancy generation, crystal solid annealing, and dislocation motion, benefiting materials science, mathematics, and education. This project will train students in challenging, multidisciplinary applied mathematics at the UNC Charlotte in the U.S. and the University of Warwick in the U.K. Moreover, the ability to travel will give the U.S.-based students access to beneficial interdisciplinary, international research networks, outreaches and training.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2534607","Conference: SIAM Great Lakes 2025 Meeting","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/01/2025","08/06/2025","Trevor Leslie","IL","Illinois Institute of Technology","Standard Grant","Hailiang Liu","08/31/2026","$35,000.00","Shuwang Li","tleslie@iit.edu","10 W 35TH ST","CHICAGO","IL","606163717","3125673035","MPS","126600, 127100","7556","$0.00","This award provides travel support for students and early career researchers to attend the 2025 SIAM Great Lakes Section Conference (GLSIAM 2025), to be held September 27-28, 2025, at the Illinois Institute of Technology in Chicago.  The conference will bring together applied mathematicians and engineers from across the Midwest, fostering interdisciplinary collaboration and professional development. Emphasizing the value of a wide range of expertise in tackling complex scientific challenges, GLSIAM 2025 aims to strengthen regional research networks and promote partnerships with societal impact.<br/><br/>The scientific program will explore the intersection of differential equations, computational mathematics, data science, and the physical and biological sciences. Highlights include plenary lectures by leading experts, a poster session, and parallel contributed talks. A key focus of the conference is to increase the visibility of early-career participants, connecting them with peers, mentors, and future collaborators. NSF support will help ensure broad and equitable access to this opportunity. The event will be open to anyone interested in the conference themes.  More information can be found through the conference website, https://sites.google.com/iit.edu/glsiam2025/, with updates beginning June 2025.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2505987","Collaborative Research: Unified Neural Operator (UNO): Towards Trustworthy Operator Learning for Scientific Applications","DMS","COMPUTATIONAL MATHEMATICS, MSPA-INTERDISCIPLINARY","09/01/2025","08/06/2025","Grady Wright","ID","Boise State University","Standard Grant","Ludmil T. Zikatanov","08/31/2028","$200,000.00","","gradywright@boisestate.edu","1910 UNIVERSITY DR","BOISE","ID","837250001","2084261574","MPS","127100, 745400","075Z, 079Z, 9150, 9263","$0.00","Modern scientific challenges?from predicting complex fluid flows to modeling plasma behavior in fusion reactors?demand computationally efficient, trustworthy surrogates that can rival traditional numerical solvers while harnessing the power of artificial intelligence. Scientific machine learning (SciML), identified as a core technology for AI, offers immense potential for surrogate modeling in both data?rich and data?scarce situations; of particular interest is the field of operator learning. However, current operator learning frameworks lack unified theoretical foundations, robustness guarantees, and scalable training methods, which limit their adoption in high-stakes applications. The Unified Neural Operator (UNO) considered in this project will fill this gap by embedding all operator learning techniques into a unifying framework, marrying the mathematical rigor of traditional methods with the expressivity of modern AI. By delivering certifiable, interpretable AI?driven surrogates, UNO advances Presidential priorities in artificial intelligence and nuclear energy?supporting both next?generation AI capabilities and efficient modeling of magnetohydrodynamic systems critical for fusion energy?while fulfilling NSF?s mission ?to promote the progress of science; to advance the national health, prosperity, and welfare; and to secure the national defense?<br/><br/>Within SciML, operator learning has shown tremendous potential as a powerful tool for creating surrogate models, leading to a bevy of deep machine learning (ML)-based operator learning techniques known as ?neural operators?. However, poorly-understood robustness characteristics, lack of explainability and interpretability, and the sheer variety of such approaches make it challenging for practitioners to choose the appropriate methods for different tasks, especially in the context of scientific applications. This project tackles these urgent challenges through the inception of a new computational framework: the Unified Neural Operator (UNO). UNO distills neural operators down into three essential components: an input encoder, a set of basis functions for the output space, and a projection operator. The work will (1) provide a mathematical formalism that both encompasses existing neural operators and allows us to generate novel architectures that target specific tasks and problems; (2) provide algorithms for scalable and adaptive training and inference, allowing UNO to adapt to local solution features and to tackle high-dimensional data efficiently in data-rich regimes; (3) provide a robust theoretical foundation in the form of universal approximation theorems, error estimates, and a guiding theoretical framework for robust sampling and adaptivity. The UNO framework also allows for automatic and natural uncertainty quantification capabilities of existing and new neural operators. In data-poor situations, the UNO framework preserves accuracy by analytically preserving physics, thereby making it well-suited to both in situ and ex situ surrogate modeling in scientific applications. The challenging applications targeted by this project include turbulent, multiscale, and multiphysics fluid flow problems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2504439","Collaborative Research: Scientific Computing Assisted Machine Learning for Wave Imaging","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS, CDS&E-MSS","09/01/2025","08/06/2025","Youzuo Lin","NC","University of North Carolina at Chapel Hill","Standard Grant","Jodi Mead","08/31/2028","$220,000.00","","yzlin@unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275995023","9199663411","MPS","125300, 127100, 806900","9263, 079Z, 075Z","$0.00","Computational wave imaging, vital for uncovering hidden properties in diverse fields of science and engineering, such as materials science, medicine, and geoscience, faces significant challenges. Traditional methods struggle with the inherent complexity and computational demands of such problems. Although deep learning offers promise for these scientific inverse problems, its efficacy is hindered by the scarcity of labeled data, often due to costly experiments and expertise requirements. This underscores the need for innovative approaches that circumvent data limitations in wave imaging. This project seeks to optimize the potential of deep learning in computational wave imaging by introducing techniques to address data scarcity and improve generalizability, aiming to drastically lessen deep learning's dependence on extensive labeled datasets, efficiently generate high-quality training data, and greatly improve deep learning's capacity to solve real-world problems. It also emphasizes educational integration and interdisciplinary collaboration, and promotes the sharing of open-source computer codes and datasets, enhancing the broader scientific community?s ability to conduct research and providing educators with valuable tools for teaching computational and data-enabled science, engineering, and mathematics.<br/> <br/>Physical principles will be integrated with advanced deep learning models in hybrid learning strategies. Hybrid strategies involve efficient wave simulations results which can address the challenges of data and label scarcity, and the weak generalizability in computational wave imaging.  A novel self-supervised learning method will be introduced, which can uncover hidden physical principles within the latent space. Preliminary investigations have revealed an ?Auto-Linear? phenomenon, where features from different physical domains automatically correlate linearly. This discovery allows for simultaneous forward and inverse modeling, significantly enhancing performance in imaging tasks that lack paired data. Efficient wave simulations will also be developed. They will involve high-order methods for effective forward propagation and backpropagation, with explicit Runge-Kutta time stepping for non-stiff problems and A-stable implicit Runge-Kutta time stepping for stiff problems, combined with Fourier or spectral element spatial approximations. Furthermore, integral-based methods with asymptotic short-time Green's function will be developed for problems with point-source-like source functions. This configuration is designed to simulate wave propagation with high accuracy and minimal sampling requirements in both time and space, thus avoiding the pollution effect and promising a leap in simulation efficiency and quality.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2446127","Collaborative Research: RTG: Building a robust mathematical foundation for AI and integrated data science at Auburn and Tuskegee University","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS, WORKFORCE IN THE MATHEMAT SCI","09/01/2025","08/22/2025","Yanzhao Cao","AL","Auburn University","Continuing Grant","Jodi Mead","08/31/2030","$1,323,521.00","Asheber Abebe, Shiwen Mao, Nedret Billor, Junshan Lin","yzc0009@auburn.edu","321-A INGRAM HALL","AUBURN","AL","36849","3348444438","MPS","125300, 127100, 733500","9263, 079Z, 075Z, 9150, 7301, 9251","$0.00","Artificial intelligence (AI) and data science are revolutionizing the way complex systems are modeled, data is analyzed, and decisions are made across science, technology, and industry. There is a growing need to train researchers with a rigorous mathematical foundation to ensure that AI and data-driven methods are reliable, efficient, and adaptable to real-world challenges. This Research Training Group (RTG) project will train undergraduate students, graduate students, and postdoctoral researchers to conduct advanced research at the intersection of mathematics, AI, and data science. Through a structured program of interdisciplinary research, AI and Data Science summer school, seminars, and industry-partnered projects, participants will acquire the mathematical, computational, and analytical tools necessary to contribute to the future of AI and data science, both in theory and in practice.<br/><br/>The project centers on three integrated research modules: (1) diffusion modeling for generative AI, (2) topological data analysis (TDA) for complex datasets, and (3) partial differential equation-based machine learning for anomaly detection. These modules pair fundamental mathematics with application areas including wireless communications, medical imaging, and cybersecurity. By rotating through all three modules, trainees will develop a comprehensive skill set on stochastic modeling, algebraic topology, inverse problems, and algorithmic implementation. The program emphasizes both conceptual understanding and hands-on experience through research, capstone projects, and collaboration with industry. Trainees of this project will be prepared to lead in the development and application of mathematically grounded methods in AI and data science.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2446128","Collaborative Research: RTG: Building a robust mathematical foundation for AI and integrated data science at Auburn and Tuskegee University","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS, WORKFORCE IN THE MATHEMAT SCI","09/01/2025","08/22/2025","Mohammed Qazi","AL","Tuskegee University","Continuing Grant","Jodi Mead","08/31/2030","$479,660.00","Mandoye Ndoye, Fan Wu, Osman Yardimci","mqazi@tuskegee.edu","1200 W MONTGOMERY RD","TUSKEGEE INSTITUTE","AL","360881923","3347278970","MPS","125300, 127100, 733500","7301, 9263, 075Z, 079Z, 9251, 9150","$0.00","Artificial intelligence (AI) and data science are revolutionizing the way complex systems are modeled, data is analyzed, and decisions are made across science, technology, and industry. There is a growing need to train researchers with a rigorous mathematical foundation to ensure that AI and data-driven methods are reliable, efficient, and adaptable to real-world challenges. This Research Training Group (RTG) project will train undergraduate students, graduate students, and postdoctoral researchers to conduct advanced research at the intersection of mathematics, AI, and data science. Through a structured program of interdisciplinary research, AI and Data Science summer school, seminars, and industry-partnered projects, participants will acquire the mathematical, computational, and analytical tools necessary to contribute to the future of AI and data science, both in theory and in practice.<br/><br/>The project centers on three integrated research modules: (1) diffusion modeling for generative AI, (2) topological data analysis (TDA) for complex datasets, and (3) partial differential equation-based machine learning for anomaly detection. These modules pair fundamental mathematics with application areas including wireless communications, medical imaging, and cybersecurity. By rotating through all three modules, trainees will develop a comprehensive skill set on stochastic modeling, algebraic topology, inverse problems, and algorithmic implementation. The program emphasizes both conceptual understanding and hands-on experience through research, capstone projects, and collaboration with industry. Trainees of this project will be prepared to lead in the development and application of mathematically grounded methods in AI and data science.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2504438","Collaborative Research: Scientific Computing Assisted Machine Learning for Wave Imaging","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS, MSPA-INTERDISCIPLINARY, CDS&E-MSS","09/01/2025","08/06/2025","Songting Luo","IA","Iowa State University","Standard Grant","Jodi Mead","08/31/2028","$281,836.00","","luos@iastate.edu","1350 BEARDSHEAR HALL","AMES","IA","500112103","5152945225","MPS","125300, 127100, 745400, 806900","079Z, 075Z, 9263, 9150","$0.00","Computational wave imaging, vital for uncovering hidden properties in diverse fields of science and engineering, such as materials science, medicine, and geoscience, faces significant challenges. Traditional methods struggle with the inherent complexity and computational demands of such problems. Although deep learning offers promise for these scientific inverse problems, its efficacy is hindered by the scarcity of labeled data, often due to costly experiments and expertise requirements. This underscores the need for innovative approaches that circumvent data limitations in wave imaging. This project seeks to optimize the potential of deep learning in computational wave imaging by introducing techniques to address data scarcity and improve generalizability, aiming to drastically lessen deep learning's dependence on extensive labeled datasets, efficiently generate high-quality training data, and greatly improve deep learning's capacity to solve real-world problems. It also emphasizes educational integration and interdisciplinary collaboration, and promotes the sharing of open-source computer codes and datasets, enhancing the broader scientific community?s ability to conduct research and providing educators with valuable tools for teaching computational and data-enabled science, engineering, and mathematics.<br/> <br/>Physical principles will be integrated with advanced deep learning models in hybrid learning strategies. Hybrid strategies involve efficient wave simulations results which can address the challenges of data and label scarcity, and the weak generalizability in computational wave imaging.  A novel self-supervised learning method will be introduced, which can uncover hidden physical principles within the latent space. Preliminary investigations have revealed an ?Auto-Linear? phenomenon, where features from different physical domains automatically correlate linearly. This discovery allows for simultaneous forward and inverse modeling, significantly enhancing performance in imaging tasks that lack paired data. Efficient wave simulations will also be developed. They will involve high-order methods for effective forward propagation and backpropagation, with explicit Runge-Kutta time stepping for non-stiff problems and A-stable implicit Runge-Kutta time stepping for stiff problems, combined with Fourier or spectral element spatial approximations. Furthermore, integral-based methods with asymptotic short-time Green's function will be developed for problems with point-source-like source functions. This configuration is designed to simulate wave propagation with high accuracy and minimal sampling requirements in both time and space, thus avoiding the pollution effect and promising a leap in simulation efficiency and quality.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2505986","Collaborative Research: Unified Neural Operator (UNO): Towards Trustworthy Operator Learning for Scientific Applications","DMS","COMPUTATIONAL MATHEMATICS","09/01/2025","08/06/2025","Varun Shankar","UT","University of Utah","Standard Grant","Ludmil T. Zikatanov","08/31/2028","$250,000.00","Akil Narayan","shankar@cs.utah.edu","201 PRESIDENTS CIR","SALT LAKE CITY","UT","841129049","8015816903","MPS","127100","9263, 079Z, 075Z","$0.00","Modern scientific challenges?from predicting complex fluid flows to modeling plasma behavior in fusion reactors?demand computationally efficient, trustworthy surrogates that can rival traditional numerical solvers while harnessing the power of artificial intelligence. Scientific machine learning (SciML), identified as a core technology for AI, offers immense potential for surrogate modeling in both data?rich and data?scarce situations; of particular interest is the field of operator learning. However, current operator learning frameworks lack unified theoretical foundations, robustness guarantees, and scalable training methods, which limit their adoption in high-stakes applications. The Unified Neural Operator (UNO) considered in this project will fill this gap by embedding all operator learning techniques into a unifying framework, marrying the mathematical rigor of traditional methods with the expressivity of modern AI. By delivering certifiable, interpretable AI?driven surrogates, UNO advances Presidential priorities in artificial intelligence and nuclear energy?supporting both next?generation AI capabilities and efficient modeling of magnetohydrodynamic systems critical for fusion energy?while fulfilling NSF?s mission ?to promote the progress of science; to advance the national health, prosperity, and welfare; and to secure the national defense?<br/><br/>Within SciML, operator learning has shown tremendous potential as a powerful tool for creating surrogate models, leading to a bevy of deep machine learning (ML)-based operator learning techniques known as ?neural operators?. However, poorly-understood robustness characteristics, lack of explainability and interpretability, and the sheer variety of such approaches make it challenging for practitioners to choose the appropriate methods for different tasks, especially in the context of scientific applications. This project tackles these urgent challenges through the inception of a new computational framework: the Unified Neural Operator (UNO). UNO distills neural operators down into three essential components: an input encoder, a set of basis functions for the output space, and a projection operator. The work will (1) provide a mathematical formalism that both encompasses existing neural operators and allows us to generate novel architectures that target specific tasks and problems; (2) provide algorithms for scalable and adaptive training and inference, allowing UNO to adapt to local solution features and to tackle high-dimensional data efficiently in data-rich regimes; (3) provide a robust theoretical foundation in the form of universal approximation theorems, error estimates, and a guiding theoretical framework for robust sampling and adaptivity. The UNO framework also allows for automatic and natural uncertainty quantification capabilities of existing and new neural operators. In data-poor situations, the UNO framework preserves accuracy by analytically preserving physics, thereby making it well-suited to both in situ and ex situ surrogate modeling in scientific applications. The challenging applications targeted by this project include turbulent, multiscale, and multiphysics fluid flow problems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2514001","Computation of Non-symmetric Tensor Decomposition: Theory, Algorithms and Applications","DMS","COMPUTATIONAL MATHEMATICS, MSPA-INTERDISCIPLINARY","09/01/2025","07/30/2025","Zequn Zheng","LA","Louisiana State University","Standard Grant","Ludmil T. Zikatanov","08/31/2028","$239,806.00","Hongchao Zhang","zzheng@lsu.edu","202 HIMES HALL","BATON ROUGE","LA","708030001","2255782760","MPS","127100, 745400","9150, 9263","$0.00","With the surge of artificial intelligence (AI) and data science, increasing data and parameters of machine learning models come with high-order structures, also known as tensors. Tensor decomposition (TD) is commonly used to compress the data and analyze the underlying information. This project aims to develop both theoretically justified and practically efficient TD algorithms, as well as algorithms for low-rank tensor approximations and tensor completions. Such tools have wide applications in data science, statistics, engineering, and industry, including multi-view learning, convolutional neural networks (CNNs), and large language models (LLMs). The project also includes training of undergraduate and graduate students studying in scientific computing and data science.<br/><br/>This project studies a range of challenging research tasks centered on the computation and analysis of tensor decompositions. A major goal is to overcome limitations of existing algebraic-based and optimization-based methods, which are either computationally expensive or theoretically insufficient.  The tensor decomposition algorithms utilized in this project are based on generating polynomials to reformulate and understand the non-symmetric TD. The developed TD algorithms will have the following advantages: computationally efficient in terms of speed and memory, easy to implement in linear algebra friendly software, have theoretical guarantees, can be used to detect certain tensor ranks, and support higher tensor ranks. For generic tensors satisfying certain rank bounds, the approach in this project is to construct the TD by solving linear equations. When the tensor rank is higher, the problem is reformulated as a nonlinear optimization with linear constraints and can be solved using modern optimization methods. The generating polynomial-based framework can also be utilized to reformulate and solve low-rank tensor approximation and tensor completion problems, which are widely used in data science applications.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513106","Robust and efficient high-order algorithms for fluid dynamics simulations: structure-preserving methods and optimization-based limiters","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","09/01/2025","07/23/2025","Chen Liu","AR","University of Arkansas","Standard Grant","Jodi Mead","08/31/2028","$210,000.00","","chenl@uark.edu","1125 W MAPLE ST STE 316","FAYETTEVILLE","AR","727013124","4795753845","MPS","125300, 127100","9150, 9263","$0.00","The Navier-Stokes (NS) equations are fundamental mathematical models with a wide range of applications in computational math and various engineering fields. The major objective of this project is to explore high-order accurate structure-preserving methods for various NS equations, including compressible, incompressible, and compressible flow with incompressible limit. The outcomes have potential applications in aeronautics and astronautics, petroleum industries for enhancing oil recovery, and possibly extended to benefit computational materials science. In addition, this project will provide valuable research opportunities for graduate and/or undergraduate students in computational mathematics.<br/><br/>Designing high-order methods for NS equations that preserve fundamental principles such as conservation, bounds, and energy law, while ensuring efficiency for large-scale simulations, presents significant challenges. The current state of high-order accurate structure-preserving numerical methods for NS equations is still far from being practically satisfactory. The PI will explore high-order structure-preserving algorithms for various NS equations, emphasizing efficiency and robustness in simulating real-world problems. For compressible NS, a novel approach combining large-scale non-smooth optimization with discontinuous Galerkin methods will be applied to construct invariant-domain-preserving schemes. This methodology is extensible to other methods, such as finite volume and finite difference by incorporating constraints on cell averages and point values. For incompressible NS, the PI will explore both theoretical analysis and algorithm design on splitting methods. The outcomes are crucial for designing reliable simulators and can be extended to other fields, such as phase-field equations. High-order asymptotic-preserving methods for compressible flow and incompressible limit will be explored.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513118","Collaborative Research: Acceleration and Preconditioning Methods for Deep Learning","DMS","COMPUTATIONAL MATHEMATICS","09/01/2025","07/01/2025","Yuanzhe Xi","GA","Emory University","Standard Grant","Ludmil T. Zikatanov","08/31/2028","$325,000.00","","yxi26@emory.edu","201 DOWMAN DR NE","ATLANTA","GA","303221061","4047272503","MPS","127100","9263, 079Z, 075Z","$0.00","The remarkable progress of Artificial Intelligence (AI) in recent years is starting to greatly influence research across a wide range of disciplines. As Numerical Linear Algebra plays a crucial role in Deep Learning models, this trend presents unprecedented opportunities for experts in numerical analysis and linear algebra to contribute to ongoing AI research. This proposal represents a step toward capitalizing on this opportunity. The focus of the proposed work is not on applying AI to solve a specific problem, but rather on enhancing AI methods themselves by exploiting insights from numerical methods to optimize the Deep Learning process. This process is time-consuming, energy-intensive, resource-demanding, and overall very costly. Therefore, any improvements that can speed up the process are likely to have a significant impact. The investigators will leverage their experience in numerical methods to develop a number of techniques for accelerating the training of large AI models.<br/><br/>The project aims to develop techniques that exploit both accelerators and preconditioners to speed up iterative procedures used in training deep learning models.  The same combination of preconditioning and acceleration techniques is central to the effectiveness of iterative solution methods for linear systems. Acceleration methods such as Anderson/Pulay mixing or the Reduced Rank Extrapolation method, among others, have had immense success across various fields of science and engineering. However, in the context of deep learning, these methods face challenges, particularly since they were not developed for stochastic sequences common in deep learning.  The team will investigate the relationship between mini-batching, a technique used for sampling subfunctions in stochastic methods, and its impact on both the convergence speed and the accuracy of the resulting models. Simple diagonal preconditioning methods have already been incorporated into optimization techniques in deep learning.  The research team will explore more advanced preconditioning methods based on various approximations to the Fisher information matrix, a matrix that measures the amount of information that the observed data provides about the parameters. It has been shown that replacing the Hessian in second order methods by the Fisher matrix yields a more meaningful form of scaling of the variables, leading to better convergence and generalization. The investigating team will consider various methods for obtaining inexpensive approximations of the Fisher matrix and for combining them with accelerators. The proposed work is expected to benefit research in ""scientific machine learning"" by promoting participation of numerical linear algebra specialists in AI research. The PIs plan on several specific activities to promote the dissemination of knowledge in machine learning, such as writing a book on the topic of numerical methods in machine learning or offering tutorials and short courses. These activities will stimulate the interest of students in a field of increasing importance and that it will help with the immersion of those students from other areas, e.g., mathematics, into data-related disciplines.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2505605","Leveraging Geometric Structure in Learning Dynamical Systems","DMS","COMPUTATIONAL MATHEMATICS, CDS&E-MSS","09/01/2025","07/15/2025","John Harlim","PA","Pennsylvania State Univ University Park","Standard Grant","Jodi Mead","08/31/2028","$519,851.00","Daning Huang","jharlim@psu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","127100, 806900","079Z, 9263, 075Z","$0.00","Fluid-structural interactions arise in many engineering applications, such as large-scale offshore wind turbines and urban air mobility vehicles. One of the key challenges in modeling such dynamical interactions is to identify the appropriate mathematical representation that respects the physical constraints that are encoded in the observed data. The goal of this project is to model such dynamical interactions with a novel machine learning algorithm that incorporates the geometrical constraints that can be revealed from the data. The key scientific product of this research is a stable and accurate Artificial Intelligence (AI) model for long-time dynamical predictions under external disturbances. In the urban air mobility vehicles application, for example, one is interested in predicting the structural deformation with the strong coupling to the unsteady aerodynamics. Another important byproduct of this research is the reduction of the high energy consumption in training and prediction using AI models. Besides the engineering applications, this project is likely to generate new mathematical questions, fostering interactions between computational mathematics and data-enabled science. This project will contribute to the NSF's mission of advancing STEM through the training of graduate students in an interdisciplinary research training environment to be proficient in mathematical analysis, applied differential geometry, statistical learning, and scientific computing.<br/><br/>The goal of the project is to reveal geometric structures encoded in the measured time series of the dynamics, i.e., the data manifold, to enable compact reduced-order modeling for scalable numerical simulations. The proposed approach is to develop provably convergent computational algorithms to identify vector fields of dynamical systems under the data manifold. The focus is on two hypotheses: under the manifold assumption and under a more refined structural constraint, such as Lie groups. The proposed project is to: 1) Develop an operator-valued kernel that ensures the vector fields lie on the tangent bundle in the limit of large data. The underlying vector field will be identified through standard regression algorithms with the novel operator-valued kernel and extend it to noisy measurements that perturb the time series to be slightly off the manifolds. 2) Devise a normal correction to the standard Euler scheme that approximates the exponential maps of the vector fields induced by the dynamics to ensure the robustness of the proposed model on nontrivial geometry. 3) Devise a data-driven Lie group analysis, in the form of a constrained optimization, to identify potential Lie group structure from the data. 4) Extract scaling laws from the identified Lie groups, which represent the equivariance among dynamics at different operating conditions. With such a scaling law structure, the reduced order model is represented by a manifold structure that can be decomposed into a product of fiber bundles and base space. Here, the fiber bundle represents the scaling laws, while the reduced-order model can be identified as a vector field on the base space. The effectiveness of these approaches will be demonstrated numerically on a series of dynamics with increasing complexity, including the academic test examples with inertial manifold structure (e.g., Kuramoto-Sivashinsky and Korteweg-de Vries equations), to real-world fluid-structural interaction problems with limit cycle oscillations and nontrivial scaling law structures.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2514152","Fast and Robust Algorithms in Cryo-Electron Microscopy Imaging","DMS","COMPUTATIONAL MATHEMATICS","09/01/2025","07/17/2025","Yunpeng Shi","CA","University of California-Davis","Standard Grant","Yuliya Gorb","08/31/2028","$250,000.00","","ypshi@ucdavis.edu","1850 RESEARCH PARK DR STE 300","DAVIS","CA","956186153","5307547700","MPS","127100","9263","$0.00","Cryo-electron microscopy (cryo-EM) has revolutionized the way scientists uncover the 3D structure of proteins, making critical contributions to our understanding of viruses, cancer, and neurodegenerative diseases. However, despite its transformative potential, cryo-EM is limited by the immense computational cost required to process the large, noisy, and unstructured image data it generates. This project aims to overcome these barriers by developing robust, efficient, and theoretically guaranteed algorithms for reconstructing 3D molecular structures from raw cryo-EM data. These algorithms will allow researchers to extract higher-resolution structures more quickly and reliably, accelerating scientific discoveries in biomedicine and supporting translational science in areas like drug development. Graduate student training will also be included in this project. <br/><br/>Technically, the project addresses two critical stages of the cryo-EM pipeline: image alignment and molecular orientation estimation. For image alignment, the project will develop new shift-robust and deformation-tolerant metrics to improve classification and registration of raw 2D images. For orientation estimation, the project will develop a novel, decentralized message-passing algorithm to synchronize noisy and partially corrupted pairwise measurements of euclidean motions of 2D images and 3D molecules. By leveraging tools from harmonic analysis, optimal transport, and Riemannian optimization, the proposed methods will significantly improve the speed, accuracy, and transparency of current reconstruction techniques. These innovations will be implemented as open-source software, broadly benefiting applications in biomedical imaging, computer vision, and robotics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513112","Accuracy Controlled Optimization in Physics Informed Deep Learning","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","08/15/2025","07/07/2025","Wolfgang Dahmen","SC","University of South Carolina at Columbia","Standard Grant","Ludmil T. Zikatanov","07/31/2028","$249,949.00","Zhu Wang","dahmen@math.sc.edu","1600 HAMPTON ST","COLUMBIA","SC","292083403","8037777093","MPS","125300, 127100","075Z, 079Z, 9150, 9263","$0.00","Deep learning excels in error-tolerant applications with abundant data, but struggles in scientific settings where accuracy is critical, such as solving physics-based equations with limited observations. The core challenge lies in non-convex optimization, where traditional training lacks guarantees of reliability. This project develops a rigorous framework to control optimization accuracy by aligning iterative updates with mathematically sound ?ideal descent paths? derived from the underlying physics. By dynamically adapting model complexity and certifying each step?s accuracy, we aim to overcome the unpredictability of non-convex optimization, enabling trustworthy artificial intelligence (AI) for high-stakes applications in engineering, medicine, and beyond. This work provides foundational tools to ensure AI-driven scientific predictions are both accurate and actionable.<br/><br/><br/>This project addresses the fundamental challenge of uncertain optimization success in physics-informed deep learning. Non-convex objective landscapes severely impede on accuracy control when dealing with error-sensitive problems, especially those involving partial differential equations (PDEs). The proposed approach establishes a mathematically grounded framework that enforces optimization accuracy control through residual-based loss functions that are ?variationally correct?. This means that the loss is always proportional to the current approximation error with respect to model-compliant norms derived from variational formulations of the underlying PDE model. This enables a posteriori error control, which is crucial in a new methodology based on an ?ideal descent path? paradigm. This reinterprets standard training as a controlled ?perturbation? of a provably convergent convex process in an ambient Hilbert space, given by the variational formulation. Each iterative step is monitored to meet carefully calibrated error tolerances anchored to the infinite-dimensional reference problem. Adaptive a posteriori error criteria dynamically trigger network expansions via natural gradient flows when required by precision thresholds. This prevents over-parameterization and guarantees physically valid solutions. A systematic integration of theoretically justified optimization, physics-compliant error control, and adaptive architecture growth gives rise to the first end-to-end framework for certifiably accurate physics-informed learning. The resulting methodology demonstrates transformative potential for high-stakes applications?from inverse problems to multiscale modeling?where conventional deep learning lacks reliability guarantees. By advancing the mathematical foundations of scientific machine learning, the project delivers practical tools for domains requiring rigorous uncertainty quantification.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2529303","MATH-DT: Mathematical underpinnings of population-based cardiac digital twins","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS, MSPA-INTERDISCIPLINARY","08/15/2025","08/05/2025","Karli Gillette","UT","University of Utah","Standard Grant","Yuliya Gorb","07/31/2028","$594,001.00","Akil Narayan","karli.gillette@utah.edu","201 PRESIDENTS CIR","SALT LAKE CITY","UT","841129049","8015816903","MPS","125300, 127100, 745400","9263","$0.00","Cardiovascular diseases are the leading cause of death in the United States, with arrhythmic heart disease and heart failure as common final pathways. The engineering and design of therapies, devices, and drugs to combat these diseases is challenging due to a limited understanding of both patient-specific and population-level characteristics of cardiac anatomy and physiology. A promising approach for supporting the development of precision medicine in addressing these challenges is the simulation-based, data-driven paradigm of cardiac digital twins (CDTs). This project makes core advances in the science and application of CDTs by leveraging mathematical and statistical foundations to enhance the trustworthiness of CDT simulations. This project will then demonstrate the potential of CDTs in clinical settings by deploying them on state-of-the-art cardiac simulation models and utilizing real-world clinical data.<br/><br/>The project aims will be achieved through three technical tasks. The first task builds a framework for assessing and constructing CDTs through statistical inference of virtual heart populations (VHPs) using novel data sources, optimization-based calibration of simulation models, and the introduction of customized methods for surrogate modeling and quantification of aleatoric and epistemic uncertainty. The second task involves developing new exploration-exploitation meta-algorithms to enhance the predictive capabilities of CDTs through innovative paradigms for ensemble learning, model management, and computational budget allocation. The foundational algorithmic advances from the first two tasks will be applied to establish a new holistic CDT framework in the third task. This new framework integrates models across cellular, tissue, and organ-level scales with multimodal and multifaceted clinical data. Exploratory scientific tasks using this new CDT and VHP framework include the development of VHPs for populations affected by specific classes of diseases and the investigation of population-level progression mechanisms that lead to cardiac disease.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513346","Computational Tools for Active Suspensions","DMS","COMPUTATIONAL MATHEMATICS","08/15/2025","07/21/2025","Shravan Veerapaneni","MI","Regents of the University of Michigan - Ann Arbor","Standard Grant","Yuliya Gorb","07/31/2028","$370,000.00","","shravan@umich.edu","1109 GEDDES AVE STE 3300","ANN ARBOR","MI","481091015","7347636438","MPS","127100","9263","$0.00","This project will develop advanced computational tools to simulate and optimize the locomotion in a fluid medium of microscopic particles, such as bacteria or specially-designed micro-robots. Understanding how these microswimmers move is crucial for a wide range of applications, from improving our understanding of how biological systems function at the cellular level to creating innovative technologies. For instance, this research could lead to breakthroughs in targeted drug delivery, where microscopic robots deliver medicine precisely where it is needed in the body, or in developing new ways to transport materials within lab-on-a-chip or organ-on-a-chip devices. By making these simulations more efficient and accurate, this project aims to provide fundamental insights that will benefit fields such as biotechnology and materials science, ultimately contributing to scientific discovery and technological advancements that impact people's daily lives. <br/><br/>Despite advancements in modeling and simulations of microswimmers, performing control and optimization in complex environments is still daunting, primarily owing to the lack of computational tools that scale to realistic problem sizes and work on arbitrary moving geometries. The primary goal of this project is to develop accurate, computationally efficient, and scalable numerical algorithms necessary for large-scale simulations, as well as shape and functional optimization of microswimmers. The research will address key computational difficulties, including the accurate evaluation of near-singular integrals and periodization schemes in three dimensions that support adaptivity. Adjoint formulations will be derived for various practical scenarios, such as microswimmers in confined flows or in the presence of other active or passive particles. Building on existing work with integral equation methods, the project will specifically develop adjoint-based shape optimization schemes, new high-order nearly-singular integration schemes to simulate flows through confined geometries, and spectrally-accurate, adaptive three-dimensional periodization schemes that can be accelerated by existing fast N-body algorithms.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2438074","CAREER: Quantum Simulation with Unbounded Operators: Algorithms, Analysis, and Applications","DMS","QISET-Quan Info Sci Eng & Tech, COMPUTATIONAL MATHEMATICS","08/01/2025","08/14/2025","Di Fang","NC","Duke University","Continuing Grant","Yuliya Gorb","07/31/2030","$127,246.00","","di.fang@duke.edu","2200 W MAIN ST","DURHAM","NC","277054640","9196843030","MPS","105Y00, 127100","7203, 1045, 9263, 9251","$0.00","Simulation of quantum dynamics, also known as Hamiltonian simulation, served as the original motivation for quantum computers and remains a core task in quantum computing today. It has wide-ranging potential in fields such as quantum physics, quantum chemistry, and biological molecular dynamics. This project aims to advance quantum simulation by addressing challenges posed by so-called unbounded operators, which frequently arise in scientific and engineering context due to the discretization of differential operators. By tackling these issues, the project seeks to enhance computational techniques, deepen theoretical understanding, and broaden the practical impact of quantum computing while strengthening its connections with mathematics. Graduate and undergraduate students involved will gain valuable interdisciplinary training at the intersection of mathematics and quantum information science. <br/><br/>This project focuses on developing innovative quantum algorithms and advancing mathematical frameworks for quantum simulation with unbounded Hamiltonians. Key contributions include the development of quantum algorithms based on techniques such as Trotterization, randomization, Linear Combination of Unitaries, and Magnus expansion. These methods aim to overcome computational challenges and significantly accelerate the application of quantum simulation across various fields. Rigorous numerical analysis will be integrated to estimate the quantum complexity and provide performance guarantees for these algorithms. Special attention will be given to understanding and constructing superconvergence, particularly in relation to spatial discretization, leveraging mathematical tools from continuous and discrete microlocal analysis. By applying these advancements to real-world applications, this project will contribute to scalable quantum computing solutions and establish new benchmarks for algorithmic efficiency and accuracy.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2440040","CAREER: Randomized Iterative Methods for Corrupted Data, Constrained Problems, and Compressed Updates","DMS","COMPUTATIONAL MATHEMATICS","08/01/2025","02/10/2025","Jamie Haddock","CA","Harvey Mudd College","Continuing Grant","Jodi Mead","07/31/2030","$65,505.00","","jhaddock@g.hmc.edu","301 PLATT BLVD","CLAREMONT","CA","917115901","9096218121","MPS","127100","1045","$0.00","The scientific goal of this CAREER project is to develop theoretically-founded, randomized iterative methods for problems common in numerical linear algebra (NLA) and optimization, and extend their application and analysis to face a new and important set of challenges. The incredible growth in size and complexity of data sets commonly analyzed has made it imperative to have randomized computational techniques that are robust to adversarial error, incorporate or are adaptable to natural problem constraints, and can be applied in settings in which both the number and dimension of data are massive.  This project additionally provides opportunities for students to engage in cutting-edge research, and supports creation of materials for an advanced undergraduate-level modern numerical linear algebra course to be used at Harvey Mudd College (HMC) and beyond.  This course will feature significant curricular research projects which align with the technical directions identified in this project; descriptions of potential course project topics will be released with the public course materials.  The project will additionally provide vertically-integrated mentorship opportunities for visiting graduate students, HMC undergraduates, and high school students through HMC?s federally funded Upward Bound (UB) program.  Finally, the project will support an annual professional development workshop for early career participants interested in research mentorship at primarily undergraduate institutions.<br/><br/>The intellectual merit of this CAREER project is the development and analysis of a suite of randomized iterative methods for problems with devastating adversarial corruption, problem constraints, and extremely large data dimension.  The project will focus specifically on three main research thrusts: (1) Developing and analyzing corruption-robust variants of randomized iterative methods in numerical linear algebra for least-squares regression, and generalizing these analyses to first-order methods in numerical optimization for a more general class of convex optimization problems. (2) Analyzing the iterative behavior of common combinatorial and numerical iterative methods for randomly sketched and subsampled regression problems with nonnegative and related constraints, and using these analyses to develop efficient randomized iterative methods for such problems.  (3) Extending the application of randomized iterative methods to problems in which both the number and size of data may be massive by developing provably effective randomly compressed and sparsified iterative updates. Open-source software implementations of the developed and analyzed methods will accompany the work completed under each of the above thrusts.  Additionally, this work will be distributed both in formal peer-reviewed journal and conference submissions, and in educational resources for students.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513699","Versatile and Scalable Sampling via Geometric Methods, Optimization, and Numerical Analysis","DMS","COMPUTATIONAL MATHEMATICS","08/01/2025","07/03/2025","Molei Tao","GA","Georgia Tech Research Corporation","Standard Grant","Ludmil T. Zikatanov","07/31/2028","$220,003.00","","mtao@gatech.edu","926 DALNEY ST NW","ATLANTA","GA","303186395","4048944819","MPS","127100","9263","$0.00","This project considers a core computational problem, namely, how to draw samples from a high-dimensional probability distribution. Being a fundamental task in science and engineering, the sampling problem involves generating representative examples of a stochastic object, and the ability to do so enables the modeling, simulation, and inference that are essential for understanding complex systems with uncertainties. Because of its importance, sampling is a classical problem that has been considered in statistics, physical sciences, and social sciences for decades. Moreover, it recently received renewed interest due to the exploding number of applications in data sciences, machine learning, and artificial intelligence, which motivates the research. The project aims to provide a better understanding of the existing practice and guide the construction of new methods that scale better. To address such an urgent need, this project will develop innovative and versatile sampling algorithms, together with analytical tools that can facilitate their design and certify their performance.<br/><br/>More precisely, the intellectual merit of this project is to propose, in a principled and mathematically provable way, samplers that scale well (with dimension, condition number, etc.) and work in versatile setups (e.g., sampling from Euclidean space, sampling from a constrained domain, and sampling difficult multimodal distribution). This goal will be enabled via a synergy of three strategies. The first is to view a class of sampling algorithms as appropriate time discretizations of certain underlying dynamics in continuous time. This perspective allows the algorithmic design and analysis to be modularized into those for the continuous dynamics and those for the discretization, thus not only enabling an exploitation of profound mathematical tools but also helping better identify and focus on the true performance bottleneck. The second strategy is to leverage rich tools in optimization and extrapolate them to the sampling setup. It also includes a modern perspective, which is to view sampling as optimization in the infinite-dimensional space of probability distributions. The third strategy is to utilize geometric ideas, which not only lead to a deeper understanding of various sampling dynamics but also facilitate sampling from constrained distributions. Educational activities will be closely integrated with the research.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2512392","Nonlinear Geometric PDEs: Modeling, Analysis and Approximation","DMS","COMPUTATIONAL MATHEMATICS","08/01/2025","07/18/2025","Ricardo Nochetto","MD","University of Maryland, College Park","Standard Grant","Yuliya Gorb","07/31/2028","$420,000.00","","rhn@math.umd.edu","3112 LEE BUILDING","COLLEGE PARK","MD","207425100","3014056269","MPS","127100","9263","$0.00","Understanding slender structures is one of the great unresolved challenges of modern science and technology. Such structures permeate biological systems (flowers, leaves, tissue, and active matter), materials science (programmable materials), robotics (deployable devices), and biomedical engineering (soft robotics). These problems are typically lower-dimensional and susceptible to geometric effects such as metric constraints, length and area constraints, and curvature. Corresponding models are thus governed by geometric partial differential equations (PDEs), which, much like nature, are nonlinear. Fabrication of slender materials is time-consuming, expensive, and often erratic, which makes the development of predictive computational tools of paramount importance in engineering and science. The numerical treatment of nonlinear geometric PDEs must cope with the dynamic deformation of geometries, the presence of strong nonlinearities, and the development of self-penetrating structures and topological changes.<br/><br/>Central to this proposal is the essential role of liquid crystals (LCs) as key constituents in the fabrication and actuation of slender structures. Models of nematic LC films are used to describe morphogenesis (shape formation) and active matter. Prestrained plates and LC networks are used to comprehend the shapes of flowers and leaves as well as to design and actuate programmable materials. Moreover, approximating local and nonlocal geometric problems, governed by fully nonlinear PDEs and singular integro-differential operators, constitutes a formidable yet distinct computational challenge. This research program combines reduced-order modeling (using differential geometry), structure-preserving algorithms, and efficient computation, and is supplemented by analysis (asymptotics and G-convergence). This project consists of three intertwined thrusts involving modeling, analysis, and approximation of several nonlinear geometric PDEs and nonlocal equations. The research is suitable for student training in exciting, mathematically and computationally challenging, and practically relevant areas of contemporary research, and is conducted together with former students, postdocs, and collaborators, who visit regularly.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513092","Numerical methods for miscible displacement in coupled 3D-1D domains","DMS","COMPUTATIONAL MATHEMATICS","08/01/2025","07/18/2025","Beatrice Riviere","TX","William Marsh Rice University","Standard Grant","Yuliya Gorb","07/31/2028","$333,000.00","","Beatrice.Riviere@rice.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","MPS","127100","9263","$0.00","Novel computational methods will be developed and analyzed for modeling coupled flow and transport phenomena occurring in networks of one-dimensional lines embedded in a three-dimensional porous domain. The scientific outcome is a foundational basis for models used in biotechnology and in geosciences: for instance, for the modeling of organ perfusion, the modeling of embolization and drug delivery in damaged, unhealthy organs, and the modeling of flow of solvent mixed with resident fluid in fractured subsurface for applications. The computational models are efficient thanks to the reduced cost of one-dimensional solutions. The numerical analysis of the methods provides a guaranteed accuracy of the computational models.<br/><br/>One outcome of the project is the convergence analysis of a numerical scheme that employs the interior penalty discontinuous Galerkin methods in space and backward Euler in time for solving the miscible displacement problem in coupled domains of codimension equal to two. The numerical analysis is non-standard because of the low regularity of the weak solution and the lack of consistency of the scheme. Additional difficulties for the derivation of error bounds include the coupling between flow and transport via nonlinear coefficients and the unboundedness of the diffusion-dispersion matrix in the three-dimensional concentration equation. Depending on the assumptions on the data, convergence is obtained by the derivation of a priori error estimates or by a compactness argument. Via a python-based implementation, robustness and accuracy of the schemes are investigated for several numerical and physical scenarios, such as evaluating the effect of different time step sizes for pressures and concentrations, and investigating the amount and stability of the overshoot and undershoot phenomena. Another outcome of the project is the formulation and analysis of multinumerics schemes that combine finite element methods and two variants of discontinuous Galerkin methods for single-phase flows in coupled three-dimensional domains and metric graphs. Two different treatments of the bifurcation conditions are introduced. A priori error estimates are derived. Robustness and accuracy of the multinumerics schemes are numerically investigated. Of particular interest is the verification of the Neumann-Kirchoff conditions as well as how the schemes perform on networks with increasing complexity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513857","Numerical scheme-guided Deep Learning for scientific computing","DMS","COMPUTATIONAL MATHEMATICS","08/01/2025","06/11/2025","Yen-Hsi Tsai","TX","University of Texas at Austin","Standard Grant","Jodi Mead","07/31/2028","$399,998.00","","ytsai@math.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","127100","160Z, 075Z, 079Z, 9263","$0.00","In recent years, driven by the impressive advancement in Artificial Intelligence, extremely powerful GPUs and software have become available. Meanwhile, with the increasing availability and importance of drones and robotic devices, the need for efficient algorithms to optimally control these devices has become more pressing. This project will develop novel algorithms with solid mathematical theories, bringing Artificial Intelligence to drones and robotic devices for mission-critical tasks, and pushing the frontier of scientific computing and simulations. In addition to drones and robotic devices, research outcomes will expand simulation capacity for a range of application areas, including nuclear fusion research. Regarding education and human resource development, research outcomes will be integrated into graduate-level courses and a new course series for undergraduates emphasizing the mathematical and numerical analytical foundations for machine learning. <br/><br/>This project aims to develop and analyze innovative algorithms that integrate classical numerical schemes and the Deep Learning paradigm, including its software-hardware ecosystem, to address complex scientific computing challenges. By leveraging the flexibility of neural networks, the stability and convergence properties of numerical methods, and the computational power of modern GPUs, the proposed framework will tackle problems in high-dimensional, fully nonlinear differential equations, long-time simulation of Hamiltonian systems, and boundary integral equations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2527651","Conference: 5th Biennial Meeting of SIAM Pacific Northwest Section","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","08/01/2025","07/17/2025","Heather Wilber","WA","University of Washington","Standard Grant","Yuliya Gorb","01/31/2026","$15,000.00","","hdw27@uw.edu","4333 BROOKLYN AVE NE","SEATTLE","WA","981951016","2065434043","MPS","126600, 127100","7556, 9263","$0.00","The University of Washington (Seattle, Washington) will host the 5th Biennial Pacific Northwest Section of the Society for Industrial and Applied Mathematics (SIAM) meeting from October 3-5, 2025. This vertically integrated meeting will bring together individuals from undergraduates to distinguished researchers at universities, national labs, and industry mainly from the Pacific Northwest region. These conference participants, working at the forefront of applied and computational mathematics, have expertise in many of the key priority areas of the NSF Division of Mathematical Sciences (DMS). The goal of the meeting is to facilitate the advancement of knowledge in cutting edge areas of applied mathematics and computational mathematics for the benefit of both the Pacific Northwest region and the US more broadly.<br/><br/>Themes for the meeting will include sessions in numerical linear algebra, optimization, numerical methods for solving partial differential equations, image processing, inverse methods and data assimilation, high performance computing, numerical modeling and simulation in the geosciences. This year in particular, the meeting will showcase particular expertise in the Pacific Northwest on hazards modeling, including hazards from earthquakes, tsunamis, debris flows and volcanic activity. A website listing conference activities and details can be found at https://sites.google.com/site/siampnwsection/biennal-meeting.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513122","Optimal O(N) Helmholtz and Eigenvalue Solvers for Multi-Domain Problems","DMS","COMPUTATIONAL MATHEMATICS","08/01/2025","06/30/2025","William Henshaw","NY","Rensselaer Polytechnic Institute","Standard Grant","Ludmil T. Zikatanov","07/31/2028","$220,000.00","Donald Schwendeman, Jeffrey Banks","henshw@rpi.edu","110 8TH ST","TROY","NY","121803590","5182766000","MPS","127100","9263","$0.00","The design and optimization of many important engineering devices, seismic exploration for oil or gas, or non-intrusive testing of aircraft parts are a few of the many applications that rely on fast computer simulation of certain so-called Helmholtz problems. Helmholtz problems are notoriously difficult to solve computationally, and there has been much research into finding better algorithms for this key and essential task. Despite this past research, there remains room for improvement. The benefit of improved algorithms could be, for example, the creation of advanced optical meta-materials that can outperform traditional optical devices used in civilian and military applications, e.g., being lighter, using less power, or operating in multiple regimes. This proposal will develop new fast algorithms for solving Helmholtz problems. The algorithms are optimal in the sense that the number of operations needed to solve the problem is proportional to the number of degrees of freedom (number of unknowns). The breakthrough is based on viewing the Helmholtz problem as the time-periodic solution of an associated wave propagation problem using the recently developed WaveHoltz algorithm.<br/><br/>Time-periodic problems and associated eigenvalue problems arise in a wide range of applications in engineering and applied sciences involving systems exhibiting time-harmonic behavior. This proposal aims to address problems of this type by developing new and efficient high-order accurate algorithms for solving large-scale Helmholtz and eigenvalue problems for multi-domain and multi-physics applications. Numerical schemes for these problems will be based on an extended WaveHoltz algorithm for Helmholtz problems, along with a new EigenWave algorithm for eigenvalue problems.  WaveHoltz computes solutions to the Helmholtz problem by filtering solutions of a related time-domain wave equation, thus avoiding the need to invert a large, indefinite matrix. The EigenWave algorithm follows a similar approach and can compute eigenvalues of an elliptic operator anywhere in the spectrum without inverting an indefinite shifted matrix. In addition to the extension of WaveHoltz to complex geometry on overset grids, the basic WaveHoltz approach will be accelerated using large-time-step implicit time-stepping at an O(N) cost per iteration (N being the number of grid points), and by deflation using eigenmodes (or approximate coarse-grid eigenmodes) computed with the new EigenWave algorithm. Dispersive (pollution) errors will be ameliorated using high-order accurate spatial approximations. WaveHoltz will also be extended to dispersive wave propagation problems as well as multi-domain problems that couple different physics or materials in different domains, coupled with high-order accurate interface conditions. For open domain problems (e.g. scattering problems) the new algorithms will be coupled to advanced radiation boundary conditions.  The development of the proposed algorithms and simulation capabilities will lead to a new and transformative approach for solving large-scale Helmholtz and eigenvalue problems, and will provide high-performance open source software tools to the community.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513394","Finite Elements in the Quantum Era","DMS","QISET-Quan Info Sci Eng & Tech, COMPUTATIONAL MATHEMATICS","08/01/2025","08/01/2025","James Adler","MA","Tufts University","Standard Grant","Yuliya Gorb","07/31/2028","$450,000.00","Xiaozhe Hu, Seulip Lee","jadler3@gmail.com","80 GEORGE ST","MEDFORD","MA","021555519","6176273696","MPS","105Y00, 127100","7203, 9263, 7928","$0.00","Quantum scientific computing, a rapidly growing interdisciplinary field, integrates classical numerical methods with quantum technologies to tackle challenges across physics, chemistry, biology, engineering, industrial applications, and beyond, and has the potential to vastly outperform classical computers in solving such problems. In this project, the overall goal is to develop, analyze, and implement quantum and quantum-inspired numerical algorithms that leverage both well-studied classical methods and state-of-the-art quantum techniques to overcome bottlenecks in numerical simulations of complex problems, such as ""the curse of dimensionality,"" which restricts the development of efficient methods and solvability for problems in high-dimensional space. The quantum methods developed in this work have the potential to translate into advancements in many practical applications, e.g., machine learning, data science, optimization, and electric grid simulations.  All techniques will be implemented in an open-source software package and will be made available to the scientific community.<br/><br/>The main focus of this project is to develop, analyze, and implement quantum finite-element methods (FEMs) for solving partial differential equations (PDEs).  While the discretization steps of FEMs can be implemented optimally on classical computers, solving the resulting large-scale and often ill-conditioned linear systems remains the most computationally intensive step. To overcome this challenge, the project explores the use of quantum algorithms and investigates the conditions under which quantum methods offer polynomial versus exponential speedups, clarifying optimal cases for a quantum advantage. This work has two main research objectives: (1) To develop efficient and provable quantum-inspired classical FEMs for solving high-dimensional PDEs; and (2) To develop practical quantum FEMs for solving PDEs on both near-term and far-term quantum computers with theoretical guarantees.  In the first objective, quantum principles are introduced into classical algorithms, creating quantum-inspired classical algorithms that achieve comparable speedups for FEM applications on classical computers. In the second objective, hybrid quantum-classical approaches are first developed for near-term quantum computers, which exist today.  The long-term goal is then to extend these methods to fully quantum FEM implementations on far-term large-scale quantum computers, which have yet to be developed.  This involves incorporating quantum techniques into adaptivity and mesh refinement, as well as developing structure-preserving quantum FEMs.  The goal is to produce new fundamental theory and advanced numerical methods for solving PDEs in the quantum era.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513073","Decoupling algorithms for fluid-structure interaction problems: Advances in theory, methodology, and applications","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","08/01/2025","06/26/2025","Hyesuk Lee","SC","Clemson University","Standard Grant","Yuliya Gorb","07/31/2028","$303,199.00","","hklee@clemson.edu","201 SIKES HALL","CLEMSON","SC","296340001","8646562424","MPS","125300, 127100","9150, 9263","$0.00","Understanding how fluids interact with elastic or porous materials, such as blood flowing through arteries or water filtering through soil, is crucial for addressing practical challenges in medicine, environmental science, and engineering. This type of modeling, known as fluid-structure interaction (FSI) or fluid-poroelastic structure interaction (FPSI), involves complex physics and mathematics because the fluid and the structure influence each other in strongly coupled ways. Traditional domain decomposition approaches solve the fluid and structure parts separately, then iteratively exchange information, but this process can be computationally expensive, especially for large systems. This research aims to develop new and efficient numerical methods that can solve these coupled problems more accurately and with reduced computational cost, enhancing simulation capabilities across diverse applications from hemodynamics to subsurface flow.<br/><br/>This project is on a rigorous development and analysis of numerical schemes for solving FSI and FPSI problems, using a unified, monolithic framework with Lagrange multipliers to enforce interface conditions. The core of the work includes: (1) formulating and analyzing a monolithic system to establish well-posedness, stability, and finite element error estimates; (2) deriving a Schur complement equation to decouple the subdomain problems and enable efficient computation of the Lagrange multipliers; (3) applying projection-based reduced order modeling (ROM) to the Schur system, stabilized by supremizer enrichment, to reduce computational cost; and (4) extending the framework to a novel three-dimensional fluid?two-dimensional plate interaction model. These advancements aim to significantly enhance the computational efficiency and robustness of simulations for strongly coupled multiphysics systems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2442463","CAREER: Mathematical Foundations of Generative Scientific Deep Learning","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","08/01/2025","07/01/2025","Yulong Lu","MN","University of Minnesota-Twin Cities","Continuing Grant","Stacey Levine","07/31/2030","$296,023.00","","lu000683@umn.edu","2221 UNIVERSITY AVE SE STE 100","MINNEAPOLIS","MN","554143074","6126245599","MPS","126600, 127100","1045, 079Z, 9251, 9263, 075Z","$0.00","Generative Artificial Intelligence (AI) has demonstrated its ability to create novel content, such as images and text while also providing tools that are driving breakthroughs in varied scientific disciplines. However, its rapid advancement has introduced fundamental theoretical challenges that remain largely unaddressed. The primary goal of this project is to establish the mathematical foundations of two models that underpin generative AI methodologies in a number of scientific contexts: score-based generative models and transformer-based foundation models. This project will utilize and develop mathematical tools for examining the generative capabilities of score-based generative models in high dimensions and understanding the predictive capabilities and limitations of transformers in solving a broad range of scientific problems. These fundamental understandings are intended to contribute to the development of scientifically reliable AI systems. The project will also support undergraduate and graduate students through research mentorship and education in the mathematical foundations of generative AI.<br/><br/>This project aims to study the mathematical underpinnings of score-based generative models and transformer-based foundation models. The project will study the role of fine data structures in mitigating the curse of dimensionality of score-based generative models, through quantifying the improved approximation, statistical and algorithmic complexities in learning high-dimensional distributions with two ubiquitous physical structures: symmetry and hierarchy. The project will also investigate the in-context learning capabilities of transformer-based foundation models for solving partial differential equations by characterizing their scaling laws and generalization performance under distribution shifts. Finally, the project will develop unsupervised foundational generative models for sampling from multiple distributions with provable guarantees.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513740","New stochastic algorithms for minimax-structured nonconvex nonsmooth optimization and applications in machine learning","DMS","COMPUTATIONAL MATHEMATICS","08/01/2025","06/30/2025","Yangyang Xu","NY","Rensselaer Polytechnic Institute","Standard Grant","Ludmil T. Zikatanov","07/31/2028","$220,000.00","","xuy21@rpi.edu","110 8TH ST","TROY","NY","121803590","5182766000","MPS","127100","9263, 079Z","$0.00","This project focuses on problems arising in game theory, statistics, engineering, and machine learning. Research on minimax problems dates back almost a century, when von Neumann published his minimax theorem about zero-sum games. The past several years have witnessed tremendous research interest in solving minimax problems, motivated by training deep learning models, including generative artificial intelligence and robust machine learning. Though well-trained deep learning models can deliver high-quality performance in many tasks, they are often vulnerable to adversarial attacks. Using such models can cause serious safety and security risks; thus, improving their robustness is very important. Most existing methods for solving minimax problems require certain strong conditions that do not hold for modern applications, such as training robust deep learning models. This project will develop new optimization algorithms for solving minimax problems, which can deliver guaranteed stability and reliability under weaker and more practical conditions. Software packages will be developed and released for public use to benefit both academic and industry researchers. The results from the project will be integrated into regularly offered or topical courses at RPI for both undergraduate and graduate students.<br/><br/>Different algorithms will be designed by leveraging the structures of the considered minimax problems, and analysis will be conducted as well to show the convergence of these algorithms and their complexity. For solving nonconvex nonsmooth minimax problems that satisfy a certain regularity condition for the dual part, a momentum-accelerated primal-dual stochastic subgradient method (PDSsG) will be investigated, and a Moreau-envelope based smoothed PDSsG, as an alternative, will also be explored. For solving nonconvex-nonconcave nonsmooth minimax problems that do not satisfy regularity conditions, new approaches will be developed by using the log-exponential smoothing function to approximate the maximization part. On solving problems that involve too-big data, new distributed methods will be designed under the setting of either a complete network or an incomplete connected network. Low-precision communication and error-compensation techniques will be used, for the first time, to solve nonconvex minimax problems, to save communication, and achieve fast convergence. These investigations are expected to invent new analysis techniques and lead to novel and efficient algorithms for solving large-scale minimax structured optimization.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513764","Accurate, Efficient, and Stable Numerical Methods for Reversible-Irreversible Thermodynamically Consistent PDEs","DMS","COMPUTATIONAL MATHEMATICS","08/01/2025","06/17/2025","Jia Zhao","AL","University of Alabama Tuscaloosa","Standard Grant","Jodi Mead","07/31/2028","$199,814.00","","jia.zhao@ua.edu","801 UNIVERSITY BLVD","TUSCALOOSA","AL","35401","2053485152","MPS","127100","9263, 9150","$0.00","Complex physical systems, such as those found in material science, fluid dynamics, and life science, often involve intricate interactions between energy-conserving mechanisms and entropy-generating processes. These systems are usually modeled by reversible-irreversible thermodynamically consistent partial differential equations (RITC-PDEs). However, solving these RITC-PDEs accurately and efficiently over a long time period remains computationally challenging due to their non-equilibrium nature and the need to preserve thermodynamic properties at the discrete level. This project will develop a general computational framework to solve RITC-PDEs while maintaining their energy conservation and nonnegative entropy production for long-time dynamic simulations and predictions. The proposed research will lead to a unified computational framework for studying multiscale non-equilibrium phenomena across various scientific disciplines, along with open-source tools for the broader research community. The project will support STEM education through outreach to K-12 students and educators.<br/><br/>Reversible-irreversible thermodynamically consistent (RITC) PDEs arise from the principles of thermodynamics. They are essential for modeling coupled processes involving energy-conserving(reversible, dispersive) and entropy-producing (irreversible, dissipative) dynamics. This project will develop high-order, accurate, efficient, easy-to-implement, and structure-preserving numerical schemes that maintain thermodynamic properties for RITC-PDEs. Specifically, the project will (a) design innovative structure-preserving discretization methods, including decoupled and high-order schemes, to accurately simulate complex RITC systems while maintaining their inherent thermodynamic consistency; (b) develop advanced time-stepping algorithms that ensure efficiency and accuracy for multiscale dynamics, by leveraging system properties such as energy budgets, entropy production, and topological changes to guide adaptive time step sizes; (c) construct a structure-preserving model order reduction framework that can generate reliable surrogate models for large-scale RITC systems; and (d) implement an open-source software package for simulating RITC-PDEs with GPU acceleration, adaptive meshing, and user-defined model inputs. Ultimately, the proposed research will lead to a unified computational framework to study multiscale non-equilibrium phenomena and contribute to the fields of numerical analysis, scientific computing, material science, fluid mechanics, and interdisciplinary modeling.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513689","Gradient Sampling Methods for Noisy Nonconvex Nonsmooth Optimization","DMS","COMPUTATIONAL MATHEMATICS","08/01/2025","06/30/2025","Frank Curtis","PA","Lehigh University","Standard Grant","Ludmil T. Zikatanov","07/31/2028","$219,328.00","","fec309@lehigh.edu","526 BRODHEAD AVE","BETHLEHEM","PA","180153008","6107583021","MPS","127100","9263","$0.00","Computational techniques for solving problems in image processing, statistical learning, robust control, distance geometry, and other areas require that large-scale unstructured optimization problems be solved.  To obtain solutions that translate best into real-world settings, these problems should involve models of the real world that are as accurate as possible, which in a mathematical context means that the problems may need to involve a large number of decision variables and complicated formulas with features such as nonsmoothness.  Thanks to the thriving field of mathematical optimization, there exist algorithmic methodologies for solving certain instances of problems of this type.  However, contemporary methodologies also have limitations that preclude their use for solving complex problems robustly and efficiently.  for example, it may be that with respect to an objective that is optimized, only the consequences of a certain set of decisions can be estimated (in terms of a cost, error, or other measure).  This can occur, when the value can only be determined through a computer simulation or as a statistical prediction over only partially observed data.  Such a context demands that contemporary approaches be extended so that they can intelligently handle noisy or stochastic (i.e., randomized) estimates of the value of decisions.  This project aims to design such algorithmic extensions for solving important classes of optimization problems arising in these prevalent and challenging application areas.<br/><br/>This project will involve the design, analysis, and implementation of gradient-sampling-based algorithms for solving locally Lipschitz optimization problems, specifically those that have nonconvex and nonsmooth objective functions.  The main scope of the project is to extend contemporary gradient-sampling-based algorithms for settings when function and derivative evaluations are corrupted by computational and/or stochastic noise.  In settings with such noise, fundamental properties on which gradient-sampling methods rely for their convergence guarantees break down, meaning that these fundamental properties need to be revisited and enhanced for settings with computational and/or stochastic noise.  These, in turn, will necessitate careful redesigns of complete algorithmic methodologies along with their corresponding convergence theories.  The real-world impact of the project will be enhanced by the fact that it will translate into enhancements to the state-of-the-art software developed by the principal investigator.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513254","Tight Relaxation Methods for Optimization","DMS","COMPUTATIONAL MATHEMATICS","07/15/2025","07/10/2025","Jiawang Nie","CA","University of California-San Diego","Standard Grant","Ludmil T. Zikatanov","06/30/2028","$250,000.00","","njw@math.ucsd.edu","9500 GILMAN DR","LA JOLLA","CA","920930021","8585344896","MPS","127100","9263","$0.00","This project is on the development of a class of methods known as ""tight relaxation methods"" for solving optimization problems, such as polynomial optimization, generalized Nash equilibria, matrix constrained optimization, and other related research questions. These problems are usually nonlinear, nonconvex, and are often given by polynomial or rational functions. Locating their global optima is a crucial task in various applications. Tight relaxation methods are especially useful for solving these optimization problems globally, which, in the case of a nonconvex objective function, is a non-trivial task. Results produced by this project have broad applications in science and engineering and have the potential to provide tools for locating Nash equilibria, solving mixed integer nonlinear programming problems, and optimizing power flow.<br/> <br/>This project works on research tasks for solving some hard optimization problems. In many applications, computing a critical point or local optimizer may not be satisfactory for the needs. Tight relaxation methods are preferable for computing the global optima. One problem, considered in this project, is the generalized Nash equilibrium problem (GNEP), which deals with solving several optimization problems simultaneously. Each optimization problem represents the strategy selection by a player. All players look for a common selection of strategies such that all players achieve their optimal decisions. The GNEP is particularly hard, since the objective function and feasible set for each player depend on strategy selections by other players. Another problem in this project is the matrix-constrained polynomial optimization problem (MCPOP). Its constraints are given by polynomial matrix inequalities, which are typically nonlinear and nonconvex. A major challenge in solving MCPOP is the lack of efficient computational methods for computing global optimizers. There are other types of hard optimization problems with behavior similar to the GNEP and MCPOP. Tight relaxation methods provide a computational framework for solving them. The tools used in constructing tight relaxation methods are Lagrange multiplier expressions, sum of squares, moment relaxations, and semidefinite programs. This project aims to develop efficient computational methods for solving these hard optimization problems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513234","Adaptive sampling for scientific machine learning: algorithms and applications","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","07/15/2025","07/07/2025","Xiaoliang Wan","LA","Louisiana State University","Standard Grant","Jodi Mead","06/30/2028","$285,669.00","","xlwan@math.lsu.edu","202 HIMES HALL","BATON ROUGE","LA","708030001","2255782760","MPS","125300, 127100","075Z, 9263, 079Z, 9150","$0.00","This project will focus on establishing a unified framework for adaptive sampling to enhance scientific machine learning algorithms. Scientific machine learning has proven to be a transformative force in advancing science and engineering. It blends the predictive capabilities of artificial intelligence (AI) with the precision of scientific models to address complex challenges beyond traditional numerical methods. It enables breakthroughs in fields as varied as healthcare and infrastructure development. A critical aspect of its importance lies in solving high-dimensional partial differential equations (PDEs), which are mathematical models central to describing phenomena like fluid dynamics, heat transfer, or electromagnetic fields. Traditional numerical methods struggle with the computational complexity of high-dimensional PDEs, but scientific machine learning dramatically reduces computation time while maintaining accuracy. As a result, this capability unlocks advancements in engineering designs and medical simulations, where such equations are prevalent. By enhancing the efficiency and affordability of research through improved adaptive sampling techniques, scientific machine learning can continue to drive innovation while also delivering practical solutions to pressing global issues like public health and energy, benefiting society at large. The project also includes a significant educational plan with three major components: (1) developing an introduction course on scientific machine learning; (2) training undergraduate and graduate students in research; (3) conducting outreach to educate high school students on basics regarding scientific computing and deep learning.<br/><br/>The goal of this project is to establish a unified framework through adaptive sampling, aimed at simultaneously optimizing both the training set and the loss of deep learning-based techniques for solving high-dimensional (parametric) PDEs. While deep learning has achieved remarkable success in numerous AI applications as a data-driven approach, applying it to solve high-dimensional PDEs introduces an additional challenge: its performance significantly deteriorates if the chosen training set does not align well with PDE solution properties. This is similar to what occurs when one attempts to solve a low-regularity problem with a finite element method on a uniform mesh. We must optimize not only the loss function but also the selection of random samples in the training set. From a numerical perspective, we must balance the statistical error induced by random samples and the approximation error induced by the neural network model. Optimizing the selection of random samples requires a generic density model capable of approximating arbitrary distributions and generating samples efficiently. A good candidate for this is a deep generative model. In this project, we will further develop two normalizing flow models: KRnet, suitable for distributions with dimensions on the order of 10, and VAE-KRnet, designed for distributions with dimensions on the order of 1000. Using these deep generative models, we will develop adaptive sampling strategies that reduce statistical error when solving (parametric) PDEs with physics-informed neural networks (PINNs) or Deep Ritz method. In particular, we will address two important problems in physics and chemistry: the simulation of viscoelastic flow and the approximation of the committor function. Due to the curse of dimensionality, these problems are traditionally tackled using stochastic approaches. However, deep learning offers a promising alternative approach where the estimated physical quantities do not suffer from the stochastic fluctuation. Adaptive sampling, enabled by deep generative models, will play a critical role in the algorithms developed for these problems. The educational objectives will focus on training young scientists in tackling interdisciplinary problems across scientific computing and deep learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513176","Collaborative Research: Computational Methods for Extremal Eigenvalue Problems with Geometric Constraints","DMS","COMPUTATIONAL MATHEMATICS","07/15/2025","07/07/2025","Chiu-Yen Kao","CA","Claremont McKenna College","Standard Grant","Ludmil T. Zikatanov","06/30/2028","$147,731.00","","ckao@claremontmckenna.edu","500 E 9TH ST","CLAREMONT","CA","917115929","9096077085","MPS","127100","9263","$0.00","In a variety of real-world applications, eigenvalues of linear partial differential operators describe physical phenomena of interest, e.g., light propagation, mechanical vibrations, and liquid sloshing.  It is of practical and fundamental interest to study the dependence of an eigenvalue on a control variable, such as the material coefficient or the domain shape, and to engineer/design/optimize control variables to enhance relevant spectral properties. This project will develop and analyze new computational methods for solving extremal eigenvalue problems, especially involving challenging geometric constraints. The research activities will advance discovery and understanding in computational mathematics and mathematical physics, as well as more general areas of science and engineering through applications. Educational activities are integrated with research activities in four specific ways: (i) training of students (including K-12, undergraduate, and graduate students across different schools) and junior researchers at different levels, (ii) encouraging participation of researchers in the area (iii) dissemination and sharing of research results publicly, and (iv) organization of international workshops on proposed research topics. Due to the collaborative nature of this proposal, students will engage in activities across R1 and primarily undergraduate institutions.<br/><br/>The aim of this project is to tackle two canonical extremal eigenvalue problems from the mathematical and engineering communities: (1) study the Steklov eigenvalue problem on a compact Riemannian surface with boundary and seek to maximize of an eigenvalue over the class of smooth metrics; (2) address a key challenge in the design of topological photonic crystals (TPCs): find materials that have large shared spectral bandgaps where the adjacent dispersion surfaces have prescribed topological invariants (e.g., the Chern number, a topological invariant obtained from Berry curvature). A technical challenge in these problems is to handle geometric constraints - either stemming from topological constraints on Riemannian surfaces or topological invariants of dispersion surfaces. The proposed research activities will develop analytical and computational tools to tackle this challenge.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513175","Collaborative Research: Computational Methods for Extremal Eigenvalue Problems with Geometric Constraints","DMS","COMPUTATIONAL MATHEMATICS","07/15/2025","07/07/2025","Braxton Osting","UT","University of Utah","Standard Grant","Ludmil T. Zikatanov","06/30/2028","$300,772.00","","osting@math.utah.edu","201 PRESIDENTS CIR","SALT LAKE CITY","UT","841129049","8015816903","MPS","127100","9263","$0.00","In a variety of real-world applications, eigenvalues of linear partial differential operators describe physical phenomena of interest, e.g., light propagation, mechanical vibrations, and liquid sloshing.  It is of practical and fundamental interest to study the dependence of an eigenvalue on a control variable, such as the material coefficient or the domain shape, and to engineer/design/optimize control variables to enhance relevant spectral properties. This project will develop and analyze new computational methods for solving extremal eigenvalue problems, especially involving challenging geometric constraints. The research activities will advance discovery and understanding in computational mathematics and mathematical physics, as well as more general areas of science and engineering through applications. Educational activities are integrated with research activities in four specific ways: (i) training of students (including K-12, undergraduate, and graduate students across different schools) and junior researchers at different levels, (ii) encouraging participation of researchers in the area (iii) dissemination and sharing of research results publicly, and (iv) organization of international workshops on proposed research topics. Due to the collaborative nature of this proposal, students will engage in activities across R1 and primarily undergraduate institutions.<br/><br/>The aim of this project is to tackle two canonical extremal eigenvalue problems from the mathematical and engineering communities: (1) study the Steklov eigenvalue problem on a compact Riemannian surface with boundary and seek to maximize of an eigenvalue over the class of smooth metrics; (2) address a key challenge in the design of topological photonic crystals (TPCs): find materials that have large shared spectral bandgaps where the adjacent dispersion surfaces have prescribed topological invariants (e.g., the Chern number, a topological invariant obtained from Berry curvature). A technical challenge in these problems is to handle geometric constraints - either stemming from topological constraints on Riemannian surfaces or topological invariants of dispersion surfaces. The proposed research activities will develop analytical and computational tools to tackle this challenge.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513336","New Computational Framework for Complex Kinetic Simulation and Prediction","DMS","COMPUTATIONAL MATHEMATICS","07/01/2025","06/27/2025","Li Wang","MN","University of Minnesota-Twin Cities","Standard Grant","Jodi Mead","06/30/2028","$220,000.00","","wangli1985@gmail.com","2221 UNIVERSITY AVE SE STE 100","MINNEAPOLIS","MN","554143074","6126245599","MPS","127100","075Z, 079Z, 9263","$0.00","Kinetic theory has transformed our understanding of interacting particle systems in both nature and engineering. Despite their importance, kinetic equations remain challenging to solve. This difficulty arises from their high dimensionality, the presence of multiple scales, and the need to preserve key structures such as conservation, positivity, and entropy dissipation. Additionally, the multi-query task of parameter identification places a higher demand on solver's efficiency. This project intends to address these challenges by developing efficient and scalable variational computational methods. These methods will integrate ideas from optimal transport, scientific machine learning, and stochastic methods, along with the unique structure of kinetic equations. The project also includes the training of graduate students, contributing to the development of the next generation of computational mathematicians.<br/><br/>The project has two main objectives. The first is to develop and analyze learning-enhanced, structure-preserving particle methods for nonlinear partial differential equations, with a particular focus on plasma models. The methods will preserve both the Hamiltonian structure of the field terms and the dissipative nature of the collision. They are intended to complement existing particle-in-cell approaches for collisionless plasmas and to offer improvements in scalability and stability for collisional plasma simulations. The second objective is to design reduced-order methods for optimization problems constrained by kinetic equations. This will involve leveraging the multiscale nature of the equations or employing intelligent use of randomness. The proposed methods aim to meet the pressing need for efficient inverse solvers, particularly given the growing applications of kinetic theory to real-world problems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2512565","Coarse-grained models for simulating fluid suspensions under confinement","DMS","COMPUTATIONAL MATHEMATICS","07/01/2025","06/23/2025","Thomas Fai","MA","Brandeis University","Standard Grant","Yuliya Gorb","06/30/2028","$292,686.00","","tfai@brandeis.edu","415 SOUTH ST","WALTHAM","MA","024532728","7817362121","MPS","127100","9263","$0.00","The behavior of fluids containing suspended elastic objects is significantly influenced by the domain geometry and interactions with boundaries. For example, it is well-known that the fluid drag on particles in dead-end channels is greater than in free space. This is relevant in many applications, including biological fluids such as blood, in which the suspended red blood cells and platelets become non-uniformly distributed in the bloodstream as a result of boundary interactions. However, confined suspensions are challenging to simulate because of their multiscale nature and the difficulty of resolving the thin films that may develop between particles and boundaries. This project aims to model and simulate confined suspensions in order to accurately capture the effects of boundaries. The goal is to study the fluid dynamics of suspensions in confined geometries and accelerate simulations of these phenomena.<br/><br/>To achieve the project goals, a hierarchy of mathematical models and numerical methods will be developed. Simulations of fluid-structure interaction will be performed to explicitly capture the wall-induced migration of elastic objects away from walls, and these will be used to parameterize a reduced model of elastic deformations and corresponding lift coefficients. In addition, the classical Oldroyd-B model of non-Newtonian fluids will be revisited to incorporate the effect of a heterogeneous particle distribution near boundaries, and the method of images will be applied to extend the Stokeslet solution to the case of dead-end geometries. Taken together, these projects will provide a set of practical numerical and analytical tools to study the behavior of suspensions in the presence of boundaries. As broader outcomes, the results from this work will be integrated into course materials, and open-source implementations of the resulting computational methods will be released to make them widely accessible.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513843","Geometric Control of Unfitted Finite Element Methods","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","07/01/2025","06/30/2025","Shawn Walker","LA","Louisiana State University","Standard Grant","Ludmil T. Zikatanov","06/30/2028","$299,992.00","","walker@math.lsu.edu","202 HIMES HALL","BATON ROUGE","LA","708030001","2255782760","MPS","125300, 127100","9150, 9263","$0.00","This project is about optimizing geometric structures in physical and biological systems. The research will investigate optimal swimming motions of microorganisms, which can help explain their behavior, as well as yield new ways of actuating mechanical systems in fluids (e.g., underwater robotics). In general, the research will create new computational tools for shape optimization that can enhance the performance of physical systems; examples are structural optimization, minimizing fluid drag, and improving heat dissipation. Moreover, it will create new methods to control the self-assembly of geometric structures in fluids, such as liquid crystals. The outcomes of this research will open new avenues for material design, provide novel methods for optimizing geometric motion, and enhance the understanding of biological locomotion in fluids. Part of this project involves interacting with elementary and middle school students to show the importance of geometry in applications through the PI's ""sit-with-a-scientist"" program.  The program provides an informal atmosphere with hands-on activities.<br/> <br/>The research objective of this project is to develop novel computational techniques for controlling geometry. It will advance the theoretical development of unfitted finite element methods (FEMs) to create robust and user-friendly numerical techniques for optimizing shape and time-dependent geometric motion. It will develop new theoretical and computational tools to optimize the swimming motions, or gaits, of microorganisms. And it will extend optimal control techniques to the self-assembly dynamics of geometric structures, with application to liquid crystals. The research will unite the ""optimize-then-discretize"" and ""discretize-then-optimize"" philosophies (which are usually contrary) for shape optimization in the context of unfitted FEMs and give new ways to compute minimizers. The research will yield new types of level set methods for simulating changing geometry. Moreover, it will extend unfitted FEMs to address time-dependent, tensor-valued, semi-linear partial differential equations with a focus on controlling the anisotropic Landau-de Gennes (LdG) model of liquid crystals. Other aspects of the research will create open-source software for the methods developed here, using both the PI's packages, FELICITY and AHF, and other open-source options (e.g., Firedrake and NGSolve).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2514066","Balanced graph cuts: algorithms, analysis and applications","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","07/01/2025","06/30/2025","Wei Zhu","AL","University of Alabama Tuscaloosa","Standard Grant","Ludmil T. Zikatanov","06/30/2028","$148,127.00","","wzhu7@bama.ua.edu","801 UNIVERSITY BLVD","TUSCALOOSA","AL","35401","2053485152","MPS","125300, 127100","9150, 9263","$0.00","The project focuses on answering the question ""How to divide a collection of objects into two groups such that the objects within each group can interact while the objects from different groups rarely interact?"" As is well known, the past two decades have witnessed an exponential increase in the use of social or other networks, which consist of objects and connections between them, and carry a lot of information. These networks can be used to detect different groups of objects, each with similar characteristics or preferences. In materials science, advanced engineering alloys, such as steels and high-entropy alloys, may be thought of as 3-dimensional graphs with atoms residing at the nodes of a graph and its edges as bonds. These materials are often polycrystalline, and sudden, unexpected failures occur frequently in the form of fractures along crystal boundaries. Such failures are extremely costly, resulting in, for example, oil and gas spills and even bridge collapses. All the above problems can be cast as balanced graph cut problems, which are very challenging. In the literature, many existing approaches resort to approximate solutions. However, these solutions may differ significantly from the optimal ones. This proposal mainly focuses on the development of efficient and reliable methods for finding optimal graph cuts, which could significantly promote their applications to practical problems in the fields of materials science and social sciences.  <br/><br/>Partitioning a large data set into a prescribed number of subsets is a fundamental problem in machine learning, and it assumes wide applications in fields such as social networks, computer science, chemical engineering, and materials science. To conduct the partition, different balanced graph cuts have been proposed, including the Cheeger cut, the ratio cut, and the normalized cut. As one of the most important balanced graph cuts, the Cheeger cut is a challenging NP-hard problem. Existing approaches only provide approximate solutions. Recently, a novel nonlinear spectral graph theory was developed, and finding the Cheeger cut amounts to solving a constrained optimization problem with a non-smooth objective function over a non-convex set that consists of many different-dimensional simplex cells. The number of these cells is an exponential function of the number of vertices of a graph. Therefore, this raises another tough optimization problem. The proposed research in this project consists of three parts: 1) developing novel efficient and reliable numerical algorithms to solve the above-mentioned problem by using optimization techniques; 2) extending the existing nonlinear spectral graph theory to weighted graphs to enrich the theory and significantly expand its applications to real problems; 3) applying the proposed methods to tackle practical problems in metallurgical engineering and materials science. The projects discussed in this proposal also offer training opportunities for graduate and undergraduate students.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513924","Robust Numerical Methods for Nonlinear Wave Equations in Second-order Form","DMS","COMPUTATIONAL MATHEMATICS","07/01/2025","06/17/2025","Lu Zhang","TX","William Marsh Rice University","Standard Grant","Jodi Mead","06/30/2028","$350,000.00","","lz82@rice.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","MPS","127100","9263","$0.00","Nonlinear wave equations in second-order form are fundamental to understanding phenomena in geophysics, plasma physics, quantum science, and beyond. However, accurately and efficiently simulating these equations remains a major challenge due to their complexity and sensitivity, which demand a careful balance of precision and speed, along with the use of stable numerical schemes to ensure reliable results. This project develops robust and efficient numerical algorithms for solving wave equations, optimized for high performance on both current and next-generation computing platforms. These computational tools will advance foundational research and have wide-ranging applications in areas where accurate wave prediction is critical. Beyond technical innovation, the project supports the development of a skilled scientific workforce by training graduate researchers and engaging students through reading groups and seminars. These educational initiatives promote participation in computational mathematics and contribute to the nation's continued leadership in science, engineering, and technological innovation.<br/><br/>The main computational challenges associated with nonlinear second-order wave equations stem from their rich and intricate range of behaviors. These equations can exhibit solitary waves, solitons, finite-time blow-ups, singularities, and rapid oscillations.  These equations, often derived from Euler?Lagrange equations, carry intrinsic geometric and energetic structures that critically shape their dynamics.  Standard numerical approaches typically reformulate them into first-order systems, which increase computational cost and potentially compromise key physical properties.  Building on the investigator?s prior success with numerical methods for (semi-)linear second-order wave problems, this project aims to address these challenges.  The goal is to design numerical schemes specifically tailored to the nonlinear second-order formulation, emphasizing stability, high accuracy, computational efficiency, and fidelity to the underlying physics.  In particular, the research will focus on constructing fully discrete, structure-preserving energy discontinuous Galerkin methods and applying them to complex physical systems, such as geometric wave models and coupled first- and second-order hyperbolic systems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513653","RUI: Reconstructing Discrete Images from Low-Frequency Fourier Data","DMS","COMPUTATIONAL MATHEMATICS","07/01/2025","06/12/2025","Howard Levinson","OH","Oberlin College","Standard Grant","Jodi Mead","06/30/2028","$250,000.00","","hlevinso@oberlin.edu","173 W LORAIN ST","OBERLIN","OH","440741057","4407758461","MPS","127100","9263, 9229","$0.00","This project will investigate how prior mathematical information can be used to dramatically improve the resolution of images from blurred data. In many real-world applications, the images to be recovered contain only a few distinct types of materials. This includes distinguishing solid rock from fluid in scientific imaging, bone from soft tissue and tumors in medical scans, and identifying organic material versus metal or plastic in security screenings. This project will focus on ways to restore fine, high-resolution details in these kinds of discrete images when only low-resolution information is available. This is a common challenge in imaging systems where data is degraded by noise, physical limitations, or transmission losses. By developing new algorithms that take advantage of this strong mathematical structure, the research has the potential to improve the quality and resolution of imaging techniques used in scientific, medical, and security applications. A major component of the project involves providing undergraduate students with hands-on research experience, including opportunities to engage with cutting-edge techniques in machine learning, helping prepare the future workforce with expertise in artificial intelligence tools.<br/> <br/>This project will address the problem of restoring missing discrete Fourier transform (DFT) coefficients in blurred images by leveraging the prior knowledge that each pixel takes on a value from a limited, known set. Prior work has established strong theoretical guarantees. The proposed research will extend these results to more general cases where the known DFT data is not confined to a pass-band and where standard error correction techniques are applied. The project will focus on developing reliable, efficient numerical methods for such inversions, along with practical analyses of runtime and stability. The work will integrate tools from cryptography, optimization, and probability theory. Undergraduate researchers will play an active role in algorithm development, theoretical analysis, and computational experimentation, with structured projects designed for meaningful student contributions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2508659","Conference: International Conference on Mathematical and Scientific Machine Learning 2025 (MSML2025)","DMS","COMPUTATIONAL MATHEMATICS","07/01/2025","02/05/2025","George Karniadakis","RI","Brown University","Standard Grant","Jodi Mead","06/30/2026","$30,000.00","","George_Karniadakis@brown.edu","1 PROSPECT ST","PROVIDENCE","RI","029129100","4018632777","MPS","127100","075Z, 079Z, 7556, 9263, 9150","$0.00","The International Conference on Mathematical and Scientific Machine Learning 2025 (MSML2025) will be held in Naples, Italy at the University of Naples Federico II, August 4-8, 2025. This conference will be hosted in the ?Aula Magna.? MSML2025 will be the fifth edition of a recently established international conference with an emphasis on promoting the study of mathematical theory and algorithms of machine learning, as well as applications of machine learning in scientific computing and engineering disciplines. This edition will be the second conference of the series to be held fully in person. This international conference aims to bring together the communities of machine learning, applied mathematics, and computational science and engineering, to exchange ideas and progress in this fast-growing field. This conference will help contribute to the training and growth of the workforce in this field by supporting the attendance of graduate students, postdoctoral researchers, and junior researchers. <br/><br/>The objective of this conference series is to promote the study of theory and algorithms of machine learning and machine intelligence as well as applications in scientific and engineering disciplines such as physics, chemistry, material sciences, fluid and solid mechanics, etc. New themes of the conference will include transformers and state-space models, analysis of attention mechanisms, causal inference, optimization for surrogate training, and optimal transport, while more traditional themes such as graph neural networks, neural operators and general mathematics of machine learning will also be featured. More information about the conference is available at the conference website:  https://sites.google.com/view/msml2025/home.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513687","Estimating Eigenvalues and Matrix Functions with a Krylov Subspace","DMS","COMPUTATIONAL MATHEMATICS","07/01/2025","06/11/2025","John Urschel","MA","Massachusetts Institute of Technology","Standard Grant","Jodi Mead","06/30/2028","$324,998.00","","urschel@mit.edu","77 MASSACHUSETTS AVE","CAMBRIDGE","MA","021394301","6172531000","MPS","127100","9263","$0.00","Krylov subspace methods are among the most popular classes of algorithms in computational mathematics, particularly when dealing with high-dimensional problems ? an increasingly important subject in all areas of engineering, science, and modern technology. Their advantages are simple: they tend to be very fast and relatively accurate. But despite their ubiquity, many questions regarding their behavior and their approximation quality remain unanswered. This project, will further understanding of the behavior and robustness of existing Krylov subspace algorithms and create new algorithms for fundamental computational tasks for which no robust algorithm currently exists. Several of the research projects are suitable for training undergraduate and graduate students. A new computational math seminar at MIT, focused on numerical linear algebra, will draw more students to the field. <br/><br/>This project investigates Krylov subspace methods through four specific problems: (1) A complex moment method: Examine the theoretical and practical feasibility of a potential new technique that builds upon theoretical work on the truncated complex moment problem in analysis. (2) Estimating matrix functions: Develop efficient algorithms for computing matrix functions for a variety of graph-related problems by applying recently developed fast Laplacian linear system solvers to rational Krylov subspace methods. (3) Constructing extremal polynomials: Introduce a class of problems that will provide insight into error estimates for Krylov subspace methods for non-Hermitian matrices. (4) Recovering a matrix from its moments: Given a finite moment sequence, when does there exist an orthogonal matrix with those moments? The PI will introduce an algorithm to answer this question for a large class of moment sequences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513481","New frontiers for Bayesian hierarchical models in inverse problems","DMS","COMPUTATIONAL MATHEMATICS","07/01/2025","06/11/2025","Erkki Somersalo","OH","Case Western Reserve University","Standard Grant","Jodi Mead","06/30/2028","$349,880.00","Daniela Calvetti","ejs49@case.edu","10900 EUCLID AVE","CLEVELAND","OH","44106","2163684510","MPS","127100","9263","$0.00","The estimation of unknown causes of observed consequences, known as inverse problems, is a task arising in many important real world applications as wells as in science and engineering. Medical imaging, large language models, the structural health of infrastructure, among other areas, all rely heavily on the availability of fast and robust computational methods known as inverse solvers, especially when the data are parsimonious and noisy. This project will advance Bayesian inverse solvers that constitute the mathematical tools to utilize qualitative properties of these unknowns in a natural way while simultaneously providing a measure of the uncertainty associated with the solutions. In particular, this project will develop hierarchical Bayesian methods since they are particularly attractive for finding solutions when the salient information is consolidated economically into few features of the unknowns, a methodology that is referred to as sparse coding, or when the entries need to be of a prescribed type to facilitate the interpretation of the solution. Successful completion of this project has the potential to advance research in biotechnology, health sciences, and artificial intelligence.<br/><br/>This project will combine hierarchical Bayesian techniques in inverse problems with novel ideas leveraging data science techniques and state of the art methods to address large scale computing challenges arising in a number of important real world applications. The targeted applications include functional magnetic resonance imaging (fMRI) of the brain, hemorrhagic stroke monitoring by electrical impedance tomography (EIT), muscle control identification in biomechanics and rehabilitation, fingerprinting of resting states in brain by magnetoencephalography (MEG), semantic and linguistics studies through large language models, and investment portfolio planning.  The innovative combination of matrix-free techniques with Bayesian and data science methods will be the foundation and building blocks of algorithms that are fast, yield better solutions by taking advantage of cleverly designed priors, and more energy-efficient than approaches based on machine learning and neural networks.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513409","A Geometric Framework for Stochastic Algorithms in Feasibility and Inclusion Problems","DMS","COMPUTATIONAL MATHEMATICS","07/01/2025","06/11/2025","Patrick Combettes","NC","North Carolina State University","Standard Grant","Jodi Mead","06/30/2028","$350,000.00","","plc@math.ncsu.edu","2601 WOLF VILLAGE WAY","RALEIGH","NC","276950001","9195152444","MPS","127100","9263","$0.00","Mathematical models arising in areas such as data analysis, artificial intelligence, geophysics, signal processing, and medical imaging are increasingly complex due to their large size and the presence of random perturbations. This project will investigate foundational principles governing the mathematical representation and the numerical solution of such large-scale random models.  New strategies and methodologies based on geometric principles to effectively incorporate randomness in the underlying mathematical representations and in the design of efficient randomized solution algorithms will be developed. Graduate students will be trained as part of the research plan. <br/><br/>This project focuses on models and convergence principles for dealing with stochasticity in a wide range of algorithms for solving various types of equilibrium problems arising in convex feasibility, best approximation, convex optimization, fixed point, variational inequality, and monotone inclusion problems. A flexible geometric framework will be developed that captures a broad array of existing algorithms while furnishing an effective pattern for designing new ones. The tools to be developed in the project aim at providing common principles to analyze the asymptotic behavior of stochastic algorithms at several levels: stochastic operator approximations, random coordinate updates, and random operator activations. The two generic classes of problems considered are convex feasibility problems and multivariate systems of structured monotone inclusions. Extensions beyond the monotone/convex setting are also planned. The theoretical and algorithmic findings will be applied to problems in the areas of signal processing, artificial intelligence, machine learning, inverse problems, statistical biology, and medical imaging.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2514012","Fast volumetric integral equation solvers and applications","DMS","COMPUTATIONAL MATHEMATICS","07/01/2025","06/16/2025","Thomas Anderson","TX","William Marsh Rice University","Standard Grant","Jodi Mead","06/30/2028","$343,612.00","","thomas.anderson@rice.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","MPS","127100","9263","$0.00","The ability to efficiently conduct high-fidelity simulations of complex physical phenomena simultaneously reflects our increased understanding of the underlying physics and enables future technological developments based on rapid iterative/inverse design. This project concerns a class of simulation techniques that rely on fundamental solutions (that is, by expressing solutions as a complicated superposition of `point sources' of light, sound, etc.) which have been highly effective when applicable as they have enabled transformational simulations of problems in electrostatics, wave phenomena as well as in human blood flow contexts. But more complicated phenomena (e.g. featuring nonlinearities or spatially-varying media), which are increasingly relevant in applications in medical imaging and also have long-standing intrinsic importance in geophysical exploration, have posed a substantial barrier to this class of methods---which thus have significant untapped potential in these application domains. This project will develop numerical methods with rigorous approximation guarantees to solve these physical problems and enable new scientific questions to be answered / for new technology to be designed, thereby strengthening the U.S. competitiveness and national defense. On the education front, the project will involve training in modern scientific computing generally and for their use in integral equation methods and applied to wave propagation particularly, all rare skills highly valued by industry.<br/><br/>Integral equation formulations of nonlinear and/or variable-coefficient problems typically involve one or more volume integral operators (VIOs) featuring the free-space Green's function over the (generally complicated) domain of interest. This project proposes a novel class of volume regularization methods for accurately discretizing any of these VIOs, and if necessary to allow for their simultaneous computation. By suitably exploiting Green's identity the proposed methods allow for singularity-oblivious quadrature to nevertheless be used for these erstwhile singular integrals; accompanying error analysis in two and three dimensional contexts and in curvilinear domains will place the proposed methods on a firm theoretical foundation, and they will be integrated with fast N-body interaction methods. These methods will be coupled into advanced solvers that enable treatment of complex nonlinearities that arise in acoustic problems found in medical imaging. More generally, the methods will allow the extension of the integral equation methods to nonlinear and possibly time-dependent PDEs, as VIOs reduce inhomogeneous linear PDEs to corresponding homogeneous problems---for which surface integral methods have always been highly advantageous. Implementation of the numerical methods will be publicly distributed via the open-source integral equations software project Inti.jl.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513273","Ellipticity, Optimization and Finite Elements","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","07/01/2025","06/25/2025","Susanne Brenner","LA","Louisiana State University","Standard Grant","Yuliya Gorb","06/30/2028","$314,416.00","","brenner@math.lsu.edu","202 HIMES HALL","BATON ROUGE","LA","708030001","2255782760","MPS","125300, 127100","9150, 9263","$0.00","There are three topics in this proposal: elliptic optimal control problems, elliptic problems with rough coefficients and fully nonlinear elliptic partial differential equations. Ellipticity, optimization and finite elements are central to all of the proposed research projects. The results from the projects in optimal control are relevant for the optimal design processes in engineering. The results from the projects for problems with rough coefficients can be applied to multiscale problems that appear in materials science and geoscience. The results from the projects in fully nonlinear elliptic partial differential equations will provide reliable and useful computational tools for differential geometry and optimal transport. The proposed work will build bridges among the communities of numerical partial differential equations, optimization, elliptic optimal control,  multiscale modeling and domain decomposition.<br/><br/>The research in elliptic optimal control problems will extend the recent work of the PI and collaborators in distributed control with pointwise state constraints to general cost functions and general partial differential equation (PDE) constraints. It will also develop new error analyses for boundary control problems with control constraints that can be applied to multiscale finite element methods when the coefficients in the PDE constraint are rough. The research in elliptic problems with rough coefficients will develop multiscale finite methods that are based on the local orthogonal decomposition (LOD) methodology with a domain decomposition (DD) twist.  It will extend the DD-LOD framework to problems with high contrast channels, to variational inequalities, to Neumann boundary value problems, to fourth order problems and to elliptic boundary control problems with control constraints. The research in fully nonlinear elliptic partial differential equations will focus on problems that involve Monge-Ampere equations:  the Minkowski problem, the prescribed Gaussian curvature problem and the second boundary value problem for the Monge-Ampere equation.  It is based on novel convexity enforcing finite elements discovered by the PI and collaborators in recent years and a nonlinear least-squares approach.  The goal is to develop finite element methods that can capture smooth solutions and that come with a rigorous error analysis and convergence rates.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2513639","Rigorous Hausdorff dimension estimates for conformal fractals","DMS","COMPUTATIONAL MATHEMATICS","07/01/2025","06/13/2025","Dmitriy Leykekhman","CT","University of Connecticut","Standard Grant","Yuliya Gorb","06/30/2028","$340,000.00","Vasileios Chousionis","dmitriy.leykekhman@uconn.edu","438 WHITNEY RD EXTENSION UNIT 1133","STORRS","CT","062699018","8604863622","MPS","127100","9263","$0.00","This project explores a range of computational problems that naturally emerge in the dimension theory of conformal dynamical systems. Conformal fractals are intricate geometric objects generated via iterated schemes of conformal (angle-preserving) transformations, and they have numerous interdisciplinary applications in mathematical physics, computer graphics, and data science. Measuring the size of conformal fractal attractors has been one of the central themes in the evolution of modern dynamical systems. One of the most well-known ways for measuring such complex geometric objects is the concept of Hausdorff dimension, which provides a robust way of determining the roughness of a set, extending the idea of dimension beyond integer values. The Hausdorff dimension of conformal fractals cannot be derived via simple analytic closed formulas, and obtaining effective and rigorous estimates becomes a challenging computational problem. The scope of this project is to introduce new methods from numerical partial differential equations with the scope of developing versatile, rigorous, and efficient methods for computing the Hausdorff dimensions of various conformal attractors.<br/><br/>The project's topic is naturally interdisciplinary, encompassing a wide range of problems across Real and Complex Analysis, Dynamical Systems, Numerical Analysis, and Large-Scale Computations. The goal is to derive accurate and rigorous Hausdorff dimension estimates for a broad class of conformal fractals by integrating techniques from finite element methods, dynamical systems, and fractal geometry. Finite element analysis is a well-established approach for approximating solutions to a wide range of partial differential equations, with numerous refined methods developed over the years to ensure accurate and reliable numerical results. In contrast, the field of rigorous computation of Hausdorff dimensions for conformal limit sets is still in its infancy. The primary innovation of this project lies in adapting numerical methods typically used for solving PDEs to the estimation of Hausdorff dimensions. This new methodology demands deep analytical foundations and the development of novel theoretical results, presenting significant challenges, especially within the broader context of conformal graph-directed Markov systems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2514690","Conference: Groups, Logic, and Computation: Interactions between Group Theory, Model Theory, and Computer Science. GAGTA 2025.","DMS","ALGEBRA,NUMBER THEORY,AND COM, Algorithmic Foundations, COMPUTATIONAL MATHEMATICS, FOUNDATIONS, GEOMETRIC ANALYSIS, APPLIED MATHEMATICS","06/01/2025","04/07/2025","Alexander Ushakov","NJ","Stevens Institute of Technology","Standard Grant","James Matthew Douglass","05/31/2026","$34,000.00","Mahmood Sohrabi","sasha.ushakov@gmail.com","ONE CASTLE POINT ON HUDSON","HOBOKEN","NJ","070305906","2012168762","MPS","126400, 779600, 127100, 126800, 126500, 126600","","$0.00","This award supports participants of the conference ""Groups, Logic, and Computation: Interactions between Group Theory, Model Theory, and Computer Science (GAGTA 2025)"" which will take place at the Stevens Institute of Technology (New Jersey), June 9--13, 2025. The event will bring together researchers from various branches of group theory, model theory, and computer science to explore open questions in the field, now being approached from fresh and promising perspectives. It will also strengthen the discipline's connections to other branches of mathematics. Through this exchange of ideas among experts, students, and postdoctoral researchers, the conference aims to disseminate current knowledge and identify promising directions for future research.<br/><br/>The conference will focus on recent developments in group theory, emphasizing groups and group actions, as well as their applications across various areas of mathematics where they serve as fundamental tools. The program will cover multiple branches of modern group theory with a particular focus on geometric, asymptotic, and combinatorial group theory, dynamics of group actions, probabilistic and analytic methods, first-order rigidity and classification, and Diophantine problems in groups and rings. Additionally, the conference will explore emerging AI connections, with dedicated sessions examining how group theory can further impact machine learning, formal verification, and symbolic computation and how AI methods may contribute to advances in group-theoretic research. This interdisciplinary exchange aims to foster collaboration and open new directions in both mathematics and AI. More information can be found at https://web.stevens.edu/algebraic/Stevens2025/<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2441153","CAREER: Robust Manifold and Metric Learning: Techniques for Noise, Intersections, and Geometric Regularization","DMS","COMPUTATIONAL MATHEMATICS","06/01/2025","01/21/2025","Anna Little","UT","University of Utah","Continuing Grant","Ludmil T. Zikatanov","05/31/2030","$126,025.00","","little@math.utah.edu","201 PRESIDENTS CIR","SALT LAKE CITY","UT","841129049","8015816903","MPS","127100","1045, 9263","$0.00","This project aims to advance machine learning techniques by developing new mathematical tools to better analyze and visualize complex, high-dimensional data. Many real-world data sets, such as genetic information or molecular images, contain hidden structures that can be uncovered using geometric methods. Leveraging these hidden structures can decrease the computational resources needed to analyze large data sets and can also provide scientific insight regarding various biological and physical processes. The goal of this project is to harness the full power of geometric methods for modern machine learning by the design of innovative solutions to the critical challenges facing the field. The project will focus on developing methods that can handle noisy data and tools for data visualization that preserve important geometric details. In addition to its scientific goals, the project will have a broad impact by offering new educational programs to support student mental health, increase diversity in data science, and encourage underrepresented groups to engage in this field. By addressing both technical and social challenges, the project aims to create more reliable, scalable tools for data analysis while promoting inclusion and innovation in science and education.  <br/><br/>In many applications, real data often concentrates around low-dimensional structures or manifolds, and manifold learning algorithms are a powerful tool for uncovering this low-dimensional structure. The project is on manifold learning algorithms, tackling the key challenges facing the field, including how noise affects algorithm performance, how to preserve both local and global geometric details, and how to effectively handle complex collections of manifolds. This research will investigate best practices for denoising, analyze how noise impacts spectral manifold learning algorithms, and clarify the regime in which algorithms can reliably recover manifold structure. The project will develop novel algorithms that utilize diffusion to faithfully encode geometric information at various scales and also hybrid methods for geometric regularization of manifold learning algorithms. Since real data often fails to concentrate around a single manifold, this work will contribute a robust and scalable solution for clustering collections of manifolds via a novel angle-based path metric on simplices, so that manifold learning algorithms can be applied under less restrictive assumptions. In addition, since data often contains numerous irrelevant features and features measured on very different scales, the project aims to develop a probabilistic framework for learning and adjusting features according to their actual relevance. Overall, the goal is to design a comprehensive data analysis pipeline that is noise-robust and capable of balancing local and global geometric information to represent data in just a few dimensions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2520375","Conference: Research Collaboration Workshop in the Science of Data and Mathematics","DMS","COMPUTATIONAL MATHEMATICS","06/01/2025","05/29/2025","Yifei Lou","NC","University of North Carolina at Chapel Hill","Standard Grant","Jodi Mead","11/30/2025","$31,340.00","Harlin Lee","yflou@unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275995023","9199663411","MPS","127100","9263, 7556","$0.00","This grant supports travel for 40 US participants to the Research Collaboration in the Science of Data and Mathematics, to be held at the University of North Carolina at Chapel Hill, NC, in the week of August 4-8, 2025. The proposed five-day workshop consists primarily of time spent in small, focused working groups led by prominent field leaders to address pre-defined open research problems. This format promotes intensive collaboration on key challenges, encourages the free exchange of scientific ideas, and strengthens the research skills of participants. The workshop is open to all researchers. In addition to research collaboration, the workshop will provide essential networking and mentorship opportunities that are particularly valuable for researchers at early career stages. <br/><br/>The organizing committee has carefully selected six pairs of group leaders to guide research groups focused on challenging topics in mathematical data science. These topics include advanced modeling tools such as optimal transport, randomized algorithms, diffusion generative models, and manifold inference. The resulting research is expected to advance computational mathematics significantly, particularly in areas such as (randomized) linear algebra, differential geometry, and statistical learning. Some research groups will also address critical applications in areas like image processing, and single-cell biology. The results of the workshop will be published in a peer-reviewed volume by Springer. The project results will also be disseminated via a follow-up workshop in conjunction with major conferences including the SIAM Annual Meeting, Joint Mathematical Meeting, etc. For more information about the workshop, please visit https://datascience.unc.edu/wisdm-2025/<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2500005","Conference: Summer School ""Stability in Topological Data Analysis""","DMS","TOPOLOGY, COMPUTATIONAL MATHEMATICS","06/01/2025","05/22/2025","Barbara Giunti","NY","SUNY at Albany","Standard Grant","Paulo Lima Filho","05/31/2026","$15,800.00","","bgiunti@albany.edu","1400 WASHINGTON AVE","ALBANY","NY","122220100","5184374974","MPS","126700, 127100","7556","$0.00","This award provides financial support for junior and early-career US participants in the summer school ?Stability in Topological Data Analysis?, to be held at the Institute Mittag-Leffler, Stockholm, Sweden, June 30 - July 4, 2025. Topological Data Analysis (TDA) aims to develop new techniques based on topology and other disciplines in pure mathematics to understand complex data. Research questions are strongly motivated by applications from neuroscience, image recognition, biology, material science, geography, and beyond. The underlying idea is that topology helps recognize patterns within data and, therefore, turn data into compressed, useful knowledge. Besides advancing the progress of science by helping to prepare the next generation of applied topologists, this school is also designed to expand the reach of applied topology.<br/><br/>The topic of the school is the study of general techniques to achieve stability of invariants in TDA that can be applied to different objects, from persistence modules to Reeb graphs. In particular, the focus is on questions about the stability of various TDA tools: 1) Which metrics can be introduced to ensure the stability of traditional topological invariants? 2) Which invariants can be developed to ensure stability with respect to traditional metrics? Through questions like these, TDA enriches the traditional fields of algebraic topology and geometry while at the same time striving for theoretical guarantees for practitioners in data analysis. There will be three lecturers alternating in the mornings, an introductory poster section, problem sessions in the afternoons, and a few short research talks from the participants. Ultimately, the school?s goal is to encourage students to develop their own application-motivated results in TDA by considering well-established principled strategies. Further details can be found at: https://www.mittag-leffler.se/activities/ewm-ems-summer-school-stability-in-topological-data-analysis/<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2448109","Conference: Early-Career and Student Support for the XXII Householder Symposium","DMS","COMPUTATIONAL MATHEMATICS","05/01/2025","02/04/2025","Anil Damle","NY","Cornell University","Standard Grant","Jodi Mead","12/31/2025","$24,000.00","David Bindel, Alex Townsend","damle@cornell.edu","341 PINE TREE RD","ITHACA","NY","148502820","6072555014","MPS","127100","7556, 9263","$0.00","The Householder Symposium XXII will be held June 8-13, 2025, at the Statler Hotel on the campus of Cornell University in Ithaca, NY. The symposium gathers the world's most active researchers in numerical linear algebra once every three years to review advances in the field, present recent theoretical and practical results, and assess where the field is headed in the future. A hallmark of the Symposium is its intimate atmosphere, which promotes close personal interaction and the free exchange of ideas. Many researchers in numerical linear algebra consider this gathering to be the most important and influential meeting in the field, reflecting its rich tradition dating back to the original ""Gatlinburg"" conferences founded by Alston Householder in the 1960s. This proposal supports the travel costs of 12 junior U.S. researchers to the Householder Symposium XXII. The funds will provide essential support for U.S. graduate students and recent Ph.D.s who might otherwise be unable to attend. By enabling full participation for promising junior members of the U.S. numerical linear algebra community, these NSF funds ensure that early-career scientists are introduced to leading experts in the field and have opportunities to showcase their cutting-edge work. The Householder Symposium has traditionally been a gateway conference into numerical linear algebra, making the attendance of junior scientists vital both for their professional development and for maintaining the robust U.S. competitiveness in this critical discipline. <br/><br/>Key topics to be emphasized at Householder XXII include the solution of large systems of linear equations, eigenvalue problems, preconditioning, perturbation theory, least squares, integral equations, and diverse applications in scientific and engineering computation, such as control, systems and signal processing, data mining, data compression, and bioengineering. Advances in numerical linear algebra have had profound effects on numerous scientific and technological fronts, including web search engines, the global positioning system, high-speed supercomputing algorithms, machine learning, and data science. Ensuring that the next generation of researchers actively participates in the conference will sustain the innovative momentum needed to address future challenges in science and engineering. More information about the conference is available at the website: https://householder-symposium.github.io.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2507452","Conference: Structure-Preserving Scientific Computing and Machine Learning Summer School and Hackathon","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","05/01/2025","04/15/2025","Jingwei Hu","WA","University of Washington","Standard Grant","Jodi Mead","10/31/2025","$39,560.00","Andy Wan","hujw@uw.edu","4333 BROOKLYN AVE NE","SEATTLE","WA","981951016","2065434043","MPS","126600, 127100","7556, 9263","$0.00","A Summer School and Hackathon event on Structure-Preserving Scientific Computing and Machine Learning will take place at the University of Washington, Seattle on June 16-25, 2025. Structure-Preserving Scientific Computing is an emerging field of research focused on the design of efficient numerical methods or algorithms that preserve fundamental mathematical structures or properties of continuous models at the discrete level. Such approaches are often essential to maintain accuracy and stability of numerical solutions, as well as to enhance efficiency in large-scale simulations. Moreover, scientific machine learning, which utilizes machine learning techniques to solve scientific computing problems, can also benefit from incorporating structure-preserving ideas to improve their prediction capability and generalizability on data-driven models. The main objectives of this Summer School and Hackathon event are: 1) Create a synergistic opportunity for established researchers, industry partners, postdocs, and graduate students to meet, network, and share the latest cutting-edge research in structure-preserving scientific computing. 2) Engage and provide training to graduate students working in computational mathematics. 3) Enable early career researchers to form strong connections and receive mentorship with world-leading experts and industry project leaders. 4) Cultivate long-lasting collaborations and innovative research among students and researchers at all career stages from academia, government agencies, industry, and beyond. <br/><br/>The Summer School will feature world-renowned experts delivering four minicourses on topics in Structure-Preserving Scientific Computing and Machine Learning, including operator splitting, dynamical low-rank methods, neural ordinary differential equations (ODEs), and neural operators. Building on this synergy, the subsequent Hackathon will challenge students to apply their newly acquired knowledge to real-world applications through four projects, led by project leaders from academia, government agencies, industry, and national laboratories. Event details and applications for graduate student participation will be posted on the conference website: https://sites.google.com/view/crg-spd/events/seattle-2025.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2529107","Interacting particle system for nonconvex optimization","DMS","COMPUTATIONAL MATHEMATICS","04/01/2025","06/18/2025","Yuhua Zhu","CA","University of California-Los Angeles","Continuing Grant","Jodi Mead","06/30/2027","$162,576.00","","yuhuazhu@ucla.edu","10889 WILSHIRE BLVD STE 700","LOS ANGELES","CA","900244200","3107940102","MPS","127100","9263","$0.00","Collective Intelligence offers profound insights into how groups, whether they be cells, animals, or even machines, can work together to accomplish tasks more effectively than individuals alone. Originating in biology and now influencing fields as varied as management science, artificial intelligence, and robotics, this concept underscores the potential of collaborative efforts in solving complex challenges. On the other hand, the quest for finding global minimizers of nonconvex optimization problems arises in physics and chemistry, as well as in machine learning due to the widespread adoption of deep learning. Building the bridge between these two seemingly disparate realms, this project will utilize Collective Intelligence to leverage the interacting particle systems as a means to address the formidable challenge of finding global minimizers in nonconvex optimization problems. Graduate students will also be integrated within the research team as part of their professional training. <br/><br/>This project will focus on a gradient-free optimization method inspired by a consensus-based interacting particle system to solve different types of nonconvex optimization problems. Effective communication and cooperation among particles within the system play pivotal roles in efficiently exploring the landscape and converging to the global minimizer. Aim 1 targets nonconvex optimization with equality constraints; and Aim 2 addresses nonconvex optimization on convex sets; while Aim 3 applies to Clustered Federated Learning. Additionally, convergence guarantees will be provided for nonconvex and nonsmooth objective functions. Theoretical analyses, alongside practical implementations, will provide valuable insights and tools for addressing different types of nonconvex optimization challenges.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2515513","Conference: Regional Applied Interdisciplinary Numerical (Cascade RAIN) conference in the Cascade Mountains area","DMS","COMPUTATIONAL MATHEMATICS","03/15/2025","03/10/2025","Malgorzata Peszynska","OR","Oregon State University","Standard Grant","Jodi Mead","12/31/2025","$9,737.00","Nathan Gibson, Nicholas Marshall","mpesz@math.oregonstate.edu","1500 SW JEFFERSON AVE","CORVALLIS","OR","973318655","5417374933","MPS","127100","7556, 9263","$0.00","The ""Regional Applied Interdisciplinary Numerical (Cascade RAIN) in the Cascade Mountains area"" conference will convene on the Oregon State campus on April 26, 2025. The conference will bring together faculty and students from across the Pacific Northwest to facilitate the exchange of scientific advancements in the area of computational mathematics and interdisciplinary applications. Presentations are expected to cover almost all topics within computational mathematics including state-of-the-art methods for numerical partial differential equations and foundational mathematics of machine learning and artificial intelligence. Through the use of travel support, the conference will seek to broaden the participation across this geographic area and reach the broadest possible cohort including graduate students and junior faculty in the region. The conference will also feature mini-tutorials on basic and advanced computational mathematics and the mathematics of data science as a means of engaging both less prepared and more senior participants in research in computational mathematics. Furthermore, this conference will seek to foster future collaborative efforts between participants at all career stages.  <br/><br/>This conference will provide support for the participants of the conference and aims to bring together researchers across many career stages including senior, junior faculty and other researchers as well as students involved in computational mathematics across its different aspects including numerical analysis and interdisciplinary work. The participants will gain new insights and perspectives in computational mathematics and various application domains from researchers in local universities. The specific minitutorials include hands-on training of advanced finite-difference and finite-volume methods for initial boundary value problems as well as unsupervised and supervised learning methods. The website of the conference is https://sites.google.com/oregonstate.edu/rain2025<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2436232","Collaborative Research: MATH-DT Closing the generalization gap of digital twins","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","03/01/2025","08/28/2024","Yitong Huang","MA","Smith College","Standard Grant","Dmitry Golovaty","02/29/2028","$269,187.00","","yhuang86@smith.edu","10 ELM ST","NORTHAMPTON","MA","010636304","4135842700","MPS","125300, 127100","075Z, 9263","$0.00","From the weather to human health to fighter jets, there are many complex systems whose outcomes we would like to predict and control. To achieve these goals, scientists and engineers often build digital twins---computer models that emulate and interact with the underlying physical systems. The current project describes fundamental research into the generalization ability of digital twins: to what degree can digital twins predict outcomes under conditions they have not previously encountered? For example, if the digital twin for an airplane has only seen data collected under normal operating conditions, can it accurately predict the plane's response to turbulence? By combining mathematical tools from nonlinear dynamics and computational tools from machine learning, this project aims to develop fundamental theories on generalization and build robust digital twins that can perform well in extreme or unexpected conditions. While the proposed framework applies to a broad class of complex systems, it is first being applied to circadian rhythms, which are the internal timekeeping mechanisms of the human body. Human biological clocks are increasingly subject to disturbances introduced by modern lifestyles such as long-haul air travel and nighttime computer use. Predictive digital twins can give personalized recommendations on effective interventions, such as optimal strategies to speed up recovery from jet lags. The project will also provide opportunities to teach modern mathematical concepts to a diverse population of undergraduate and graduate students. Through this project, students learn valuable skills in mathematical modeling, data analysis, science communication, and gain first-hand experience in building and managing state-of-the-art machine learning pipelines.<br/><br/>Current domain-agnostic digital twins based on deep neural networks are very expressive but can struggle when generalizing beyond their training conditions. Physics-based digital twins, on the other hand, generalize better to unseen conditions thanks to the strong inductive bias built into the model. On the other hand, they are often not sufficiently flexible to fully capture the rich dynamics in data. This project develops a new class of hybrid digital twins with tunable physics-based and domain-agnostic components, allowing practitioners to balance expressivity versus generalization, depending on the available data and the nature of the task. Utilizing concepts such as basins of attraction in multistable dynamical systems, a key objective of the project is to quantify how the generalization ability of the digital twin changes as the weights assigned to the two components are adjusted. In particular, the project explores the possibility that a properly weighted domain-agnostic component in the hybrid digital twin can sometimes improve out-of-distribution generalization, especially when the inductive bias provided by the physics-based component is imperfect. Digital twins that generalize to unseen conditions are crucial to applications such as finding optimal interventions for restoring disrupted circadian rhythms. For example, to find optimal strategies to speed up recovery from jet lags, a digital twin needs to predict the dynamics of a severely perturbed circadian clock based on data gathered mostly from normally operating clocks. These investigations will guide the creation of more robust digital twins and help inform critical decisions under new or uncertain conditions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2436233","Collaborative Research: MATH-DT Closing the generalization gap of digital twins","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","03/01/2025","08/28/2024","William Gilpin","TX","University of Texas at Austin","Standard Grant","Dmitry Golovaty","02/29/2028","$250,000.00","","wgilpin@utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","125300, 127100","075Z, 9263","$0.00","From the weather to human health to fighter jets, there are many complex systems whose outcomes we would like to predict and control. To achieve these goals, scientists and engineers often build digital twins---computer models that emulate and interact with the underlying physical systems. The current project describes fundamental research into the generalization ability of digital twins: to what degree can digital twins predict outcomes under conditions they have not previously encountered? For example, if the digital twin for an airplane has only seen data collected under normal operating conditions, can it accurately predict the plane's response to turbulence? By combining mathematical tools from nonlinear dynamics and computational tools from machine learning, this project aims to develop fundamental theories on generalization and build robust digital twins that can perform well in extreme or unexpected conditions. While the proposed framework applies to a broad class of complex systems, it is first being applied to circadian rhythms, which are the internal timekeeping mechanisms of the human body. Human biological clocks are increasingly subject to disturbances introduced by modern lifestyles such as long-haul air travel and nighttime computer use. Predictive digital twins can give personalized recommendations on effective interventions, such as optimal strategies to speed up recovery from jet lags. The project will also provide opportunities to teach modern mathematical concepts to a diverse population of undergraduate and graduate students. Through this project, students learn valuable skills in mathematical modeling, data analysis, science communication, and gain first-hand experience in building and managing state-of-the-art machine learning pipelines.<br/><br/>Current domain-agnostic digital twins based on deep neural networks are very expressive but can struggle when generalizing beyond their training conditions. Physics-based digital twins, on the other hand, generalize better to unseen conditions thanks to the strong inductive bias built into the model. On the other hand, they are often not sufficiently flexible to fully capture the rich dynamics in data. This project develops a new class of hybrid digital twins with tunable physics-based and domain-agnostic components, allowing practitioners to balance expressivity versus generalization, depending on the available data and the nature of the task. Utilizing concepts such as basins of attraction in multistable dynamical systems, a key objective of the project is to quantify how the generalization ability of the digital twin changes as the weights assigned to the two components are adjusted. In particular, the project explores the possibility that a properly weighted domain-agnostic component in the hybrid digital twin can sometimes improve out-of-distribution generalization, especially when the inductive bias provided by the physics-based component is imperfect. Digital twins that generalize to unseen conditions are crucial to applications such as finding optimal interventions for restoring disrupted circadian rhythms. For example, to find optimal strategies to speed up recovery from jet lags, a digital twin needs to predict the dynamics of a severely perturbed circadian clock based on data gathered mostly from normally operating clocks. These investigations will guide the creation of more robust digital twins and help inform critical decisions under new or uncertain conditions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2436231","Collaborative Research: MATH-DT Closing the generalization gap of digital twins","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","03/01/2025","08/28/2024","Yuanzhao Zhang","NM","Santa Fe Institute","Standard Grant","Dmitry Golovaty","02/29/2028","$269,979.00","","yuanzhao.zhang.1@gmail.com","1399 HYDE PARK RD","SANTA FE","NM","875018943","5059848800","MPS","125300, 127100","075Z, 9150, 9263","$0.00","From the weather to human health to fighter jets, there are many complex systems whose outcomes we would like to predict and control. To achieve these goals, scientists and engineers often build digital twins---computer models that emulate and interact with the underlying physical systems. The current project describes fundamental research into the generalization ability of digital twins: to what degree can digital twins predict outcomes under conditions they have not previously encountered? For example, if the digital twin for an airplane has only seen data collected under normal operating conditions, can it accurately predict the plane's response to turbulence? By combining mathematical tools from nonlinear dynamics and computational tools from machine learning, this project aims to develop fundamental theories on generalization and build robust digital twins that can perform well in extreme or unexpected conditions. While the proposed framework applies to a broad class of complex systems, it is first being applied to circadian rhythms, which are the internal timekeeping mechanisms of the human body. Human biological clocks are increasingly subject to disturbances introduced by modern lifestyles such as long-haul air travel and nighttime computer use. Predictive digital twins can give personalized recommendations on effective interventions, such as optimal strategies to speed up recovery from jet lags. The project will also provide opportunities to teach modern mathematical concepts to a diverse population of undergraduate and graduate students. Through this project, students learn valuable skills in mathematical modeling, data analysis, science communication, and gain first-hand experience in building and managing state-of-the-art machine learning pipelines.<br/><br/>Current domain-agnostic digital twins based on deep neural networks are very expressive but can struggle when generalizing beyond their training conditions. Physics-based digital twins, on the other hand, generalize better to unseen conditions thanks to the strong inductive bias built into the model. On the other hand, they are often not sufficiently flexible to fully capture the rich dynamics in data. This project develops a new class of hybrid digital twins with tunable physics-based and domain-agnostic components, allowing practitioners to balance expressivity versus generalization, depending on the available data and the nature of the task. Utilizing concepts such as basins of attraction in multistable dynamical systems, a key objective of the project is to quantify how the generalization ability of the digital twin changes as the weights assigned to the two components are adjusted. In particular, the project explores the possibility that a properly weighted domain-agnostic component in the hybrid digital twin can sometimes improve out-of-distribution generalization, especially when the inductive bias provided by the physics-based component is imperfect. Digital twins that generalize to unseen conditions are crucial to applications such as finding optimal interventions for restoring disrupted circadian rhythms. For example, to find optimal strategies to speed up recovery from jet lags, a digital twin needs to predict the dynamics of a severely perturbed circadian clock based on data gathered mostly from normally operating clocks. These investigations will guide the creation of more robust digital twins and help inform critical decisions under new or uncertain conditions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2503030","Conference: East Coast Optimization Meeting 2025 (ECOM25)","DMS","COMPUTATIONAL MATHEMATICS","02/15/2025","02/04/2025","Harbir Antil","VA","George Mason University","Standard Grant","Yuliya Gorb","01/31/2026","$21,510.00","","hantil@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","MPS","127100","9263, 7556","$0.00","The fifth East Coast Optimization Meeting (ECOM) will occur on April 17-18, 2025, at George Mason University, Arlington, Virginia. The goal of ECOM is to introduce students and early-career researchers to current trends in optimization as well as to provide a strong networking environment between academia, industry, and the national laboratories. The focus of this fifth meeting will be on the role of optimization for Digital Twins. Digital Twins are expected to have a significant impact on science, engineering, and society. For instance, it is anticipated that they will lead to new developments in identifying weaknesses in structures such as bridges, nuclear plants, and wind turbines. Digital Twins of human organs have the potential to lead to cures of diseases that have long eluded researchers.  The variety of topics to be discussed in the meeting such as stochastic optimization, modeling, partial differential equations, and risk averse optimization are also of much wider interest beyond Digital Twins. The meeting will also provide a unique opportunity for graduate students, postdocs and other early career scientists to take courses from two leading researchers in modeling, optimization, and scientific computing. <br/><br/>ECOM speakers and participants will study the key question of how to best utilize optimization to combine physics-based and data-driven models. This approach, when carried out for the entire complex physical system, for its lifetime, can be termed a ""Digital Twin."" One of the critical components of a Digital Twin, which distinguishes it from classical modeling, is the use of data over the entire lifetime of the physical system to update the Digital Twin. Subsequently, Digital Twins bring together several research areas in mathematics, including modeling, analysis, control, optimization, numerical analysis, and scientific computing. New algorithmic developments are expected in these areas and this workshop aims to dive deeper into the topics relevant to Digital Twins: optimization constrained by simulation, optimization under uncertainty, and inexact optimization algorithms. A particular focus of this workshop will be the identification and development of benchmark applications and software implementation. The tutorials and invited talks will focus on consequential problems and will discuss state-of-the-art optimization solvers to handle these problems. As a result, the attendees will be equipped to tackle a new set of challenging problems. More details can be found at the conference website: https://math.gmu.edu/~hantil/ECOM/2025/<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2501357","Conference: Midwest Numerical Analysis Day 2025","DMS","COMPUTATIONAL MATHEMATICS","02/15/2025","02/04/2025","Huijing Du","NE","University of Nebraska-Lincoln","Standard Grant","Jodi Mead","01/31/2026","$30,000.00","Petronela Radu","78731612@nebraska.edu","2200 VINE ST # 830861","LINCOLN","NE","685032427","4024723171","MPS","127100","7556, 9150, 9263","$0.00","The 2025 Midwest Numerical Analysis Day (MWNADay) is scheduled to take place on April 5-6, 2025, at the University of Nebraska-Lincoln. This conference will provide a collaborative platform for researchers from the Midwest region and beyond to share knowledge and build connections in numerical analysis, computational mathematics, and related applied fields. By fostering a welcoming and low-pressure environment, MWNADay has become particularly valuable for early-career researchers, enabling them to present their work, exchange ideas, and explore collaborations. This event will also emphasize and encourage participation from individuals across many types of groups and institutions with limited access to major conferences. As computational technologies continue to impact various disciplines, MWNADay serves a crucial role in strengthening the community and advancing the frontiers of computational and numerical sciences.<br/><br/>MWNADay 2025 focuses on promoting advancements in numerical analysis and scientific computing by providing a forum for researchers to discuss cutting-edge developments, exchange methodologies, and explore interdisciplinary applications. The conference will draw participants from various academic and research institutions, including (according to the Carnegie Classification System) the 26 R1 (very high research activity) and 32 R2 (high research activity) universities in the Midwest, to share insights and engage in collaborative discussions. Central to its mission is the development of efficient numerical algorithms and their theoretical foundations, which are essential for addressing challenges in fields such as fluid dynamics, biomechanics, and geophysics. The local organizing committee aims to facilitate the participation of a broad audience, particularly early-career researchers, as well as faculty from institutions where access to major research conferences may be limited. MWNADay will offer a range of activities, including technical presentations, poster sessions, and networking opportunities, to inspire innovation and foster partnerships among attendees. Additionally, the conference aims to bridge gaps between research communities by integrating junior and senior researchers and advancing knowledge transfer across disciplines, ultimately contributing to the broader fields of numerical analysis and computational mathematics. The conference website is https://math.unl.edu/midwest-numerical-analysis-day-2025<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2436333","Math-DT: Advancing the Mathematical Foundations for Dynamic Digital Twinning of Next-Generation Mobile Wireless Networks","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","01/01/2025","08/09/2024","Jeff Calder","MN","University of Minnesota-Twin Cities","Standard Grant","Dmitry Golovaty","12/31/2027","$900,000.00","Zhi-Li Zhang, Yulong Lu","jwcalder@umn.edu","2221 UNIVERSITY AVE SE STE 100","MINNEAPOLIS","MN","554143074","6126245599","MPS","125300, 127100","075Z, 9263","$0.00","Digital Twins?virtual models of physical systems?have garnered growing attention in recent years, driven by rapid advances in sensing, communications, computing, machine learning and artificial intelligence, and hold the potential to vastly accelerate scientific discovery and revolutionize many industries. In particular, Digital Twins play a fundamental role in designing, managing and optimizing 5G wireless networks and will be essential in enabling next-generation 6G wireless networks. Despite recent advances in realistic channel modeling, there are still many fundamental challenges in developing fit-for-purpose Digital Twins for next generation wireless networks that can seamlessly integrate data for informed decision making, and can be dynamically updated as the physical environment varies and network operational objectives change. Motivated by these challenges, the team of investigators develops novel mathematical theories, and new data-driven, AI-guided models and algorithms that will lay the mathematical foundations for digital twinning of next generation wireless networks. The award also supports undergraduate and graduate students from underrepresented groups in research and educational activities as well as organization of K-12 outreach programs.<br/><br/>This proposal aims to advance the mathematical foundations of next generation wireless network Digital Twins. The investigators will place the ray tracing problem?essential to such digital twins?in the more general framework of first order Hamilton-Jacobi equations, and will make theoretical and algorithmic advances in data-driven learning of Hamilton-Jacobi equations. The research team will prove optimal sample size complexity bounds for learning Hamilton-Jacobi equations and their solutions from data, and develop algorithms for achieving these bounds, in both the static and active learning settings. They will develop a temporal surface reconstruction algorithm that combines temporal LiDAR and video camera information by leveraging neural kernels and transport equations. In order to quantify the uncertainty in their results, the investigators will establish posterior contraction rates for learning Hamilton-Jacobi equations, and develop methods to construct and analyze Bayesian credible sets and perform scalable posterior sampling. Finally, the investigators will integrate their theoretical and algorithmic advances into a next generation wireless network Digital Twin platform that will be evaluated in both controlled and dynamic real-world environments.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2533443","MATH-DT: Gradient-enhanced Deep Gaussian Processes for Optimization of Diffusive High-Speed Unsteady Mixers","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","01/01/2025","05/21/2025","Annie Booth","VA","Virginia Polytechnic Institute and State University","Standard Grant","Yuliya Gorb","12/31/2027","$498,290.00","","annie_booth@ncsu.edu","300 TURNER ST NW","BLACKSBURG","VA","240603359","5402315281","MPS","125300, 127100","","$0.00","Rotating detonation combustors (RDCs) coupled to highly diffusive mixers enable compact, green, and efficient energy production.  RDCs operate through the injection of an air-fuel mixture which is detonated through a reactive shock wave rotating at supersonic speeds and fed through the mixer to cool and slow the flow before it reaches a turbine which ultimately harnesses the energy.  RDC-mixers hold great promise to revolutionize power and propulsion systems, but they are difficult to model/optimize due to unsteady mixing, extreme temperatures, and high-speed diffusion.  This collaborative project aims to develop models and methodologies that enable optimization of the RDC-mixer for maximal fuel efficiency.  The investigators will leverage a three-pronged meta-modeling framework featuring an innovative digital twin, a novel statistical surrogate model, and a physical experiment involving a high speed wind tunnel in which the mixer will be assessed through high-frequency optical and probe-based measurement techniques.  RDC-mixer-turbine systems are directly impactful to clean energy and heat production, but their potential impact is even broader. Diffusing elements and mixers are used in a variety of applications, ranging from aviation, aerospace, agriculture, refrigeration cycles and heat exchangers. The mathematical modeling foundations developed in this project will be widely applicable to computer simulation experiments and digital twins. <br/><br/>This project is organized into three aims. First, motivated by the complexities of the digital twin, a gradient-enhanced Bayesian deep Gaussian process surrogate will be developed to provide non-stationary flexibility, uncertainty quantification, gradient-enhancement for improved accuracy, and gradient predictions to facilitate Bayesian optimization.  Second, the digital twin of the RDC-mixer will be developed at reduced computational costs as existing simulations of RDC-mixers require weeks of compute time.  Tailored unsteady boundary conditions are proposed to separate the computational fluid dynamic simulations for the combustor and mixer, which will enable faster computation.  The digital twin will incorporate steady and unsteady flows, meshing, and adjoint solvers to provide gradient information at minimal cost.  Third, a novel calibrated Bayesian optimization framework will be developed to first optimize calibration parameters of the digital twin, then use these with a bias-correction model to sequentially optimize the physical experiment. The physical model will be used in the calibration feedback loop to train the bias-correction model and to test and validate the best designs.  Collectively, the surrogate model, digital twin, and physical experiment will enable effective optimization of the RDC-mixer design for optimal fuel efficiency.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2436164","MATH-DT: Gradient-enhanced Deep Gaussian Processes for Optimization of Diffusive High-Speed Unsteady Mixers","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","01/01/2025","08/09/2024","Annie Booth","NC","North Carolina State University","Standard Grant","Yuliya Gorb","05/31/2025","$498,290.00","James Braun","annie_booth@ncsu.edu","2601 WOLF VILLAGE WAY","RALEIGH","NC","276950001","9195152444","MPS","125300, 127100","","$0.00","Rotating detonation combustors (RDCs) coupled to highly diffusive mixers enable compact, green, and efficient energy production.  RDCs operate through the injection of an air-fuel mixture which is detonated through a reactive shock wave rotating at supersonic speeds and fed through the mixer to cool and slow the flow before it reaches a turbine which ultimately harnesses the energy.  RDC-mixers hold great promise to revolutionize power and propulsion systems, but they are difficult to model/optimize due to unsteady mixing, extreme temperatures, and high-speed diffusion.  This collaborative project aims to develop models and methodologies that enable optimization of the RDC-mixer for maximal fuel efficiency.  The investigators will leverage a three-pronged meta-modeling framework featuring an innovative digital twin, a novel statistical surrogate model, and a physical experiment involving a high speed wind tunnel in which the mixer will be assessed through high-frequency optical and probe-based measurement techniques.  RDC-mixer-turbine systems are directly impactful to clean energy and heat production, but their potential impact is even broader. Diffusing elements and mixers are used in a variety of applications, ranging from aviation, aerospace, agriculture, refrigeration cycles and heat exchangers. The mathematical modeling foundations developed in this project will be widely applicable to computer simulation experiments and digital twins. <br/><br/>This project is organized into three aims. First, motivated by the complexities of the digital twin, a gradient-enhanced Bayesian deep Gaussian process surrogate will be developed to provide non-stationary flexibility, uncertainty quantification, gradient-enhancement for improved accuracy, and gradient predictions to facilitate Bayesian optimization.  Second, the digital twin of the RDC-mixer will be developed at reduced computational costs as existing simulations of RDC-mixers require weeks of compute time.  Tailored unsteady boundary conditions are proposed to separate the computational fluid dynamic simulations for the combustor and mixer, which will enable faster computation.  The digital twin will incorporate steady and unsteady flows, meshing, and adjoint solvers to provide gradient information at minimal cost.  Third, a novel calibrated Bayesian optimization framework will be developed to first optimize calibration parameters of the digital twin, then use these with a bias-correction model to sequentially optimize the physical experiment. The physical model will be used in the calibration feedback loop to train the bias-correction model and to test and validate the best designs.  Collectively, the surrogate model, digital twin, and physical experiment will enable effective optimization of the RDC-mixer design for optimal fuel efficiency.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2506531","Conference: NSF Computational Mathematics Meeting 2025","DMS","COMPUTATIONAL MATHEMATICS","01/01/2025","02/18/2025","Yekaterina Epshteyn","UT","University of Utah","Standard Grant","Jodi Mead","12/31/2025","$99,999.00","Alexander Alekseenko, James Adler, Lars Ruthotto","epshteyn@math.utah.edu","201 PRESIDENTS CIR","SALT LAKE CITY","UT","841129049","8015816903","MPS","127100","9263, 7556","$0.00","The National Science Foundation (NSF) Computational Mathematics (CompMath) Principal Investigators (PI) Meeting, ""NSF Computational Mathematics Meeting 2025"" will be held on May 8 - 9, 2025, at the University of Utah, in Salt Lake City, Utah. The meeting will bring together program officers of the NSF Division of Mathematical Sciences (DMS) CompMath program, program officers from related programs, and researchers working in computational mathematics and related fields. Participation is open to all including those already funded by the NSF CompMath program, as well as participants seeking funds from the NSF, such as early career faculty, postdoctoral fellows, and graduate students. The major goals of the meeting are to provide a forum for the NSF CompMath-sponsored researchers to showcase their projects regarding intellectual merit and broader impacts, to raise awareness of the breadth of the program's topics and their impacts, and to allow the computational mathematics community to assess the programs in their entirety. In addition, the meeting is intended to facilitate the exchange of ideas and spur collaboration on the development of crucial insights into future directions of computational mathematics, to broaden the expertise of the community by introducing junior researchers to the NSF CompMath program, and to help communicate to the public the scope of the impacts of the computational mathematics field. The meeting is open to all interested in computational mathematics.<br/> <br/>The NSF DMS CompMath program supports fundamental mathematical, applied, and interdisciplinary research in diverse areas where computation plays a central and crucial role. Algorithms and numerical simulations have long become necessary and unavoidable for the description, analysis, and predictions of real-world phenomena. However, the proliferation of computation continues at an accelerated pace, aided by advances in available computational power. The unprecedented growth in the scope of applications of computational mathematics highlights the need for continuing progress in the development of revolutionary algorithms to address, for example, a broad range of complex multiscale and multiphysics problems to maintain the pace of scientific, engineering, technological, and societal discoveries. This unique meeting and forum for the computational mathematics discipline will provide invaluable overviews of the broad spectrum of research topics within the field and showcase many achievements of the projects funded by the NSF CompMath program. The meeting will help to further strengthen the computational mathematics community by creating a supportive and engaging atmosphere for new interactions and collaborations among participants. In addition, the meeting will provide an important platform for exposing junior investigators, from graduate students to postdoctoral researchers and early-career faculty, to all the exciting directions of modern computational mathematics, as well as will give them an opportunity to learn more about the NSF DMS CompMath program and various funding options to support the research and educational activities in the area. The focus areas of the program for the NSF CompMath meeting 2025 range from more classical areas to novel emergent directions. Topics include the design of numerical algorithms for the solution of mathematical models based on differential equations, the development of algorithms for inverse problems, numerical analysis, scientific computing, optimization, mathematical aspects of data science and artificial intelligence, mathematical and computational aspects of the development of digital twins, quantum computing, and applications of these numerical analysis and computational tools for the solutions of pressing scientific, engineering, and societal problems. The meeting website: https://sites.google.com/gcloud.utah.edu/nsfcompmath-meeting-2025/home<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2531805","Innovative Time Integrators for Stiff and Highly Oscillatory Systems","DMS","COMPUTATIONAL MATHEMATICS","01/01/2025","05/21/2025","Vu Thai Luan","TX","Texas Tech University","Standard Grant","Yuliya Gorb","08/31/2026","$172,450.00","","vu.luan@ttu.edu","2500 BROADWAY","LUBBOCK","TX","79409","8067423884","MPS","127100","1303, 5294, 9150, 9263","$0.00","Advancements in science and engineering increasingly require fast and accurate computational methods for simulating complex multi-physical processes and their interactions occurring at a wide range of temporal scales or high frequencies. Numerical weather prediction and climate modeling are notable examples of such applications that rely on the computational solution of primitive equations, which are used to predict the behavior of the atmosphere, oceans, land surface, ice, etc., as well as the complex interactions among them. Numerical solutions of such multiphysics problems remain a challenging task due to the presence of multiple time scales in the system where different processes take different amounts of time to complete. As such, developing advanced numerical methods capable of offering fast and reliable solutions is crucial for many applications that rely on large-scale simulations of complex systems. The overall goal of this project is to develop novel time integration methods for stiff and highly oscillatory systems and demonstrate their performance on applications such as numerical weather prediction, ocean modeling, and molecular dynamics simulations. Additionally, the project aims to train one doctoral student and offer opportunities to undergraduate and graduate students in mathematics at Mississippi State University. Training of at least one graduate student on the topics of the proposed work is expected. <br/><br/>The project has four primary aims. First, the investigator will derive novel mixed exponential integrators and preconditioned rational exponential integrators for stiff systems and implement them. Second, the investigator will develop stiffly-accurate embedded multirate exponential methods for additively partitioned systems. Third, the investigator will develop stiffly-accurate exponential Nystrm methods. Fourth, the investigator will investigate the performance of the newly developed methods on applications in numerical weather prediction, ocean modeling, and molecular dynamics simulations. The investigator will build off of his previous expertise in constructing, analyzing, and implementing exponential and multirate time integration methods to achieve these aims. Ongoing collaborations with numerical analysts, meteorologists, and computer scientists will also contribute to the success of the project.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
