"AwardNumber","Title","NSFOrganization","Program(s)","StartDate","LastAmendmentDate","PrincipalInvestigator","State","Organization","AwardInstrument","ProgramManager","EndDate","AwardedAmountToDate","Co-PIName(s)","PIEmailAddress","OrganizationStreet","OrganizationCity","OrganizationState","OrganizationZip","OrganizationPhone","NSFDirectorate","ProgramElementCode(s)","ProgramReferenceCode(s)","ARRAAmount","Abstract"
"0713829","Discontinuous Galerkin Methods for PDEs with Heterogeneous Coefficients","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","07/22/2009","Jean-Luc Guermond","TX","Texas A&M Research Foundation","Continuing Grant","Junping Wang","08/31/2011","$300,000.00","Raytcho Lazarov, Guido Kanschat","guermond@math.tamu.edu","400 HARVEY MITCHELL PKWY S STE 3","COLLEGE STATION","TX","778454375","9798626777","MPS","1271","0000, 9263, OTHR","$0.00","Heterogeneity and anisotropy are phenomena encountered in many different settings: flows in porous media, optical tomography, neutron transport, radiative transfer, electromagnetics, etc. While the differential equations modeling these problems may be different in nature, the common feature they share is that they involve parameters that may be highly heterogeneous (values may have jumps of many orders of magnitude) or can be highly anisotropic. Under the usual terminology these problems are degenerate (i.e. there is no uniform ellipticity) and, as a result, cannot be handled using standard mathematical methods. The objective of this research project is to analyze degenerate problems (well-posedness, stability, etc.)  and to develop general discontinuous Galerkin techniques for approximating them. The discontinuous Galerkin that will be constructed will be stable for all the degenerate cases of interest and will automatically approximate the physically meaningful transmission conditions between sub-domains with different parameter ranges without the user having to identify sub-domains with specific properties a priori. The key is to use the mathematical framework of Friedrichs systems and to design the operators that controls discontinuities in the approximate solution appropriately.<br/><br/><br/>The merit of the proposed approximation technique is that it addresses the problem at hand from a radically different perspective than the usual multi-domain/multi-algorithmic approaches.  The new technique will automatically detect heterogeneity/anisotropy and will adapt to situations without the user having to take manual action.  The impact of this research project will be broad since the class of problems addressed touches many fields in engineering, in environmental sciences, in geophysics, in petroleum engineering, semiconductor industry, etc.  Proposing a novel robust approximation technique for solving problems with highly heterogeneous and anisotropic properties will eventually benefit many areas of science and engineering where controlling or dealing with this type of problem is still a serious challenge.<br/>"
"0713868","International Conference on Computational Methods in Energy and Environmental Research","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","08/17/2007","Guan Qin","TX","Texas A&M Research Foundation","Standard Grant","Junping Wang","08/31/2008","$27,000.00","Dongxiao Zhang","gqin@uwyo.edu","400 HARVEY MITCHELL PKWY S STE 3","COLLEGE STATION","TX","778454375","9798626777","MPS","1271","0000, 7556, 9263, OTHR","$0.00","Real world problems that arise in energy and environmental research are often times mathematically challenged. They contain comprehensive issues that require thorough understanding of the underlining principles of physics, mathematical modeling, numerical solution techniques and computing infrastructure. Therefore, it is essential to form a multi-disciplinary team to efficiently solve theses problems. This inaugural conference on Computational Methods in Energy and Environmental Research will be a highly multi-disciplinary meeting. Researchers from different<br/>disciplines will attack some of the critical challenges in energy and environmental research. The objective of the conference is to have the researchers present their work and share their vision on important energy and environmental issues. In the mean time, they will listen, consult and learn from others, especially from those who are engaged in different disciplines. The plenary speakers, who are leading researchers in their area, will present their research and vision to lead the conference discussion. The plenary sessions will be followed by parallel minisymposium sessions, which feature in-depth technical discussions on the subject of special interest that is related to the conference topics. <br/><br/>The organizing committee chose to hold the inaugural conference in China for China's increasing importance in global energy and environment development. China is currently the world's second biggest energy consumer and greenhouse gas emitter after the United States. In the battle against energy shortage and vast environmental footprints, China's top leaders have launched robust policy initiatives that support research on renewable sources, energy efficiency, policy, petroleum exploration and other important energy and environmental problems. The organizing committee anticipates strong participation from Chinese energy and environmental research communities. They will share the hard lessons learnt and also catch up with frontier research through interactions with leading international scientists. It is also the first U.S.-China conference in this very important field. The conference will foster open dialogue and substantial research collaborations that will benefit both counties and arm them for the battle against energy crisis and global environmental deterioration."
"0753797","New Numerical Methods for Hamilton-Jacobi and Liouville Equations; Their Applications to Geometrical Optics, Wave Propagation and Travel-time Tomography","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","10/15/2007","Jianliang Qian","MI","Michigan State University","Standard Grant","Leland Jameson","07/31/2008","$36,563.00","","qian@math.msu.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1271","0000, 9263, OTHR","$0.00","The investigator develops novel and efficient numerical<br/>methods for Hamilton-Jacobi and Liouville equations. These equations arise<br/>from seismic wave propagation, geometrical optics, optimal control,<br/>travel-time tomography, medical imaging, computer vision, and material<br/>sciences. His previous works on computing viscosity solutions and<br/>multivalued solutions of Hamilton-Jacobi equations lead him to develop<br/>more powerful and efficient numerical methods<br/>for solving these equations and incorporate these new methods<br/>into seismic modeling and inversion, as well as other possible<br/>applications. Problems under consideration include continued development<br/>of adaptive eikonal solvers for three-dimensional isotropic and<br/>anisotropic media; fast sweeping methods for stationary Hamilton-Jacobi<br/>equations on unstructured meshes; extending slowness matching methods to<br/>general Hamilton-Jacobi equations for computing multivalued solutions; and<br/>applications of paraxial Liouville equations for geometrical optics, wave<br/>propagation and transmission tomography.<br/>This investigation advances the state-of-the-art in geometrical optics,<br/>wave propagation and seismic travel-time tomography.<br/><br/>These fields and applications are of great strategic value in the US oil<br/>and gas industry, in environmental sciences, and in medical imaging.<br/>Recently, for example, the price of gasoline soared dramatically in the<br/>United States. One way to reduce the cost of production of oil involves<br/>lowering drilling costs by advancing the seismic data processing<br/>techniques that oil companies use to find good drilling sites.  The<br/>investigator's new methods expedite routine data processing, provide new<br/>tools for exploration geophysicists to use for ground-breaking<br/>applications, and enable substantial cost savings in seismic explorations,<br/>as the speed and reliability of the underlying computational engine allows<br/>``rig-site'' adjustments to both seismic survey and drilling decisions.<br/>"
"0713807","Tight Wavelet Frames for Data Compression","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","08/22/2007","Ming-Jun Lai","GA","University of Georgia Research Foundation Inc","Standard Grant","Leland Jameson","08/31/2010","$215,855.00","Alexander Petukhov","mjlai@uga.edu","310 E CAMPUS RD RM 409","ATHENS","GA","306021589","7065425939","MPS","1271","0000, 9263, OTHR","$0.00","The investigator and his colleague study the problem how to use tight wavelet frames for image/data compression. They have related the problem to many useful equivalent problems such as compressed sensing, cryptography, error correcting codes, in-painting or recovery of lost data, and consistent recovery from quantized expansions so that the ideas and mathematical techniques from the equivalent problems can be borrowed to study the image/data compression based on tight wavelet frames. They will use the method of virtual components, finite state machine, new variations of orthogonal greedy algorithm, lp optimization with p between 0 and 1, and harmonic frames to tackle the data compression problem. Preliminary results show that they are very promising. An ultimate goal of the proposed research is to build flexible methods for constructing multivariate tight wavelet frames with required properties for data compression and make them available for applications. <br/><br/>Images and data compression is absolutely necessary for internet, multimedia communication, and data storage/transmission. Fifteen years ago, FBI  established a standard using a wavelet function to compress all finger prints for storage and processing. Tight wavelet frames are more flexible to construct than orthonormal wavelet functions. The investigator and his colleague will study how to use tight wavelet frames for image and data compression. The expected scientific results will enable better understanding how to find the most sparse representation of data in redundant linear systems. The results will have immediate impact on the modern design of communication systems like mobile telephony, digital camera, and digital broadcasting as well as on the methods of multimedia data compact representation.<br/>"
"0713876","Adaptive Multilevel Iterative Substructuring Methods","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","08/22/2007","Jan Mandel","CO","University of Colorado at Denver-Downtown Campus","Standard Grant","Junping Wang","08/31/2011","$209,965.00","","Jan.Mandel@ucdenver.edu","1380 LAWRENCE ST STE 300","DENVER","CO","802042055","3037240090","MPS","1271","0000, 9263, OTHR","$0.00","In an elliptic partial differential equation, the solution is non-local: its value at any point depends on the right-hand-side at any other point. Such equations arise in fluid and solid mechanics. In addition, real problems have often irregular (quickly varying) geometry or material properties in some places, and, after discretization, result in very large problems, particularly in 3D; hundreds of millions of degrees of freedom are not so unusual any more. Because of the size of the problem, the use of distributed massively parallel computers is mandatory, both for processor power and for the memory space. Iterative substructuring methods are a class of domain decomposition methods devised to use massively parallel computers for such problems in spite of the non-locality of the solution. This project will start from one of the most advanced methods of this class, the BDDC method, which requires algebraic information only (the matrices of the substructures). Substructuring method are scalable with the number of processors up to some point; after that, the complexity of direct solution of the coarse problem, needed to coordinate the solution between the processors, will dominate. In this project, the method itself is applied recursively and results in a multilevel method much like in multigrid, except naturally adapted to parallel processing from the outset. Robust treatment of irregular problems will be made possible by the use of adaptive techniques, which focus computational work in the places where it is needed.<br/><br/>Efficient algorithms for physical simulations on massively parallel computers are of strategic importance. Computational modeling is augmenting and to a large extent substituting expensive and possibly dangerous or infeasible physical experiments in engineering. Significant growth of computational power is now achieved by using more processors in parallel. This project will develop new methods to use a large number of processors efficiently. It will also contribute to the mathematical understanding of massively parallel algorithms, which is essential because it allows one to guarantee that they will work on more processors and on other problems than they can currently be tested on.<br/>"
"0712853","AMC-SS Self-Optimized Monte Carlo Methods for Radiative Transport","DMS","COMPUTATIONAL MATHEMATICS","07/01/2007","06/22/2007","Jerome Spanier","CA","University of California-Irvine","Standard Grant","Junping Wang","06/30/2009","$113,815.00","","jspanier@uci.edu","160 ALDRICH HALL","IRVINE","CA","926970001","9498247295","MPS","1271","0000, 9263, OTHR","$0.00","Monte Carlo (MC) methods were developed more than sixty years ago in order to investigate the transport of neutrons through fissionable assemblies of nuclear material.  In the intervening years, their use has grown dramatically and they now provide a 'gold standard' of computational support for many other important problems of science and engineering that are modeled using the radiative transport equation.  Examples in biomedicine alone include modeling light-tissue interactions in heterogeneous tissue systems and establishing reliable radiation therapy plans for cancer patients based on accurate dosimetry.  Because of their importance in these and many other applications, MC simulations account for a significant fraction of all computer time used worldwide and for well over 50% of supercomputer expenses in the United States alone.<br/><br/>Over the years many significant improvements in the MC method have been suggested and adopted but few fundamental advances have been made.  This project proposes such an advance by developing novel MC algorithms that accelerate the convergence of the MC method through the introduction of a learning mechanism into the algorithm.  When executed correctly, this adaptive learning mechanism causes a 'snowballing' increase in computational efficiency (technically, an exponentially increased convergence rate) that enables computations with the new algorithms to be completed in seconds that would require years and even centuries of conventional MC simulation on the same computer platform. <br/><br/>The theoretical principles involved in this work have been understood for at least a decade and implementations on 'simple' problems have produced astonishing efficiency gains.  However, when attempted on more complex problems, the computational advantage breaks down because of increases in computational complexity.  The methods to be developed in this project circumvent these difficulties by narrowing the computations to only their most essential components.  In doing this, the new algorithms sacrifice unlimited accuracy in representing the RTE solution throughout the system for very high precision in a much smaller number of quantities that represent just the system 'measurables'.  The basic theory underlying these new methods and their application on 'model' transport problems will be investigated in this initial year of funding."
"0715060","Reconstruction algorithms for inverse obstacle problems","DMS","COMPUTATIONAL MATHEMATICS","08/01/2007","09/14/2009","William Rundell","TX","Texas A&M Research Foundation","Continuing Grant","Junping Wang","07/31/2012","$296,083.00","","Rundell@math.tamu.edu","400 HARVEY MITCHELL PKWY S STE 3","COLLEGE STATION","TX","778454375","9798626777","MPS","1271","0000, 9263, OTHR","$0.00","Many parameters of physical interest cannot be studied directly. Examples include: imaging the interior of the body or locating buried objects; determining the location and size of cracks within solid objects; reconstructing material parameters such as the conductivity of interior regions. When these problems are translated into mathematical terms they take the form of partial differential equations. However, since we have additional unknowns in the model, these introduce unknown parameters in the equations that we must additionally resolve by means of further measurements. A central theme of the proposal is the question of when a unique determination can be made (what is the minimal amount of data needed) as well as the design of algorithms for the efficient numerical recovery of the unknowns. This proposal considers the practical and computational aspects of this from a mathematical perspective. Specific problems addressed include the recovery of the location, shape, and material properties of interior objects from surface measurements. In such inverse problems two things must always be understood. First, the reconstructions will be extremely sensitive to small changes in the data, this is inherent in the underlying physics; in mathematical terms these are highly ill-conditioned problems containing both analytical and computational complexity. Second, the available data is always subject to error. However, we may know a model for the data error such as, for example, its mean and variance. This proposal seeks a formulation that will allow us to provide similar information on the geometry of the obstacle - namely a quantitative assessment of the ranges of reconstructions one could expect with a given level of data error. This would allow us to assign a probability that a particular feature would be identifiable or that, say, the volume of the object is greater than a given value.<br/><br/>The proposal has a range of broader impacts.These include not only the breadth of applications to science and engineering covered by these inverse problems, but there is an important training aspect involved. Specifically, many of the problems have simplified versions where both the experimental apparatus needed as well as some of the corresponding reconstruction algorithms are within reach of advanced undergraduates. This will enable a wider audience to gain an understanding of both the challenges and possible solutions to these ubiquitous but complex problems."
"0713872","Computational Theory and Methods for Finding Multiple Solutions to Differential Systems","DMS","COMPUTATIONAL MATHEMATICS","07/15/2007","08/04/2008","Jianxin Zhou","TX","Texas A&M Research Foundation","Standard Grant","Junping Wang","06/30/2011","$221,270.00","","jzhou@math.tamu.edu","400 HARVEY MITCHELL PKWY S STE 3","COLLEGE STATION","TX","778454375","9798626777","MPS","1271","0000, 9263, OTHR","$0.00","Dr. Zhou, the principal investigator, proposes to develop computational <br/>theory and methods for finding multiple unstable solutions to PDE <br/>(eigen) systems. Multiple unstable solutions, lowly or highly, singly or <br/>multiply excited, to many nonlinear systems have been observed with very <br/>different instabilities, maneuverabilities and configurations. Hence they <br/>imply a variety of applications. When multi-bodies (particles, molecules, <br/>species, etc.) are involved in a system, they may interact with each other <br/>in many different ways, such as strongly coupled vs. weakly coupled, <br/>cooperative vs. non-cooperative, definite vs. strongly indefinite, <br/>variational vs. non-variational, etc. Thus mathematically systems can be <br/>classified into many different types. Based on the results obtained from the <br/>previous NSF funded project and several successful preliminary <br/>investigations, the PI proposes a new game theory methodology that treats <br/>each body in a system as a player. According to the interactions among all <br/>bodies, two-level local optimization methods will be developed to solve <br/>proposed problems and mathematical justification of those methods will be <br/>established. Several important model problems in Bose-Einstein condensates, <br/>nonlinear optics, biology and non-Darcian/Newtonian fluids/materials are <br/>proposed to solve for testing the new theory and methods. The instability <br/>index of unstable solutions is important information for application and <br/>thus will be analyzed.<br/><br/>Unstable solutions appear only in a short time period, but may have much <br/>higher performance index. They used to be considered too hard to catch by <br/>traditional technologies or numerical algorithms and thus too difficult to <br/>apply. Thanks to new technologies (synchrotronic, laser), scientists are now <br/>able to induce or reach various unstable solutions and search for NEW <br/>applications, in particular, in system design and control of EMERGENCY <br/>machineries for MISSION CRITICAL SITUATIONS. So far, understanding of such <br/>solutions is still quite limited and analytic solutions are too difficult to <br/>obtain. Thus, development of efficient and reliable numerical methods to <br/>solve such problems for multiple solutions in an order becomes very <br/>important to both research and applications. However, there is no theory in <br/>literature to devise such a method. The outcome of this project will (1) <br/>greatly enhance understanding of unstable solutions by mathematical <br/>characterizations and lay a solid foundation for future study, (2) provide <br/>efficient and reliable algorithms to compute multiple solutions so that <br/>people can compare and then select the best one, and (3) promote new <br/>applications with new solution configurations.<br/>"
"0713815","Fully Locally Conservative Characteristic Methods for Transport Problems","DMS","COMPUTATIONAL MATHEMATICS, MATH PRIORITY SOLICITATION, MSPA-INTERDISCIPLINARY","09/01/2007","08/24/2007","Todd Arbogast","TX","University of Texas at Austin","Standard Grant","Junping Wang","08/31/2011","$258,529.00","","arbogast@ices.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271, 7446, 7454","0000, 7303, 9263, OTHR","$0.00","The transport of a chemical tracer within an ambient fluid (such as a contaminant in groundwater), can be approximated by Eulerian-Lagrangian numerical methods.  These methods conserve tracer mass locally, but not the mass of the ambient fluid.  They therefore compute inaccurate densities, which can seriously degrade the quality of the solution over time.  The PI and coworker recently defined the Volume Corrected Characteristics-Mixed Method (VCCMM) for the simplest transport problem, by considering the transport problem not as a single hyperbolic equation for the tracer, but rather as a system of two equations describing the motion of both the tracer and ambient fluids, each of which must be conserved locally.  This project will:<br/>(1) Complete the development of VCCMM, by placing it on a sound theoretical footing and developing a parallel version of the software; (2) Improve and extend VCCMM to more complex flows; (3) Develop a grid adapted version; and (4) Develop methods for nonlinear transport problems, including miscible, compressible flows, and two-phase, immiscible flows, for which the solution may contain shocks and rarefactions.  The project is expected to result in significant improvement in the approximation of transport problems for long time simulation, because the discrete approximation will have less numerical diffusion and preserve important physical principles. The project is expected to have broader impacts, including: (1) Developing a scientific software tool that can be applied to a wide range of practical problems; (2) The training of one Ph.D. student in a multidisciplinary environment; and (3) Societal benefits by allowing better modeling of, e.g., geologic basin formation, long-lived radio-isotope decay, miscible fingering, and two-phase flows.<br/><br/>The ability to predict the movement of a chemical specie, called a tracer, within another, ambient fluid is important in many applications.  For example, the need arises in ground-water contaminant migration studies.  This project investigates ways to improve the prediction of tracer transport through computer simulation. State-of-the-art numerical algorithms of Lagrangian type simulate tracer transport by explicitly calculating the movement of individual particles within small regions of space.  Tracer mass is conserved, meaning that no mass is artificially created or destroyed by the numerical calculations.  This is a critical property for studies involving, e.g., contaminants, since even small concentrations can be toxic to humans, and any creation or degradation of the tracer must be due to physical and chemical processes and not to numerical artifacts. However, Lagrangian methods do not conserve the mass of the ambient fluid.  This results in inaccurate tracer densities.  That is, although tracer mass is conserved, its concentration is incorrectly computed, which can lead to serious inaccuracies in reaction dynamics and degradation in the predicted movement over time.  The approach taken by the PI to resolve these difficulties is to consider the transport of both the tracer and ambient fluids, each of which must be conserved.  The research is expected to result in significant improvement in the approximation of transport problems for long time simulation, and the training of at least one Ph.D. student in a multidisciplinary environment.  This work has potential societal benefits as applied to problems in the contamination of ground-water, petroleum and natural gas production, and CO2 sequestration.<br/>"
"0713835","Novel Nonconforming Finite Element Methods for Maxwell's Equations","DMS","COMPUTATIONAL MATHEMATICS","07/15/2007","07/10/2007","Susanne Brenner","LA","Louisiana State University","Standard Grant","Junping Wang","06/30/2011","$260,000.00","Li-yeng Sung","brenner@math.lsu.edu","202 HIMES HALL","BATON ROUGE","LA","708030001","2255782760","MPS","1271","0000, 9150, 9263, OTHR","$0.00","The research in this project is based on the recent discovery of the PIs that numerical solutions of Maxwell's equations can be based on variational formulations that use function spaces where the divergence free condition is enforced.  This is made possible by combining classical nonconforming finite elements for incompressible fluid flows and techniques from discontinuous Galerkin methods. In this new approach the boundary value problems of the time-harmonic (frequency-domain) Maxwell's equations are solved as elliptic problems, and the performance of the new nonconforming finite element methods for both the source (deterministic) problem and the eigenproblem (cavity resonance problem) is comparable to the performance of classical finite element methods for computational mechanics. In particular the discrete eigenvalues have neither spurious modes nor nonphysical zero eigenvalues. The proposed research will design and analyze many novel schemes for the Maxwell equations and the Maxwell eigenproblem using this new approach. Fast solvers (multigrid and domain decomposition methods) and adaptive algorithms will also be developed, with applications to related electromagnetic problems.<br/><br/>The results of the proposed research will provide powerful computational tools for the design and analysis of electromagnetic devices such as antennas, radar sensors, waveguides, photonic crystals, magnetoresistive sensors and particle accelerators, with applications to diverse areas such as telecommunications, integrated optics, lasers, high energy physics, plasma physics, and nondestructive damage detection.<br/>"
"0713767","New Models and Algorithms in Image Processing with Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","07/01/2007","05/31/2007","Selim Esedoglu","MI","Regents of the University of Michigan - Ann Arbor","Standard Grant","Leland Jameson","06/30/2011","$257,360.00","","esedoglu@umich.edu","1109 GEDDES AVE, SUITE 3300","ANN ARBOR","MI","481091079","7347636438","MPS","1271","0000, OTHR","$0.00","The PI, together with his collaborators and students, will develop new <br/>models and numerical algorithms for the solution of a number of <br/>fundamental problems in image processing and computer vision. The <br/>models will be based on the calculus of variations and partial <br/>differential equations (PDE) that describe curve and surface <br/>evolutions. A main goal of the project will be to devise new models <br/>that incorporate prior shape information into existing variational <br/>image segmentation techniques such as the Mumford-Shah model and its <br/>variants. The new models will be designed to find in given images <br/>objects resembling a specified shape regardless of the objects' <br/>location and orientation in the image. In addition, they will have <br/>convenient numerical implementations using techniques that have already <br/>proven their utility in related vision applications, such as the level <br/>set method. A second area of research will be to develop novel, <br/>efficient numerical algorithms for the solution of PDE that arise in a <br/>number of computer vision models and in other fields such as material <br/>science. Specifically, the investigator will explore new computational <br/>techniques for the solution of high order PDE that describe geometric <br/>motion of interfaces, such as the Willmore flow and motion by surface <br/>diffusion. These evolutions are computationally very expensive using <br/>current techniques. The new approach will be to reduce the computation <br/>of these motions to alternating simple operations for which efficient <br/>algorithms are already available. Also in this vein, the project will <br/>develop new numerical algorithms inspired by models and techniques in <br/>image processing for the computation of energy driven dynamics of <br/>multiple phases and junctions.<br/><br/>Image segmentation is a fundamental procedure of computer vision. It is <br/>a necessary preliminary step whenever useful information is to be <br/>extracted from digital images automatically. Its goal is to identify <br/>parts of the image that belong to distinct objects, often without <br/>knowing what objects might be present in the image. In many practical <br/>applications, however, a specific object of known shape is sought in <br/>the images. For example, in aerial imagery, the object of interest <br/>might be a certain vehicle that has a distinctive outline. Or, in a <br/>medical application, it might be desired to identify automatically the <br/>individual vertebrae in x-ray images of the spine. It such settings, it <br/>would help the success rate of the segmentation procedure if the <br/>algorithms could be made aware of what is being sought. This project <br/>will develop models and numerical techniques that incorporate prior <br/>shape information about objects of interest into the segmentation <br/>process, thereby leading to better segmentation methods.<br/>"
"0712744","Analysis, Algorithms and Computation of Some Model Problems in Interface and Defect Dynamics","DMS","COMPUTATIONAL MATHEMATICS, MSPA-INTERDISCIPLINARY","09/01/2007","08/24/2007","Qiang Du","PA","Pennsylvania State Univ University Park","Standard Grant","Junping Wang","08/31/2010","$213,840.00","","qd2125@columbia.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271, 7454","0000, 7303, 9263, OTHR","$0.00","This project is concerned with the study of interfaces and defects which are ubiquitous in physical and biological systems and are essential to the materials properties and biological functions. Building on the previous research work, the PI will develop and apply analytical and numerical simulation tools to study both deterministic and stochastic effects associated with various material interfaces and defects with particular emphasis on defects in superconductors and Bose-Einstein condensates as characterized by quantized vortices, and soft interfaces as characterized by model biomimetic cell membranes. The investigation will be largely following the general Ginzburg-Landau (diffuse interface, phase field) formalism with connections to other multiscale and stochastic modeling approaches. Systematic model derivations, analysis and simplifications will be conducted. Adaptive algorithms and statistics retrieval algorithms will be designed and analyzed. These research activities will enhance the simulation capability of complex systems and the predictive power of large scale numerical computation. While focusing on specific applications, the central algorithmic development work in this project will be in tune with the modern theme of integrated, adaptive and intelligent scientific computation. <br/><br/>This project lies at the interface of computational mathematics, physics,  materials and biological sciences. The physical and biological objects to be studied through mathematical analysis and numerical simulations include quantized vortices which are well-known signatures of superfluidity, and biological membranes which are soft interfaces designed by nature as the fundamental building blocks of life. The PI will develop new analytical theory on the complex nonlinear models and new tools for extracting useful statistics and exploring hidden structures from massive simulations. The research activities will bring new advances to mathematics and provide better understanding of various basic physical and biological processes. They in turn may aid the efforts in discovering new technology based on the superconductivity and superfluidity, and new design of drug and drug delivery vehicles based on biomimetic membranes, both are of significant economic value and national priority.  In addition, this project will provide valuable training environment and interdisciplinary research experience to the future generation of workforce and young researchers that showcases the TEAMS (Training in Experiments, Analysis, Modeling and Simulations) spirit.<br/>"
"0713743","Research Experience in Numerical Methods for Partial Differential Equations with Singularities","DMS","COMPUTATIONAL MATHEMATICS","07/01/2007","06/22/2007","Victor Nistor","PA","Pennsylvania State Univ University Park","Standard Grant","Dalin Tang","06/30/2011","$44,963.00","","nistor@math.psu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271","0000, 9263, OTHR","$0.00","Computational methods are used in almost any area in which computers are used.  Improved numerical and computational methods are one of the main venues to improve the speed of modern computer applications.  The ""Finite Element Method"" is a very popular numerical method that is used by engineers, physicists, biologists, meteorologists, in financial mathematics, and in many other areas.  More concretely, the finite element method is used in the study of heat propagation, radar detection, medical imaging, structural analysis of buildings, design of aircraft wings, and in many other practical problems.<br/><br/>The first step in the use of the Finite Element Method is to fictitiously divide the domain to be studied (the domain occupied by a building, aircraft, body to be imaged) into many small triangles, parallelepipeds, or tetrahedra.  This is to a large extent an elementary task, but very time-consuming.  Moreover, additional care has to be paid close to the vertices and the edges of the domain.  Without this additional extra care in the way we divide our domain, obtaining the desired precision in calculations would take much longer.  For example, some recent results in which the Principal Investigator is also involved lead to the estimate that, for a precision of three exact digits, a careful division procedure can decrease the time of calculation by one million times or more.  For a precision of five exact digits, the estimated improvement is one trillion times or more.<br/><br/>While the mathematical techniques to decide the shape of the improved divisions of the computational domain are quite sophisticated (anisotropic mesh refinement, elliptic partial differential equations, non-compact manifolds, functional analysis), once such a division algorithm has been formulated, it can be taught to a good beginning undergraduate student.  The main purpose of this proposal is to train undergraduate and graduate students in state-of-the-art Finite Element Method techniques (including, but not limited to, anisotropic mesh refinement, a priori and adaptive mesh refinement, meshless methods, and multigrid methods for solving the resulting linear systems).  The more advanced the students, the more opportunities they will be given to learn about the inner workings of these methods.  Each of the students involved will be expected to produce original research at their corresponding level of mathematical training.  The resulting training of the students will provide the necessary numerical experience needed by the students, by the Principal Investigator, and by others to conduct cutting-edge research in the future.  Another important quality of the Finite Element Method is that it can be taught to students with a very wide scale of mathematical backgrounds and hence sophistication.  As such, by training more people with various backgrounds to use such methods and to do research on them, it is expected, based on previous experience, that a wider range of students, including underrepresented groups, will be attracted to mathematical research."
"0738028","Theory and Applications of Multigrid","DMS","COMPUTATIONAL MATHEMATICS","10/15/2007","09/26/2007","Susanne Brenner","LA","Louisiana State University","Standard Grant","Junping Wang","08/31/2009","$35,156.00","","brenner@math.lsu.edu","202 HIMES HALL","BATON ROUGE","LA","708030001","2255782760","MPS","1271","0000, 9150, 9263, OTHR","$0.00","The research in this project is on the theory and applications of multigrid methods.  One of the goals is to generalize the investigator's additive multigrid theory, which can handle the convergence of V-cycle and F-cycle algorithms for nonconforming methods, to more difficult problems such as anisotropic problems, nonsymmetric problems and indefinite problems, and to new discretization techniques such as mortar finite element methods and discontinuous Galerkin methods.  Another goal is to extend the PI's multigrid method for singular solutions and stress intensity factors to more complicated problems and to three dimensions.  This new multigrid approach can recover the optimal convergence rates of simple  finite elements on simple grids, even in the presence of strong singularities caused by nonsmooth geometries, abrupt changes in boundary conditions, or jumps in the coefficients of partial differential equations.  It can also take full advantage of superconvergence phenomena, extrapolation techniques, and parallel implementations.<br/><br/>Multigrid methods can produce fast solutions to large systems of equations.  The errors of multigrid solutions are comparable  to the smallest possible errors and at the same time the  computational cost of multigrid methods is proportional to the number of unknowns.  Therefore multigrid methods have optimal complexity, and they (either on their own or combined with  other methods) are powerful engines for large scale scientific computations.  The results of this project can provide answers to the important question of the reliability of multigrid methods and provide guidelines for the development of new algorithms.  They will also generate useful computational tools for many challenging problems in material science, fracture mechanics,  fluid flow and electromagnetism.<br/>"
"0712925","RUI: Adaptive Kernels for Partial Differential Equation Models in Image Denoising: Construction and Algorithms","DMS","COMPUTATIONAL MATHEMATICS","08/01/2007","07/25/2007","Jianzhong Wang","TX","Sam Houston State University","Standard Grant","Leland Jameson","07/31/2011","$168,645.00","","mth_jxw@shsu.edu","1806 AVE J","HUNTSVILLE","TX","773410001","9362943621","MPS","1271","0000, 9229, 9263, OTHR","$0.00","The investigator constructs adaptive kernels for diffusion PDE models in image denoising and develops kernel-based denoising algorithms. An adaptive kernel is a kernel that adaptively changes its kernel characteristics depending on the image content within a local window. Discrete kernels are filters, which are widely used in industrial image processing; and non-iterative filters can realize the real-time denoising. The proposed adaptive kernels are mainly derived from PDE models. Due to Rudin-Osher-Fatemi's influential work, there are a considerable number of PDE models for image denoising. Based on the extensive results in numerical analysis, highly accurate and stable algorithms have been developed. However, most numerical PDE algorithms involve either iteration or inverse matrices. They are time and/or memory consuming and therefore not suitable for real-time pre-processing noise reduction. The investigator studies the construction of adaptive kernels for some popular PDE models, designs parametric adaptive filters from these kernels, and develops algorithms for their implementations with emphasis on the extremely fast single-pass filter process. The investigator creates the GUI software to perform noise reduction based on the kernel-based algorithms, which provide a development kit suitable for industrial demands. The infinitesimal method is the main tool for the development of the adaptive kernels. He also applies Bayesian Decision Theory to create the rule for the optimal selection of the parameters in the adaptive filters, which are used to control the quality of noise reduction. <br/><br/>This research support the national interest in NANOTECHNOLOGY and INFORMATION TECHNOLOGY due to the demand for digital images/videos for low-cost security cameras, mobile digital TV, cell-video phones, all of which are used for HOMELAND SECURITY and DEPARTMENT OF DEFENSE applications. The research also impacts feature-preserve noise reduction techniques, which is on the rise. On-line videos such as web-cams generally produce low-quality pictures. Even high-quality digital cameras and camcorders used in low-light or artificial-light environments produce noise. Feature-preserve noise reduction techniques provide a low-cost solution for enhancing these low-quality images. There are many types of software on the market for picture cleaning and computer enhancement, however mobile videos and similar products require real-time processing that can be built into the devices. The security demand for these techniques is very high, especially in U.S. Border areas, while the number of solutions are low. This project bridges the gulf between the highly developed theory and the underdeveloped industrial applications.  <br/>"
"0652795","FRG:  Collaborative Research:  Dynamics of elastic biostructures in complex fluids","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY","07/01/2007","05/31/2007","Lisa Fauci","LA","Tulane University","Standard Grant","Mary Ann Horn","07/31/2012","$572,525.00","Ricardo Cortez","fauci@tulane.edu","6823 SAINT CHARLES AVE","NEW ORLEANS","LA","701185665","5048654000","MPS","1266, 1271, 7334","0000, 1616, 9150, OTHR","$0.00","Problems in biological fluid dynamics typically involve the interaction of an elastic structure with a surrounding fluid. Mucus transport by cilia in the respiratory tract, sperm penetration of the oocyte in fertilization, and peristaltic contractions of the oviduct are examples of such interactions. Many biological fluids are actually complex; that is they are not liquids or mixtures of a simple molecular structure that yields Newtonian responses, but instead have complicated non-Newtonian mechanical responses that arise, usually, because they have suspended microstructure.  While much progress has been made in the development of mathematical models and numerical methods for fluid-structure interactions in a Newtonian fluid, much work needs to be done in the case of complex fluids. This focused research group will use a combination of analytical, computational and experimental tools to investigate the dynamics of elastic structures coupled to a complex fluid. Accurate and robust numerical methods for viscoelastic fluids coupled to moving and flexible  boundaries will be developed that build upon classical immersed boundary methods and particle methods previously designed for Newtonian fluids. Continuum descriptions of the viscoelastic fluid will be implemented, as well as models that track discrete viscoelastic microstructure of the fluid. While the methods developed will be widely applicable, the team will focus upon the biofluidmechanics of reproduction, nematode motility in microfluidic chambers, as well as mucus-ciliary transport. Computational models will be coordinated with physical and biological experiments performed at the Applied Mathematics Lab at the Courant Institute.<br/><br/>Mathematics has had a huge impact on engineering and the physical sciences through its development of theoretical analyses and numerical methods for Newtonian fluid flows.  The dynamics of complex fluids is emerging as another such opportunity, and is one which draws some of its richest problems from new areas in biophysics and engineering, medicine and reproductive health, and from core biology. The integration of mathematical and computational analysis into biological science presents educational challenges and great opportunities. This research project embraces these challenges, and is based upon collaborations of investigators at four institutions - Tulane University, New York University, Washington State University and the University of California, Los Angeles.  A central component of this project is the training of graduate students and postdoctoral researchers.  This FRG project will sponsor two summer programs, where the postdoctoral researchers and graduate students will spend six weeks at the Applied Mathematics Lab at Courant Institute. This will provide opportunities for all the students and postdocs involved in the project to work together side by side, develop a comprehensive understanding of the various aspects of the research, and experience and participate in the life of a working fluids lab.<br/>"
"0724331","CMG Research:  Constraints on the Earth's thermal history and probing the geomagnetic field beneath the core-mantle boundary using nonlinear inversions","DMS","COMPUTATIONAL MATHEMATICS, OPPORTUNITIES FOR RESEARCH CMG, MATHEMATICAL GEOSCIENCES","10/01/2007","09/11/2007","Glenn Ierley","CA","University of California-San Diego Scripps Inst of Oceanography","Standard Grant","Junping Wang","09/30/2010","$244,359.00","Catherine Constable","gierley@ucsd.edu","8622 DISCOVERY WAY RM 116","LA JOLLA","CA","920931500","8585341293","MPS","1271, 7215, 7232","0000, 4444, 7232, 7303, 9263, OTHR","$0.00","Current thinking on the Earth's thermal history is marked by notable controversies on the age of the inner core and whether core radiogenic heating is required in order to maintain the magnetic field.  A key factor in this balance is the power required to drive the geodynamo, dissipated internally as heat. Present estimates, primarily based on numerical dynamo simulations operating far from the relevant parameter range, vary significantly. The aim of this project is to constrain the Earth's thermal history by finding rigorous lower bounds for the dissipation of the present field. Building on an existing bound based on constraints from observation and models for the Earth's nutation, the proposed addition of the Taylor constraint will impose a significant dynamical restriction long known to be appropriate for the core field. If the resulting bound is sufficiently increased, then contentious scenarios for the lifetime of the inner core without radiogenic heating may well be excluded.  Further, this variational formulation exposes some intriguing mathematical issues germane to consideration of the geodynamo as a dynamical system.  The optimal fields resulting will be both three-dimensional and time-dependent and thus for the first time give evidence of whether or not the large body of recent observationally-derived findings of large-scale surface features are really representative of the internal field.<br/><br/>Large scale computer simulation has fundamentally altered the way in which science is done. Yet for all the numerous advances, many of the most demanding computations in the area of geophysical fluid dynamics require that key properties, notably viscosity (the fluid ""thickness""), be set to artificially high values. The effects of this adjustment on the numerical results are poorly understood and will remain so short of a better theory of turbulence than any presently in prospect.  The so-called variational methods outlined in this proposal will both complement and critique numerical simulations of the Earth's dynamo. The results do not rely on artificial parameterizations and their interpretation as providing a bound on heat generated by the dynamo process is thus entirely rigorous. Key to this work will be a collaborative effort to link extensive long term observational data with a mathematically appropriate and numerically tractable formulation of the problem.<br/>"
"0713770","Adaptive FEM for controlling pointwise errors and level sets","DMS","COMPUTATIONAL MATHEMATICS","07/01/2007","06/22/2007","Alan Demlow","KY","University of Kentucky Research Foundation","Standard Grant","Junping Wang","06/30/2011","$112,787.00","","demlow@math.tamu.edu","500 S LIMESTONE","LEXINGTON","KY","405260001","8592579420","MPS","1271","0000, 9263, OTHR","$0.00","Elliptic partial differential equations are ubiquitous in science and engineering applications, and their fast and accurate numerical solution remains an important area of research.  Adaptive finite element algorithms for automatically constructing efficient computational grids are very popular tools for solving such equations.  An adaptive finite element method (AFEM) is an iterative feedback procedure in which an initial approximate solution is computed, and information from the initial approximation is then used to construct a better approximation.  What is meant here by ""better approximation"" depends upon the desired output from the computation.  Most adaptive codes are designed to control the energy norm (root-mean-square, or average, of the first derivatives) of the error because the energy norm is closely associated with the finite element algorithm.  The goal output from many computations, on the other hand, is related to other ways of measuring the error, and there is generally no guarantee that control of the energy error will lead to computationally efficient control of other measures of the error.  Much recent research has thus focused on using adaptive codes to compute ""quantities of interest"" not related to the energy norm.<br/><br/>This project involves the construction and analysis of adaptive algorithms for computations where the goal quantity is either related to pointwise information about the error, or is a location within the overall computational domain.  Situations where such information is desirable include locating the maximum temperature in a body at thermal equilibrium and determining where the stresses in an elastic body exceed a given threshold.  Level set methods in which evolving interfaces are represented as level sets of solutions to partial differential equations have also gained popularity in recent years.    This project contains three main goals.  First, the PI and others have previously developed several aspects of a basic theory for a posteriori estimation of pointwise errors in simple model problems.  This theory will be enriched and extended.  Secondly, we will investigate application of this basic theory to systems important in applications, in particular the stationary Stokes system from fluid dynamics and equations of linear elasticity.  Finally, we will develop an adaptive algorithm that rigorously controls level sets of solutions to elliptic problems.  The proposed research also provides for the training of a graduate student in numerical analysis and scientific computing."
"0813825","Mathematical and computational modeling of fluid-structure-control interactions with multidisciplinary applications in science and engineering","DMS","COMPUTATIONAL MATHEMATICS","10/01/2007","08/04/2008","Padmanabhan Seshaiyer","VA","George Mason University","Standard Grant","Junping Wang","06/30/2010","$108,152.00","","pseshaiy@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","MPS","1271","0000, 9263, OTHR","$0.00","The efficient solution of modeling the complex nonlinear interaction of a fluid with a structure has remained a challenging problem in computational mathematics. Such applications often involve complex dynamic interactions of multiple physical processes which present a significant challenge, both in representing the multiphysics involved and in handling the resulting coupled behavior. If the desire to control and design the system is added to the picture, then the complexity increases even further. The focus of the proposed research will therefore be to sytematically develop non-conforming finite element methods tuned to high performance computing applied to several computatationally challenging multidisciplinary applications involving fluid-strucuture-control interaction. The thrust will be to mathematically and computationally investigate the stability, convergence and control of a variety of non-conforming finite element techniques and use this information to develop an efficient and general solution methodology for fluid-structure-control applications. More specifically, the proposed research will explore the robustness of this methodology by investigating (a) computational stability and convergence of fully-coupled algorithms; (b) computational stability and convergence for iterative coupling and; (c) theoretical and computational investigation for shape, boundary and distributed control applications. The performance of the compuational algorithms developed as a part of this research will be applied to two realistic fluid-structure applications: (a) Blood flow in a parent-artery-aneurysm multistructure and (b) Computational aeroelasticity of micro-air-vehicles.<br/> <br/>The proposed research aims to develop optimal computational algorithms for fluid-stucture-control interaction problems arising in science and engineering applications. The proposed work is highly multidisciplinary and the algorithms developed as a part of this research can be quickly adopted to a wide range of engineering and medical applications. For instance, this research may be used to better understand the rupture of aneurysms which are responsible for significant morbidity and mortality in the country. This work may also be used to develop enhanced and efficient design of micro air vehicles with flexible aircraft wings, that may be used for a variety of missions such as reconnaissance and surveillance, targeting, tagging, bio-chemical sensing and many more. Integrated with the research component is also an educational plan that will encourage interdisciplinary research, that will involve the pedagogical implications of the proposed research in curriculum development and that will contribute to the scientific development of graduate students, undergraduate students, high school students and teachers.  More specifically, the proposed research will be used to develop learning modules that will be used to train students and teachers on the efficient use of compuatational mathematics to solve multidisciplinary problems in science and engineering. The research will also greatly encourage women and underrepresented minorities to pursue careers in computational mathematics, especially in interdisciplinary areas that bridge the biological, mathematical, and compuational sciences.<br/>"
"0713225","SAGE:  Software for Algebra and Geometry Experimentation","DMS","ALGEBRA,NUMBER THEORY,AND COM, COMPUTATIONAL MATHEMATICS","07/15/2007","07/10/2007","William Stein","WA","University of Washington","Standard Grant","Leland Jameson","06/30/2010","$144,543.00","","wstein@math.washington.edu","4333 BROOKLYN AVE NE","SEATTLE","WA","981950001","2065434043","MPS","1264, 1271","0000, 9263, OTHR","$0.00","The investigator and his colleagues are creating wide-ranging open source mathematical software to support research in cryptography, number theory, algebra, geometry, and numerical computation.  They are sutdying distributed computation with complicated algebraic objects in heterogenous networks, exact linear algebra, computation with elliptic curves, highly optimized polynomial arithmetic, and protocols for communication between mathematical software systems.<br/><br/>This project involves creating open source mathematical software that plays a key roll in research in cryptography, number theory, geometry, and other area.  It promotes the progress of science by making many highly optimized research-oriented algorithms widely available, and making it easy to simultaneously create and work with objects defined in almost any mathematical software package.  This project also stimulates new forms of collaboration between researchers in diverse areas of mathematics, and between undegraduates, graduate students, and professors.<br/>"
"0708076","Control and Numerical Analysis of Nonlinear Intrinsic Shells","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","06/15/2007","06/20/2007","Catherine Lebiedzik","MI","Wayne State University","Standard Grant","Mary Ann Horn","05/31/2010","$102,502.00","","kate@math.wayne.edu","5700 CASS AVE STE 4900","DETROIT","MI","482023692","3135772424","MPS","1266, 1271","0000, OTHR","$0.00","This research is in the general area of control theory for PDE models that involve shell (curved surface) dynamics.  While a great deal of research has been done for plate and wave dynamics and other so-called flat geometries, very little is known as far as rigorous control theory for shell models. This particularly refers to problems such as controllability, stabilization and optimal control problems.  On the other hand, from the point of view of applications this is precisely the more interesting case -- for example an airplane or helicopter cabin is curved, so the structural acoustic case is naturally modeled with shells.  While the interest in studying shells need not be defended on physical/application grounds, the mathematical analysis (in particular in the context of control theory) is poorly understood with many challenges. In fact, methods developed for flat geometries are no longer applicable, and approaches such as microlocal analysis or geometric optics had to be introduced in order to resolve the problem.  The geometry of the problem is responsible for these problems, and the idea pursued in this research is that a solid understanding of that geometry is the key to surmounting these obstacles. The goal of this project is to capture this geometry through the correct modeling and exploit it in the proofs.  The research builds upon recently developed ""intrinsic"" models due to Michel Delfour and Jean-Paul Zolesio which are coordinate free. This very fact, together with an appropriately developed calculus rooted in geometry, provides a tool for deriving the appropriate inequalities.<br/><br/>In previously funded work, models based on the intrinsic geometry have been developed for linear, nonlinear, and thermoelastic shells.  Answers to questions such as stabilization, control, and well-posedness for these models have been established, and the linear model has been numerically verified to be accurate.  The objective for the current research is to further investigate control and numerical analysis of the nonlinear intrinsic shell model.  As such, the following issues will be addressed:  Model verification for the nonlinear shell; error analysis in order to derive the optimal rates of convergence for the finite element approximation to the nonlinear shell model; control theory for shells (i.e., issues of stability and/or stabilizibility of the nonlinear model, long time behavior and attractors, and exact controllability from the boundary); and numerical analysis of control problems.  In part, the intellectual merit of this work lies in the construction of a complete theory of the control of shell structures.  However, the methods involved are themselves of independent interest as very special inverse-type inequalities are derived in the proofs which have applications to other problems as well.  In addition, the numerical libraries developed can be applied to many different types of problem. The issue of the shell is an issue of geometry, and the geometrical and topological aspects of this work are very rich.  The broader impact of this work will be seen in the integration of education and research, participation of underrepresented groups in mathematics, technology transfer and cross-fertilization with industry."
"0712881","AMC-SS: Dynamic Algorithms For Blind Separation Of Convolutive Sound Mixtures","DMS","COMPUTATIONAL MATHEMATICS","07/15/2007","07/10/2007","Jack Xin","CA","University of California-Irvine","Standard Grant","Leland Jameson","06/30/2011","$300,095.00","","jxin@math.uci.edu","160 ALDRICH HALL","IRVINE","CA","926970001","9498247295","MPS","1271","0000, 9263, OTHR","$0.00","The principal investigator and coworkers will study mathematical and computational issues of blind source separation algorithms of convolutive sound mixtures. The convolutive sound mixtures appear in any enclosed environment when there are multiple speakers. The goal is achieve dynamic separation of mixtures and source recovery adaptively with no prior knowledge of the environment, based on source independence and received data at multiple locations. Though the fast Fourier transform helps to localize the problem in the frequency domain, and separation is quite successful at each frequency with existing methods, permutation and scaling issues remain indeterminate and may greatly influence the separation quality. The investigators will use dynamically updated statistical signal information to fix permutation, and minimization of mixing filter lengths in the time domain to fix scaling. They will also study dynamic algorithms in the time domain by optimizing mixing filter lengths and source independence, as well as the dynamic stability and convergence of the recovered mixing filters by using probability theory.<br/><br/><br/>The project aims to develop algorithms to separate realistic sound mixtures, a task that machines (computers) are unable to perform as well as humans. The challenge, also known as the cocktail party problem, is fundamental to improving the quality of modern hearing devices. For example, hearing aids and cochlear implants are known to work well in quiet, however, they degrade rapidly when there are competing sound sources. Even for normal hearing people, it is difficult to carry out a conversation over a cell phone call that comes from a rather noisy location such as a restaurant. Understanding the mathematics of blind source separation and applying it to actual computation is a key step to solution. The project bodes well in generating broad impact and making mathematical contributions to the advancement of information technology and biotechnology.<br/><br/>"
"0712875","Nonlinear Diffusions And Image Processing","DMS","COMPUTATIONAL MATHEMATICS","07/15/2007","07/10/2007","Patrick Guidotti","CA","University of California-Irvine","Standard Grant","Leland Jameson","06/30/2011","$270,428.00","","gpatrick@math.uci.edu","160 ALDRICH HALL","IRVINE","CA","926970001","9498247295","MPS","1271","0000, 9263, OTHR","$0.00","A new class of regularizations is proposed for the classical Perona-Malik equation of image processing, along with a modification thereof. It differs from more standard regularization procedures in that it allows one to more finely tune the regularization degree. It can be interpreted as a slight non-local weakening of the standard nonlinear diffusion coefficient. The regularized equations obtained in this way have desirable analytical properties such as local classical well-posedness or the fact that piecewise constant functions are stationary solutions. These properties are welcome from a practical image processing point of view since they lead to discretizations which perform the task of denoising remarkably well while avoiding the blurring common to standard regularization techniques and the ``stair-casing'' phenomenon known to occur for discretizations of Perona-Malik.<br/><br/><br/>Partial differential equations have a long and successful history as mathematical, quantitative models for the often nontrivial dynamics of a variety of nonlinear phenomena of practical interest. Traditional application fields include all branches of physics, chemistry and some subfields of biology. More recently they have found a whole variety of new domains to which they can contribute. Among them are econometrics, molecular biology, information technology and a vast number of industrial and/or engineering problems. This proposal deals with nonlinear diffusions and their application to image processing. In the last two or three decades many mathematical models have been successfully utilized to process raw digital data in the form of images obtained by various devices of which medical ones are maybe a prime example. Often raw data needs to be processed before it can be properly interpreted, like in medical scans, sometimes one would like to be able to develop software to automatically extract useful information from raw data without human intervention, as in surveillance devices. In both cases methods based on the use of partial differential equations have proven useful. The proposer and his collaborator take on the task of furthering the theoretical understanding of complex nonlinear systems and of enhancing state-of-the-art techniques based thereupon of relevance in information technology and image processing, in particular, but that are quite general in nature, thus opening the possibility of applications to other fields, too.<br/>"
"0712935","Efficient dynamic mesh adaptation for numerical simulation of evolutionary problems arising from physical science","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","08/24/2007","Weizhang Huang","KS","University of Kansas Center for Research Inc","Standard Grant","Junping Wang","08/31/2011","$130,000.00","","whuang@ku.edu","2385 IRVING HILL RD","LAWRENCE","KS","660457552","7858643441","MPS","1271","0000, 9150, 9263, OTHR","$0.00","This research project is to develop efficient dynamic mesh-adaptation strategies for the numerical simulation of evolutionary problems arising from physical science.  Mesh adaptation is an indispensable tool for use in mesh-based numerical simulation in science and engineering.  Its basic idea is to put more mesh nodes in regions of large solution variation than those where the solution is smooth.  In this way, fewer mesh nodes are required to reach a specified level of accuracy and thus significant economies are gained.  Dynamic mesh adaptation is a type of mesh adaptation which moves mesh nodes around to follow the dynamic features of the physical problem.  Its continuous nature in time makes a dynamic mesh-adaptation method the natural choice of method for use in the numerical solution of evolutionary problems.<br/><br/>The proposed research focuses on improving the efficiency of dynamic mesh adaptation.  Topics of study include the investigation of time integration of partial differential equations on moving meshes, the development of the Schwarz waveform moving-mesh method, and the development of simple and efficient solvers for mesh equations.  All studies will be targeted on evolutionary partial differential equations arising from liquid-crystal models and phase-change problems.  These problems have many important industrial applications and have attracted considerable interest among scientists.  Successful completion of this project will provide a powerful tool for studying the formation of solution singularities and the propagation of moving interfaces arising from these problems.  Graduate students will be actively involved in the research project.  Students' training will benefit from large-scale computations as well as theoretical studies."
"0649644","Special Meeting at Copper Mountain Conference","DMS","COMPUTATIONAL MATHEMATICS","05/01/2007","04/24/2007","Van Henson","AZ","Front Range Scientific Computations, Inc.","Continuing Grant","Henry Warchall","04/30/2010","$31,500.00","","henson5@llnl.gov","8865 E CALLE BUENA VIS","SCOTTSDALE","AZ","852558364","3035541232","MPS","1271","0000, 7556, 9263, OTHR","$0.00","This award provides support for a series of three meetings on current topics in computational mathematics, held annually at Copper Mountain, Colorado. The subject of these meetings alternates between Multigrid Methods (in odd-numbered years) and Iterative Methods (in even-numbered years).  The conference series encourages and financially supports participation by students and members of groups underrepresented in the mathematical sciences.<br/><br><br><br/>In addition to contributed talks of approximately one half hour each, conference activities feature a student paper competition and evening sessions devoted to panel discussions, workshops, and an informal research forum.  The meetings have an egalitarian style with no invited talks, and student presentations are put on equal footing with all others. Additional details can be found at the conference web site <br/><br><br/>http://amath.colorado.edu/faculty/copper/<br/><br/>"
"0713771","Hierarchical and Calderon Regularization of Time Domain Integral Equations for Electromagnetics","DMS","COMPUTATIONAL MATHEMATICS","07/15/2007","07/10/2007","Eric Michielssen","MI","Regents of the University of Michigan - Ann Arbor","Standard Grant","Leland Jameson","06/30/2011","$248,040.00","","emichiel@umich.edu","1109 GEDDES AVE, SUITE 3300","ANN ARBOR","MI","481091079","7347636438","MPS","1271","0000, 9263, OTHR","$0.00","Marching on in time (MOT)-based time domain integral equation (TDIE) solvers provide an appealing avenue for analyzing transient electromagnetic interactions with large and complex structures. Unfortunately, these solvers often suffer from temporal (low-frequency) and spatial (dense-mesh) breakdown phenomena when applied to the analysis of low- to medium-frequency electromagnetic transients on geometrically intricate and multiscale structures, thereby preventing their application to many important scientific and engineering problems. This project seeks the development of new plane wave time domain-accelerated, regularized MOT-TDIE solvers that are immune to temporal and spatial breakdown phenomena.  The proposed techniques eliminate temporal and spatial breakdown phenomena in MOT-TDIE solvers by leveraging hierarchical basis functions and new time domain Calderon identities, respectively. In addition, they guaranty low-frequency stability in MOT-TDIE solvers by exploiting the spectral properties of the Calderon regularizer. MOT-TDIE solvers resulting from this effort will permit the fast analysis of low- to medium-frequency electromagnetic transients on geometrically intricate and mixed-scale structures. The educational objective of this project is to develop a comprehensive set of educational materials supporting a course covering all aspects of fast MOT-TDIE technology and to use them in teaching and outreach.<br/><br/>The development of fast and higher-order accurate MOT-TDIE solvers that robustly and seamlessly apply across spatial and temporal scales will permit the analysis of a wide class of scientific and real-world electromagnetic engineering problems that are intractable using present day methods. Given their grid-robust nature, the electromagnetic simulators resulting from this effort will permit optical scientists to rigorously analyze transient effects in nonlinear and disordered metamaterials and nanostructures without resorting to homogenization approximations, thereby creating a new avenue for controlling and directing the flow and electromagnetic waves and light in fibers and on chips. In addition, they will allow electronic engineers to design digital integrated circuits and RF wireless sensors without resorting to ad-hoc spatial decomposition methods, thereby resulting in significant savings in development time and costs. And finally, they will permit automotive and aerospace engineers to appropriately protect their designs from unwanted electromagnetic interference, thereby improving safety and impacting national security by reducing the threat of remotely generated system upsets.<br/>"
"0715510","LTB:  Accurate Computational Methods for Very Large Dynamical Systems","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","08/01/2007","07/18/2007","Divakar Viswanath","MI","Regents of the University of Michigan - Ann Arbor","Standard Grant","Dalin Tang","07/31/2011","$157,436.00","","divakar@umich.edu","1109 GEDDES AVE, SUITE 3300","ANN ARBOR","MI","481091079","7347636438","MPS","1266, 1271","0000, 116E, 9251, 9263, OTHR","$0.00","Foundational principles of the theory of dynamical systems, such as the closing lemma and the Poincare recurrence theorem, suggest that dynamics can be understood quite generally in terms of periodic motions.  This project will use those principles as a beacon and develop numerical methods that elucidate the dynamics of systems with more than a million degrees of freedom using accurate computations of steady solutions, traveling waves, periodic motions, and relative periodic motions.  These methods will be applied to fluid turbulence at low and moderate Reynolds numbers and to the technologically important transition-to-turbulence problem.  This project will advance the instruction of computational science by training students to be skillful at using and creating scientific software."
"0753111","New numerical techniques for non-Newtonian flow simulations and their application to modelling of complex flows","DMS","COMPUTATIONAL MATHEMATICS","07/01/2007","10/15/2007","Young-Ju Lee","NJ","Rutgers University New Brunswick","Standard Grant","Leland Jameson","06/30/2010","$82,726.00","","y_l39@txstate.edu","3 RUTGERS PLZ","NEW BRUNSWICK","NJ","089018559","8489320150","MPS","1271","0000, 9263, OTHR","$0.00","The research of the investigator is on the timely study of the<br/>fluid dynamics of non-Newtonian fluid flows. The investigator<br/>will examine systematically the design and development of an efficient<br/>computational modelling package that can handle various<br/>macroscopic models of complex fluids and also a wide spectrum of<br/>physical parameters that have been elusive for  conventional<br/>numerical methods. In addition to general algorithmic developments<br/>including the fast solution method like the multigrid methods, the<br/>investigator aims to study and understand proper mathematical<br/>models for a great variety of new physical phenomena arising in<br/>the area of experimental rheology. In particular, the investigator<br/>will tackle an important challenge of modelling a continual<br/>oscillation of falling sphere in  worm-like micellar fluid flows.<br/>In contrast to the Newtonian fluid or the polymeric fluids, the<br/>falling sphere in a worm-like micellar fluid undergoes a continual<br/>and sustained oscillation as it falls. This part of the project<br/>will involve testing various macroscopic models that are relevant for<br/>the worm-like micellar fluids and will lead to  identification of the right<br/>mathematical models for a falling sphere experiment. The<br/>investigator will also address a mathematical foundation for<br/>the so-called  high Weissenberg number problem. Despite  recent<br/>significant progress, the successful computations are still<br/>confined to very restrictive size of the Weissenberg number for a<br/>large class of non-Newtonian fluid models including the well-known<br/>Oldroyd-B model. The investigator will implement the new numerical<br/>methods for the computer simulations of highly elastic fluid<br/>flows, namely, models with high Weissenberg number to simulate and<br/>understand another newly observed intriguing physical phenomenon,<br/>the elastic turbulence.<br/><br/>Fluids comprised of large macromolecules, known as non-Newtonian<br/>fluids or complex fluids, can generate many new physical<br/>phenomenon. Examples of non-Newtonian fluids can be found<br/>throughout our daily lives,  including molten plastics,<br/>engine oils with polymeric additives, paints, and many biological<br/>fluids such as egg white and blood. The design, implementation,<br/>and the use of numerical methods for the computer simulation of<br/>such physical phenomena requires full grasp of non-Newtonian<br/>fluids and the results of the investigator's  research are<br/>expected to have significant applications, for example in industry.<br/>Namely, a polymer engineer could perform elaborate<br/>Computer Aided Design (CAD) studies in which the link between the<br/>molecular architecture of the raw material and the final<br/>properties of the product would be established, at least<br/>qualitatively. Production problems would be predicted and<br/>partially overcome through improved design. One could also think<br/>of using an on-line computational rheology model in concert with<br/>appropriate control algorithms to provide for intelligent,<br/>physics-based process control techniques. There are many more<br/>opportunities that the investigator's  research results<br/>could generate.<br/>"
"0653868","Variational and Topological Methods: Theory,  Applications,  Numerical Simulations,  and  Open Problems","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, ANALYSIS PROGRAM","05/01/2007","04/10/2007","John Neuberger","AZ","Northern Arizona University","Standard Grant","Henry Warchall","04/30/2008","$25,650.00","Maya Chhetri","John.Neuberger@nau.edu","601 S KNOLES DR","Flagstaff","AZ","86011","9285230886","MPS","1266, 1271, 1281","0000, 7556, OTHR","$0.00","Proposal: 0653868<br/>Principal Investigator: Neuberger, John M<br/>Institution:  Northern Arizona University<br/>Proposal Title: Variational and Topological Methods: Theory, Applications, Numerical Simulations, and Open Problems<br/><br/>ABSTRACT<br/><br/>This award will fund travel and local expenses of nine invited speakers and 25 new PhDs, graduate students and underrepresented minority mathematicians to attend a conference on ""Variational and Topological Methods: Theory, Applications, Numerical Simulations, and Open Problems,"" to be held at Northern Arizona University in Flagstaff, Arizona, May 23-26, 2007.  The topics to be discussed are semilinear boundary value problems, p-Laplacians and other fully nonlinear equations, eigenvalue problems, symmetry, dynamical systems, and equations from quantum-mechanical systems.  Emphasis is on cooperation across disciplines and integration of numerical simulations.  The program will consist of invited lectures and contributed talks.  A tutorial will precede the conference. The conference maintains a web site at http://jan.ucc.nau.edu/~jmn3/var07/var07.html .<br/>"
"0712955","Discontinuous Galerkin Methods for Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","07/01/2007","06/22/2007","Bernardo Cockburn","MN","University of Minnesota-Twin Cities","Standard Grant","Junping Wang","06/30/2011","$366,202.00","","cockburn@math.umn.edu","200 OAK ST SE","MINNEAPOLIS","MN","554552009","6126245599","MPS","1271","0000, 9263, OTHR","$0.00","This project is devoted to devising and studying, theoretically as well as computationally, efficient methods for numerically solving problems modeled by partial differential equations.  We propose to investigate how to overcome several difficulties raised by the application of the so-called discontinuous Galerkin method to a variety of problems of practical interest.  The applications are to the evolution of surfaces and to navigation of robots in arbitrary terrains (Hamilton-Jacobi equations), to incompressible fluid flow (Navier-Stokes equations), to structural mechanics with special emphasis on shells (elasticity equations), and to Darcy flow in porous media (second-order elliptic equations).<br/><br/>For each of the above problems, we consider the problem of how to obtain highly accurate computer simulations.  In many of these problems (fluid flow and structural mechanics), the emphasis will be put on the development of a recently discovered class of discontinuous Galerkin methods more robust and efficient than previously known methods.  In others (evolution of surfaces <br/>and navigation of robots), the effort will be concentrated in the efficient control of the quality of the simulation.  Indeed, since the exact solution of these complex problems is not known, to guarantee a given accuracy of the simulation, special techniques have to be devised in order to assess its quality.  Moreover, these techniques can be employed to automatically let the computer know when and where to increase or decrease the computational effort to obtain the simulation; in this way, the efficiency of its computation<br/>is significantly enhanced.  Discontinuous Galerkin methods are particularly well-suited for this approach."
"0713568","Finite element exterior calculus and applications","DMS","COMPUTATIONAL MATHEMATICS","07/01/2007","06/22/2007","Douglas Arnold","MN","University of Minnesota-Twin Cities","Standard Grant","Junping Wang","06/30/2011","$298,564.00","","arnold@umn.edu","200 OAK ST SE","MINNEAPOLIS","MN","554552009","6126245599","MPS","1271","0000, 9263, OTHR","$0.00","The first step in simulating, understanding, predicting, and eventually controlling a complex natural or man-made physical system, or even social system, is often to model the system mathematically.  For a wide variety of systems--for example those based on solid mechanics, fluid mechanics, quantum mechanics, electromagnetism, gravitation, acoustics, thermodynamics, certain stochastic processes, and many others--the best mathematical models take the form of a set of partial differential equations.  For the complex modern applications that arise in structural engineering, climatology, biology, or many other fields, the resulting partial differential equations can only be solved approximately using fast computers.  The development of accurate algorithms to approximately solve these equations on computers remains a tremendous challenge as we tackle new and more complex applications.  One of the greatest advances for the computer solution of partial differential equations came in the past century with the development of the finite element method, which has become an indispensable tool for simulation of a wide variety of phenomena arising in science and engineering.  A tremendous asset of finite elements is that they not only provide a methodology to develop numerical algorithms for simulation, but also a theoretical framework in which to assess the accuracy of the computed solutions.  This project aims to develop new algorithms which extend the applicability of the finite element method, and to develop new tools which allow for better understanding of the performance of finite element algorithms, and, in particular, allow precise certification of their accuracy.  A particular emphasis will be on the partial differential equations of elasticity, which describe the deformation and possible fracture of a solid body subject to forces like gravity, loading, and wind, and on the partial differential equations of electromagnetism, which are used in a wide variety modeling situations involving electric power transmission, transmission of light, radio waves, and magnetism.  But the framework considered will be quite general and the techniques will extend to numerous other application areas.<br/><br/>Robust and reliable methods for solving the equations of elasticity are needed in many industrial and engineering applications, especially in the most challenging design applications, for example for aircraft, advanced buildings and bridges, and offshore oil platforms.  Recent design failures, some of them catastrophic, have been traced to inadequate numerical algorithms for elasticity.  Similarly reliable methods for solving the equations of electromagnetism are at the basis of much of modern technology.  Thus this project has the potential to contribute to national competitiveness and public safety."
"0749676","Numerical Analysis of Path-dependent Options with Regime Switching and Calibration of Interest Rate Models","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","08/24/2007","Hongtao Yang","NV","University of Nevada Las Vegas","Standard Grant","Leland Jameson","08/31/2011","$115,409.00","","hongtao.yang@unlv.edu","4505 S MARYLAND PKWY","LAS VEGAS","NV","891549900","7028951357","MPS","1271","0000, 9150, 9263, OTHR","$0.00","The main objectives of the proposed research are to develop, analyze, and implement new, fast, and accurate numerical methods for valuation of path-dependent options with regime switching and calibration of interest rate models.  The fast growth in financial derivative markets provides natural needs and great challenges in computational mathematics.  According to the quarterly report of Office of the Comptroller of the Currency, commercial banks held a record $119.2 trillion in derivatives contracts in the second quarter of 2006.  Financial products are utilized as instruments of risk reduction by organizations and individual investors who have sizable assets and are exposed to moves in the world markets.  The proposed research will focus on two specific topics of computational finance (financial engineering): (1) pricing of American options with regime switching; (2) fitting the quadratic model of short interest rates to current market data.<br/><br/>This project will produce reliable tools for economists and practitioners in the financial industry to understand and evaluate the studied financial derivatives, and thus they can make better financial decisions about the risk management of their portfolios.  Also, Ph.D. students will be involved in the project through working on some problems of the project for their dissertations and will also be trained in C++ programming by implementing the proposed numerical algorithms.  These students will most likely work for a bank or a financial services firm and can make these U.S. financial institutions more competitive in world markets."
"0713018","Optimal Polyhedral Homotopies on Supercomputers for Algebraic Sets","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","08/22/2007","Jan Verschelde","IL","University of Illinois at Chicago","Standard Grant","Junping Wang","08/31/2011","$255,000.00","","janv@uic.edu","809 S MARSHFIELD AVE M/C 551","CHICAGO","IL","606124305","3129962862","MPS","1271","0000, 9263, OTHR","$0.00","Algebraic sets are solutions of polynomial systems.  Exploiting the sparse structure of a polynomial system, polyhedral homotopies are optimal for computing all isolated solutions of general systems in the sense that every solution path converges to a solution.  The goal of this proposal is to develop new homotopy algorithms that will be generically optimal for computing numerical representations of positive dimensional solution sets.  To solve large polynomial systems, the new homotopy algorithms will be made suitable to run on supercomputers.<br/><br/>Polynomial systems arise frequently in many problems in science and engineering.  The algorithms to solve polynomial systems are implemented in an open source software package PHCpack, available for free on the web.<br/>User-friendly interfaces to PHCpack (in computer algebra systems such as Maple (commercial), SAGE (open source), and in scientific software systems such as MATLAB (commercial), Octave (open source)) will continue to benefit many scientists and engineers who solve polynomial systems in their research.<br/>The principal investigator teaches his students to transfer mathematical technology through software with an eye towards high performance computing.<br/>"
"0707949","Regularity and Critical Thresholds  in Nonlinear Transport-Diffusion Equations","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/01/2007","05/04/2009","Eitan Tadmor","MD","University of Maryland, College Park","Continuing Grant","Henry Warchall","06/30/2010","$398,059.00","","tadmor@cscamm.umd.edu","3112 LEE BLDG 7809 REGENTS DR","College Park","MD","207420001","3014056269","MPS","1266, 1271","0000, 9263, OTHR","$0.00","We will use modern mathematical tools complemented by novel computational simulations to examine the phenomena of regularizing effects, critical thresholds, time decay, entropy stability, and scaling.  The project will address the following questions: <br/>(i) Transport-diffusion equations: How do diffusion and entropy dissipation dictate the regularizing effect in such equations? <br/>(ii) Eulerian dynamics: How does the competition between rotation and pressure forcing determine the overall stability? <br/>(iii) Chemotaxis and related bio-related transport-diffusion models: How should we interpret the solutions beyond their critical time? <br/>(iv) Hierarchical decompositions of images: How can the inverse scale space be adapted to the data for effective image processing? <br/>The principal investigator and his collaborators plan to pursue the development of new analytical and computational tools to explore transport-diffusion models, which are expected to contribute to understanding of the dynamics of realistic models in a variety of applications. <br/><br/>The goal of this project is to study the persistence of global features in nonlinear transport-diffusion equations, which arise in a wide variety of applications.  Examples include nonlinear conservation laws with degenerate diffusion, which model sedimentation, traffic flows, and data-driven applications in image processing; the ubiquitous Eulerian dynamics governing a range of phenomena from the small scale of semi-conductors through the largest scale of star formation; and chemotaxis models found in biological applications.  We focus our attention on the unifying mathematical content of the underlying transport-diffusion equations.  Of primary interest are problems with critical regularity properties that hinge on a borderline balance between the nonlinear convection mechanisms, the nonlinear diffusion processes, and the possibly nonlinear forcing driving such a system.<br/>"
"0721585","CMG COLLABORATIVE RESEARCH: Development of New Statistical Learning Theory and Techniques for Improvement of Convection Parameterization in Climate Models","DMS","COMPUTATIONAL MATHEMATICS, OPPORTUNITIES FOR RESEARCH CMG, MATHEMATICAL GEOSCIENCES","10/01/2007","09/05/2007","Michael Fox-Rabinovitz","MD","University of Maryland, College Park","Standard Grant","Junping Wang","09/30/2010","$351,863.00","Vladimir Krasnopolsky","foxrab@essic.umd.edu","3112 LEE BLDG 7809 REGENTS DR","College Park","MD","207420001","3014056269","MPS","1271, 7215, 7232","0000, 4444, 7232, 7303, 9263, OTHR","$0.00","This proposal focuses upon two interconnected and equally important problems. The first of them is developing a new Statistical Learning Theory (SLT) dedicated to modeling specific complex systems. The second one is to develop a new convection representation for numerical climate models. Understanding climate and weather is important to science, society and the economy. The processes we focus upon (clouds, and particularly convection) are critical to climate and weather. The proposal involves a novel approach to improving the representation of those processes. Our goal is to combine a team of mathematical scientists with expertise in SLT, and atmospheric scientists with expertise in cloud modeling and climate system modeling to produce an innovative representation for convection in the atmospheric models used for numerical weather prediction and climate change studies. The project will develop an SLT system that emulates the statistical behavior of a more realistic but very expensive high resolution Cloud System Resolving Model (CSRM) in a variety of cloud regimes. Employing even the simplest of these CSRM frameworks in a large scale model increases the cost of today?s atmospheric models by factors of thousands, which make their use impractical for many studies. By emulating the behavior of these more realistic frameworks in a large scale model we develop a new SLT parameterization, dramatically reducing the cost of the more realistic representations of model convection, and providing an opportunity to address problems currently viewed as critical within the scientific community. By developing the application-oriented SLTs we hope to make the more realistic cloud and convective formulations currently being explored, computationally feasible and use them in climate models.<br/> <br/>This proposal combines research used in the computational statistics scientific community with climate science. One of the most important components of the climate system is the representation of clouds. They control many aspects of the energy and heat that enter and leave the climate system, and they interact with many components of the earth system (agriculture, weather, society, and the economy). But clouds are so complex that they can not be treated very precisely in models that are used for understanding climate and weather. The equations required to represent clouds are so complex that a precise treatment would slow down current models by factors of thousands or millions. Current computational climate and weather models cannot afford a precise representation of clouds so faster approximate treatments of clouds are needed. Traditional representations for clouds in climate and weather models are not sufficiently accurate, and progress has been slow in improving these model components. This proposal employs advanced statistical-mathematical methods to try and improve the situation. These methods (called Statistical Learning Theory or SLT) allow one to represent very complex systems with accurate, and very fast approximations. We are going to try to approximate very detailed, complex and expensive models of convective clouds using SLT to produce an accurate approximation for clouds with the goal of using this approximation (these approximations are frequently called a parameterization in climate and weather models). This research will push forward the knowledge base used in both the SLT community, and the climate community.<br/>"
"0715135","Collaborative Research: Finite Element Methods for Discretizing Geometric PDEs with Nonlinear Constraints and Gauge Freedom","DMS","COMPUTATIONAL MATHEMATICS","08/01/2007","09/19/2008","Donald Estep","CO","Colorado State University","Standard Grant","Junping Wang","07/31/2011","$146,581.00","","donald.estep@colostate.edu","601 S HOWES ST","FORT COLLINS","CO","805212807","9704916355","MPS","1271","0000, 9263, OTHR","$0.00","This project is concerned with the approximate solution of certain<br/>systems of evolution partial differential equations (PDE) arising at<br/>the intersection of mathematical physics and geometric analysis.<br/>Such systems of equations, known as Geometric PDE, with both constraints<br/>and gauge degrees of freedom, appear in a wide range of physical and<br/>mathematical problems; examples include Maxwell's equations (or more<br/>generally the Yang-Mills equations on a curved background), and<br/>Einstein's field equations and other Hamiltonian systems with an<br/>infinite-dimensional symmetry group. The Cauchy formulation for such <br/>systems yields a constrained evolution system which has to be augmented <br/>with gauge-fixing conditions in order to get a unique evolution vector field.<br/>The project will involve constructing finite element discretizations<br/>for solving such geometric PDE systems; various techniques for dealing<br/>with evolution systems with constraints will be analyzed, including<br/>constraint-projection using variational techniques (where the numerical<br/>solution is projected back to the constraint manifold after<br/>some number of time steps), the use of special finite elements which<br/>automatically solve the linearized constraints and thereby remain on a<br/>piecewise-linear approximation to the constraint manifold, and finally<br/>least-squares approaches which only control the constraints rather than<br/>enforce them. In particular, stability results guaranteeing convergence<br/>of the numerical solution to the continuum solution will be derived,<br/>at least for the linearized equations.  A posteriori error estimates will <br/>be derived for studying properties of the discretizations, and for <br/>building adaptive methods.<br/><br/>This project involves the design, development, and implementation of<br/>new mathematical and computational techniques for solving a large class <br/>of important, challenging, and pressing mathematical problems in<br/>multiscale and multiphysics modeling and simulation.  The techniques <br/>developed will lead to the aquisition of new knowledge in areas of <br/>science such as relatistic astrophysics, by making possible more reliable <br/>and accurate simulations of phenomena such as gravitational collapse, <br/>nonlinear stability of deformed rotating black holes, binary black hole <br/>collision, and the production and emission of gravitational radiation.<br/>Most of these problems are currently of great interest due to the <br/>recent construction of gravitational wave detectors such as the NSF-funded<br/>LIGO devices in Lousiana and Washington.  The results from this project <br/>will have a broad impact on areas of mathematics such as geometric analysis,<br/>as well as in astrophysics and general relativity.  The methods developed <br/>here will contribute to the advancement of numerical methods for complex <br/>three-dimensional constrained nonlinear dynamical simulations, and the <br/>technology produced will provide powerful tools for the exploration of <br/>models in astrophysics and relativity as well as in some areas of pure <br/>mathematics such as geometric analysis.<br/>"
"0714612","Multiscale Computations of Stiff Oscillatory Ordinary Differential Equations","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/01/2007","07/01/2010","Bjorn Engquist","TX","University of Texas at Austin","Continuing Grant","Junping Wang","08/31/2011","$299,999.00","Yen-Hsi Tsai","engquist@math.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1266, 1271","0000, 9263, OTHR","$0.00","Stiff oscillatory ordinary differential equations are common mathematical models in many important scientific fields, ranging from classical celestial mechanics to atomistic dynamics in modern physics and chemistry.  These models are gaining ever more importance as the computer capability increases.  Numerous simulations based on such systems are being performed in order to predict the nature, for example, of propagation of cracks and dislocations in metals and under what condition certain proteins change shape and take on specific functions that can be used in drug design.  Many fundamental phenomena are generated through delicate interactions between rapid oscillations.<br/><br/>The challenge is to simulate these highly oscillatory interactions over physically relevant time without having the quality of the output being damaged by numerical errors.  The research of this proposal aims at developing a new multi-scale computational approach such that the interesting phenomena resulting from interaction between oscillations can be computed accurately and efficiently over long time.  The corresponding mathematical analysis of the algorithms will also be performed."
"0702979","Conference on Highly Ocillatory Problems: Computation, Theory and Applications.","DMS","COMPUTATIONAL MATHEMATICS","07/01/2007","06/27/2007","Thomas Hou","CA","California Institute of Technology","Standard Grant","Leland Jameson","06/30/2008","$10,000.00","","hou@acm.caltech.edu","1200 E CALIFORNIA BLVD","PASADENA","CA","911250001","6263956219","MPS","1271","0000, 7556, 9263, OTHR","$0.00","Highly oscillatory problems, ubiquitous in applications, are typically consider to be very difficult theoretically and demanding computationally. However, recent developments provide highly effective means to treat problems with rapid oscillation. The Isaac Newton Institute program brings together professionals concerned in highly oscillatory phenomena, with an emphasis on multiscale modeling, homogenization, symplectic integration, Riemann-Hilbert techniques, highly oscillatory quadrature and exponential integrators, together with theoreticians and with workers in a wide range of applications. Typical grand challenges that we seek to address by this multidisciplinary collaboration are the solution of Schroedinger, Helmholtz and Maxwell equations, as well as long-term integration of equations originating in molecular dynamics.<br/><br/>High oscillation pervades a very wide range of applications:<br/>electromagnetics, fluid dynamics, molecular modelling, quantum chemistry, computerized tomography, plasma transport, celestial mechanics, medical imaging, signal processing. . . . It has been addressed by a wide range of mathematical techniques, ranging from asymptotic theory, harmonic analysis, theory of dynamical systems, theory of integrable systems and differential geometry. The computation of highly oscillatory problems has spawned a large number of different numerical approaches and algorithms. The purpose of this program is to foster research into different aspects of high oscillation, including the theoretical, the computational and the applied, from a united standpoint and to promote the synergy implicit in an interdisciplinary activity.<br/>"
"0713223","Efficient Algorithms for Interface Motion and Wave Propagation","DMS","COMPUTATIONAL MATHEMATICS","07/01/2007","09/04/2012","James Sethian","CA","University of California-Berkeley","Continuing Grant","Junping Wang","06/30/2013","$794,056.00","","sethian@math.berkeley.edu","1608 4TH ST STE 201","BERKELEY","CA","947101749","5106433891","MPS","1271","0000, 7237, 9179, 9263, OTHR","$0.00","The proposed work will develop mathematical and numerical techniques to make computer algorithms more efficient in several key manufacturing and engineering processes.  The work will focus on (i) semiconductor manufacturing to create faster and more reliable computer chips; (ii) seismic imaging to efficiently and accurately locate petroleum reserves; (iii) fluid jetting devices in the construction of computer display devices, bio-engineering of tissue scaffolding, and micro-jetting tools for printing circuit boards; (iv) injection molding and part manufacturing, and (v) logistical transport to determine optimal routing of goods and robotic motion. <br/><br/>These topics are linked through the requirement to efficiently, accurately, and robustly track the motion of complex interfaces.  Moving interface problems, which describe how boundaries move under intricate physics, are at the core of a host of practical and critical engineering and manufacturing problems.  As examples, semiconductors are built through multiple processes of shaping, depositing, and etching the interfaces between chemicals.  Seismic imaging in petroleum analysis requires fast solutions of propagating waves through the earth.  Fluid jetting devices, which appear across a range of scales from desktop inkjet printers down to automatic bioassay testing, require careful attention to the moving fluid interface problems between air, fluids (such as ink), and solid walls.  Injection molding requires carefully tracking the evolving boundaries between liquid, molten, and solid plastic as they fill a pre-formed mold.  Logistical transport and robotics require tracking optimal control interfaces to determine first arrivals. <br/><br/>The proposed work will be two-fold.  First, previous NSF support has allowed us to develop many of the current state-of-the-art numerical techniques for tracking moving interfaces, including level set methods, fast marching methods, ordered upwind methods, and escape arrival methods; this work will continue through a focus on more efficient versions and extensions to more complex physics.  Second, we will concentrate on prototype codes in each of the above-listed areas, in collaboration with industrial scientists, with the goal of creating practical engineering algorithms and simulations."
"0713793","Multiscale Numerical Strategies for Models with Quadratic Nonlinearity","DMS","COMPUTATIONAL MATHEMATICS","08/01/2007","06/22/2007","Ilya Timofeyev","TX","University of Houston","Standard Grant","Leland Jameson","07/31/2011","$143,704.00","","ilya@math.uh.edu","4300 MARTIN LUTHER KING BLVD","HOUSTON","TX","772043067","7137435773","MPS","1271","0000, 9263, OTHR","$0.00","The main goal of the proposed research is to develop a novel mathematical approach to allow faster numerical integration of certain types of Partial Differential Equations.  The types of Partial Differential Equations considered in this proposal are very common in many areas of physics and, in particular, play a crucial role in numerical weather and climate studies.  The main idea behind the proposed approach is that in many applications the main quantities of interest are large-scale averaged quantities (e.g., mean temperature changes over the next five to ten years, mean wind velocities during the summer, mean sea-surface temperature).  Therefore, in such applications it is not necessary to resolve all small-scale physics (e.g., local wind speed at any particular location) accurately.  On the other hand, the time-step of numerical integration is often limited (for technical reasons) by these small-scale processes.  The proposed research seeks systematic modification of the underlying partial differential equations to reduce the overall influence of small-scale processes and, thus, to allow for a bigger time-step in numerical simulations."
"0713012","Novel Computational Methods for the Analysis, Synthesis and Simulation of Shapes of Surfaces","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","06/25/2010","Washington Mio","FL","Florida State University","Continuing Grant","Leland Jameson","08/31/2012","$667,981.00","Xiuwen Liu","mio@math.fsu.edu","874 TRADITIONS WAY","TALLAHASSEE","FL","323060001","8506445260","MPS","1271","0000, 9178, 9251, 9263, OTHR","$0.00","The main goal of this project is to develop novel computational models and strategies to analyze the shapes of spherical surfaces in Euclidean 3-space.  In recent years, there has been a substantial progress in the computational study of shapes of curves with methodology based on the geometry of infinite-dimensional spaces of curves. However, attempts to extend these approaches to surfaces have encountered tall obstacles. In this project, an effective computational solution is proposed that encompasses all fundamental aspects of the problem. Shape spaces will be constructed equipped with geodesic metrics, which will provide a natural environment for the quantitative study of shapes of surfaces. A full set of computational tools will be designed and implemented to quantify shape similarity and divergence, to develop statistical models from samples, to synthesize shapes from learned models, and to analyze and simulate shape dynamics. Techniques will be developed to convert a noisy point-cloud representation of a surface of genus zero to a minimum-distortion parametrization over the  standard sphere. Alignment algorithms will be designed to best match the geometric features of surfaces and to extract optimal parametrizations for modeling a family of shapes. Riemannian metrics inherited from weighted Sobolev spaces will capture geometric similarities and discrepancies between shapes to any desired order. The project will focus on first-order metrics, as they offer a good balance between geometric accuracy and robustness for computations. Due to the typical complexity of the geometry of surfaces, many algorithms will employ a coarse-to-fine approach both for the processing of point clouds and triangular meshes. Localization of spherical shapes in the frequency or spatio-temporal domains will also be employed for statistical modeling and to achieve computational efficiency.<br/><br/>The proposed research on shapes and forms of 3D objects is motivated by a series of problems arising in areas such as computer vision, medical imaging, and computational biology. Shape is a key attribute associated with patterns arising in geometric data and its effective computational representation and analysis will have an impact on application domains such as the recognition of objects or targets from various modalities of images, modeling brain anatomy and functions, the simulation of biological growth and motion, and anatomical changes associated with diseases and aging. As such, the proponents will make the tools of shape modeling and analysis developed under this project available to the broader research community and will also actively pursue  collaborations  with researchers in these areas.<br/><br/>"
"0708071","High-Order Numerical Algorithms for Steady and Unsteady Simulation of Viscous Compressible Flow","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","06/05/2009","Antony Jameson","CA","Stanford University","Continuing Grant","Leland Jameson","08/31/2010","$421,614.00","","antony.jameson@tamu.edu","450 JANE STANFORD WAY","STANFORD","CA","943052004","6507232300","MPS","1271","0000, 9263, OTHR","$0.00","The goal of this project if to produce an efficient high-order methodology for 3D, high-speed unsteady viscous fluid flow in complex domains. No existing solver achieves all these goals, despite the fact that significant progress in relevant research areas has been made during the last few years. To achieve this goal, two major objectives may be identified. Firstly, the development of the high-order Spectral Difference (SD) Method for unstructured grids will be addressed. More specifically, the scheme will be extended to three dimensions, and formulated for mixed-element grids. The latter is necessary for efficient resolution of flows at high Reynolds numbers. Furthermore, upon analyzing and validating viable viscous discretization techniques, the scheme will be extended by the principal investigator and his colleagues to the Navier-Stokes equations on mixed grids. The second major objective is to improve the efficiency and robustness of the high-order methodology.  Numerical schemes of third or higher spatial order are not yet efficient enough for many problems of practical engineering interest, in particular high-speed viscous flow. To keep the number of degrees of freedom comparable to that of a second order method, the number of grid cells must be reduced as the order is increased. To resolve discontinuities sharply without oscillations h-p adaptively will be introduced. For both steady-state and time- dependent problems a fast solution technique is necessary to solve the arising systems of nonlinear equations. In order to meet this goal, an h-p multigrid strategy will be combined with efficient time stepping and relaxation schemes for both steady and unsteady flows.<br/><br/>Computational simulation has revolutionized the engineering design process and is by now the single most important tool in a wide range of high technology industries.  That in turn has had a huge impact in many real life applications of great importance to society and science, from aerospace to health to the environment.      The proposed research is targeted at advancing the state of the art of numerical algorithms which will be needed for the U.S. to remain at the forefront of computational simulation for both industrial and scientific applications.  In the Aerospace Industry simulation methods have been largely responsible for doubling the fuel efficiency of long range commercial aircraft since the advent of jet transport. The need for further improvement is crucial for both the economics and environmental impact of air transport, a jumbo jet releases its take-off weight (around 400 tons) in carbon dioxide emissions during a single flight. The European Union has recognized the importance of advancing simulation techniques with a variety of European wide and national initiatives (such as the German Mega Flow and Mega Design programs.)     Simulations and optimized redesign of the 747 wing can save tons"" of fuel, travel time and reduce emissions.   Computer simulation is equally crucial to advances in numerous other applications.  For example, simulations of blood flow through a beating heart and its valves, helps doctors understand and repair the malfunctioning heart;  simulation of air traffic control patterns can move that industry faster toward safer skies, reduce the occurrence of mid-air collisions and the time to reroute flights around weather systems;  modeling of air flow around computer chips and over the surface of a fast spinning disk drive improve function and reliability.  Today's ability to model huge global weather system can change the fate of nations struggling with tsunami's, floods,  the devastation of hurricanes;  Astrophysics and many studies of importance to National Security all rely on this new aspect of science and mathematics.  At the heart of all these is the development of more advanced numerical algorithms which provide the cornerstone of computational simulation. The proposed research intends to extend these  to more efficient high-order 3D methods,  While the immediate application of the research is to fluid flow problems related to aerospace, an improved fluid flow simulation capability is immediately transferable to other industrial and scientific applications, including those mentioned above as well as many others such as the automotive and marine industries, wind energy, and a wide range of environmental issues. Even the flow patterns in urban areas around buildings can be used to evaluate how germ or chemical particles would be spread by winds circulating through the 'canyons' of clustered tall buildings. Further advances in all aspects of computational simulation and its underlying numerical methology is essential in order to maintain the Unites States' technological leadership and competitiveness in the rapidly evolving global economy. The results of these developments and techniques will play an increasingly pivotal role and have major implications environmentally, scientifically economically and socially as the results filter down into the many applications using them today, as well as future applications that will need to evaluate complex nonlinear partial differential equations for a variety of physics.<br/><br/>"
"0809285","Optimal Cross Parameterizations of Surfaces: Computational Methods and Scientific Applications","DMS","COMPUTATIONAL MATHEMATICS","12/01/2007","05/28/2008","Xiangmin Jiao","NY","SUNY at Stony Brook","Standard Grant","Junping Wang","08/31/2011","$225,574.00","","xiangmin.jiao@stonybrook.edu","W5510 FRANKS MELVILLE MEMORIAL L","STONY BROOK","NY","117940001","6316329949","MPS","1271","0000, 9263, OTHR","$0.00","Mesh-based computations, such as finite-element or finite-volume analysis, are important for a wide range of scientific and engineering applications, ranging from the design of aircrafts and rockets to the understanding of cardiovascular disease.  Many modern computational problems involve two or more surfaces or multiple discretizations (such as meshes) of a common surface and require correlating and cross-parameterizing these surfaces to analyze, match, manipulate, or map data between them.  Examples include non-conforming domain decomposition, multiphysics simulations, analysis of biomedical images, shape matching, and shape retrieval. The problem of robust cross-parameterization of surfaces is challenging, because in many practical situations the domains do not match well and some major discrepancies (such as singularities and topological changes) may occur in numerical simulations as well as in the physical world.  Most existing methods used in practice often assume the distances between corresponding points are at a local minimum.  They do not offer theoretical guarantees, may produce inaccurate and even unstable results in the presence of singularities or large discrepancies, and do not offer the accuracy and physical meaningfulness required by scientific and engineering applications.  Addressing these problems in a consistent and robust manner is critical for high-fidelity numerical simulations of complex systems and other related applications.<br/><br/>In this project, we will devise and analyze a general and unified framework for optimal cross-parameterizations of surfaces and deliver this enabling technology to those numerical applications.  Our framework will be based on efficient solutions of variational problems motivated by careful analysis of the accuracy and stability requirements of the underlying physical and numerical applications.  Unlike most existing methods, our framework will construct cross-parameterizations directly on curved surfaces without intermediate parameterizations on a template surface, and thus will avoid those spurious sources of numerical errors.  We emphasize theoretical foundations for optimal cross-parameterizations, efficient and robust algorithms for static and dynamic surfaces, and applications such as medical imaging, mesh optimization, and manifold learning."
"0741471","Large Scale Random Systems: Stochastic Partial Differential Equations and Random Matrix Theory","DMS","COMPUTATIONAL MATHEMATICS, COFFES","07/01/2007","10/24/2008","Toufic Suidan","AZ","University of Arizona","Standard Grant","Michael Steuerwalt","08/31/2009","$97,545.00","Thomas Kennedy","tsuidan@math.arizona.edu","845 N PARK AVE RM 538","TUCSON","AZ","85721","5206266000","MPS","1271, 7552","0000, 9263, OTHR","$0.00","     The investigator studies two topics: statistical<br/>hydrodynamics, and various combinatorial models with their<br/>connections to random matrix theory.  With regard to infinite<br/>dimensional stochastic equations and statistical hydrodynamics,<br/>the investigator focuses on three questions.  The first concerns<br/>the structure of typical solutions for nonlinear stochastic<br/>partial differential equations such as the two-dimensional<br/>stochastic Navier-Stokes equations and the stochastic Burgers<br/>equation.  The second concerns the uniqueness of steady states for<br/>inviscid randomly forced equations on unbounded domains.  The<br/>third concerns the mechanism of energy transfer from high to low<br/>modes in stochastically forced formally conservative systems.  For<br/>each of these questions new analytic approaches and new phenomena<br/>have been described.  A goal of this work is to more completely<br/>analyze these phenomena.  In combinatorics, growth models, and<br/>random matrix theory the investigator studies basic questions of<br/>Gaussian Orthogonal Ensemble (GOE) random matrix theory, focusing<br/>on the connection of symmetrized combinatorial models to limiting<br/>distributions of the Gaussian orthogonal ensemble.  The questions<br/>considered include problems of random tiling that arise in<br/>physics, polynuclear growth models that arise in the study of<br/>random interfaces, and percolation models that arise in condensed<br/>matter physics and electrical engineering.  A goal of the work is<br/>to prove new central limit theorems in the context of GOE random<br/>matrix theory. <br/><br/>     Understanding the small-scale structure of stochastically<br/>forced hydrodynamic equations is related to turbulence theory and<br/>statistical mechanics.  The small-scale structure of solutions is<br/>of both theoretical and experimental importance.  It is this<br/>structure that matters in turbulent flows arising in many concrete<br/>problems of aerodynamics and fluid mechanics.  The particular<br/>questiuons studied here contribute to the current understanding of<br/>this small-scale structure.  It has recently become clear that<br/>random matrix theory techniques answer a wide range of questions<br/>in a variety of seemingly unrelated fields.  Essentially, random<br/>matrix theory affords a model that captures the fluctuations of<br/>many distinct processes.  The questions studied in this project<br/>widen this class of problems and processes and improve the current<br/>understanding of the various phenomena that lead to random matrix<br/>statistics."
"0707564","Rapidly-convergent, high-performance PDE solvers for materials-science and engineering applications: theory, implementation and applications.","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/15/2007","07/11/2009","Oscar Bruno","CA","California Institute of Technology","Continuing Grant","Michael Steuerwalt","08/31/2011","$532,544.00","","obruno@caltech.edu","1200 E CALIFORNIA BLVD","PASADENA","CA","911250001","6263956219","MPS","1266, 1271","0000, 7237, 9251, 9263, OTHR","$0.00","Bruno<br/>0707564<br/><br/>     The investigator seeks development and analysis of accurate,<br/>rapidly convergent, high performance solvers for the types of<br/>challenging partial differential equations that arise in<br/>present-day materials science applications, as well as use of<br/>such solvers for design of concrete devices and prediction of<br/>properties of realistic systems.  He creates algorithms to treat<br/>certain types of problems related to potential theory and wave<br/>propagation, composite materials and optical devices, elasticity,<br/>acoustics, and electromagnetism.  Significant difficulties arise<br/>in these classical fields of numerical analysis and computational<br/>science in the context of the materials science problems<br/>considered, which require treatment of microstructures,<br/>non-coercive systems, geometric singularities, resonant<br/>structures, high frequencies, multiple scattering, etc.  These<br/>are mathematical problems that, in spite of significant efforts<br/>and progress over the last century, remain elusive in a wide<br/>range of important instances.  The combination of a number of<br/>such challenges often arises in the treatment of materials<br/>science configurations, which has made materials problems<br/>difficult to tackle.  In particular, most algorithms available<br/>for the types of materials science applications considered in the<br/>project lack in either accuracy, computational efficiency, or<br/>both -- a circumstance that has hindered progress in the field. <br/><br/>     The investigator develops effective, high-performance<br/>computational methods for solving partial differential equations<br/>that model the properties and behaviors of various physical<br/>systems, emphasizing features important for materials.  The<br/>project has consequences for several areas of societal interest,<br/>including the medical field (tomography, imaging), electrical<br/>engineering (optics, electronics), military and civilian remote<br/>sensing (radar, sonar, stealth), communications (antennas),<br/>atmospheric science, etc.  The project also provides training for<br/>students at both graduate and undergraduate levels, as well as<br/>for postdoctoral associates."
"0713670","Dynamic Stability and Multiscale Computation of 3D Incompressible Flows.","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","07/10/2007","Thomas Hou","CA","California Institute of Technology","Standard Grant","Leland Jameson","08/31/2010","$313,830.00","","hou@acm.caltech.edu","1200 E CALIFORNIA BLVD","PASADENA","CA","911250001","6263956219","MPS","1271","0000, OTHR","$0.00","The investigator and his colleagues study two fundamental problems in fluid dynamics. The first one is the dynamic stability property of 3D incompressible flows. The second one is to derive a systematic multiscale model to simulate the long time solution of the 3D Navier-Stokes equations. The dynamic stability property of the 3D incompressible Euler or Navier-Stokes equations plays a very important role in our understanding of the fluid dynamic stability and dynamic depletion of nonlinear vortex stretching. For a long time, many experts had believed that the nonlinear vortex stretching term is mostly a destabilizing term, which may lead to a finite time singularity of the 3D Euler or Navier-Stokes equations with a smooth initial condition.<br/>In this proposal, the investigator proposes a new strategy to study the dynamic stability of fluid flows by exploiting the anisotropic scaling of the singular support and the local solution structure. Furthermore, the investigator proposes a new multiscale model for the 3D Navier-Stokes equations by using a reparameterization of the solution in the frequency space and a nested multiscale expansion with a multiscale phase function. <br/>Careful numerical experiments will be performed to validate the multiscale model against direct numerical simulations and study the statistical properties of turbulent flows using the proposed multiscale model.<br/><br/><br/>Many fascinating natural phenomena such as tornadoes, hurricanes, typhoons, and tsunami waves are governed by the Navier-Stokes equations. The understanding of the solution behavior of the Navier-Stokes equations and the development of efficient computational methods to simulate their solutions have a tremendous impact in improving the national technology and for the well-being of the society.<br/>The advances in the proposed research could potentially improve the ability in weather forecasting, studying environmental change, and in predicting natural disasters.<br/>The proposed study on the dynamic stability and dynamic depletion of vortex stretching could lead to important insights on the large time behavior of the incompressible flows. This is one of the major open problems in physics and science. A systematic multiscale analysis could lead to a new generation of multiscale computational method to simulate turbulent flows, with potential for great impact throughout science and technology. An additional impact of this project will be the involvement of graduate students and postdoctoral fellows. The proposed research provides a solid training in mathematical analysis, physical modeling and numerical simulation. The interdisciplinary training they receive in this project will be very important for careers in mathematics and science.<br/>"
"0714050","Multi-scale,  Geometrical Study of Eddy-structure in Turbulence","DMS","COMPUTATIONAL MATHEMATICS","07/15/2007","07/10/2007","Dale Pullin","CA","California Institute of Technology","Standard Grant","Leland Jameson","06/30/2011","$207,460.00","","dpullin@caltech.edu","1200 E CALIFORNIA BLVD","PASADENA","CA","911250001","6263956219","MPS","1271","0000, 9263, OTHR","$0.00","The investigator and his students work to develop a new computational-mathematical framework for the identification and characterization of eddy-like structures in turbulence. The general methodology consists of a multi-scale analysis of a turbulence volume data set followed by the eduction of structures of interest and their geometrical characterization. The multi-scale analysis is performed through the curvelet transform.<br/>The eduction of structures is achieved by isocontouring the volume data sets for different scales. The geometrical characterization is based on the probability density functions of shape index and curvedness, in terms of area coverage,associated with each structure. This allows a global characterization of the set of structures as well as the study and comparison of relevant groups of structures contained within this set. The investigator has already developed the basic framework which has been subjected to validation testing based on reproducing the geometrical character of a synthetic ``virtual turbulence''. The work is presently focused on studying the geometrical structure of scalar turbulence obtained from 512^3 direct-numerical simulation in a periodic cube. Further development is in progress to refine and improve this framework at the extraction and classification levels in order to better adapt it to the properties of turbulence data bases. The methodology is also being applied to the 256^3, 512^3 and 1024^3 data sets of the same turbulence image (at three different resolutions) provided by K. Horiuti (Nagoya Japan). Turbulent fields under study include the scalar dissipation and quantities derivable from velocity gradients such as vorticity, invariants of the velocity-gradient tensor, functions of these quantities that identify local, vorticity-dominant regions, and functionals of the pressure. The methodology will also be applied to non-homogeneous turbulent fields such as those obtained from turbulent channel flow.<br/><br/><br/> From the time of Leonardo Da Vinci, who crafted detailed images of eddying fluid flow, the to present era of enhanced computer graphics and the visualization of natural phenomena, there has been an ongoing fascination with both characterizing and understanding the natural geometry of turbulent fluid flow.<br/>But despite intense study, the structure and morphology of turbulent eddies remains elusive. A better understanding of this structure should both elucidate one of nature's profound mysteries and at the same time provide a firm basis for the development of improved predictive models for turbulent fluid flow for application to many diverse areas of science and engineering ranging from the galactic scale, through solar-system dynamics, star formation and stellar interior dynamics, the solar wind, climate modeling of planet earth, to environmental fluid dynamics and industrial and engineering applications. The present research is motivated by the recent availability of high-fidelity data bases representing very detailed and realistic turbulent flow fields obtained from intensive computer simulation.<br/>The investigator and his students combine novel pattern-recognition techniques from the field of computer science with new applied-mathematical methods based on ``multi-scale'' analysis, to study these data. The significance of this work is that it will provide a new methodology for analysing the underlying geometrical structure and content of extremely large, turbulent fluid-flow data fields.<br/>The computer codes developed in this research will be made openly available, with documentation through publications in thesis dissertations and in archival journals.<br/>This should allow potential users to apply the modeling methodologies developed in this work to large data bases obtained from both numerical-simulation and experiment. Applications beyond fluid flows, to any set of continuous fields, are envisioned.<br/>"
"0733051","Sparse Representations and High-Dimensional Geometry, Conference","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","08/28/2007","Jared Tanner","UT","University of Utah","Standard Grant","Junping Wang","08/31/2008","$10,000.00","Ronald DeVore, Anna Gilbert","tanner@math.utah.edu","201 PRESIDENTS CIR","SALT LAKE CITY","UT","841129049","8015816903","MPS","1271","0000, 7556, 9263, OTHR","$0.00","This grant supplies funds to cover shared local accommodations and meals for approximately fifteen US based junior researchers to attend the 2007 AMS von Neumann Symposium ""Sparse Representation and High-Dimensional Geometry"" being  held from July 8th through the 12th, 2007.   Junior researcher is defined as a graduate student, or researcher who has received their PhD. during or after 2002.<br/>This conference is the first major conference in the USA dedicated to the emerging topic of sparse approximation and as such is expected to play an important role in the development of a cohesive research community.  With its relationship to fundamental questions in pure mathematics as well as important implications for information acquisition, sparse approximation has received a great deal of interest from both mathematicians and engineers.  The conference will be focused around the themes of: fundamental frameworks for where sparsity is present and can be exploited, application areas and practical considerations, the underlying high-dimensional geometric phenomenon allowing for sparse approximation algorithms to work, the design and analysis of computationally efficient algorithms, and presentations of application results. The conference is truly interdisciplinary, including participants from google and other industries, theoretical mathematicians studying banach spaces, and leading electrical engineers.<br/><br/>This grant supplies funds to allow approximately fifteen US based junior researchers to attend the first conference in the USA dedicated to sparse approximation; for details of this conference see ""www.ams.org/meetings/vonneumann07.html.""  This topic concerns the development of mathematical tools to simplify large data sets, through the construction of good approximations which are as parsimonious as the data allows.  These tools are increasingly important in the modern scientific environment characterized by ever larger data sets.  Applications already under investigation include dynamic visualizations of the human beating heart, next generation circuit components for wireless communications, and faster sequencing of biological micro-arrays.  Funds from this grant will allow for the rapid training of early stage researchers in this topic, increasing the rate and quality of expected advances in both its theory and application.<br/>"
"0715146","Collaborative Research: Finite Element Methods for Discretizing Geometric PDEs with Nonlinear Constraints and Gauge Freedom","DMS","COMPUTATIONAL MATHEMATICS","08/01/2007","07/24/2007","Michael Holst","CA","University of California-San Diego","Standard Grant","Junping Wang","07/31/2011","$180,000.00","Gabriel Nagy","mholst@math.ucsd.edu","9500 GILMAN DRIVE","LA JOLLA","CA","920930021","8585344896","MPS","1271","0000, 9263, OTHR","$0.00","This project is concerned with the approximate solution of certain<br/>systems of evolution partial differential equations (PDE) arising at<br/>the intersection of mathematical physics and geometric analysis.<br/>Such systems of equations, known as Geometric PDE, with both constraints<br/>and gauge degrees of freedom, appear in a wide range of physical and<br/>mathematical problems; examples include Maxwell's equations (or more<br/>generally the Yang-Mills equations on a curved background), and<br/>Einstein's field equations and other Hamiltonian systems with an<br/>infinite-dimensional symmetry group. The Cauchy formulation for such <br/>systems yields a constrained evolution system which has to be augmented <br/>with gauge-fixing conditions in order to get a unique evolution vector field.<br/>The project will involve constructing finite element discretizations<br/>for solving such geometric PDE systems; various techniques for dealing<br/>with evolution systems with constraints will be analyzed, including<br/>constraint-projection using variational techniques (where the numerical<br/>solution is projected back to the constraint manifold after<br/>some number of time steps), the use of special finite elements which<br/>automatically solve the linearized constraints and thereby remain on a<br/>piecewise-linear approximation to the constraint manifold, and finally<br/>least-squares approaches which only control the constraints rather than<br/>enforce them. In particular, stability results guaranteeing convergence<br/>of the numerical solution to the continuum solution will be derived,<br/>at least for the linearized equations.  A posteriori error estimates will <br/>be derived for studying properties of the discretizations, and for <br/>building adaptive methods.<br/><br/>This project involves the design, development, and implementation of<br/>new mathematical and computational techniques for solving a large class <br/>of important, challenging, and pressing mathematical problems in<br/>multiscale and multiphysics modeling and simulation.  The techniques <br/>developed will lead to the aquisition of new knowledge in areas of <br/>science such as relatistic astrophysics, by making possible more reliable <br/>and accurate simulations of phenomena such as gravitational collapse, <br/>nonlinear stability of deformed rotating black holes, binary black hole <br/>collision, and the production and emission of gravitational radiation.<br/>Most of these problems are currently of great interest due to the <br/>recent construction of gravitational wave detectors such as the NSF-funded<br/>LIGO devices in Lousiana and Washington.  The results from this project <br/>will have a broad impact on areas of mathematics such as geometric analysis,<br/>as well as in astrophysics and general relativity.  The methods developed <br/>here will contribute to the advancement of numerical methods for complex <br/>three-dimensional constrained nonlinear dynamical simulations, and the <br/>technology produced will provide powerful tools for the exploration of <br/>models in astrophysics and relativity as well as in some areas of pure <br/>mathematics such as geometric analysis.<br/>"
"0713812","Novel Approaches to Empirical Force Field Models in Molecular Modeling via Multidimensional Scaling","DMS","COMPUTATIONAL MATHEMATICS, MSPA-INTERDISCIPLINARY","07/01/2007","06/29/2007","Robert Lewis","VA","College of William and Mary","Standard Grant","Dalin Tang","06/30/2011","$133,759.00","Michael Trosset","buckaroo@math.wm.edu","1314 S MOUNT VERNON AVE","WILLIAMSBURG","VA","231852817","7572213965","MPS","1271, 7454","0000, 7237, 7303, 9263, OTHR","$0.00","The project focuses on new computational methods for the determination of biomolecular structure, which is crucial to our understanding of how biomolecules such as proteins perform the functions they do.  This functional understanding, in turn, figures in the development of techniques for disease diagnosis and treatment.<br/>     A widely used approach to determining the structure of biomolecules is the minimization of the molecule''s potential energy, computed using a force-field model.  The potential energy accounts for such features as the stretching of bonds between atoms, the deformation of bond angles, and the interactions of non-bonded atoms (e.g., electrostatic forces).  Of interest are molecular configurations that have very low potential energies, since biomolecules fold themselves into shapes that tend to minimize the potential energy: Nature is an optimizer.  One seeks physically meaningful molecular configurations by applying computational techniques to systematically vary the locations of the atoms to reduce the potential energy.<br/>     A serious difficulty encountered when applying computational algorithms to energy minimization arises when the search needs to move through configurations with high potential energies on the way to configurations with low potential energies.  For instance, moving atoms close past one another increases the potential energy due to repulsive forces.  Minimization algorithms have difficulty dealing with this situation since they cannot be sure in advance that allowing increases in potential energy will ultimately lead to configurations with lower energy.  As a consequence, algorithms may halt at structures that minimize the potential energy only among nearby configurations, but not overall, and are not of physical interest.<br/>     This project explores a new approach to address this difficulty.  We pose the problem in terms of the interatomic distances, rather than the locations of the atoms, rewriting the potential energy in terms of these distances.  Roughly speaking, our approach corresponds to adding fictitious copies of each atom, one for each of the other atoms.  Of course, we must also add conditions that ensure that all the fictitious copies of an atom ultimately coalesce into a single atom.  However, we use conditions that can be relaxed at intermediate steps of the energy minimization process and are only enforced as we approach a solution.<br/>     This approach benefits from adding a large number of extra dimensions to the search space.  As an analogy, imagine a search for the lowest point in North America, Death Valley, starting from Chicago.  As purely earthbound voyagers we might be fooled into stopping at a local low point at the foot of the Rockies or around the Great Salt Lake, just as optimization algorithms might halt at local energy minimizers.  But if we relax the requirement of traveling by land and allow travel by air, then we can pass over local minimizers on the ground to arrive at the desired destination.  <br/>     Preliminary tests have shown that our approach greatly improves the behavior of the more notoriously troublesome energy terms.  This project will investigate its use for molecular structure determination and will examine extensions to other applications such as drug docking and finding transition mechanisms for chemical reactions."
"0636586","EMSW21-RTG - Program in Applied and Computational Analysis","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, ANALYSIS PROGRAM, WORKFORCE IN THE MATHEMAT SCI","06/15/2007","06/01/2011","Irene Gamba","TX","University of Texas at Austin","Continuing Grant","Junping Wang","12/31/2013","$2,098,599.00","Panagiotis Souganidis, Luis Caffarelli, Bjorn Engquist, Thaleia Zariphopoulou","gamba@math.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1266, 1271, 1281, 7335","0000, 7301, 9263, OTHR","$0.00","The proposed program is the area of applied and computational analysis to be hosted by the Department of Mathematics and the Institute for Computational Engineering and Sciences (ICES) at the University of Texas at Austin. The goal is the creation of a model program in applied and computational mathematic that will include enhanced undergraduate research experience (REU), reduced time to graduation and stronger background in applicable mathematics for graduate students, and the highest level of postdoctoral mentoring, all to be achieved by curriculum and examination reform, new undergraduate concentrations, new integrated seminar and working group series, summer programs, and an active mentoring program.<br/><br/>The intellectual merit of the proposed work is based on applied and computational analysis as the fundamental field that links mathematics to the different areas of applications in the natural and social sciences and engineering both within and outside of the university. Focus will be on non-linear theory and computations of differential equations, which give the most fundamental of mathematical models in science and technology from an applied point of view. The need for young, well-trained mathematicians capable of connecting to diverse areas of applications has never been higher. At the local level, the proposed program will contribute towards the increase of the number of students attracted to mathematics, and, at the national level, it will serve as a model program for similar initiatives.<br/>"
"0754374","Analysis and Control of Complementary Systems","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/01/2007","10/24/2007","Jong-Shi Pang","IL","University of Illinois at Urbana-Champaign","Standard Grant","Victor Roytburd","08/31/2009","$114,282.00","","jongship@usc.edu","506 S WRIGHT ST","URBANA","IL","618013620","2173332187","MPS","1266, 1271","0000, 9263, OTHR","$0.00","A complementarity system is a dynamical system defined by an ordinary differential equation (ODE) involving the solutions of a finite-dimensional complementarity problem parameterized by the state of the differential equation.  Complementarity systems constitute a new mathematical paradigm that finds a wide range of applications in nonsmooth mechanics, robotics, multi-body dynamics, switched circuit systems, economic and traffic systems, and even biological systems.  As such, the rigorous study of these systems is warranted.  Due to their intrinsically nonsmooth characteristics, such a study defies classical dynamical systems theory and requires novel mathematical analysis, computational and design tools.  This proposed project is devoted to the investigation of challenging issues in the analysis and control of complementarity systems.  We propose to apply state-of-art techniques from mathematical programming, convex analysis, systems theory, and control theory to tackle these problems.  On the analytical side, we will address several fundamental and critical issues of system behavior, e.g., existence and uniqueness of solutions and Zeno property, which are directly related to numerical computation and system analysis.  Moreover, we aim at studying controllability and observability and developing control algorithms that will be applied to robot motion planning, multi-body systems subject to unilateral constraints, and constrained dynamic optimization problems.<br/><br/>Dynamical systems modeled by ODEs provide a powerful mathematical and computational framework for the study and understanding of a wide range of time-dependent physical phenomena that naturally occur in many engineering applications.  As the application areas expand, researchers and designers are encountering increasingly complex systems subject to various constraints, which arise as a result of the global behavior of the systems and the interactions between them and their complex environment and/or other systems at different levels.  A trivial example of such constraints is a falling object before and after hitting the ground.  At the instant where the object touches the ground, an impact occurs followed by a rebounce of the object that results in a change of direction of the object's motion.  This is a mode transition.  The proposed research aims at treating dynamical systems where mode transition is an unknown but important component of the overall system configuration.  If successful, the results of the research will let us gain a better understanding of many complex engineering systems with mode changes and will provide a solid foundation for the improved design of such systems that in turn will have a significant impact on many practical fields.  The proposed work will also contribute to the advancement of basic sciences and to the education and training of the human workforce."
"0636574","EMSW21-RTG: Applied Mathematics Training Program for Interdisciplinary Research in Science and Engineering","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, WORKFORCE IN THE MATHEMAT SCI, MATH PRIORITY SOLICITATION, MSPA-INTERDISCIPLINARY","09/01/2007","06/11/2011","Alvin Bayliss","IL","Northwestern University","Continuing Grant","Henry Warchall","08/31/2014","$2,253,006.00","David Chopp, Vladimir Volpert, Michael Miksis, Moshe Matalon, Sascha Hilgenfeldt","a-bayliss@northwestern.edu","633 CLARK STREET","EVANSTON","IL","602080001","3125037955","MPS","1266, 1271, 7335, 7446, 7454","0000, 7301, 7303, 9263, OTHR","$0.00","This project establishes a flexible, modern training program in applied mathematics within the Research Training Group program.  <br/><br/>Mathematics is a central component in physical sciences, biological sciences, and engineering, and many diverse disciplines exhibit common mathematical structures.  Work in these fields profits from the involvement of applied mathematicians with broad backgrounds.  This program will train such young applied mathematicians at all levels, from undergraduates through postdoctoral researchers.  <br/><br/>A significant feature of the program is its interdisciplinary nature -- the group's activities involve not just mathematicians, but engineers and scientists as well.  Thus, group members, while trained as applied mathematicians, will be comfortable interacting with non-mathematicians in research teams.  The research activities will emphasize breadth and flexibility; trainees will be able to tackle problems involving a wide variety of mathematical techniques, ranging from analytical and computational methods to the development of suitable models of physical processes, and they will be able to adapt their research to diverse areas as opportunities arise. <br/><br/>The group's activities will involve mathematical research ranging from analytical to computational, in application areas including life sciences (particularly microbiology and biological fluids), fluid mechanics, materials science, and combustion.  A special focus is on interfacial phenomena and phenomena involving multiple scales.<br/><br/>The project will produce a group of young applied mathematicians who are multifaceted in their scientific knowledge, able to grasp common mathematical features in problems from a diverse range of application areas, comfortable working and interacting with scientists and engineers in an interdisciplinary environment, and sufficiently flexible to pursue productive research in other areas as national priorities evolve. <br/>"
"0712827","Multiscale Total Variation Methods for Integral Equation Models in Image Processing","DMS","COMPUTATIONAL MATHEMATICS","08/15/2007","05/01/2009","Yuesheng Xu","NY","Syracuse University","Continuing Grant","Leland Jameson","07/31/2010","$358,900.00","Charles Micchelli, Lixin Shen","y1xu@odu.edu","900 S CROUSE AVE","SYRACUSE","NY","132440001","3154432807","MPS","1271","0000, 9263, OTHR","$0.00","Models currently used in image processing are discrete. They are piecewise constant approximations of the true models - integral equation models. The discrete models impose bottleneck model errors which cannot be compensated from the numerical methods developed based upon them. To overcome this drawback, the PIs propose to directly use the integral equation models for image processing. The integral equation models will offer us much greater flexibility for the in-depth analysis of the corresponding images. An ideal method for image processing should be sensitive to geometric features of images and computationally efficient. Presently, the total variation method and the multiscale method are two main mathematical approaches for image processing. They are complementary to each other in their strength and weakness. The total variation method is sensitive to geometric features of images but it is computationally inefficient. The standard multiscale method is convenient for computation due to its multiscale structure but it is not very sensitive to the geometric features of images. Aiming at designing computationally efficient algorithms that are sensitive to geometric features of images, the PIs propose to develop multiscale total variation methods which combine the strengths from both of these two methods. The PIs study the following four mathematical problems related to image processing: (1) Multiscale approximation of images based on integral equation models; (2) Multiscale total variation regularization; (3) Missing data recovery with redundant systems; and (4) Design of application-driven wavelet and framelet filter banks.  <br/><br/><br/>Image processing arises in a variety of scientific, medical and engineering applications. Specifically, applications in medical sciences and technologies range from computer tomography to diagnoses of diseases, applications in environmental sciences include natural resources and pollution control via satellite imaging, applications in art sciences have vision analysis and digital restorations of cracked ancient paintings in digitized fine art museums and applications in security identification include weapon, fingerprints and face identifications.  In these applications, a key issue is restorating images from available data. This is an ill-posed problem. Solving this problem needs advanced mathematical models and efficient computational algorithms. The main objective of this proposal directly addresses this issue by proposing multiscale total variation methods for integral equation models in image processing. The projects in the proposal will enhance the integration of high level pure mathematics with the contemporary digital and computer technology. These projects will train graduate studetns in this important area to prepare them to face the mathematical and computational challenge in future scientifical and technological development. Moreover, th PIs will develop a multidisciplinary course for upper level undergraduate students based on research results of these projects. <br/>"
"0802609","Computational Methods and Software for Structured Multiscale Models of Tumor Invasion","DMS","COMPUTATIONAL MATHEMATICS","08/01/2007","10/17/2007","Bruce Ayati","IA","University of Iowa","Standard Grant","Leland Jameson","07/31/2009","$61,507.00","","bruce-ayati@uiowa.edu","105 JESSUP HALL","IOWA CITY","IA","522421316","3193352123","MPS","1271","0000, 9263, OTHR","$0.00","The investigator and student propose to develop computational methods and software to solve systems of partial differential equations that arise in multiscale models of tumor invasion.  The behavior of these systems depends not only on time and space, but also on physiological traits such as size or age. The methods decouple time from the physiological variables. In doing so they, unlike previous methods, prevent the often fine-resolution time discretization from infl ating the number of nodes in the physiological variables.  Collaboration with cancer biologists is a critical component of this research plan. The software will be developed and used in the context of models developed and parameterized with cancer biologists at Vanderbilt University, with the expectation that they will have a significant and near-term impact on understanding the mechanisms of tumor invasion. This collaboration is also vital to ensure the relevance and usefulness of the methods and software; methods developed in an application vacuum tend to lack utility.<br/><br/>The investigator and his student propose the development of computer software and algorithms -- the mathematical rules that determine how the software works -- to study how cancer tumors, in middle and later stages of their development, invade nearby tissue.   In particular, the software will handle the complicated situation where the different genetic profiles of the multitudes of individual cells within a tumor, and the different stages in the cell-division cycle of each of these cells, are linked to the physically larger complete tumor.  This is important, for example, in studying the overall effects of chemotherapy when using drugs that affect cells differently depending on their genetic type or what part of the cell-division cycle they are in.  The mathematics behind the algorithms in this proposal are significantly more advanced than what came before, resulting in software that can be used effectively with the computers of today and the near future.  An important part of this research proposal is the collaboration between the investigators and colleagues in mathematics and cancer biology at Vanderbilt University in Nashville, TN, and at the University of Dundee in Scotland.<br/>"
"0705455","Computational and Conformal Geometry","DMS","GEOMETRIC ANALYSIS, COMPUTATIONAL MATHEMATICS, ANALYSIS PROGRAM","06/01/2007","05/19/2009","Christopher Bishop","NY","SUNY at Stony Brook","Continuing Grant","Christopher Stark","05/31/2011","$179,999.00","","bishop@math.sunysb.edu","W5510 FRANKS MELVILLE MEMORIAL L","STONY BROOK","NY","117940001","6316329949","MPS","1265, 1271, 1281","0000, 9263, OTHR","$0.00","The PI, Christopher Bishop, will study problems in two and three dimensional geometry which come from classical complex analysis, the theory of quasiconformal mappings, hyperbolic geometry and computational geometry, with a particular emphasis on interactions between these areas. In recent work the PI has shown that ideas from hyperbolic and computational geometry could help resolve a question of classical analysis: how to efficiently compute conformal maps onto planar domains.  This work will be extended to new settings, and will be used to study problems arising in computational geometry, e.g., efficient generation of meshes with desirable properties. The PI will investigate the possible application of the carpenter's rule problem from computational geometry to an analysis problem about deforming chord-arc curves. He will also continue his work on the distortion properties of quasiconformal mappings and on the conformal welding problem.<br/><br/><br/>The PI, Christopher Bishop, will continue his investigations into the theory and computation of conformal and quasiconformal maps. Conformal maps send one region to another so that angles (but not necessarily distances) are preserved. Quasiconformal maps may distort angles, but only by a limited amount. One of the oldest and most famous examples is the Mercator projection which maps the spherical Earth to flat piece of paper. This can't be done without some sort of distortion, and for navigation it is more convenient to have angles preserved than distances (so looking at a chart you know the correct direction to head, if not the exact distance to be covered). Conformal maps also appear in many applications where one wants to transfer a problem from a domain with complicated geometry to a simpler one (such as a disk) where it is easier to solve. Examples come from aerodynamics, fluid flow, vibrating membranes, heat flow, electrostatics and many other problems. Conformal maps also play a fundamental role within pure mathematics in areas such as dynamics, complex analysis, probability and geometry. Because of their importance, there are numerous techniques for computing conformal maps numerically, but different methods work best in different situations and often a method fails for sufficiently complicated regions. The PI has developed an algorithm that is guaranteed to work for a large class of regions, and is able to estimate the time needed to achieve a given accuracy.  The algorithm is based on new connections between geometric concepts from computer science and non-Euclidean geometry arising in pure mathematics. Under the current proposal the PI will seek to turn this theoretical algorithm into a practical method, investigate generalizations more complicated regions and to higher dimensions, and apply the method to problems arising from computer science.<br/>"
"0636590","EMSW21-RTG  Mathematics of Materials: Model Development, Analysis, Simulation and Control","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, WORKFORCE IN THE MATHEMAT SCI","07/01/2007","05/31/2011","Ralph Smith","NC","North Carolina State University","Continuing Grant","Leland Jameson","06/30/2013","$1,899,907.00","Negash Medhin, Michael Shearer, Pierre Gremaud, Mansoor Haider","rsmith@ncsu.edu","2601 WOLF VILLAGE WAY","RALEIGH","NC","27607","9195152444","MPS","1266, 1271, 7335","0000, 7301, 9263, OTHR","$0.00","The program ""Mathematics of Materials"" provides a wide range of interdisciplinary research and training opportunities for undergraduates, graduate students, and postdocs in the mathematical sciences.  The research activities are organized around five topics that play a fundamental role in emerging technologies: multifunctional materials, polymers and composites including carbon nanotubes, orthopaedic biomaterials, dynamics of thin material layers, and material behavior of laser welding.  Within each topic, investigations focus on fundamental model development, mathematical solution, numerical simulation, and control design.  Each project involves substantial collaboration with experimental colleagues that provides interdisciplinary training opportunities to mathematics students and postdocs.  The training component is designed to prepare students and postdocs for the varied roles of interdisciplinary research mathematicians.  This includes training modules that introduce participants to research and career topics not typically covered in coursework, targeted courses on topics pertaining to research areas and national research agendas, and participation in summer internships and national conferences.<br/><br/>""Mathematics of Materials"" is an interdisciplinary research training group program designed for undergraduates, graduate students and postdocs in the mathematical sciences.  The research activities are organized around five topics that play a fundamental role in emerging<br/>technologies: multifunctional materials, polymers and composites including carbon nanotubes, orthopaedic biomaterials, dynamics of thin material layers, and material behavior of laser welding.  The training component involves a coordinated set of activities designed to prepare students and postdocs for the varied roles of interdisciplinary research mathematicians.<br/>This includes training modules that introduce participants to research and career topics not covered in traditional coursework, new courses pertaining to the five research topics and areas of national need, and participation in summer internships and national conferences spanning multiple disciplines.  The objective of the program is to attract and train highly qualified students and postdocs for academic and nonacademic careers at the interface between applied mathematics, materials science, engineering, physics, and advanced technology.<br/>"
"0731503","Fast Simulation of Wave Scattering and Propagation in Inhomogeneous Media with Complex Geometries","DMS","COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY","02/13/2007","08/07/2007","Shan Zhao","AL","University of Alabama Tuscaloosa","Standard Grant","Junping Wang","08/31/2010","$58,263.00","","szhao@ua.edu","301 ROSE ADMIN BLDG","TUSCALOOSA","AL","354870001","2053485152","MPS","1271, 7334","0000, 9263, OTHR","$0.00","The goal of the proposed project is to develop innovative numerical approaches to produce fourth order accurate simulation of electromagnetic waves in inhomogeneous media with complex geometries, by using only simple Cartesian grids. The rapid growth of computer capability in the past few decades not withstanding, our ability to model three-dimensional wave propagation and scattering involving geometrically complicated dielectric interfaces is severely limited. Mathematically, the wave solutions are usually non-smooth or even discontinuous across the material interfaces, so that our effort in designing efficient algorithms is easily foiled, unless the complex interfaces are properly treated. The complex interfaces and geometries are commonly tackled by using body-fitted grids in the literature. Even though considerable progress has been made in grid generation, the formation of a good quality body-fitted grid system in geometrically complex domain remains a difficult and time-consuming task. Alternatively, in this project, the investigator will explore how to accommodate dielectric interfaces with complex geometries by using Cartesian grids including the staggered Yee grids. The resulting Cartesian grid methods, which in some sense fit the numerical differentiation operators to the complicated geometries, are less well studied in the literature, in contrast to the body-fitted grid methods. The development of high order Cartesian grid methods with complex interfaces being accurately treated, is of imminent practical importance to efficient wave simulations, but remains unsolved. In this project, innovative fourth order Cartesian grid approaches will be constructed based on the matched interface and boundary (MIB) method newly developed by the investigator and his collaborators for solving partial differential equations (PDEs) involving material interfaces or inhomogeneous media. To address a widespread variety of electromagnetic applications, a complete set of fourth order MIB methods will be developed for different electromagnetic formulations including the Helmholtz equation, the wave equation, and Maxwell's equations, and for different scenarios including the transverse magnetic mode, the transverse electric mode, and fully three-dimensional mode. <br/><br/>Computational electromagnetics (CEM), an interdisciplinary field where one witnesses mutual contributions from mathematicians and engineers is of paramount importance for a wide range of applications, including analysis and synthesis of antenna, calculation of radar cross section (RCS), simulation of ground or surface penetrating radar, to name only a few. The proposed numerical approaches aim to address challenging CEM applications involving large-scale and irregularly shaped structures, for which currently existing methods encounter great difficulties. By delivering more accurate and efficient wave simulations, the proposed methods will lead to breakthroughs in resolving long-standing problems in the real CEM applications. Moreover, the proposed methods will have considerable impact on other challenging interface problems in scientific computing, such as the immersed interface and moving interface problems in fluid dynamics, electrostatic interface problems for structural prediction of large biomolecules in computational biology.<br/><br/><br/>"
"0645266","CAREER: Computing Information in Image Processing and Stochastic Differential Equations","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/01/2007","02/27/2007","Hao-Min Zhou","GA","Georgia Tech Research Corporation","Standard Grant","Leland Jameson","06/30/2013","$401,824.00","","hmzhou@math.gatech.edu","926 DALNEY ST NW","ATLANTA","GA","30332","4048944819","MPS","1266, 1271","0000, 1045, OTHR","$0.00","The goal of this research is to develop new methodologies and their mathematical theory for problems in two areas: digital image processing, and stochastically perturbed differential equations in physical and engineering systems. The common theme is computing and extracting desired information embedded or hidden in the problems and use it in the applications. In image processing, the investigator and his colleagues develop a novel multi-channel image denoising strategy based on cross channel information. Several high level mathematical tools including geometrical partial differential equations (PDE's), multiresolution harmonic analysis and calculus of variation are integrated together with some statistical methods and computer vision theory such as color spaces to remove noise from images while retaining salient geometrical features such as edges and corners. The investigator and collaborators also study a rigorous error analysis theory for wavelet based PDE techniques in image processing. In stochastic differential equations, the investigator and colleagues analyze the phase noise and time jitter for electric oscillators including an Analog Digital Conversion (ADC) model. The key is to use a moving coordinate system based on a vector bundle theory to completely decompose the phase noise and amplitude noise, and then study the associated Fokker-Planck equations which separate the deterministic statistical properties such as mean and variance from the randomness. A novel numerical method based on the Fokker-Planck equations is designed to compute Shannon's entropy which can be used to evaluate the performance of the oscillators.<br/><br/>Computing information has become one of the fastest growing aspects in many areas of science and technology. For instance, digital image processing analyzes and extracts useful information from digital images. Many images, including satellite, radar or sonar images and medical images, are polluted by noise from the environments like air, water, lighting conditions and dust on lens when they are acquired, or damaged during transmission processes such as wireless communications. Image denoising, which removes the noise, becomes one of the most important tasks in applications. A key objective in this research is to design new strategies removing noise in images while restoring important and useful information such as edges and shapes, which are often hard to be separated from the noise. Stochastic differential equations are commonly used to describe complicated physical or engineering systems with uncertainties. Examples include composite materials, turbulence, circuit design and optics. For instance, electric oscillators are the key circuits used in many electric devices such as antennas, and are often modeled by systems of stochastic differential equations. Phase noise, which causes channel interference in wireless communications, is one of the most important factors for designing oscillators. One objective of this study is to develop mathematical theory and methods to analyze and compute useful statistical information from random processes in oscillators so that they can be used in designing or evaluating the performance of oscillators. In addition, another major objective is to integrate the research activities with education and training of undergraduate, graduate students and postdocs through seminars and courses.<br/>"
"0713830","Geometric methods for the symbolic integration of differential equations","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","08/24/2007","Ian Anderson","UT","Utah State University","Standard Grant","Junping Wang","08/31/2011","$184,581.00","Mark Fels","ian.anderson@usu.edu","1000 OLD MAIN HILL","LOGAN","UT","843221000","4357971226","MPS","1271","0000, 9263, OTHR","$0.00","The principle objective of this  proposal is to develop new methods for the exact solution of  ordinary and partial differential equations. The research topics contained in this proposal are motivated by recent advances in symbolic methods and recent theoretical developments in the field of geometric analysis of differential equations.  The theoretical developments provide for a new,  unified, coherent approach to symmetry-based solution techniques. Advances in symbolic methods for symmetry computations and in the implementation of symbolic software for computations  in differential geometry and Lie theory provide the computational environment for testing the practical utility of these theoretical constructions.  The proposed research activities balance mathematical formalism and rigor with a desire to create effective and efficient new algorithms for solving differential equations which build upon and complement existing solution methodologies.<br/><br/>Almost all  processes in the physical sciences and engineering are modeled by differential equations of one kind or another.  By studying these differential  equations and their solution, one gains understanding of  how these processes evolve.   Mathematicians use analytical, numerical, geometric and algebraic methods to study differential equations. This proposal deals with geometric and algebraic methods since these methods are best suited for implementation in interactive computer algebra systems (CAS). This work will expand the number and kinds of equations which can be solved  by CAS.  A unique feature of this proposal is the investigators ability to quickly implement new theoretical advances and distribute them to a very broad clientel of  mathematicians, scientists and engineers. In addition, the computer software developed by the investigators is very useful for training  advanced undergraduate and graduate students in important topics  in geometry and algebra.<br/>"
"0715021","Modeling Fluid Dynamics and Solute Transport in the Kidney","DMS","COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY","08/15/2007","08/10/2007","Anita Layton","NC","Duke University","Standard Grant","Mary Ann Horn","07/31/2012","$274,231.00","","alayton@math.duke.edu","2200 W MAIN ST","DURHAM","NC","277054640","9196843030","MPS","1271, 7334","0000, 9263, OTHR","$0.00","The overall goal of this project is to use analysis and computational mathematics to gain a better understanding of the effects of the complex fluid dynamics, frequently exhibited by renal tubular flows, on renal transport of water and solutes. Using the immersed boundary approach, mathematical models will be built to represent the fluid dynamics around the proximal tubule brush border microvilli, and to represent the tubular flow in a papillary collecting duct undergoing peristaltic contractions.  The resulting models will be used to study the effects of the two-way fluid-structure interactions on solute and water transport along the proximal tubule and along the collecting duct. Additionally, nonlinear optimization techniques will be used to further the physiological investigation of cellular homeostasis, by assessing the effectiveness of various regulatory mechanisms in homeostatic recovery.<br/><br/>If one is stranded in the ocean for days, should one drink the sea water to quench one's thirst? The answer depends on whether the subject is a person (don't!) or a rat (no problem, drink away!). The reason is that the osmolality (i.e., total solute concentration) of sea water is higher than the maximum urine osmolality that can be produced by a human. In contrast, a little rat can produce a urine twice as concentrated as sea water. It may be hard to believe, but the mechanism by which some mammals produce highly concentrated urine is not well understood. This project will use mathematical analysis and computational techniques to answer a number of basic and important questions in renal physiology: How do the peristaltic contractions of the renal papilla impact the concentrating mechanism of the kidney? How do the brush border microvilli, which are found along portions of the nephrons (little tubules in the kidney), affect solute transport in the kidney? What are the most effective ways for kidney cells to change aspects of its transport properties in order to survive in its ever-changing surroundings? The answers to those questions are crucial in an overall understanding of renal physiology, renal pathophysiology, and other autoregulatory mechanisms."
"0715713","International Workshop on Computational Methods in Geosciences","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","08/17/2007","Xiaobing Feng","TN","University of Tennessee Knoxville","Standard Grant","Leland Jameson","08/31/2008","$24,000.00","","xfeng@utk.edu","201 ANDY HOLT TOWER","KNOXVILLE","TN","379960001","8659743466","MPS","1271","0000, 7556, 9150, OTHR","$0.00","Computational methods, in particular, those for partial<br/>differential equations, have experienced major developments over the past<br/>thirty years in both algorithmic advances and applications to other fields.<br/>Computational simulation of physical phenomena has now fully joined<br/>engineering experimentation and theoretical/analytical<br/>analysis as the third method of scientific investigation.<br/>As the application problems become ever complicate and challenging,<br/>it becomes more and more difficult or even impossible to solve<br/>these problems by isolated individuals. The magnitude and complexity<br/>of the problems often require various expertise (such as field data<br/>acquisition, modeling, mathematical analysis, computational methods,<br/>computer programming and visualization, and data analysis), hence,<br/>their solutions require persistent collective effort of international<br/>scientific communities of various disciplines. Also, because face to<br/>face interaction is important to effective exchange of ideas and<br/>collaborations, it is vital to bring together researchers with similar<br/>research interests to  conferences of various scales.<br/>To meet the need and to facilitate such an interaction,<br/>the principal investigator (PI), together with colleagues from U.S., China,<br/>and Korea, will organize the ``International Workshop on Computational<br/>Methods in Geosciences"", which will be held from July 5-7, 2007<br/>at Xi'an Jiaotong University, China. The requested funding will be<br/>used to support U.S. researchers, in particular, graduate students<br/>and postdocs, to attend the workshop.<br/><br/>The anticipated international workshop is expected to contribute<br/>to promoting, enhancing, and stimulating the cross-continental<br/>research interactions and collaborations in mathematical sciences.<br/>Such community-wise research activities often<br/>serve the purpose of enhancing and promoting collaborations<br/>between U.S. and international researchers in mathematical<br/>and applied sciences, which in turn contributes critically<br/>to the course of solving challenging scientific problems<br/>such as flow and transport in porous media, weather prediction,<br/>nano-materials design, genome sequencing and analysis.<br/>In addition, organizing such a workshop in China will<br/>bring prominent researchers from U.S. and Europe working in such<br/>an active scientific research area to Asia, consequently, the anticipated<br/>workshop will do a good service to and have a positive impact on<br/>the international applied and computational mathematics community.<br/>"
"0650445","Multi-Scale Modeling and Simulation in Materials Science","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","06/24/2008","Timothy Schulze","TN","University of Tennessee Knoxville","Standard Grant","Junping Wang","08/31/2008","$15,000.00","Vasilios Alexiades, Xiaobing Feng","schulze@math.utk.edu","201 ANDY HOLT TOWER","KNOXVILLE","TN","379960001","8659743466","MPS","1271","0000, 7556, 9150, 9263, OTHR","$0.00","The 2007 Barrett Memorial Lectures: Multiscale<br/>Modeling and Simulation in Materials Science will<br/>bring together ten distinguished speakers, three of<br/>whom will give a series of three lectures on some<br/>aspect of the conference theme. The aim of the <br/>conference is to explore modeling and simulation of<br/>materials over a range of length scales from atomistic<br/>to continuum, as well as methods that seek to <br/>combine techniques that normally apply on different length<br/>scales. Topics are to include: the quasicontinuum method,<br/>the heterogeneous multiscale method and heteroepitaxial<br/>growth. In addition, there will be an opportunity for junior<br/>researchers to present their work in poster format.<br/>The requested funds are to support the travel of these<br/>junior participants. <br/> <br/>The 2007 Barrett Memorial Lectures: Multiscale<br/>Modeling and Simulation in Materials Science will<br/>bring together ten distinguished speakers, three of<br/>whom will give a series of three lectures on some<br/>aspect of the conference theme. The aim of the <br/>conference is to explore modeling and simulation of<br/>materials over a large range of length scales, including<br/>the nanoscale, as well as methods that seek to <br/>combine techniques that normally apply on different length<br/>scales. The meeting will be highly interdisciplinary<br/>in nature, drawing an audience from universities in<br/>the Southeast as well as Oak Ridge National Laboratory.<br/>In addition, there will be an opportunity for junior<br/>researchers to present their work in poster format.<br/>The requested funds are to support the travel of these<br/>junior participants. <br/>"
"0710831","Numerical Methods and Algorithms for Second Order Fully Nonlinear Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","07/15/2007","07/10/2007","Xiaobing Feng","TN","University of Tennessee Knoxville","Standard Grant","Junping Wang","06/30/2011","$227,909.00","","xfeng@utk.edu","201 ANDY HOLT TOWER","KNOXVILLE","TN","379960001","8659743466","MPS","1271","0000, 9150, 9263, OTHR","$0.00","Second order fully nonlinear partial differential equations (PDEs) arise from many areas in science and engineering such as differential geometry, optimal control, mass transportation, materials science, meteorology, geostrophic fluid dynamics. They constitute the most difficult class of differential equations to analyze analytically and to approximate numerically. In the past two decades, enormous advances in the theoretical analysis has been achieved, based on the viscosity solution theory, for second order fully nonlinear PDEs. On the other hand, in contrast to the success of the PDE analysis, numerical solutions for general second order fully nonlinear PDEs is mostly an untouched area, and computing viscosity solutions of second order fully nonlinear PDEs has been impracticable. In this research project, the PI plans to conduct an extensive and systematic study of numerical methods and algorithms for second order fully nonlinear PDEs based on a newly developed moment solution concept and a constructive vanishing moment methodology. The specific tasks of the project include (i) to continue developing the moment solution theory for Monge-Ampere type PDEs and for general second order fully nonlinear elliptic and parabolic PDEs in two and three dimensions; (ii) to develop finite element, mixed finite element, discontinuous Galerkin, and spectral Galerkin discretization methods; (iii) to analyze convergence and rates of convergence for all proposed discretization methods; (iv) to design preconditioned Newton type nonlinear solvers; (v) to develop computer code based on Comsol Multiphysics platform for implementing the proposed discretization methods and solution algorithms on high performance workstations.<br/><br/>The completion of the proposed project will have a profound impact on both theoretical study and numerical approximations of second order fully nonlinear PDEs. It will provide the first practical and successful methodology/approach, which is backed by rigorous PDE and numerical theories, for approximating second order fully nonlinear PDEs. As a by-product, the moment solution theory will enrich the current understanding of the viscosity solution theory, and might be very likely to provide a logical and natural generalization/extension for the viscosity solution concept. The findings of the proposed research will provide the much needed capability and enabling tools for computing correctly and efficiently those challenging fully nonlinear PDEs from differential geometry, general relativity, fluid mechanics, materials science, optimal control, mass transportation, meteorology, image processing, especially, in the cases where there are no theories. The educational component of this project is to engage and train graduate students in developing necessary applied and computational mathematics knowledge and skills so that they can pursue a successful career in science and engineering in the future.<br/>"
"0704216","Applications of frames to speech recognition, distributed processing, bio-medical engineering and more","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, SIGNAL PROCESSING SYS PROGRAM","07/01/2007","11/16/2009","Peter Casazza","MO","University of Missouri-Columbia","Continuing Grant","Michael Steuerwalt","06/30/2011","$350,386.00","","casazzap@missouri.edu","121 UNIVERSITY HALL","COLUMBIA","MO","652113020","5738827560","MPS","1266, 1271, 4720","0000, 9263, OTHR","$0.00","Casazza<br/>DMS-0704216<br/><br/>     The investigator and his colleagues work on designing<br/>Hilbert space frames for applications. This involves working<br/>directly with the groups needing such frames such as Siemens<br/>Corporate Research, the Bio-Medical Engineering Center at<br/>Carnegie Mellon University, and the Digital Signal Processing<br/>Center in the Electrical Engineering department at Rice<br/>University. One project involves designing frames and algorithms<br/>for doing signal reconstruction without phase. This project is<br/>designed to remove certain background noises from a signal so<br/>that the voice signals are clearer. Another project involves<br/>answering the question: What is the role and what can imaging do<br/>for systems biology?  The goal is to have distributed yet<br/>integrated large bioimage databases that would allow researchers<br/>to upload their data, have it processed, share the data, download<br/>data as well as having platform-optimized code, all in a common<br/>format. A third project involves doing signal reconstruction with<br/>erasures.  The investigator has designed a system that accounts<br/>for erasures without any extra coefficient calculations, which is<br/>both fast and accurate.  This method needs to be custom designed<br/>for the myriad of applications where there are transmission<br/>losses or erasures.  Another project involves designing ""fusion<br/>frames"" for problems in distributed processing.  This requires<br/>designing localized frames that globally fuse data both quickly<br/>and accurately -- especially in the face of losses. These are<br/>used for a variety of problems including sensor networks. <br/>Another project is geared to finding equal-norm equi-angular<br/>Parseval frames and mutually unbiased bases. These frames are<br/>used in quantum state tomography, quantum cryptography and<br/>foundational issues in quantum mechanics.<br/><br/>     The signal reconstruction project is designed to clean up<br/>certain types of audio signals that have noise embedded in their<br/>phase to present a clearer signal.  Another project involves<br/>sensors that are used to observe the world around us.  The amount<br/>of sensed data that is currently being collected is more than can<br/>be collected in one place for analysis.  The investigator and his<br/>colleagues are designing intelligent ways to reduce the amount of<br/>raw data that is analyzed, and this necessitates understanding<br/>the nature and role of the redundancy in the measurements. <br/>Making mathematical contributions to our fundamental<br/>understanding of redundant information could advance the<br/>engineering solutions to problems in environmental monitoring<br/>(including agricultural technology), military surveillance,<br/>understanding the operation of sensory neural systems, and<br/>improving general data collection methods that efficiently turn<br/>the analog events in the natural world into digital signals ready<br/>for analysis. Bioimaging has a serious need for accurate<br/>classification, some of which involves life and death decisions<br/>and are currently very sensitive to misclassification (such as<br/>false negative decisions in detecting cancer).  The goal here is<br/>to design systems that are able to classify with close-to-perfect<br/>accuracy.<br/>"
"0713256","A Computational study of the spray characteristics of a liquid jet atomized by cross-flowing air","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","05/11/2007","Mark Sussman","FL","Florida State University","Standard Grant","Leland Jameson","08/31/2011","$322,377.00","","sussman@math.fsu.edu","874 TRADITIONS WAY","TALLAHASSEE","FL","323060001","8506445260","MPS","1271","0000, 9263, OTHR","$0.00","It is proposed to develop new numerical algorithms and mathematical models <br/>predicting the breakup of liquid into droplets due to cross-flowing air <br/>and the resulting gas-liquid mixture that follows.   New numerical methods <br/>are proposed which exploit large-aspect ratio computational elements.  The <br/>investigator together with two graduate students, shall develop new algorithms <br/>for including the capability for large aspect ratio elements, as a part of <br/>a dynamic block-structured adaptive mesh method.   The study of large aspect <br/>ratio elements as a part of an adaptive, unstructured grid framework has <br/>received significant attention recently (albeit, not in the context of <br/>two-phase flows, as we propose to study).   In contrast, the study of <br/>moving mesh methods with large aspect ratio elements, as a part of a block <br/>structured adaptive framework, has received very little attention.  An <br/>algorithm based on block structured adaptive mesh refinement affords one <br/>the advantage of easy scalability in regard to parallel computing, adoption <br/>of multigrid methodology and implementation of temporal sub-cycling <br/>techniques.  Numerical analysis issues regarding stability and convergence <br/>of a numerical method when applied on a moving mesh, block structured <br/>adaptive grid, shall be investigated.  Also, algorithms defining the motion <br/>of the moving mesh shall be investigated.   It is important that the level <br/>of skewness for the moving mesh can be controlled.  Research developed in <br/>this proposal can be applied to mathematical problems that exhibit moving <br/>boundary layers, shock waves, ignition fronts, or sharp interfaces.   <br/><br/>This proposal is concerned with the development of orders of magnitude faster <br/>(100 times faster) numerical tools for the simulation of multiphase flow <br/>problems as applicable to science and industry.  These numerical tools shall <br/>be specifically formulated for high-density ratio, high-shear flows at an <br/>acceptable computational cost for engineering analysis of practical problems.  <br/>One immediate application of the proposed research is a jet-propulsion system <br/>in which fuel injected as a liquid is atomized into spray by interaction with <br/>a gas phase.  Another application is the prediction of momentum and energy <br/>transfer in the ocean due to hurricane force winds.  In order to predict <br/>momentum and energy transfer at the sea surface, one must take into account <br/>the sea spray generated by the high speed winds.  The ultimate benefits <br/>to society are reduced pollution, increased engine efficiency, and improved <br/>hurricane predictive capability due to a more accurate sea-spray <br/>parameterization.  This proposal is motivated by interactions between the <br/>PI and industry (e.g. UTRC).  Success of this proposal will not only have a <br/>direct impact on industrial applications relevant to atomization type <br/>processes, but also a direct impact on any industrial/scientific application <br/>of multiphase flow (e.g. navy ship hydrodynamics, microfluidic applications <br/>for testing human serum, biological fluid flows, nuclear reactor cooling <br/>systems, and underwater explosions).  The PI has ongoing collaborations with <br/>SAIC (ship hydrodynamics), Department of Applied Chemistry at the Muroran <br/>Institute of Technology (non-newtonian multiphase flows in chemical processing <br/>applications), the Center for Bio-Imaging and Modeling at Rutgers University <br/>(CBIM, visualization and animation of multiphase flows), for which all of <br/>these collaborations benefit from the proposed research on simulating <br/>multiphase flows.  The proposed research involves the participation of <br/>graduate students; graduate students shall be trained on issues which are <br/>timely and to which they have access to experts in the field.    <br/>"
"0713718","A 3D implicit immersed boundary method with application","DMS","COMPUTATIONAL MATHEMATICS","07/01/2007","06/22/2007","Luoding Zhu","IN","Indiana University","Standard Grant","Leland Jameson","12/31/2010","$193,484.00","","luozhu@iupui.edu","107 S INDIANA AVE","BLOOMINGTON","IN","474057000","3172783473","MPS","1271","0000, OTHR","$0.00","The investigator studies a 3D implicit immersed boundary (IB) method and its parallel implementation with applications.  The IB method has been widely used to simulate problems involving interactions of an elastic structure and an incompressible viscous fluid.  Because of the attractive relative simplicity of an explicit IB method numerous explicit versions of the method have been used in practice.  However, an explicit IB method has a drawback: the time-step size must be small to maintain numerical stability of the immersed solid boundary which is not economical in computational cost, especially for three dimensional problems.  The investigator develops a 3D implicit IB method by implementing an implicit scheme for computing forces imparted by the immersed boundary to the fluid and for updating the solid boundary configuration.  Because the mixed Lagrangian and Eulerian descriptions of the fundamental variables and their complicated interconnections, a highly nonlinear algebraic system of equations has to be solved for each time step to advance the solution.  In order to reduce the complexity of the 3D implicit IB method and to facilitate its parallel implementation, the lattice Boltzmann method (the D3Q19 model) is used to solve the incompressible viscous Navier-Stokes equations. In addition, The investigator studies an efficient preconditioner based on inherent properties of the problem for expediting the solution of the nonlinear algebraic system  of equations.  The investigator applies the new implicit IB method to investigate the drag reduction process associated with a flexible sheet of finite thickness immersed in a flowing viscous fluid. The objective is to develop scaling laws for drag with respect to oncoming flow speed, Reynolds number, dimensionless bending modulus and dimensionless mass density.  More advanced applications include modeling and simulation of the primary cilia and the endothelial surface layer interacting with viscous moving fluids.<br/><br/>Nature is very rich in problems involving interactions of a flexible body and a fluid (e.g., a flapping flag in the air).  Such interactions underlie a wide range of phenomena in science and engineering which are very complicated and not yet well understood.  The investigator studies a numerical method for investigating the fluid-flexible-body-interaction through large-scale scientific computing using modern supercomputers.  The method is applicable to many important problems in science and biomedical engineering. One immediate application is study of drag reduction induced by body flexibility.  The major energy expense for underwater propulsion is used for overcoming the resistance (drag) of ambient fluid. One aim of a hydrodynamic design is to reduce the drag experienced by an immersed body (e.g. a vehicle).  Reduced drag means improved propulsion efficiency and lowered energy cost.  The investigator's study may inspire genesis and development of novel designs of underwater propelling technologies with improved efficiency and increased speed.  More sophisticated applications include modeling and simulations of the primary cilia of the epithelial cells interacting with the moving viscous fluid in the kidney tubules, which is related to the polycystic kidney disease, and studying the genesis of atherosclerosis (leading cause of heart attacks and stokes) in which blood flow with transport and reacting constituents interacting with a compliant vessel wall covered by an endothelial surface layer.<br/>Such applications may lead to greater understandings of the polycystic kidney disease and the atherosclerosis.<br/>"
"0715127","Robust Numerical Methods in Polynomial Algebra with Approximate Data","DMS","COMPUTATIONAL MATHEMATICS","08/01/2007","07/24/2007","Zhonggang Zeng","IL","Northeastern Illinois University","Standard Grant","Junping Wang","01/31/2012","$125,000.00","","Z-Zeng@neiu.edu","5500 N SAINT LOUIS AVE","CHICAGO","IL","606254625","7734424671","MPS","1271","0000, 9263, OTHR","$0.00","This project aims at continuing development of reliable, accurate and <br/>efficient numerical algorithms for approximate polynomial algebra, <br/>along with implementations for expanding the capacity of a software <br/>toolbox ApaTools.  In addition to those robust algorithms/software <br/>developed under previous NSF support, The PI proposes to design and <br/>implement algorithms for three fundamental algebraic problems:  <br/>the approximate irreducible factorization of multivariate polynomials,<br/>identification of the multiplicity structure, and numerical <br/>elimination in solving polynomial systems. <br/><br/>This research is to be carried out in the intersection of computer <br/>algebra and numerical analysis with an outcome consists of algorithms <br/>and software packages for solving mathematical problems.  The results <br/>of this project are expected to supply critical tools for application <br/>areas such as robotics, molecular conformation, chemical equilibrium, <br/>automatic control, and other branches of mathematics such as algebraic <br/>geometry."
"0709046","Highly effective representations for surface and solid spherical studies","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/15/2007","04/13/2009","Pencho Petrushev","SC","University South Carolina Research Foundation","Continuing Grant","Henry Warchall","09/30/2010","$143,907.00","","pencho@math.sc.edu","915 BULL ST","COLUMBIA","SC","292084009","8037777093","MPS","1266, 1271","0000, 9150, 9263, OTHR","$0.00","Various practical applications require effective representation of functions on the sphere or on the ball. Examples include the gravitational field modeling, geomagnetism, helioseismology, astronomy, cosmology, and seismology. In most applications the functions on the sphere have been traditionally represented in terms of spherical harmonics. The nature of spherical harmonics as global functions, however, creates problems. The spherical harmonic representations rely on delicate cancellation/interference of spherical harmonics and are slowly convergent. The existing representations on the ball using orthogonal polynomials or other methods have the same drawbacks or are even worse. The primary objective of this project is to develop innovative multiscale data representations on the sphere and on the ball based on newly created wavelet type systems, called ""needlets"". The needlet system on the sphere consists of almost exponentially localized radial band-limited functions, which are automatically extendable to harmonic functions in the exterior of the sphere and thereby enabling needlet representations to provide a highly effective framework for representation and analysis of harmonic functions such as the gravitational potential. The needlet compatibility with spherical harmonics permits for fast conversions between needlet and spherical harmonic representations. This makes them easy to integrate into the existing models based on spherical harmonics. Furthermore, the superb localization of needlets at fine scales makes needlet-based models highly amenable to efficient local updates, which is a significant advantage over traditional models based on spherical harmonics. The needlet system on the ball has a similar structure and consists of almost exponentially localized algebraic polynomials. Theoretical results show that the new representations are superior to the existing mono- and multiscale methods used in these areas. An important element of the proposed research is the employment of nonlinear approximation methods for effective representation and approximation of functions from needlets. These are multilevel techniques which allow control of the uniform (or other) norm of the error of approximation. Another step forward will be the development of anisotropic elements on the sphere and ball (e.g. curvlets) for better extraction of curvlinear features of the data.<br/><br/>The targeted applications of this research are mainly in the domain of geodesy. Most geodetic applications rely on the ability to compute accurately the gravitational (disturbing) potential. This project will pursue the implementation of multiscale needlet representations for modeling of the gravitational potential. Other potential applications of the new representations are in geomagnetism, helioseismology, astronomy, cosmology, seismology, where spherical harmonic representations are widely used. An important goal of this project is to promote the broad utilization of the new representations in other diverse disciplines (from geophysics to high-speed videoendoscopy) and to stimulate interest in younger mathematicians to this area. This research project offers an excellent opportunity for graduate and undergraduate students at the University of South Carolina to participate in testing ideas for further development."
"0713763","Discontinuous Immersed Finite Element Methods for Interface Problems","DMS","COMPUTATIONAL MATHEMATICS","07/15/2007","07/10/2007","Tao Lin","VA","Virginia Polytechnic Institute and State University","Standard Grant","Junping Wang","06/30/2011","$153,000.00","Slimane Adjerid","tlin@math.vt.edu","300 TURNER ST NW","BLACKSBURG","VA","240603359","5402315281","MPS","1271","0000, 9263, OTHR","$0.00","Immersed finite element (IFE) methods have been developed to solve problems with discontinuous coefficients and they are very competitive because of two essential features: (1) they allow structured meshes and avoid mesh distortion associated with Lagrangian and interface-tracking methods; (2) their basis functions incorporate the interface jump conditions imposed by physics. The objectives of this project are to combine IFE methods with the versatile discontinuous Galerkin (DG) finite element methods to efficiently and accurately capture solution discontinuities, simplify h and h-p adaptivity, and yield efficient parallel methods for interface problems arising from modeling multi-scale and multi-physics procedures in engineering and sciences. The PIs of this project plan to construct and analyze DG methods with IFE spaces that attain optimal or near optimal convergence rates under h and h-p refinement on meshes not necessarily aligned with interfaces. The PIs plan to focus on three representative types of boundary value problems with discontinuous coefficients in two and three dimensions:  (i) Second-order elliptic problems, (ii) Linear elasticity systems and fourth-order equations for beams and plates, (iii) Maxwell's equations. The PIs will investigate problems with linear and curved interfaces on meshes consisting of triangles and quadrilaterals in two dimensions, tetrahedrons and hexahedrons in three dimensions. The PIs will perform error analysis and investigate the convergence of the IFE solution to the true solution under h, p and h-p refinement.  The PIs will also investigate superconvergence properties of discontinuous IFE solutions and use these results to construct efficient and reliable a-posteriori IFE error estimators for assessing solution quality and guiding adaptivity.<br/><br/>Simulating a multi-scale/multi-physics phenomenon often involves a domain consisting of different materials and leads to an interface problem consisting of partial differential equations with discontinuous coefficients, boundary (and initial) conditions, and jump conditions required by pertinent physics across the material interfaces. It is well known that efficiently solving interface problems is critical for numerical simulations in many applications of engineering and sciences, including flow problems, electromagnetic problems, shape/topology optimization problems, to name just a few.  IFE methods are competitive methods for solving interface problems and the methods developed in the proposed research projects will have direct impacts on  numerical simulations in electric propulsion of plasma engine design/research,  optimal packaging of electronic devices, efficient and better image reconstruction in computer tomography, polymer matrix carbon fiber reinforced composites and related material technologies in aerospace and space structures, non-destructive/non-invasive detection of suspicious materials in security check, design of optimal shapes for lighter and stronger structures, and many other application areas of great federal interests.<br/>"
"0713799","Numerical Methods for Structured Polynomial Eigenvalue Problems","DMS","COMPUTATIONAL MATHEMATICS","07/15/2007","07/10/2007","Niloufer Mackey","MI","Western Michigan University","Standard Grant","Junping Wang","06/30/2010","$177,681.00","D. Steven Mackey","nil.mackey@wmich.edu","1903 W MICHIGAN AVE","KALAMAZOO","MI","490085200","2693878298","MPS","1271","0000, 9263, OTHR","$0.00","Polynomial eigenproblems are playing an increasingly important role in contemporary engineering design.  Indeed, the computation of resonant frequencies arising from extreme designs presents a real numerical challenge, as these designs can lead to very large eigenproblems with poor conditioning.  On the other hand the underlying physics of such problems often leads to algebraically structured polynomial eigenproblems, with concomitant symmetries in the spectrum and special properties of the corresponding subspaces. Existing algorithms, unfortunately, often ignore these structural properties.  The types of structured polynomial addressed in this project arise in a variety of applications: T-palindromic (analysis of rail noise from high-speed trains, SAW filters), *-palindromic (discrete-time optimal control), K-palindromic (differential delay equations), alternating (corner singularities, gyroscopic systems, continuous-time optimal control), and hyperbolic (overdamped mechanical systems).  Polynomial eigenproblems are usually solved by embedding the system into a larger linear system called a ``linearization''. Until recently, the palette of easily available linearizations has been very limited.  Recent work, though, has shown how to systematically construct a continuum of linearizations, from which structure-preserving linearizations and linearizations with nearly optimal conditioning can be chosen.  This project aims to further this growing body of work by developing algorithms that exploit these new theories, and in turn, develop new theory and insight for the next generation of algorithms in this critical area of scientific computation.<br/><br/>The problems studied in this proposal are ubiquitous in a wide range of important problems in engineering and applied sciences. Numerical methods for their solution are critical in structural mechanics, molecular dynamics, vibrational analysis, the simulation of electrical circuits, elastic deformation of anisotropic materials, and optical waveguide design, to give a few examples. The trend towards extreme designs, such as high speed trains, optoelectronic devices, micro-electromechanical systems, and ``superjumbo'' jets such as the Airbus 380, presents a challenge for the computation of the resonant frequencies of these structures.  These extreme designs often lead to computationally sensitive problems, while the physics of the underlying problem leads to algebraic structure that numerical methods should preserve in order to obtain physically meaningful results. The aim of this project is to increase our theoretical understanding of mathematical transformations that preserve these structures and thereby advance the development of computationally effective algorithms. Consequently, this work will have direct benefit to scientists and engineers across a wide range of disciplines.<br/>"
"0713125","New  Approaches in Solving Saddle Point Problems","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","06/17/2009","Constantin Bacuta","DE","University of Delaware","Standard Grant","Junping Wang","08/31/2010","$118,086.00","","bacuta@udel.edu","220 HULLIHEN HALL","NEWARK","DE","197160099","3028312136","MPS","1271","0000, 9150, 9178, 9251, 9263, OTHR","$0.00","This research project provides a plan for the development, analysis, and implementation of faster and more efficient computational methods for partial differential equations (PDEs), including second-order elliptic problems, Stokes and Navier-Stokes systems, elasticity problems, and Maxwell's equations.  PDEs have applications to many fields such as mathematics, physics, chemistry, biology, and engineering.  The new methods for solving Stokes and Navier-Stokes systems will contribute to modeling flow problems of increasing size and complexity, e.g., modeling the air flow near a plane or modeling the flow near immersible objects.  The new approach for Maxwell's equations has practical applications to photonics in computing modes for devices and in radar scattering.   <br/><br/>The research will focus on two areas: solving saddle-point problems and discretization on non-matching grids.  To build new and efficient algorithms, the PI will combine his new ideas on solving saddle-point problems with already known methods from distinctive fields of numerical analysis such as iterative methods, multilevel methods, and adaptive methods for elliptic PDEs.  The main technique will be based on the new spectral results for saddle-point systems found by the PI.  The proposed work for solving saddle-point systems has scientific and technical applications in optimization, optimal control, computational fluid dynamics, linear elasticity, electromagnetism, electrical networks, linear models in statistics, and image restoration.  A second area of research will be to investigate multilevel discretizations and multilevel preconditioning techniques in the context of discretizations on nonmatching grids based on the Partition of Unity method.  The applications are to modeling fluid and gas flow near complex objects and fluid flow in porous media.<br/>"
"0714159","Collaborative Research: Multiscale Aspects for Wave Propagation Inverse Problems","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","09/03/2008","Susan Minkoff","MD","University of Maryland Baltimore County","Standard Grant","Junping Wang","08/31/2012","$125,000.00","","sminkoff@utdallas.edu","1000 HILLTOP CIR","BALTIMORE","MD","212500001","4104553140","MPS","1271","0000, 9151, 9178, 9251, 9263, OTHR","$0.00","Many natural materials exhibit structural heterogeneity across a wide range of scales. Examples of such media with microstructure include virtually every part of the Earth's crust, and manufactured composite materials such as concrete. These materials also support wave motion, and various technologies have evolved which use propagating waves for nondestructive interogation of material structure. In their present state, these technologies (reflection seismology, ultrasonic nondestructive evaluation, etc) are for the most part based on theoretical understanding and computational methods developed for waves in homogeneous (or near-homogeneous) materials. This divide between theoretical basis and application context is bridged to some extent by effective medium theories which attempt to express at macroscopic scales the effect of microscopic heterogeneities. However rigorous justification of the effective medium approach is largely limited to periodic material models, which do not resemble disordered materials such as sedimentary rock. This study will attempt to leverage recent advances in the simulation of acoustic and elastic waves in media with microstructure to assess the feasibility of explaining simulated experimental data by means of simpler models without microstructure. These models may exhibit physical characteristics not present on the microscopic scale, for instance viscous loss or anisotropic response. Our approach combines various numerial simulation methods, including  numerical upscaling, for computing waves in highly heterogeneous models, with inversion or parameter estimation to determine macroscopic models. The proposed work will rely upon a previously developed computational framework for inversion.<br/><br/>For scientists to be able to produce oil and gas, to predict earthquakes and other tectonic events such as tsunamis, to safely remediate contaminants, and to bury excess greenhouse gases underground, they must first be able to image the earth's subsurface. Rock layers, fluids, and faults need to be mapped and their depths and lateral extent understood. To create an image of the subsurface, energy is sent into the ground which generates a wave. The heterogeneous nature of the subsurface causes a portion of these waves to be sent back to the surface where seismometers (microphones) record the waves as they pass. From these signals scientists try to infer the structure of the subsurface. This inference is enormously complicated by the very complex mechanical nature of rock, which is composed of microscopic grain particles in a porous lattice. The physical characteristics of these tiny constituents and the fluids within the pores combine in a complex and poorly understood way to yield the observable response of the Earth. In our previous work, we have<br/>devised methods to simulate propagation of waves through complex microscopically structured material, and also procedures to determine the macroscopic material descriptions from observable data. This proposal envisions the fusion of these two lines of work and could shed light on which aspects of subsurface structure can, or can't, be inferred from seismic recordings."
"0712796","Optimization of Density Functional Methods for Atomic Structure Calculations","DMS","COMPUTATIONAL MATHEMATICS, CONDENSED MATTER & MAT THEORY, MSPA-INTERDISCIPLINARY","07/01/2007","06/17/2009","David Luke","DE","University of Delaware","Standard Grant","Junping Wang","06/30/2010","$183,387.00","","rluke@math.udel.edu","220 HULLIHEN HALL","NEWARK","DE","197160099","3028312136","MPS","1271, 1765, 7454","0000, 7237, 7303, 9150, 9178, 9251, 9263, OTHR","$0.00","We address numerical challenges facing simulations of molecules built upon atomic-scale physics and chemistry.  Molecular structure calculations modeling large-scale molecular systems are of fundamental importance to quantum chemistry, physics, and materials science.  They are being used by collaborators with this project for the determination of charge density at  oxide surfaces, for atomic structure determination of nanoscale materials, for optimization of the performance of nanoscale materials in solid-oxide fuel cells, and for exploring ways to reduce chemical waste and improve the efficiency of catalysts.  Worldwide, these types of calculations are exhausting the limits of the world''s supercomputing capacity; any advancements in the numerical algorithms behind these calculations would have immediate impact by expanding our capabilities for simulating ever-larger molecular systems.  The mathematical challenges presented by these types of computational problems are at the frontiers of mathematical research; these challenges are dimensionality, nonlinearity, and model inconsistency.<br/><br/>We approach the problem from two directions.  In the first, we combine conventional techniques for solving large-scale optimization problems -- so-called limited memory techniques -- with a fresh look at ways to stabilize and accelerate the techniques by directly accounting for the presence of multiple scales as well as inconsistent approximations in the model.  This involves an investigation into the sensitivity of the local numerical model and the development of a mathematical safeguard against imperfect or incomplete information about the true state of the system.  Our second direction of approach to the problem is to divide the model into smaller, more computationally tractable pieces -- known as operator splitting.  Operator-splitting methods open the door to a wide range of algorithmic options that allow one to combine computations in novel ways that avoid problems common for more conventional approaches; principal among these is the phenomenon of stagnation at a bad ''local solution''.  New operator-splitting techniques developed by the PI for problems related to molecular structure determination and that share similar mathematical features have proven effective.  The theory behind these algorithms is still being developed by the PI and extends current theory to the important cases of so-called nonconvex and inconsistent problems that are ubiquitous in applications far beyond molecular structure calculations."
"0713732","Collaborative Research: Algorithms for Simulation and Design of Analog VLSI Lattices","DMS","COMPUTATIONAL MATHEMATICS, MATH PRIORITY SOLICITATION, MSPA-INTERDISCIPLINARY","09/01/2007","08/17/2007","Ehsan Afshari","NY","Cornell University","Standard Grant","Junping Wang","08/31/2010","$111,042.00","","afshari@umich.edu","341 PINE TREE RD","ITHACA","NY","148502820","6072555014","MPS","1271, 7446, 7454","0000, 7237, 7303, 9263, OTHR","$0.00","New technologies in areas such as wireless communication, portable computing, and handheld electronics have increased the demand for signal processing at high frequencies.  Part of the challenge in designing silicon integrated circuits that can meet this demand is to overcome limitations in the efficiency and frequency bandwidth of modern transistors.  Here it is proposed to use two-dimensional networks of inductors and capacitors to overcome these limitations.  These high-speed, high-efficiency networks have a cut-off frequency that is higher than that for silicon-based transistors.  Moreover, such networks can be incorporated into standard silicon chips that can be fabricated at low cost.  The proposed research has the potential to revolutionize high-frequency analog signal processing, leading to chips that operate up to 1000 times faster than current ones.<br/><br/>There are a large number of possible designs for such networks, and only a small number of these possibilities have already been explored.  The proposed research seeks to develop algorithms that greatly assist in the simulation and design of two-dimensional inductor-capacitor networks.  Simulating a large network involves the solution of a large, coupled system of equations that can be simplified greatly through mathematical analysis.  It is proposed to use this simplification to develop fast, scalable algorithms and codes for network simulation.  This would enable engineers to quickly learn the effect of changing one or more of the thousands of parameters in a typical large-scale inductor-capacitor network.<br/><br/>It is also proposed to use optimization methods to automatically design lattices that achieve prescribed input-output relationships.  The optimization work will use as a foundation the prior results of the proposers, including, for example, the development of a two-dimensional network that computes Fourier transforms in the analog domain.  Such physically motivated ideas will be coupled with modern tools of parallel numerical computing such as PetSC (the Portable Extensible Toolkit for Scientific Computation) and TAO (the Toolkit for Advanced Optimization).  This will result in fast, accurate tools that enable engineers to rapidly optimize the design of a lattice to achieve desired performance specifications.<br/><br/>The expertise gained in carrying out the proposed research will enable the investigators to train students and researchers to solve problems in modern computational science and engineering. The proposed research encourages multidisciplinary interaction between scientists, engineers, applied mathematicians, and computer scientists spanning the spectrum from developers to users of computational tools."
"0706941","Geometry and Topology of Singular Structures with Applications to Imaging","DMS","TOPOLOGY, COMPUTATIONAL MATHEMATICS","08/15/2007","08/14/2007","James Damon","NC","University of North Carolina at Chapel Hill","Standard Grant","Joanna Kania-Bartoszynska","07/31/2012","$105,075.00","","jndamon@math.unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275995023","9199663411","MPS","1267, 1271","0000, 9263, OTHR","$0.00","Professor Damon?s research will concern the geometry, topology and deformation properties of singular structures, including stratified sets, mappings, and nonisolated singularities, and the application of these results to develop geometric methods for problems in computer imaging. This includes applying methods from singularity theory to determine from an underlying ""skeletal/medial structure"" the local, relative and global geometric properties of a region in Euclidean space and its boundary. Second, he is developing, in joint work, a new method for finding intersection of spline surfaces for geometric modeling. Third, he is developing methods to characterize local features of objects in natural images which include lighting, geometric features, and viewer movement.<br/>Professor Damon will further develop his results on skeletal and medial structures to:<br/>understand the behavior of multiple medial structures in a collection of complementary regions or objects with geometric and physical interaction. This will allow the time evolution of such objects, and enlarge the class of allowable structures to include degeneracies. These ideas will be used for investigating statistical properties of geometrical features for shape. Second, Professor Damon will further develop methods for following the evolution of intersection curves under flows of spline surfaces and apply them to give a new method for computing the medial axis of regions with boundaries defined by splines. Third, he will apply his methods to complete, in joint research, the analysis of local features in natural images allowing shade/shadow and specularity, geometric features, and movement of either viewpoint or light source. He will further begin developing algorithms with imaging scientists for their implementation.<br/><br/>Professor Damon?s research will further investigate properties of spaces used to model objects and regions, and systems of equations which provide understanding of properties of geometric spaces and their representations. These methods will be applied to several problems in computer imaging. The first method will be used for modeling multiple objects and their interaction, including statistical properties of such collections. This method will allow for degeneracies of the structures, and these resulting models will be used for analyzing interaction of regions in medical images. These same methods will also be used for understanding the evolution of intersections of deforming objects with applications to geometric modeling. Third, he will analyze the properties of equations which can be used to model the images of objects in natural images, where lighting and viewpoint affect the appearance of geometric features of objects. These results will be used in joint work with computer scientists to develop procedures for identifying objects in images.<br/>"
"0645347","CAREER: Reduced-order Modeling and Controller Design for Large-scale Dynamical Systems via Rational Krylov Methods","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","05/01/2007","04/20/2007","Serkan Gugercin","VA","Virginia Polytechnic Institute and State University","Standard Grant","Henry Warchall","04/30/2013","$400,000.00","","gugercin@math.vt.edu","300 TURNER ST NW","BLACKSBURG","VA","240603359","5402315281","MPS","1266, 1271","0000, 1045, OTHR","$0.00","Proposal ID: 0645347<br/>PI:  Gugercin, Serkan<br/>Institution: Virginia Polytechnic Institute and State University<br/>Title: CAREER: Reduced-order Modeling and Controller Design for Large-scale Dynamical Systems via Rational Krylov Methods<br/><br/>Abstract<br/><br/>Direct numerical simulation of dynamical systems has been one of the few available means for achieving accurate prediction or control of complex physical phenomena that are of scientific interest or industrial value. The ever-increasing need for improved accuracy leads to very large-scale and complex dynamical systems. Simulations in such large-scale settings can overwhelm computational resources; this is the main motivation for model reduction. The goal is to produce a simpler reduced-order model approximating the original one as accurately as possible. The resulting reduced model can then be used as an efficient surrogate to the original, to replace it in a larger simulation or to develop a simpler and faster controller suitable for real time applications. Krylov-based methods have emerged as promising candidates for model reduction in realistic large-scale settings. This project seeks to develop optimal, robust, and systematic Krylov-based projection methods for efficient construction of high fidelity and optimal reduced-order models. By carefully employing inexact solves in a Krylov-based model reduction setting, the proposed research will extend these optimal reduction techniques to realistic settings with millions of degrees of freedom while maintaining the same quality of the error measures with respect to the exact rational Krylov subspaces. In addition, systematic approaches will be developed for the design of fast and effective, low-order optimal controllers, and more generally, for reduction of interconnected (coupled) systems. The project will apply the newly developed methods to several test problems drawn from different application areas.<br/><br/>Large-scale simulations and computations play a crucial role in studying a great variety of complex physical phenomena in many areas of computational science and engineering. Examples include signal propagation and interference in electric circuits, molecular dynamics, weather forecasting, wave propagation and vibration suppression in large structures, temperature control in various media, and behavior of micro-electro-mechanical systems. Computing in large-scale settings leads to unmanageably large demands on the nation's computational resources; hence there is a growing need to approximate the complex dynamical systems with simpler, high fidelity models that will make these simulations much easier and faster to compute. This project seeks to develop techniques that will yield optimal, high fidelity approximations of complex systems; leading at once to simulations that are more rapid yet still reliable. The mathematical tools and high-quality software that will be developed through the course of this project will contribute to research efforts of scientist and engineers working with large-scale, complex multi-physics problems. In addition to the research component, this project offers a comprehensive education plan that consists of the supervision of undergraduate and graduate students; development of a graduate course; and several interdisciplinary research projects available for introducing students in a variety of areas of high-performance scientific computing.<br/><br/>"
"0705910","Multiscale Sampling with Applications","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/01/2007","06/18/2009","Alexandre Chorin","CA","University of California-Berkeley","Continuing Grant","Junping Wang","08/31/2011","$443,929.00","","chorin@math.berkeley.edu","1608 4TH ST STE 201","BERKELEY","CA","947101749","5106433891","MPS","1266, 1271","0000, 9263, OTHR","$0.00","The gist of the proposal is the development of new Monte Carlo sampling methods, where the density to be sampled is preconditioned by a nested sequence of its marginals. The probability densities of the marginals are to be determined as the sampling proceeds, using an expansion in successive linkages similar to the one used in Kadanoff's real-space renormalization. Two implementations will be explored: in one the target density and a series of its marginals will be sampled in parallel, with occasional swaps among the several parallel computations, relying on the shorter correlation times of the marginals to accelerate convergence; in the other, a single sweep from the smallest to the largest subset with available marginals will be effected, with a correction step based on an assignment of weights; this last implementation will have exactly zero temporal correlation time. At this point it is not clear which of the two may be more efficient, though it is reasonable to assume that this depends on the application. The first application will be a computer study of the three-dimensional Anderson-Edwards near-neighbors spin glass model. The second application will be to filtering and data assimilation for stochastic partial differential equations. A more distant goal is the development of more efficient training techniques for neural networks.<br/><br/>In many problems of physics and of statistics it is necessary to sample complicated probability distributions with a very large number of variables. Current methods often fail because the successive samples they produce fail to be sufficiently independent. The present proposal suggests solving this problem by creating a sequence of successively simpler problems, in such a way that the sampling of each one makes it easier to sample the next harder one; the heart of the proposal is a methodology for making this procedure self-consistent. The first application of the idea, if it is successful, will be to the analysis of a spin glass model; this is a problem of great interest in material science, and as it is known to be very hard to sample, it is a good testing ground for the methods here. The next application will be to data assimilation; this problem arises when one tries to make predictions on the basis of a partial theory and noisy observations, as one often has to do in many fields, for example in weather forecasting or in economics; the difficulty in sampling large arrays of data is often a major roadblock in this type of situation. The spin glass model is closely related to models useful in neural networks and in neurology, and a more distant goal is to use the methods developed here in these exciting areas.<br/>"
"0652427","FRG: Collaborative Research: Dynamics of elastic biostructures in complex fluids","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY","07/01/2007","05/31/2007","Joseph Teran","CA","University of California-Los Angeles","Standard Grant","Tanya Kostova Vassilevska","06/30/2010","$103,416.00","","jmteran@ucdavis.edu","10889 WILSHIRE BLVD STE 700","LOS ANGELES","CA","900244201","3107940102","MPS","1266, 1271, 7334","0000, 1616, OTHR","$0.00","Problems in biological fluid dynamics typically involve the interaction of an elastic structure with a surrounding fluid. Mucus transport by cilia in the respiratory tract, sperm penetration of the oocyte in fertilization, and peristaltic contractions of the oviduct are examples of such interactions. Many biological fluids are actually complex; that is they are not liquids or mixtures of a simple molecular structure that yields Newtonian responses, but instead have complicated non-Newtonian mechanical responses that arise, usually, because they have suspended microstructure.  While much progress has been made in the development of mathematical models and numerical methods for fluid-structure interactions in a Newtonian fluid, much work needs to be done in the case of complex fluids. This focused research group will use a combination of analytical, computational and experimental tools to investigate the dynamics of elastic structures coupled to a complex fluid. Accurate and robust numerical methods for viscoelastic fluids coupled to moving and flexible  boundaries will be developed that build upon classical immersed boundary methods and particle methods previously designed for Newtonian fluids. Continuum descriptions of the viscoelastic fluid will be implemented, as well as models that track discrete viscoelastic microstructure of the fluid. While the methods developed will be widely applicable, the team will focus upon the biofluidmechanics of reproduction, nematode motility in microfluidic chambers, as well as mucus-ciliary transport. Computational models will be coordinated with physical and biological experiments performed at the Applied Mathematics Lab at the Courant Institute.<br/><br/>Mathematics has had a huge impact on engineering and the physical sciences through its development of theoretical analyses and numerical methods for Newtonian fluid flows.  The dynamics of complex fluids is emerging as another such opportunity, and is one which draws some of its richest problems from new areas in biophysics and engineering, medicine and reproductive health, and from core biology. The integration of mathematical and computational analysis into biological science presents educational challenges and great opportunities. This research project embraces these challenges, and is based upon collaborations of investigators at four institutions - Tulane University, New York University, Washington State University and the University of California, Los Angeles.  A central component of this project is the training of graduate students and postdoctoral researchers.  This FRG project will sponsor two summer programs, where the postdoctoral researchers and graduate students will spend six weeks at the Applied Mathematics Lab at Courant Institute. This will provide opportunities for all the students and postdocs involved in the project to work together side by side, develop a comprehensive understanding of the various aspects of the research, and experience and participate in the life of a working fluids lab."
"0707220","Iterative Methods for Nonlinear Equations and Optimization","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","08/01/2007","07/27/2007","Carl Kelley","NC","North Carolina State University","Standard Grant","Michael Steuerwalt","07/31/2011","$263,084.00","","tim_kelley@ncsu.edu","2601 WOLF VILLAGE WAY","RALEIGH","NC","27607","9195152444","MPS","1266, 1271","0000, 9263, OTHR","$0.00","Kelley<br/>0707220<br/><br/>     The principal investigator studies numerical methods for the<br/>solution of nonlinear equations and optimization problems with a<br/>focus on continuation methods, nonsmooth problems, and multilevel<br/>methods for integral equations. The main topics of the research<br/>are (1) the development and analysis of multilevel continuation<br/>algorithms for optimization problems with integral equation<br/>constraints and the application of those methods in simulating<br/>atomic and molecular fluids, (2) the design and analysis of<br/>continuation/quasi-Newton methods for nonsmooth nonlinear least<br/>squares, with applications to calibration of models of blood<br/>flow, (3) continued study of the conditioning of the linear<br/>systems and eigenproblems that arise when pseudo-arclength<br/>continuation is used in bifurcation analysis, and (4) multi-model<br/>methods in which one physical model, based on differential or<br/>integral equations, for example, is used as a preconditioner for<br/>a solver which is based on a more accurate, more expensive to<br/>evaluate model, such as a molecular dynamics or stochastic<br/>simulation.<br/><br/>     Nonlinear equations and optimization problems are commonly<br/>encountered in science and engineering.  Motivated by<br/>applications in chemistry and medicine, the principal<br/>investigator studies equations with multiple solutions, the<br/>challenge being to determine which of those solutions represents<br/>the real world and which cannot be seen in actual physical<br/>systems, and optimization problems for which standard methods and<br/>computer codes fail.  This work should lead to new approaches<br/>useful in many branches of science and engineering.<br/>"
"0652775","FRG: Collaborative Research: Dynamics of elastic biostructures in complex fluids","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY","07/01/2007","05/31/2007","Michael Shelley","NY","New York University","Standard Grant","Mary Ann Horn","06/30/2011","$503,288.00","Jun Zhang","shelley@cims.nyu.edu","70 WASHINGTON SQ S","NEW YORK","NY","100121019","2129982121","MPS","1266, 1271, 7334","0000, 1616, OTHR","$0.00","Problems in biological fluid dynamics typically involve the interaction of an elastic structure with a surrounding fluid. Mucus transport by cilia in the respiratory tract, sperm penetration of the oocyte in fertilization, and peristaltic contractions of the oviduct are examples of such interactions. Many biological fluids are actually complex; that is they are not liquids or mixtures of a simple molecular structure that yields Newtonian responses, but instead have complicated non-Newtonian mechanical responses that arise, usually, because they have suspended microstructure.  While much progress has been made in the development of mathematical models and numerical methods for fluid-structure interactions in a Newtonian fluid, much work needs to be done in the case of complex fluids. This focused research group will use a combination of analytical, computational and experimental tools to investigate the dynamics of elastic structures coupled to a complex fluid. Accurate and robust numerical methods for viscoelastic fluids coupled to moving and flexible  boundaries will be developed that build upon classical immersed boundary methods and particle methods previously designed for Newtonian fluids. Continuum descriptions of the viscoelastic fluid will be implemented, as well as models that track discrete viscoelastic microstructure of the fluid. While the methods developed will be widely applicable, the team will focus upon the biofluidmechanics of reproduction, nematode motility in microfluidic chambers, as well as mucus-ciliary transport. Computational models will be coordinated with physical and biological experiments performed at the Applied Mathematics Lab at the Courant Institute.<br/><br/>Mathematics has had a huge impact on engineering and the physical sciences through its development of theoretical analyses and numerical methods for Newtonian fluid flows.  The dynamics of complex fluids is emerging as another such opportunity, and is one which draws some of its richest problems from new areas in biophysics and engineering, medicine and reproductive health, and from core biology. The integration of mathematical and computational analysis into biological science presents educational challenges and great opportunities. This research project embraces these challenges, and is based upon collaborations of investigators at four institutions - Tulane University, New York University, Washington State University and the University of California, Los Angeles.  A central component of this project is the training of graduate students and postdoctoral researchers.  This FRG project will sponsor two summer programs, where the postdoctoral researchers and graduate students will spend six weeks at the Applied Mathematics Lab at Courant Institute. This will provide opportunities for all the students and postdocs involved in the project to work together side by side, develop a comprehensive understanding of the various aspects of the research, and experience and participate in the life of a working fluids lab."
"0715446","Cutting Planes and Surfaces, and Conic Programming","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","08/24/2007","John Mitchell","NY","Rensselaer Polytechnic Institute","Standard Grant","Leland Jameson","08/31/2011","$259,999.00","","mitchj@rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","MPS","1271","0000, 9263, OTHR","$0.00","Convex optimization problems arise in many practical areas.  They are vitally important in engineering, financial, medical, and scientific applications.  Development of more effective methods for large-scale convex optimization problems will enable the solution of more accurate and detailed models in these fields.  The power of convex optimization is beginning to be realized, with state-of-the-art techniques being exploited in real-world settings, and sophisticated models being developed to take advantage of the availability of these techniques.  Some specific areas of application are network utility maximization, development of novel medications, and optimization of financial<br/>portfolios.<br/><br/>The research in this proposal is aimed at developing good algorithms for certain classes of large-scale convex optimization problems.  Further, techniques will be developed for solving integer programming and certain nonconvex problems that have relaxations that are convex.  The methods of interest require constructing a convex relaxation of the original problem, finding a good solution to the relaxation, and then improving the relaxation if the solution to the relaxation is not a good enough solution to the original problem.  The scientific interest is in the method for selection of the candidate point and in the discovery of methods for improving the relaxation.  Taking place alongside the development of algorithms will be the development of models that can exploit the algorithms.  Relaxations that are conic optimization problems are of particular interest.  Candidate good points in such relaxations can be found efficiently using interior-point methods, and the relaxations can be updated through the addition of nonlinear conic constraints that accurately approximate the original model in the region of the candidate point."
"0714321","Nonsmooth, Nonconvex Optimization: Algorithms, Theory, and Applications","DMS","COMPUTATIONAL MATHEMATICS","08/01/2007","07/19/2007","Michael Overton","NY","New York University","Standard Grant","Junping Wang","07/31/2010","$495,846.00","","overton@cs.nyu.edu","70 WASHINGTON SQ S","NEW YORK","NY","100121019","2129982121","MPS","1271","0000, 9263, OTHR","$0.00","Optimization problems arise in every branch of science and engineering.  In these problems, typically one needs to choose parameters in order to minimize an objective such as energy or cost.  ""Nonsmooth"" means that the objective may not vary smoothly with the parameters, and ""nonconvex"" means that the problems may have multiple minimizers with different objective values, making them especially difficult to solve.<br/><br/>The project focuses on three aspects of these problems: algorithms, theory, and applications.  The intellectual merit of the proposed work concerns the details of all three aspects, which are all interrelated.  Algorithms are formal ways to specify computational methods.  We focus on two algorithms in particular: a new easily-stated but computationally intensive method designed specifically for nonsmooth problems, and an older, well known, highly effective method for smooth optimization which up until the present has not been considered a viable option in the nonsmooth case.  We intend to develop a theoretical foundation for the convergence of these methods.  We are also interested in other theoretical issues.  Finally, applications of nonsmooth, nonconvex optimization abound in engineering and applied science, particularly in control engineering.  Making an impact in these application areas requires much effort: first of all, understanding the problems of interest and their theoretical aspects, and following this by applying our algorithms to the problems and analyzing the results.<br/><br/>The broader impact of the proposed work has many components.  One is that it will lead to publicly available software that can be downloaded by engineers and other users.  The importance of robust, easy-to-use portable software and its impact on the scientific infrastructure cannot be overstated.  Nonsmooth, nonconvex optimization has many potential applications, and it is hoped that the successful application of the algorithms developed in this project to challenging problems arising in practice will inspire other researchers to apply them directly to their problems.  Finally, the proposed work includes many opportunities for the principal investigator to continue advising and mentoring students, including members of underrepresented groups."
"0736328","Computational Methods for Nonlinear Dimension Reduction","DMS","COMPUTATIONAL MATHEMATICS, Special Projects - CCF","09/01/2007","06/16/2009","Hongyuan Zha","GA","Georgia Tech Research Corporation","Standard Grant","Junping Wang","08/31/2010","$150,000.00","Haesun Park","zha@cc.gatech.edu","926 DALNEY ST NW","ATLANTA","GA","30332","4048944819","MPS","1271, 2878","0000, 9263, OTHR","$0.00","Manifold learning approach for nonlinear dimension reduction has drawn considerable interests from the machine learning as well as applied mathematics communities. The basic idea is to consider  data as samples from a low-dimensional nonlinear manifold embedded in a high-dimensional space. Hongyuan Zha and Haesun Park propose to develop efficient computational algorithms for nonlinear dimension reduction and theoretical tools for analyzing and better understanding their behaviors as well as applications to video sequence annotation and ad-hoc sensor network localization problems, focusing on the following two important issues in manifold learning: 1) deeper understanding of the behaviors of manifold learning methods such as local tangent space alignment through analysis of the spectral properties of the alignment matrix, and developing specialized pre-conditioning methods for effectively handling ill-conditioned problems; and 2) exploring and adapting methods such as domain decomposition to develop more efficient and scalable computational algorithms for manifold learning. As applications of the proposed algorithms, video sequence annotation in the context of semi-supervised manifold learning and algorithms for ad-hoc sensor network localization problems especially for the case when the terrain is nonflat will <br/>be developed. <br/><br/>Extracting compact representations of complex and high-dimensional data are at the core of many scientific and engineering endeavors.  Manifold learning has become a very active research field aiming at discovering hidden structures from the statistical and geometric regularity inherent in many complex high-dimensional data. The investigators study methods that have the promise of significantly expanding the applicability and functionality of existing and new manifold learning methods and thus advancing the state of the art in manifold learning research. The proposed research lies at the interface between scientific computing and machine learning applications and provides an ideal setting for research cross-fertilization and collaboration as well as training of graduate students in interdisciplinary research. The applications in Video sequence annotation is important in surveillance analysis for homeland security and localization methods for sensor networks will contribute to the development of new generation of networking systems. <br/>"
"0713833","Frontiers of finite element methods","DMS","COMPUTATIONAL MATHEMATICS","07/01/2007","06/22/2007","Jay Gopalakrishnan","FL","University of Florida","Standard Grant","Junping Wang","08/31/2010","$162,901.00","","gjay@pdx.edu","1523 UNION RD RM 207","GAINESVILLE","FL","326111941","3523923516","MPS","1271","0000, 9263, OTHR","$0.00","Finite element methods (FEM) are an indispensable tool in the simulation of many engineering devices and natural phenomena.  The research proposed here aims to expand the frontiers of FEM in various directions.  The activities fall into four categories.  The first is a continuation of the activities pursued under previous NSF support on hybridized finite element methods, which has resulted in a paradigm shift in FEM design.  The consequent new opportunities in designing discretizations with exotic properties are explored.  The second group of activities is tailored to fundamental theoretical and practical issues in high-order FEM.  The third category deals with the analysis and construction of mathematically sound FEM for axisymmetric problems.  In the fourth category, a number of modern applications in electromagnetics which can benefit from combining other techniques with FEM are considered.<br/><br/>Broader impacts of the activities include many examples of specific engineering applications which can potentially benefit, including simulation of nanophotonic materials, design of antennas, engineering of devices for cardiac ablation, and problems of interest to the petroleum industry like logging-while-drilling and porous media flow.  Such a range of applications can be considered because the proposed research involves techniques of broad applicability.  For example, the research on hybridization techniques can be applied to many types of equations representing various physical phenomena.  Another theme of the proposed activities is the design of efficient multilevel solvers for a wide range of practical problems involving outgoing waves such as scattering and radiation.  The research on methods for axisymmetric problems can impact simulation of many engineering devices such as coaxial cables, wave guides, and optical fibers.  The research activities on high-order methods touch upon questions that have implications not only in applied mathematics, but also in pure mathematical analysis."
"0713736","Optimal Cross Parameterizations of Surfaces: Computational Methods and Scientific Applications","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","08/24/2007","Xiangmin Jiao","GA","Georgia Tech Research Corporation","Standard Grant","Junping Wang","06/30/2008","$225,612.00","Hongyuan Zha","xiangmin.jiao@stonybrook.edu","926 DALNEY ST NW","ATLANTA","GA","30332","4048944819","MPS","1271","0000, 9263, OTHR","$0.00","Mesh-based computations, such as finite-element or finite-volume analysis, are important for a wide range of scientific and engineering applications, ranging from the design of aircrafts and rockets to the understanding of cardiovascular disease.  Many modern computational problems involve two or more surfaces or multiple discretizations (such as meshes) of a common surface and require correlating and cross-parameterizing these surfaces to analyze, match, manipulate, or map data between them.  Examples include non-conforming domain decomposition, multiphysics simulations, analysis of biomedical images, shape matching, and shape retrieval. The problem of robust cross-parameterization of surfaces is challenging, because in many practical situations the domains do not match well and some major discrepancies (such as singularities and topological changes) may occur in numerical simulations as well as in the physical world.  Most existing methods used in practice often assume the distances between corresponding points are at a local minimum.  They do not offer theoretical guarantees, may produce inaccurate and even unstable results in the presence of singularities or large discrepancies, and do not offer the accuracy and physical meaningfulness required by scientific and engineering applications.  Addressing these problems in a consistent and robust manner is critical for high-fidelity numerical simulations of complex systems and other related applications.<br/><br/>In this project, we will devise and analyze a general and unified framework for optimal cross-parameterizations of surfaces and deliver this enabling technology to those numerical applications.  Our framework will be based on efficient solutions of variational problems motivated by careful analysis of the accuracy and stability requirements of the underlying physical and numerical applications.  Unlike most existing methods, our framework will construct cross-parameterizations directly on curved surfaces without intermediate parameterizations on a template surface, and thus will avoid those spurious sources of numerical errors.  We emphasize theoretical foundations for optimal cross-parameterizations, efficient and robust algorithms for static and dynamic surfaces, and applications such as medical imaging, mesh optimization, and manifold learning."
"0645604","CAREER: Algebraic Topology and Exterior Calculus in Numerical Analysis","DMS","COMPUTATIONAL MATHEMATICS, NUMERIC, SYMBOLIC & GEO COMPUT","08/01/2007","08/02/2011","Anil Hirani","IL","University of Illinois at Urbana-Champaign","Continuing Grant","Junping Wang","07/31/2012","$400,000.00","","hirani@illinois.edu","506 S WRIGHT ST","URBANA","IL","618013620","2173332187","MPS","1271, 2865","0000, 1045, 1187, 9218, 9263, HPCC, OTHR","$0.00","The PI will work on the numerical analysis aspects of discrete exterior calculus.  This is a class of numerical methods for solving partial differential equations (PDEs) and these methods attempt to preserve the geometric and algebraic structures of the physics being modeled.  One ingredient of this project will be the use of algebraic topology and differential geometry to create and analyze discretizations of objects and operators of exterior calculus that appear in important PDEs.  Several discretizations will be derived and the convergence and stability of the resulting numerical methods will be studied.  In addition to this, the PI will develop algorithms and software to make it easier to conduct experimental studies involving such discretizations.  All of this will be done in the context of several physical problems.<br/><br/>Numerical solution of partial differential equations is a core part of numerical analysis and its applications in engineering and science. Some of the equations that the PI will work on have applications in ground water contamination, oil exploration, weather modeling, nuclear fusion, star and planet formation and formation of solar flares and storms. The research in this project will use pure mathematics topics like differential geometry and algebraic topology as well as computational mathematics. Thus it will be a unique vehicle with which to introduce these topics to students in mathematics as well as computer science. Due to the wide appeal of the applications mentioned above, the PI will use animations, images and concepts produced in this research to create interest in mathematics and science amongst primary school students.<br/>"
"0715121","Fast and accurate numerical algorithms for boundary value problems of elliptic partial differential equations on open surfaces in three dimensions","DMS","COMPUTATIONAL MATHEMATICS","07/15/2007","07/10/2007","Shidong Jiang","NJ","New Jersey Institute of Technology","Standard Grant","Junping Wang","06/30/2009","$68,326.00","","shidong.jiang@njit.edu","University Heights","Newark","NJ","071021982","9735965275","MPS","1271","0000, 9263, OTHR","$0.00","The focus of the proposed work is directed toward the development of fast, accurate, and robust computational techniques for solving large-scale scattering problems when the scattering surfaces consist of a collection of open surfaces (i.e., surfaces with boundary).  Though such problems are often initially formulated as boundary-value problems of elliptic partial differential equations, integral equations have been employed as one of principal tools for the numerical solution of scattering problems, particularly for exterior problems.  Historically, most of the integral equations used have been of the first kind, since numerical instabilities associated with such equations have not been critically important for the relatively small-scale problems that could be handled at the time.  The combination of improved hardware with the recent progress in the design of ""fast"" algorithms has changed the situation dramatically.  Condition numbers of systems of linear algebraic equations resulting from the discretization of integral equations of potential theory have become critical, and the simplest way to limit such condition numbers is by starting with second-kind integral equations.  Hence, there is increasing interest in reducing scattering problems to systems of second-kind integral equations on the boundaries of scatterers.<br/><br/>The investigator proposed to apply tools from potential theory and singular integrals to construct second-kind integral-equation (SKIE) formulations for open-surface problems (especially for those whose governing PDEs are the Laplace or Helmholtz equations).  After SKIE formulations have been obtained, the investigator plans to apply them to develop and implement efficient and accurate numerical algorithms for open-surface problems, using a combination of iterative solvers and the fast multipole method.  Since the Laplace equation and the Helmholtz equation are ubiquitous in applied mathematics and many practical problems involve open surfaces, the proposed research will have broad impacts on many active research fields including acoustic and electromagnetic scattering problems, fluid mechanics, elasticity problems, and inverse-scattering problems. The proposed research is also expected to have long-term impacts on key technologies such as reflecting antennas and integrated circuits."
"0714223","LTB: Generalized Variational Integrators for Large-Scale Scientific Computation","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","08/24/2007","Melvin Leok","IN","Purdue University","Standard Grant","Junping Wang","02/28/2010","$163,743.00","","mleok@math.ucsd.edu","2550 Northwestern Ave.","West Lafayette","IN","479061332","7654941055","MPS","1271","0000, 9263, OTHR","$0.00","Geometric integration is concerned with the construction of numerical methods that preserve the geometric structure of a continuous dynamical system. Many problems arising in science and engineering, such as solar system dynamics and molecular dynamics, are highly nonlinear, sensitive to small perturbations, and have underlying geometric structure that affects the qualitative behavior of solutions. The chaotic properties of these dynamical systems render prohibitively expensive the accurate computation of particular trajectories for long-time integration. As such, it is instead desirable to study numerical methods that preserve the geometry of a problem as they yield more qualitatively accurate simulations. The goal of this project is to generalize variational integrators based on a discrete Hamilton's principle to larger-scale problems arising from astrodynamics, molecular dynamics, and computational mechanics. This will involve incorporating methods from large-scale scientific computation, such as adaptivity, spectral methods, multi-resolution hierarchical techniques, and domain decomposition, while retaining the geometric preservation properties of variational integrators for Hamiltonian ODEs and PDEs.<br/><br/>Computer simulations of complex physical systems have become an increasingly important complement to traditional experimental techniques as a tool for validating and guiding theoretical developments in science, as well as practical advances in technology and engineering. This research will improve our ability to accurately and efficiently compute the long-time behavior of complex systems, which is a fundamental aspect of the rational design of pharmaceuticals and high-performance composite materials. In addition, it has the potential to accelerate the pace of technological development by allowing the rapid prototyping of new and innovative industrial designs directly on the computer."
"0711489","Graduate Student Workshop in Inverse Problems and Applications","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","07/01/2007","06/27/2007","Jennifer Mueller","CO","Colorado State University","Standard Grant","Junping Wang","06/30/2008","$24,000.00","","mueller@math.colostate.edu","601 S Howes St","Fort Collins","CO","805232002","9704916355","MPS","1266, 1271","0000, 7556, 9263, OTHR","$0.00","The Graduate Workshop on Inverse Problems and Applications at Colorado State University, July 30th - August 3rd, 2007, will bring together graduate students from eight countries including the United States to learn about theoretical and computational aspects of inverse problems from seven world-renowned experts.  Inverse problems is an active area of contemporary mathematics with applications in engineering, biology, geophysics, medicine, finance, and chemistry.  Students at various levels in their graduate degree programs will attend a series of minicourses developed by the experts, in each of which they will study a specific topic through lectures and assigned problems.  Some topics will be tied to a specific application, while others will be more generally applicable.  Participants will have access to the computational facilities at Colorado State University for working on computing problems.  Students will have the opportunity to discuss the assigned problems as well as other topics with the experts during the interaction sessions, which are time allotted during the day for students to work on the problems and talk to the experts in a less formal setting than the lecture hall.  The goals of the workshop are to provide instruction in inverse problems and to provide a venue for interaction between senior researchers in inverse problems and graduate students at both a technical and personal level."
"0703900","Interactions between Representation Theory, Quantum Field Theory, Category Theory, and Quantum Information Theory; June 2007, Tyler, TX","DMS","ALGEBRA,NUMBER THEORY,AND COM, TOPOLOGY, COMPUTATIONAL MATHEMATICS","06/01/2007","04/30/2007","Kazem Mahdavi","TX","University of Texas at Tyler","Standard Grant","Joanna Kania-Bartoszynska","05/31/2008","$10,000.00","Deborah Koslover","kmahdavi@uttyler.edu","3900 University Boulevard","Tyler","TX","757990001","9035655670","MPS","1264, 1267, 1271","0000, 7556, 9263, OTHR","$0.00","The conference will explore the connections between Representation Theory, Quantum Field Theory,  Category Theory, Mathematical Physics, and Quantum Information Theory.  These fields are interrelated and  have motivated each others' development.  The conference will bring together experts in these areas to enhance  research interactions. <br/><br/>Cross-disciplinary interactions are widely recognized for their value in stimulating new ideas and advances. The conference will not only increase the knowledge of the participants, but could result in the invention of new theorems, interesting conjectures,  and fascinating generalizations as well as practical applications.  In particular, this conference will help further the advancement  of Quantum information Theory, which is of importance in the development of quantum computers. <br/>More information about the conference can be found on the following web page:<br/>http://math.uttyler.edu/math/conference/Representation%20Theory%20Conference<br/>"
"0713858","A New Paradigm for Finite Difference Schemes on Adaptive Grids - Application to Free Surface Microfluidics","DMS","COMPUTATIONAL MATHEMATICS","08/15/2007","05/29/2009","Frederic Gibou","CA","University of California-Santa Barbara","Continuing Grant","Leland Jameson","07/31/2010","$309,655.00","","fgibou@ucsb.edu","Office of Research","Santa Barbara","CA","931062050","8058934188","MPS","1271","0000, 9263, OTHR","$0.00","In this work, the investigator devises innovative computational methods for free surface microfluidics in order to understand and control absorption and evaporation processes in the sub-micron scale open channels, as well as to understand how to efficiently control the effect of surface tension and temperature profiles along the channels. In particular, efficient numerical schemes on adaptive meshes are constructed in order to address the multiscale nature of the problem and the limitations of computer resources. The investigator introduces a new paradigm that allows the discretization of PDEs on highly adaptive meshes as if the mesh was uniform, while attaining second-order accuracy in the maximum norm. The numerical simulations are used to supplement physical experiments in order to optimize the design of free surface fluidics devices. The simulations take into account the temperature field in the liquid and the surrounding channel walls, the temperature-induced variations in surface tension, the subsequent surface tension driven flows in the transversal direction of the main flow (Marangoni effect) and their effects on the transport of airborne particles from the surface of the liquid to its bulk. Furthermore, the simulations take the configuration of the whole air-liquid system into account and determine the shape of the free surface in order to find a design that maximizes contact between the air and the liquid surface for efficient capture of airborne species.<br/><br/>In the past 15 years, significant advances have been made in using micro/nanofluidic-based platforms for detecting chemical and biological agents. However, all the `lab-on-a-chip' platforms reported in the literature can process samples only after the samples are injected into a microchannel. This longstanding technological and scientific barrier limits the viability of these platforms for monitoring airborne species at time when the great importance of this technology to national security issues has become clear. Free-surface fluidics is an innovative technology pioneered by the investigator's collaborators at UCSB which removes this barrier by enabling previously impossible detection thresholds for certain trace airborne chemical agents and pathogens.  Airborne molecules can be directly absorbed through the free surface, where they can interact with gold or silver colloidal particles and be detected using Surface-Enhanced Raman Spectroscopy. This platform could be used, for example, for public safety in a variety of venues to detect explosives and toxic chemicals, and for continuous monitoring of biological or chemical warfare agents in air ventilation systems. In this work, the investigator devises numerical methods in order to optimize the design of free-surface fluidic devices and to better understand the physical phenomena involved. These methods have an important impact on other fields as well, as they have key applications in the fields of semi-conductor processing and in the energy industry, in bio-nanotechnology and tissue engineering, in combustion as well as in the modeling of tumor growth to name a few. In addition, the investigator develops a freely available interactive web site on computational science and engineering which guides the users through a computational science journey, exploring intriguing topics such as microfluidics, crystal growth, single and multiphase flows. The users have the possibility of further interactive exploration by altering parameters to observe the effect on simulations, hence providing a tutorial on computational science.<br/>"
"0713722","Collaborative Research: Algorithms for Simulation and Design of Analog VLSI Lattices","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","08/17/2007","Harish Bhat","NY","Columbia University","Standard Grant","Junping Wang","11/30/2007","$95,452.00","","hbhat@ucmerced.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","MPS","1271","0000, 7237, 9263, OTHR","$0.00","New technologies in areas such as wireless communication, portable computing, and handheld electronics have increased the demand for signal processing at high frequencies.  Part of the challenge in designing silicon integrated circuits that can meet this demand is to overcome limitations in the efficiency and frequency bandwidth of modern transistors.  Here it is proposed to use two-dimensional networks of inductors and capacitors to overcome these limitations.  These high-speed, high-efficiency networks have a cut-off frequency that is higher than that for silicon-based transistors.  Moreover, such networks can be incorporated into standard silicon chips that can be fabricated at low cost.  The proposed research has the potential to revolutionize high-frequency analog signal processing, leading to chips that operate up to 1000 times faster than current ones.<br/><br/>There are a large number of possible designs for such networks, and only a small number of these possibilities have already been explored.  The proposed research seeks to develop algorithms that greatly assist in the simulation and design of two-dimensional inductor-capacitor networks.  Simulating a large network involves the solution of a large, coupled system of equations that can be simplified greatly through mathematical analysis.  It is proposed to use this simplification to develop fast, scalable algorithms and codes for network simulation.  This would enable engineers to quickly learn the effect of changing one or more of the thousands of parameters in a typical large-scale inductor-capacitor network.<br/><br/>It is also proposed to use optimization methods to automatically design lattices that achieve prescribed input-output relationships.  The optimization work will use as a foundation the prior results of the proposers, including, for example, the development of a two-dimensional network that computes Fourier transforms in the analog domain.  Such physically motivated ideas will be coupled with modern tools of parallel numerical computing such as PetSC (the Portable Extensible Toolkit for Scientific Computation) and TAO (the Toolkit for Advanced Optimization).  This will result in fast, accurate tools that enable engineers to rapidly optimize the design of a lattice to achieve desired performance specifications.<br/><br/>The expertise gained in carrying out the proposed research will enable the investigators to train students and researchers to solve problems in modern computational science and engineering. The proposed research encourages multidisciplinary interaction between scientists, engineers, applied mathematicians, and computer scientists spanning the spectrum from developers to users of computational tools."
"0712958","Collaborative Research: Exploring the Space of Large Knots and Links","DMS","TOPOLOGY, COMPUTATIONAL MATHEMATICS","09/01/2007","08/20/2007","Yuanan Diao","NC","University of North Carolina at Charlotte","Standard Grant","Junping Wang","08/31/2010","$42,742.00","","ydiao@uncc.edu","9201 University City Boulevard","CHARLOTTE","NC","282230001","7046871888","MPS","1267, 1271","0000, 9263, OTHR","$0.00","The PIs propose to investigate the space of very large knots (with thousands of crossings) through a symbiosis of theoretical research and computation. The problems raised here are motivated by the applications of knot theory in chemistry, physics, and biophysics. The main goal is to develop and implement new algorithms that sample the space of large knots and that are capable of embedding large knots tightly or semi-tightly in the simple cubic lattice. In this research, theoretical work will enhance the algorithms to be developed and the empirical results will support the theoretical approaches. The proposed research project consists of several inter-related objectives: developing fast algorithms capable of generating representative samples of large knot diagrams, developing better algorithms capable of embedding large knots tightly in the simple cubic lattice, and developing new theoretical approaches to improve the upper and lower bounds of the ropelength in general or for special knot classes such as alternating knots. These objectives are difficult and challenging. For example, the distribution of large knots is unknown, determining the crossing number of large non-alternating knots is known to be NP-hard, and theoretical results concerning large knots are scarce in general. Concretely the PIs expect to sample the space of large knots using and comparing three approaches:   first applying uniform prefix vectors to generate large Hamiltonian prime knot diagrams; second, adapting a method based on uniform random polygons to sample large prime knot diagrams; finally, using graph tensor products to construct large non-alternating knots whose crossing number can be approximated by computing the breadth of the Jones polynomial (via the Tutte polynomial); sampling such non-alternating knots allows a comparison with alternating knots of similar size.  Furthermore, the PIs will work on developing a more efficient embedding algorithm by extending the constructive proof of two of the PIs regarding the embedding length of closed braids to general knots. This approach also aims at improving the general upper bound on the ropelength of knots from the current bound of crossing number to the power of 1.5.<br/> <br/>The main subjects to be studied in this proposal are large physical knots, i.e. large knots that can actually occur in the real world. Examples of such occurrences are long, knotted polymer chains or circular DNA. The problems raised in this proposal are motivated by the applications of knot theory in chemistry, physics and biophysics. For example, DNA knots formed under extreme conditions of condensation, such as those found in bacteriophage P4, can be quite large. Such large and tightly packed circular DNAs are difficult to analyze experimentally. Theoretical results or computational simulations on such systems would be of great help. Yet theoretical studies on large knots are scarce. The proposed project aims at gaining more knowledge about large knots: How much space is needed in order to pack certain large knots? How efficiently can knots be packed tightly? Is there a difference between packing a complicated knot in comparison to packing a simple knot? What role does the topology (shape) of the knot play? The PIs intend to develop computer programs that can generate large knots and pack them tightly, based on theoretical results and algorithms they have developed in the past. Empirical data can then be gathered through the repeated applications of these programs. The proposed activities may have significant implications in DNA research, polymer science, and other sciences. The activities will result in tools for researchers to compute various geometric and topological characteristics of the large knots they encounter in their field and thus help them to better understand biological and physical systems where large knotted molecules occur.<br/>"
"0714193","Collaborative Research: Multiscale Aspects for Wave Propagation Inverse Problems","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","08/28/2007","William Symes","TX","William Marsh Rice University","Standard Grant","Junping Wang","06/30/2011","$99,829.00","","symes@rice.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","MPS","1271","0000, 9263, OTHR","$0.00","Many natural materials exhibit structural heterogeneity across a wide range of scales. Examples of such media with microstructure include virtually every part of the Earth's crust, and manufactured composite materials such as concrete. These materials also support wave motion, and various technologies have evolved which use propagating waves for nondestructive interogation of material structure. In their present state, these technologies (reflection seismology, ultrasonic nondestructive evaluation, etc) are for the most part based on theoretical understanding and computational methods developed for waves in homogeneous (or near-homogeneous) materials. This divide between theoretical basis and application context is bridged to some extent by effective medium theories which attempt to express at macroscopic scales the effect of microscopic heterogeneities. However rigorous justification of the effective medium approach is largely limited to periodic material models, which do not resemble disordered materials such as sedimentary rock. This study will attempt to leverage recent advances in the simulation of acoustic and elastic waves in media with microstructure to assess the feasibility of explaining simulated experimental data by means of simpler models without microstructure. These models may exhibit physical characteristics not present on the microscopic scale, for instance viscous loss or anisotropic response. Our approach combines various numerial simulation methods, including numerical upscaling, for computing waves in highly heterogeneous models, with inversion or parameter estimation to determine macroscopic models. The proposed work will rely upon a previously developed computational framework for inversion. <br/><br/>For scientists to be able to produce oil and gas, to predict earthquakes and other tectonic events such as tsunamis, to safely remediate contaminants, and to bury excess greenhouse gases underground, they must first be able to image the earth's subsurface. Rock layers, fluids, and faults need to be mapped and their depths and lateral extent understood. To create an image of the subsurface, energy is sent into the ground which generates a wave. The heterogeneous nature of the subsurface causes a portion of these waves to be sent back to the surface where seismometers (microphones) record the waves as they pass. From these signals scientists try to infer the structure of the subsurface. This inference is enormously complicated by the very complex mechanical nature of rock, which is composed of microscopic grain particles in a porous lattice. The physical characteristics of these tiny constituents and the fluids within the pores combine in a complex and poorly understood way to yield the observable response of the Earth. In our previous work, we have <br/>devised methods to simulate propagation of waves through complex microscopically structured material, and also procedures to determine the macroscopic material descriptions from observable data. This proposal envisions the fusion of these two lines of work and could shed light on which aspects of subsurface structure can, or can't, be inferred from seismic recordings."
"0715125","AMC-SS: Multiscale Methods for Many-Particle Stochastic Systems: Coarse-Graining and Microscopic Reconstruction","DMS","COMPUTATIONAL MATHEMATICS, COFFES","09/01/2007","07/18/2007","Markos Katsoulakis","MA","University of Massachusetts Amherst","Standard Grant","Junping Wang","08/31/2011","$336,172.00","","markos@math.umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","MPS","1271, 7552","0000, 9263, OTHR","$0.00","Problems in diverse areas of scientific, technological, and societal relevance, ranging from the development of novel materials to understanding fundamental biological mechanisms to weather and climate prediction, are intrinsically multi-scale.  In essence this means that information at very small spatial and temporal scales, for instance properties and motions of  atoms or molecules, can profoundly impact intermediate- and large-scale behavior, such as the permeability of a membrane or the viscosity of a fluid.  <br/>     From a modeling and computational perspective, small spatiotemporal scales can be described in detail with microscopic models such as Molecular Dynamics or Monte Carlo methods that typically account for atomistic and/or molecular information.  On the other hand, understanding large-scale, macroscopic properties of materials requires simulations with microscopic systems at prohibitively large spatial (e.g. 10^23 atoms), as well as temporal scales.  One such example arises in the design of novel materials with pre-specified properties, where numerical simulations--when feasible--could be used as a flexible and inexpensive predictive tool.<br/>     An important class of computational tools that has been developed in recent years, precisely to bridge such scales gaps by speeding up microscopic simulation methods, is the method of coarse-graining.  The idea of this approach is to reduce the molecular system''s complexity by lumping together degrees of freedom into coarse-grained variables, thus yielding an accelerated simulation methodology.  Such coarse-grained models have been developed for the study and simulation of micro-reactors (e.g., portable energy sources), polymers, proteins, and bio-fluids (e.g., red-cell flow in small blood vessels), among others.  Existing approaches can give unprecedented speed-ups to molecular simulations and can work well in certain parameter regimes, such as high temperatures.  On the other hand, they can also give wrong predictions on important features such as diffusion, crystallization, and phase transitions. <br/>     Along these lines, a relevant mathematical and statistical goal to numerous applications, such as the ones mentioned earlier, is to develop  systematic diagnostics for determining when coarse-graining methods can give reliable predictions, and how they can be further enhanced.  Indeed, in our proposed work we intend to carry out two related main tasks: (a) understand the validity regimes of existing coarse-graining methods by developing a mathematical and statistical error quantification analysis; and (b) develop improved algorithms capable of operating in much wider parameter regimes, with the capacity to automatically adjust once substantial deviations are detected during simulation.<br/>     In our proposed work, we plan to develop novel multi-scale mathematical and computational methods, bringing together diverse techniques from probability theory, statistical mechanics, information theory, statistics, and finite elements.  A critical component of the proposed work relies on the synergy between applied mathematics and statistics methods, operating in a complementary fashion, that can provide a mathematically systematic framework for developing flexible and reliable coarse-graining algorithms for molecular simulations."
"0713848","Fast and Accurate High Dimensional Function Approximation","DMS","COMPUTATIONAL MATHEMATICS","07/15/2007","07/07/2009","Fred Hickernell","IL","Illinois Institute of Technology","Continuing Grant","Junping Wang","06/30/2011","$243,999.00","Gregory Fasshauer","hickernell@iit.edu","10 West 35th Street","Chicago","IL","606163717","3125673035","MPS","1271","0000, 9251, 9263, OTHR","$0.00","This research will develop computational methods to approximate functions of many variables based on function values which may be contaminated by noise.  The focus will be on kernel-based methods, such as radial basis function methods, smoothing splines, regression splines and moving least squares methods.  Non-isotropic kernels, space filling designs, and new convergence proofs will be used to make these methods practical in higher dimensions.  Fast transform and iterative algorithms will be developed to reduce the computational burden of kernel methods.  Both computational and statistical approaches will be brought to bear on this problem.  The theoretical development will provide practitioners insight into how the quality of the designs (sample points) affects the accuracy of approximation.  The algorithms developed will be published as software packages for widespread use. <br/><br/><br/>In this information age there is an abundance of data generated from instrumental measurements and computer simulations.  Strategic corporate planning and profitable product design both rely on accurate mathematical models to describe this data.  As the numbers of observations and variables increase, existing methods for computing the best models fail to capture the complex relationships and fail to compute an answer in a reasonable amount of time.  This research will develop a new generation of computational methods for modeling data that overcome these drawbacks. These new methods will make our manufacturing industry more competitive by facilitating more rapid prototyping of products, and they will enable our service industry to assess and respond more quickly to changing markets."
"0714945","New variational computational methods for modeling dual spaces of distributions, decomposition of functions, oscillations, and inverse problems in image analysis","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","07/15/2011","Luminita Vese","CA","University of California-Los Angeles","Continuing Grant","Leland Jameson","08/31/2012","$595,293.00","John Garnett","lvese@math.ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","MPS","1271","0000, 9263, OTHR","$0.00","The investigators will study new computational techniques with<br/>applications to inverse problems and image analysis. They will seek new<br/>methods that combine variational arguments with ideas from computational<br/>harmonic analysis and partial differential equations in order to overcome<br/>limitations of existing methods. The research will have three objectives:<br/>propose new models for cartoon and texture separation in images by working<br/>with spaces of distributions; propose completely new techniques for<br/>multiscale hierarchical decomposition of images; propose efficient<br/>algorithms for solving inverse problems.<br/><br/>From the proposed research and educational program, computational <br/>mathematics, image processing, as well as more general areas of science and<br/>engineering will benefit. Applications include image analysis, medical<br/>imaging, satellite imaging, material science, and terrain data analysis,<br/>surveillance and inverse problems.<br/>"
"0713836","Rational Landen Transformations and Hurwitz Zeta Function:  from theory to algorithms","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","08/24/2007","Victor Moll","LA","Tulane University","Standard Grant","Junping Wang","08/31/2011","$219,999.00","","vhm@math.tulane.edu","6823 ST CHARLES AVENUE","NEW ORLEANS","LA","701185698","5048654000","MPS","1271","0000, 9150, 9263, OTHR","$0.00",".The problem of integration of rational functions was considered by J. Bernoulli  and Leibnitz in the 18th century. The main difficulty associated with this procedure is to obtain a complete factorization of the denominator.  The long term goal of this project is to develop a complete solution to the problem of definite integration in finite terms. This work will complement the work done by Lazard, Rioboo, Risch and Trager in the case of indefinite integration. The implementation of this solution will have a profound impact on the current symbolic integrators. This project is an effort to investigate the mathematical theory and algorithms associated with the symbolic evaluation of definite integrals. Two classes of functions are considered: rational functions and elementary functions of the Hurwitz zeta function. The work on rational integrands centers around the rational Landen transformations developed by the PI. The analysis and implementation of these transformations is complete for definite integrals on the whole real line. We will concentrate on the finite interval case. These transformations will be incorporated into an efficient and robust symbolic algorithm for the evaluation of rational integrals, as well as some simple extensions of this class.<br/><br/>Many problems in physics and engineering require the exact evaluation of integrals in terms of the parameters appearing in those integrals.  These integrals come up in the study of particle physics and classical mechanics. While it is not always possible to find such an expression, an efficient and robust symbolic software package should give the result in closed form, or decide whether such an expression is  achievable.  The goal of this project is to develop algorithms that will expand upon the capabilities of existing software packages that are widely used in industry and universities."
"0753983","Collaborative Research: Algorithms for Simulation and Design of Analog VLSI Lattices","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","10/12/2007","Harish Bhat","CA","Claremont McKenna College","Standard Grant","Junping Wang","06/30/2009","$95,452.00","","hbhat@ucmerced.edu","500 E. Ninth St.","Claremont","CA","917115929","9096077085","MPS","1271","0000, 7237, 9263, OTHR","$0.00","New technologies in areas such as wireless communication, portable computing, and handheld electronics have increased the demand for signal processing at high frequencies.  Part of the challenge in designing silicon integrated circuits that can meet this demand is to overcome limitations in the efficiency and frequency bandwidth of modern transistors.  Here it is proposed to use two-dimensional networks of inductors and capacitors to overcome these limitations.  These high-speed, high-efficiency networks have a cut-off frequency that is higher than that for silicon-based transistors.  Moreover, such networks can be incorporated into standard silicon chips that can be fabricated at low cost.  The proposed research has the potential to revolutionize high-frequency analog signal processing, leading to chips that operate up to 1000 times faster than current ones.<br/><br/>There are a large number of possible designs for such networks, and only a small number of these possibilities have already been explored.  The proposed research seeks to develop algorithms that greatly assist in the simulation and design of two-dimensional inductor-capacitor networks.  Simulating a large network involves the solution of a large, coupled system of equations that can be simplified greatly through mathematical analysis.  It is proposed to use this simplification to develop fast, scalable algorithms and codes for network simulation.  This would enable engineers to quickly learn the effect of changing one or more of the thousands of parameters in a typical large-scale inductor-capacitor network.<br/><br/>It is also proposed to use optimization methods to automatically design lattices that achieve prescribed input-output relationships.  The optimization work will use as a foundation the prior results of the proposers, including, for example, the development of a two-dimensional network that computes Fourier transforms in the analog domain.  Such physically motivated ideas will be coupled with modern tools of parallel numerical computing such as PetSC (the Portable Extensible Toolkit for Scientific Computation) and TAO (the Toolkit for Advanced Optimization).  This will result in fast, accurate tools that enable engineers to rapidly optimize the design of a lattice to achieve desired performance specifications.<br/><br/>The expertise gained in carrying out the proposed research will enable the investigators to train students and researchers to solve problems in modern computational science and engineering. The proposed research encourages multidisciplinary interaction between scientists, engineers, applied mathematicians, and computer scientists spanning the spectrum from developers to users of computational tools."
"0713097","The Reproducing Singularity and Polynomial Particle Shape Functions for Meshless Methods","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","08/23/2007","Hae-Soo Oh","NC","University of North Carolina at Charlotte","Standard Grant","Junping Wang","08/31/2010","$86,498.00","","hso@uncc.edu","9201 University City Boulevard","CHARLOTTE","NC","282230001","7046871888","MPS","1271","0000, 9263, OTHR","$0.00","Meshless methods such as  Reproducing Kernel Particle method (RKPM) and  Partition of Unity Finite Element Method (PUFEM),  are much more effective than the conventional FEM.   However,  these methods have the following  limitations: (1) the constructions of Reproducing Kernel Particle (RKP) Shape functions are complicate. The partition of unity (PU) functions is essential in PUFEM and the popular Shepard PU functions are generally complicated rational functions. Thus, Meshless methods  require a lengthy computing time for reasonable accuracy; (2) RKPM and PUFEM  have difficulties  in dealing with essential boundary conditions. To compensate for these limitations, the PI constructed  the highly regular piecewise polynomial Reproducing Polynomial Particle (RPP) shape functions that satisfy the Kronecker delta  property. Furthermore,  he also  constructed simple piecewise polynomial PU  functions for arbitrary partitioned patches. Nevertheless, the RPP shape functions are not very practical if the solution contains singularities (such as crack singularity). To deal with singularities in the framework of Meshless Methods, the PI introduced the  Reproducing Singularity Particle (RSP) shape functions for two dimensional singularity problems. Now, the PI proposes to extend his two dimensional RPP and RSP shape functions to the three dimensional cases for three dimensional singularity problems. <br/><br/>The annual cost of fracture-related damage in the United States is an astronomical amount. Metal fatigue has been cited as the probable cause of several recent airline accidents and the bridge collapses. Moreover, the safety of aging bridges and airliners is a national concern. Material failures are a major concern for other engineering structures (nuclear power plants, hydroelectric dams, etc). Thus, for effective inspection and preventive maintenance programs, an accurate fracture analysis is needed. The proposed research is to provide accurate stress analysis of cracked materials. These analyses are essential for precise estimates of three dimensional crack propagation in materials.  Practically, the results of the proposed research will be applicable to the effective maintenance of aging bridges, off-shore oil platforms, and numerous other engineering applications where structural integrity should be closely monitored. Ultimately, this research will have direct impacts on the safety of the public and the environment.<br/><br/>"
"0712898","Innovative Numerical Methods for Nonlinear Time-Dependent PDEs","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","05/24/2007","Alina Chertock","NC","North Carolina State University","Standard Grant","Leland Jameson","08/31/2011","$272,015.00","","chertock@math.ncsu.edu","2601 Wolf Village Way","Raleigh","NC","276957514","9195152444","MPS","1271","0000, 9263, OTHR","$0.00","The project is aimed at developing accurate, efficient, and robust numerical methods for nonlinear PDEs, with particular reference to problems that admit nonsmooth (discontinuous) solutions and  problems that involve highly disparate scales, and therefore, are difficult <br/>to solve numerically. The principal part of the proposed research will be focused on the development of new techniques for solving problems involving complicated nonlinear wave phenomena, problems with complex computational domains, moving boundaries and material/layer interfaces, as well as problems that include uncertain phenomena. The new techniques will be based on particle methods<br/>and finite-volume methods, as well as their hybridization. The latter approach will utilize major advantages of particle methods, as mesh-free methods, and shock-capturing finite-volume methods, especially in problems with complex geometries, free boundaries, and flows with structural interactions. A combination of stochastic and numerical tools will also be used for solving problems with uncertainties and problems, in which multiple scales should be taken into account. The designed methods will be applied to a variety of nonlinear problems, among which are the Euler-Poincare equations, multi-phase and multi-fluid flow models, models of transport of pollutant in turbulent incompressible flow, chemotaxis models, reactive Euler equations describing stiff detonation waves, zero diffusion-dispersion limits for conservation laws, and others. Stochastic initial-value problems such as the randomly perturbed KdV equation and the Burgers equation with random force will also be solved by the proposed methods. It is significant that, besides providing the examples that corroborate the analytical approach, the foregoing applications are of a substantial independent value for a broad class of problems arising<br/>in modern science.<br/> <br/>In recent years, numerical methods for solving partial differential equations have evolved into an important and extremely efficient tool for the quantitative and qualitative study of many phenomena in different applied ares that otherwise could not have been studied at all. The proposed project will contribute significantly toward development of computational methods and will provide considerably more powerful tools for analyzing applied problems on the computer. In this proposal, a strong accent is put on designing numerical methods for complicated problems such as multi-phase and multi-fluid models, models of pollution propagation, polymer systems, chemotaxis models, active fluid transport models, multi-scale and stochastic initial-value problems, etc. These problems arise in a variety of scientific applications<br/>in fluid and gas dynamics, geophysics, meteorology, astrophysics, multi-component flows, granular flows, reactive flows, polymer flows, and other fields. A wide spectrum of applications of the studied methods reflects also the interdisciplinary character of the proposed project.<br/><br/><br/><br/>"
"0711885","Computational Methods for Astrophysical Flows","DMS","COMPUTATIONAL MATHEMATICS","07/15/2007","07/10/2007","James Rossmanith","WI","University of Wisconsin-Madison","Standard Grant","Junping Wang","12/31/2011","$150,001.00","","rossmani@iastate.edu","21 North Park Street","MADISON","WI","537151218","6082623822","MPS","1271","0000, 9263, OTHR","$0.00","Astrophysical fluid dynamics is a branch of physics concerned with understanding the evolution of far-away objects such as black holes and neutron stars. In order to fully understand such objects, mathematical models must incorporate general relativistic, electromagnetic, and fluid dynamic effects. The resulting equations are a large, coupled, nonlinear system of partial differential equations, some of which are evolution equations, while others are constraint equations that result from various gauge freedoms. The PI's research will focus on developing high-order schemes on unstructured grids to solve various simplified versions of the full astrophysical fluid dynamic model. For example, one problem of great interest to astrophysicists is that of mass accretion onto black holes and the resulting formation of relativistic jets; this phenomenon can be treated in the test-fluid limit (i.e., background spacetime metric is fixed). Another important problem is the generation of gravitational waves (i.e., ripples in spacetime) from the collision of two massive black holes; this problem can be first looked at in the minimally coupled scalar field limit. The PI will make use of both discontinuous Galerkin and residual distribution scheme methodologies to construct accurate and efficient schemes. In particular, these methods will be combined with adaptive mesh refinement strategies.  In order to do this efficiently, the PI will construct a posteriori error estimators that can be used to dynamically diagnose where large numerical errors are being made. The resulting set of numerical methods will be incorporated into a computer code that will be made freely available on the web.<br/><br/><br/>Although astrophysical objects such as black hole accretion disks, extragalactic jets, and supernovae are observable using various telescopes, direct experimentation is clearly not possible. On the other hand, mathematical models that attempt to explain the physics of these objects are necessarily complex and must include gravitational, electromagnetic, and fluid dynamic effects. Exact solutions to the resulting mathematical equations can only be constructed in very special cases. Therefore, the ability to understand astrophysical phenomena from a scientific viewpoint rests largely on the ability to run accurate and efficient computer simulations, which, in turn, rests on the quality of the computational methods that are used to carry out those simulations. The PI's research is focused on developing classes of high-order computational methods for solving the equations of astrophysical fluid dynamics. One aspect of this work will involve the construction of various error indicators that can be used to dynamically diagnose and correct the accuracy of a computation. Another aspect will be to develop a software package that will be made freely available on the web. The computational methods that result from this development will be applied to two distinct problems in astrophysics: (1) the formation of astrophysical jets from black hole accretion processes and (2) the dynamics of the interaction of two black holes and the resulting generation of gravitational waves.<br/>"
"0712997","Collaborative Research: Exploring the Space of Large Knots and Links","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","09/22/2009","Claus Ernst","KY","Western Kentucky University Research Foundation","Standard Grant","Junping Wang","08/31/2010","$55,000.00","Uta Ziegler","claus.ernst@wku.edu","Western Kentucky University","Bowling Green","KY","421011016","2707454652","MPS","1271","0000, 9263, OTHR","$0.00","The PIs propose to investigate the space of very large knots (with thousands of crossings) through a symbiosis of theoretical research and computation. The problems raised here are motivated by the applications of knot theory in chemistry, physics, and biophysics. The main goal is to develop and implement new algorithms that sample the space of large knots and that are capable of embedding large knots tightly or semi-tightly in the simple cubic lattice. In this research, theoretical work will enhance the algorithms to be developed and the empirical results will support the theoretical approaches. The proposed research project consists of several inter-related objectives: developing fast algorithms capable of generating representative samples of large knot diagrams, developing better algorithms capable of embedding large knots tightly in the simple cubic lattice, and developing new theoretical approaches to improve the upper and lower bounds of the ropelength in general or for special knot classes such as alternating knots. These objectives are difficult and challenging. For example, the distribution of large knots is unknown, determining the crossing number of large non-alternating knots is known to be NP-hard, and theoretical results concerning large knots are scarce in general. Concretely the PIs expect to sample the space of large knots using and comparing three approaches:   first applying uniform prefix vectors to generate large Hamiltonian prime knot diagrams; second, adapting a method based on uniform random polygons to sample large prime knot diagrams; finally, using graph tensor products to construct large non-alternating knots whose crossing number can be approximated by computing the breadth of the Jones polynomial (via the Tutte polynomial); sampling such non-alternating knots allows a comparison with alternating knots of similar size.  Furthermore, the PIs will work on developing a more efficient embedding algorithm by extending the constructive proof of two of the PIs regarding the embedding length of closed braids to general knots. This approach also aims at improving the general upper bound on the ropelength of knots from the current bound of crossing number to the power of 1.5.<br/> <br/>The main subjects to be studied in this proposal are large physical knots, i.e. large knots that can actually occur in the real world. Examples of such occurrences are long, knotted polymer chains or circular DNA. The problems raised in this proposal are motivated by the applications of knot theory in chemistry, physics and biophysics. For example, DNA knots formed under extreme conditions of condensation, such as those found in bacteriophage P4, can be quite large. Such large and tightly packed circular DNAs are difficult to analyze experimentally. Theoretical results or computational simulations on such systems would be of great help. Yet theoretical studies on large knots are scarce. The proposed project aims at gaining more knowledge about large knots: How much space is needed in order to pack certain large knots? How efficiently can knots be packed tightly? Is there a difference between packing a complicated knot in comparison to packing a simple knot? What role does the topology (shape) of the knot play? The PIs intend to develop computer programs that can generate large knots and pack them tightly, based on theoretical results and algorithms they have developed in the past. Empirical data can then be gathered through the repeated applications of these programs. The proposed activities may have significant implications in DNA research, polymer science, and other sciences. The activities will result in tools for researchers to compute various geometric and topological characteristics of the large knots they encounter in their field and thus help them to better understand biological and physical systems where large knotted molecules occur.<br/>"
"0712910","Numerical Algebraic Geometry: Computation of Exceptional Parameter Values","DMS","ALGEBRA,NUMBER THEORY,AND COM, APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","09/01/2007","06/25/2009","Andrew Sommese","IN","University of Notre Dame","Continuing Grant","Junping Wang","08/31/2011","$359,999.00","Charles Wampler","sommese@nd.edu","940 Grace Hall","NOTRE DAME","IN","465565708","5746317432","MPS","1264, 1266, 1271","0000, 9263, OTHR","$0.00","Sommese and Wampler propose constructing and implementing new algorithms to numerically describe exceptional algebraic subsets of the solution sets of systems of parameterized polynomial equations; and to solve polynomial systems with few solutions, but with many defining equations. In applications, such as the design of robots and mechanisms, the parameters represent constants of the device, such as the length of a link, and the variables represent the device's motion. A focus of the proposal is on techniques for the design of robots and mechanisms where the objective is to find the exceptional parameter values so that the device they represent has particular motion characteristics. These techniques, which will apply to parameterized polynomial systems generally, such as may arise in computer graphics, chemistry, robot vision, and other engineering and scientific disciplines, lead to systems of polynomials that are large in comparison to the systems presently being solved. To deal with these large systems, Sommese and Wampler propose a new equation-by-equation approach, that they call regeneration, to solve polynomial systems. This reduces the solution of a polynomial system to sequentially finding the solution of systems that starting trivial are gradually built up to the target system. Close relationship between the subsystems of equations will likely result in new algorithmic efficiencies. Sommese and Wampler propose further development of Bertini, their freely available software for polynomial system computations, including the development of parallel versions so that they can tackle nontrivial systems arising in engineering and science. They propose also the development of algorithms for computing invariants that algebraic geometers are interested in, and which, while expensive to compute symbolically, are easy to compute numerically.<br/><br/>Many technological problems, e.g., the design of artificial limbs, the design of industrial robots and other machines, economics, and a detailed understanding of critical chemical processes, such as those involved in combustion, lead to systems of polynomials that are very difficult to impossible to solve by current methods.  Sommese and Wampler are developing new mathematical and computational approaches to solve such currently intractable problems.  They are also developing Bertini, a freely available software package, so that engineers, mathematicians, and scientists may solve the polynomial systems that come up in their work without knowledge of the extensive theoretical foundations underlying the work of Sommese and Wampler.<br/>"
"0704213","The Space of Shapes: A mathematical approach with applications to computer vision","DMS","GEOMETRIC ANALYSIS, COMPUTATIONAL MATHEMATICS","08/15/2007","07/09/2009","David Mumford","RI","Brown University","Continuing Grant","Christopher Stark","07/31/2010","$247,657.00","","mumford@dam.brown.edu","BOX 1929","Providence","RI","029129002","4018632777","MPS","1265, 1271","0000, 9150, 9263, OTHR","$0.00","Object recognition tasks in computer vision and particularly medical imaging, require a theory of shape. There are many mathematical theories of geometry- Euclid's theory of triangles, Gauss's theory of the obstructions to flattening a surface, Poincare's theory of the most abstract properties unique to a sphere. But none of these seem to have captured what humans mean when they say this object is heart-shaped but that one is kidney-shaped. Automated analysis of medical scans requires that these issues be addressed. Humans have no difficulty answering questions about how similar two shapes are. This suggests two types of mathematical models. On the one hand, one might define precisely a measure of dissimilarity of two shapes, a so-called metric on the set of all shapes. On the other, one might define a probability distribution whose values represent the probability that one shape is likely to belong to the same category as the first. Both constructions are, however, not simple extensions of known mathematics because the set of all shapes is infinite dimensional: this means that any given shape can be wiggled or stretched in infinitely many distinct ways, that no finite set of numbers can fully describe any given shape. Thus new mathematics is needed to create the tools to work with shapes. It is hoped that the ideas behind this study may impact work in recognizing, identifying and comparing the objects present in any type of imaging such as MRI's and CAT-scans.<br/><br/>More precisely, this study starts from the observation that a shape (a closed surface in 3-space or a curve in the plane) can be viewed as a point in an infinite dimensional manifold. Even though the space of shapes is not linear, i.e. two shapes cannot, in any natural way, be added, the set of small deformations of a shape does form a vector space, namely the vector space of normal vector fields along the shape. Having a manifold, differential geometry can be used to define and study metrics on the space of shapes. Recent work has shown that a rich family of Riemannian metrics exists on this space with many different properties. Each one has its own geodesic equations and curvature tensor which have strikingly different properties. This project proposes to study two questions in particular: (a) the curvature for the Riemannian metric inherited from Sobolev norms on the diffeomorphism group of the ambient space and (b) the relationship between the features of the plane curve and its representation in the arguably most natural metric, the Weil-Petersson metric. We also seek to study the probability distributions on the space of shapes obtained as the marginals of diffusion processes associated to these metrics. We finally propose to make a database of scanned 2D shapes on which to compare the many metrics which have been proposed and to study clustering and the fitting of probability models to data. At present, there seem to be several good candidate metrics for applications so a comparative study is very important.<br/><br/>"
"0645035","CAREER: High Performance Computational Method for Stochastic Design Problems","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","06/15/2007","06/13/2007","Dongbin Xiu","IN","Purdue University","Standard Grant","Junping Wang","05/31/2013","$439,994.00","","xiu.16@osu.edu","2550 Northwestern Ave.","West Lafayette","IN","479061332","7654941055","MPS","1266, 1271","0000, 1045, 1187, 9263, OTHR","$0.00","The importance of uncertainty analysis and stochastic modeling<br/>has received increasing amount of attention in recent years,<br/>especially from the Computational Mathematics society.<br/>Extensive research efforts have been devoted to uncertainty<br/>quantification and stochastic computations, and novel numerical <br/>methods have been developed to efficiently deal with large and <br/>complex systems with uncertainty. Although these methods have been <br/>demonstrated to be highly effective in predicting the behavior of <br/>complex stochastic systems, the design industry has not taken full <br/>advantage of these developments, and the design procedures in many <br/>disciplines remain almost exclusively deterministic. The research <br/>objective of this proposal is to develop new mathematical and <br/>numerical methods for multidisciplinary design problems with <br/>uncertain inputs, with an emphasis on the efficiency and accuracy<br/>of the new methods so that they are applicable to large-scale, <br/>realistic engineering applications. This objective will be attained <br/>through three major efforts: (1) employing rigorous mathematical <br/>theory to form a unified framework that allows one to conduct <br/>systematical analysis and error estimates; (2) employing the <br/>state-of-the-art stochastic algorithms to construct a set of high <br/>performance design algorithms for two major classes of <br/>uncertainty-based design: robust design and reliability design;<br/>and (3) extending the new methods to large-scale complex systems<br/>and developing fast and parallel solvers.<br/><br/>Quantifying uncertainty is of paramount importance in almost all <br/>aspects of science and engineering. It is of particular significance <br/>in modern-day strategic planning and risk management where decisions <br/>are made in a constantly changing landscape with many unknown <br/>factors. Examples such as epidemic control, aircraft optimization <br/>under extreme conditions, optimal response following natural <br/>disasters, etc, are abundant. Such problems are essentially design <br/>and optimization in a complex and multidisciplinary environment, <br/>with substantial uncertainty interacting in a highly nonlinear fashion <br/>in the systems and parameters. While simulation based design tools <br/>continue to be advanced at rapid rates, little attention has been <br/>paid to incorporation of state-of-the-art mathematical techniques <br/>in stochastic analysis and uncertainty quantification. The traditional <br/>approaches, e.g., those by using safety factors to accommodate <br/>uncertainty in a gross manner, are becoming increasingly obsolete and <br/>often result in overly conservative decisions. This project is valuable <br/>for its multi-disciplinary influence, its fundamental contribution to <br/>uncertainty-based design problems, and more importantly, its high <br/>performance stochastic design algorithms the provide better and sharper <br/>analysis for decision makers. The project will unite a collection of <br/>uncertainty-based design techniques scattered over various engineering <br/>applications with the cutting-edge stochastic computation framework.<br/>It is a true synergy of Computational Mathematics tools and practical<br/>demands, and can be extended to a large class of design and optimization<br/>problems.<br/>"
"0649084","The 13th International Conference on Applications of Computer Algebra","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","08/28/2007","Tanush Shaska","MI","Oakland University","Standard Grant","Junping Wang","08/31/2008","$6,000.00","","shaska@oakland.edu","530 Wilson Hall","Rochester","MI","483094401","2483704116","MPS","1271","0000, 7556, 9263, OTHR","$0.00","Computer and Computational Algebra is a fast growing field with<br/>many applications in education, science, engineering, medical fields,<br/>etc. To develop and explore such applications close cooperation is<br/>needed between mathematicians, computer scientists, engineers, and<br/>scientists. To facilitate such cooperation the Department of Mathematics<br/>at Oakland University is organizing an international conference<br/>during the month of July 2007 at Oakland University. The main goals<br/>of this conference will be to promote the applications of Computer<br/>Algebra and Symbolic Computation and to bring together researchers<br/>from mathematics, computer science, engineering, and other sciences<br/>in order to further cooperation.<br/><br/>The applications discussed in the conference are important in areas<br/>such as education, mathematics, computer science, electrical engineering,<br/>industrial applications etc. For example, one of the sessions is<br/>organized by Charles Wampler who is the head of the GM Research<br/>and Development group on robotics. The group's main activities are<br/>based on techniques which make heavy use of computer algebra. These<br/>techniques will be discussed in detail in the conference and will introduce<br/>other researchers and students to the needs of the auto industry,<br/>which is quite important for the economy of the Detroit area. Other<br/>applications include coding theory and cryptography which are very<br/>important decoding terrorist threats and securing safe communication<br/>channels. Several of the session organizers are members of the NATO<br/>Advanced Study Institute which will be organized in Albania in 2008.<br/>This summer institute is funded by NATO and aims at training mathematicians,<br/>computer scientists, and engineers from Eastern Europe<br/>and Mediterranean countries to monitor the terrorist elements in those<br/>countries. Finally, the organizers of the Applications of Computer Al-<br/>gebra (ACA) conference at Oakland University hope that the new ideas<br/>generated in this conference will have direct impact on industrial applications<br/>and combating terrorism."
"0714087","Nonlocal Variational Processing of Image Albums","DMS","COMPUTATIONAL MATHEMATICS","07/15/2007","04/04/2009","Guy Gilboa","CA","University of California-Los Angeles","Continuing Grant","Leland Jameson","06/30/2011","$101,786.00","","gilboa@math.ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","MPS","1271","0000, 9263, OTHR","$0.00","The proposed activity is targeted to present a very general regularization framework. It enhances the processing of sets of signals and images using variational techniques.  The key idea is to exploit information from the entire set for the regularization of each image. This is done via a non-parametric variational approach.<br/><br/>This framework can improve image and signal processing techniques for many types of data-sets.<br/>Sets which contain many repetitions of similar objects or patterns are expected to gain considerable performance. Such data-sets are common in many diverse fields. The new method is anticipated to have a significant contribution in the analysis of medical images, the enhancement of aerial and satellite imagery, and in processing biological signals and genetic data.<br/>"
"0712809","Algebraic and Geometric aspects of Optimization","DMS","COMPUTATIONAL MATHEMATICS","09/01/2007","08/24/2007","Leonid Faybusovich","IN","University of Notre Dame","Standard Grant","Leland Jameson","08/31/2012","$139,724.00","","leonid.faybusovich.1@nd.edu","940 Grace Hall","NOTRE DAME","IN","465565708","5746317432","MPS","1271","0000, 9263, OTHR","$0.00","The following three topics are discussed in the project: computable self-concordant barrier functions, Jordan-algebraic aspects of optimization, and multi-dimensional trigonometric programming.  The overall goal of the project is to develop new computational and theoretical tools to address complicated nonconvex optimization problems including NP-hard problems of combinatorial optimization.  In particular, computable self-concordant barriers for the cone of so-called copositive matrices and more general polynomial cones are discussed.  Development of interior-point algorithms based on such barriers would open a totally new venue for the numerical analysis of various complex practical optimization problems, where the (approximate) knowledge of a global optimum is desirable.<br/><br/>Concrete approaches are proposed to the use of Jordan-algebraic techniques for constructing treatable convex relaxations for a very general class of nonconvex optimization problems and to robust optimization.  Proposed ideas for the transformation of polynomial programming problems into trigonometric counterparts may lead to significantly improved numerical stability of existing algorithms based on semi-definite programming approximations.<br/><br/>Optimization problems play a very important role in a wide spectrum of applications.  But existing algorithms and software allow one to reliably analyze only a very limited class of structured convex optimization problems, if the goal is to find a global optimum.  The present project aims to contribute to the problem of finding global optimal solutions (or their reasonable estimates) for a much broader and more difficult class of optimization problems which includes (but is not limited to) various types of NP-hard problems of combinatorial optimization."
"0707339","Interaction between flow and topography in interfecial electrohydrodynamics","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","08/15/2007","06/10/2011","Peter Petropoulos","NJ","New Jersey Institute of Technology","Continuing grant","Henry A. Warchall","07/31/2012","$248,199.00","Demetrios Papageorgiou","peter.g.petropoulos@njit.edu","University Heights","Newark","NJ","071021982","9735965275","MPS","1266, 1271","0000, 7237, 9263, OTHR","$0.00","A systematic study of electric field effects on nonlinear free surface flows is proposed. Applications can be found in coating and cooling problems where liquid films are used to enhance heat or mass transfer, and fluid management in microfluidics devices (for example lithographically induced self-assembly technologies).  Highly viscous flows are considered because inertia is absent in many important applications. The problems are nonlinear and mathematically challenging because they require the simultaneous solution of the equations of fluid mechanics and of the Maxwell equations. Two basic mathematical approaches are developed. The first is a fully nonlinear numerical method based on a  boundary integral equation formulation. This leads to a large system of integral equations which describe the motion and the electric field in each fluid. These equations are coupled by nonlinear boundary conditions and a stable numerical method is derived. The second approach is an asymptotic method based on long wave approximations. It leads to simpler partial differential equations whose range of validity is determined by comparing solutions with those obtained by the first approach. Analysis and computations will be used to solve for the spatio-temporal evolution of electrified coating flows over flat and variable substrates as well as the evolution of microfluidic layers under the action of electric fields in the presence of topographically structured electrodes. Of major interest is the use of electric fields to manipulate the interfacial evolution and possible robust coherent structures such as nonlinear steady- or large-time states.<br/><br/>In the high-tech world of ever decreasing machinery sizes and their components, it is vitally important to be able to construct models and study fundamental aspects of different processes. A mathematical model that can be put on a computer and solved, provides us with a rare opportunity to perform numerical experiments rather than laboratory experiments which can be both time consuming and expensive. The mathematical/computational model becomes an exploratory tool to refine the design of existing processes and at the same time to probe new regimes efficiently. It is important to produce valid mathematical models and resolve them accurately using computers.  The present study develops and studies such models with applications in coating of microelectronic components and the production of micro- and nano-sized structures in microelectronics applications.  Many components are coated with a liquid which solidifies to form the desired surface (e.g. DVD disks).  Any waves that form at the liquid surface and then get inherited in the final product after solidification, produce defects and degrade performance.   This study examines, theoretically, ways to control such features.  It also examines models that describe the formation of nano-sized features on microelectronic devices that can be used to produce micro-chips. The goal is to study and produce a theoretical protocol to control the waves that form during the liquid phase and before solidification.<br/>"
"0712974","Conference on Frontiers in Applied and Computational Mathematics (FACM): Spring 2007","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY, CCLI-Type 1 (Exploratory)","06/01/2007","05/18/2007","Daljit Ahluwalia","NJ","New Jersey Institute of Technology","Standard Grant","Mary Ann Horn","05/31/2008","$20,000.00","Peter Petropoulos","daahlu@m.njit.edu","University Heights","Newark","NJ","071021982","9735965275","MPS","1266, 1271, 7334, 7494","0000, 7317, 7556, 9178, OTHR, SMET","$0.00","The Department of Mathematical Sciences and the Center for Applied Mathematics and Statistics at the New Jersey Institute of Technology will be organizing and hosting a major conference on Frontiers in Applied and Computational Mathematics, May 14-16, 2007. This conference is the fourth in a series of conferences and for the first time it will include a significant component devoted to undergraduate student research (Undergraduate Research Day, May 14).  The first two conferences (2004, 2005) brought together more than 400 applied mathematicians working at the frontiers of mathematical biology, fluid mechanics, nonlinear waves, high-performance scientific computing, and applied statistics. The third conference (2006) focused on mathematical fluid dynamics and its applications in engineering and biology, and brought together more than 100 mathematicians from around the world to interact and present the latest advances in their respective fields.<br/><br/>The key theme of the 2007 Frontiers in Applied and Computational Mathematics conference will be the mathematical modeling of difficult real-world problems in mathematical biology and the health sciences with a significant component comprising of the mathematics of fluids, linear and nonlinear waves, high-performance scientific computing, and applied statistics. Among the impacted technological areas are fiber-optic communication systems, ocean-wave dynamics, and fluid flow in pipes. The conference will bring together renowned mathematicians and scientists from the US and abroad to interact as they present their latest research results to a large audience that also contains significant numbers of undergraduate and graduate students, postdoctoral fellows, and junior faculty. The program of the conference will have 4 plenary speakers and 48 minisymposium speakers."
"0652535","FRG: Collaborative Research: Dynamics of elastic biostructures in complex fluids","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY","07/01/2007","05/31/2007","Robert Dillon","WA","Washington State University","Standard Grant","Mary Ann Horn","06/30/2011","$211,744.00","","dillon@math.wsu.edu","280 Lighty","PULLMAN","WA","991641060","5093359661","MPS","1266, 1271, 7334","0000, 1616, OTHR","$0.00","Problems in biological fluid dynamics typically involve the interaction of an elastic structure with a surrounding fluid. Mucus transport by cilia in the respiratory tract, sperm penetration of the oocyte in fertilization, and peristaltic contractions of the oviduct are examples of such interactions. Many biological fluids are actually complex; that is they are not liquids or mixtures of a simple molecular structure that yields Newtonian responses, but instead have complicated non-Newtonian mechanical responses that arise, usually, because they have suspended microstructure. While much progress has been made in the development of mathematical models and numerical methods for fluid-structure interactions in a Newtonian fluid, much work needs to be done in the case of complex fluids. This focused research group will use a combination of analytical, computational and experimental tools to investigate the dynamics of elastic structures coupled to a complex fluid. Accurate and robust numerical methods for viscoelastic fluids coupled to moving and flexible boundaries will be developed that build upon classical immersed boundary methods and particle methods previously designed for Newtonian fluids. Continuum descriptions of the viscoelastic fluid will be implemented, as well as models that track discrete viscoelastic microstructure of the fluid. While the methods developed will be widely applicable, the team will focus upon the biofluidmechanics of reproduction, nematode motility in microfluidic chambers, as well as mucus-ciliary transport. Computational models will be coordinated with physical and biological experiments performed at the Applied Mathematics Lab at the Courant Institute.<br/><br/>Mathematics has had a huge impact on engineering and the physical sciences through its development of theoretical analyses and numerical methods for Newtonian fluid flows. The dynamics of complex fluids is emerging as another such opportunity, and is one which draws some of its richest problems from new areas in biophysics and engineering, medicine and reproductive health, and from core biology. The integration of mathematical and computational analysis into biological science presents educational challenges and great opportunities. This research project embraces these challenges, and is based upon collaborations of investigators at four institutions - Tulane University, New York University, Washington State University and the University of California, Los Angeles. A central component of this project is the training of graduate students and postdoctoral researchers. This FRG project will sponsor two summer programs, where the postdoctoral researchers and graduate students will spend six weeks at the Applied Mathematics Lab at Courant Institute. This will provide opportunities for all the students and postdocs involved in the project to work together side by side, develop a comprehensive understanding of the various aspects of the research, and experience and participate in the life of a working fluids lab."
