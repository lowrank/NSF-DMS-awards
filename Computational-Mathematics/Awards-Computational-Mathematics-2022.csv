"AwardNumber","Title","NSFOrganization","Program(s)","StartDate","LastAmendmentDate","PrincipalInvestigator","State","Organization","AwardInstrument","ProgramManager","EndDate","AwardedAmountToDate","Co-PIName(s)","PIEmailAddress","OrganizationStreet","OrganizationCity","OrganizationState","OrganizationZip","OrganizationPhone","NSFDirectorate","ProgramElementCode(s)","ProgramReferenceCode(s)","ARRAAmount","Abstract"
"2142724","Combinatorial, Computational, and Applied Algebraic Geometry, Seattle 2022","DMS","ALGEBRA,NUMBER THEORY,AND COM, COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY, Combinatorics","06/01/2022","04/22/2022","Jesus De Loera","CA","University of California-Davis","Standard Grant","Stefaan De Winter","05/31/2023","$44,999.00","","deloera@math.ucdavis.edu","1850 RESEARCH PARK DR, STE 300","DAVIS","CA","956186153","5307547700","MPS","1264, 1271, 7334, 7970","7556, 9263","$0.00","The conference ""Combinatorial, Computational, and Applied Algebraic Geometry --Seattle 2022 (CCAAGS-22)? will take place 27 June to 1 July 2022 at University of Washington Seattle. Algebraic Geometry is broadly interpreted to be the part of mathematics that studies systems of polynomial equations and inequalities. While Algebraic Geometry has often been considered a solely pure area of mathematics, the community of researchers of CCAAGS-22 promotes its applied and computational nature. Participants of CCAAGS-22 combine Algebraic Geometry with the techniques and methods from symbolic and numeric computation, algorithms, complexity theory, as well as problems motivated by applications in multiple fields. These methods have already seen applications in biology, coding theory, cryptography, combustion, computational geometry, computer graphics, quantum computing, control theory, geometric design, complexity theory, machine learning, nonlinear partial differential equations, optimization, robotics, and statistics, among others. The interaction between algebraic geometry and any of these other disciplines is beneficial for both sides.<br/><br/>This conference brings together researchers and promotes interdisciplinary work in a fast growing area. After the lack of contact during the pandemic, this is a long overdue event. It is particularly useful for junior researchers whose careers strongly depend on making connections and networking. CCAAGS-22 is indeed planned with junior researchers and underrepresented groups as the primary audience we want to attract. For more details see https://sites.google.com/view/ccaaggs-22/home<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2154556","Conference on Frontiers in Applied and Computational Mathematics (FACM-2022): New Perspectives in Mathematical Biology","DMS","COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY","05/01/2022","04/29/2022","Victor Matveev","NJ","New Jersey Institute of Technology","Standard Grant","Zhilan Feng","04/30/2023","$32,182.00","Amitabha Bose","matveev@njit.edu","323 DR MARTIN LUTHER KING JR BLV","NEWARK","NJ","071021824","9735965275","MPS","1271, 7334","7556, 9263","$0.00","This award supports participation of graduate and undergraduate students, junior faculty and postdoctoral fellows in the Conference on Frontiers in Applied and Computational Mathematics (FACM-2022): New Perspectives in Mathematical Biology conference, held May 20-21, 2022, at New Jersey Institute of Technology (NJIT) in Newark, New Jersey. This conference will bring together researchers applying advanced mathematical modeling tools to diverse problems in the life sciences ranging from cell biology to collective behavior of biological populations, allowing them to share ideas and form new connections across disciplines to tackle challenging problems of broad scientific and societal importance. The conference will host approximately 100 participants, with at least 70% of attendees comprising students, postdocs, and early-career faculty. Travel support will be specifically targeted to support the participation of junior researchers, particularly those from groups under-represented in mathematics and the life sciences, helping in the advancement of their career paths.<br/><br/>This conference is part of the series of annual conferences ?Frontiers in Applied and Computational Mathematics'' (FACM) held annually at NJIT. In the years since the first FACM meeting, held in 2004. This year the conference will focus on several specific but sufficiently broad areas of mathematical and computational modeling in the life sciences, spanning multiple levels of organization: (1) emergent collective behavior in large biological populations, (2) machine learning and data-science approaches in the study of biofluids, (3) learning paradigms in biological and artificial neuronal networks, and (4) stochastic modeling in biology at different scales. The conference will also highlight the most cutting-edge modeling approaches in the life sciences that combine data science techniques with the tools of applied and computational mathematics. Bringing together researchers working in these diverse fields will lead to important cross-pollination of ideas and new collaborations that may not otherwise be possible. Further, the conference would expose junior researchers (graduate and undergraduates students, postdoctoral fellows, and early career faculty) to these fundamental questions and the advanced inter-disciplinary tools for addressing these challenges, which they will use in their studies and future careers in science and technology.<br/><br/>Conference web site: https://sites.google.com/njit.edu/facm2022/home<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208467","Hybrid Kinetic Monte Carlo Methods with Applications in Biofabrication and Epidemics","DMS","COMPUTATIONAL MATHEMATICS, MSPA-INTERDISCIPLINARY","08/15/2022","08/09/2022","Yi Sun","SC","University of South Carolina at Columbia","Standard Grant","Yuliya Gorb","07/31/2025","$176,321.00","","yisun@math.sc.edu","1600 HAMPTON ST # 414","COLUMBIA","SC","292083403","8037777093","MPS","1271, 7454","068Z, 9150, 9263","$0.00","The coronavirus disease 2019 (COVID-19), caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has rapidly spread throughout the world. By July 30, 2022, more than 577 million cases and over 6.4 million fatalities have been reported, making it one of the deadliest pandemics to date. Over recent decades other epidemics such as HIV/AIDS, hepatitis, SARS, H1N1 swine flu, Ebola, Zika, measles, malaria, and tuberculosis have also caused tens of millions of deaths. To combat the pandemics of emergent and re-emergent infectious diseases, mathematical modeling and simulation plays an important role in predicting, assessing, and controlling potential outbreaks. Endothelial network formation is a critical process in fabricating functional vascular constructs, and it is a very crucial impediment in the state-of-the-art biofabrication technology. The goal of this project is to develop new hybrid kinetic Monte Carlo (KMC) methods and algorithms for the study of complex biological systems and problems arising in epidemics and biofabrication. This project will provide multidisciplinary research training to graduate and undergraduate students interested in both computational mathematics and mathematical biology/computational epidemiology.<br/><br/>In the thrust (1), to study spatial and temporal dynamics of epidemics, the PI proposes to develop a hybrid KMC method with focuses on the mobility and heterogeneity of individuals and spatial structures as critical aspects in determining possible outcomes for an epidemic. The proposed model describes the motion of individuals on a discrete lattice with moving rates between neighboring sites and couple the SIR-like transition mechanism to describe the conversion between individuals' health states. In the thrust (2), the PI plans to develop another hybrid KMC model with focuses on cell motility, cell-matrix and cell-cell interactions in endothelial network formation. The approach combines a hybrid mechanochemical model with the KMC algorithm to enhance the capability of the computational modeling platform in studying cell-cell and cell-matrix interactions significantly.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208277","Reduced Basis Enhancements of Neural Networks and Their Application to Quantum Materials Simulation","DMS","COMPUTATIONAL MATHEMATICS","08/01/2022","08/01/2022","Yanlai Chen","MA","University of Massachusetts, Dartmouth","Standard Grant","Stacey Levine","07/31/2025","$296,555.00","Sigal Gottlieb","yanlai.chen@umassd.edu","285 OLD WESTPORT RD","NORTH DARTMOUTH","MA","027472356","5089998953","MPS","1271","079Z, 7203, 9263","$0.00","This project combines two types of numerical techniques, one traditional and the other nascent, in the context of efficient multi-parametric simulations. The project aims to develop a new algorithm based on deep neural networks that will be applied to the simulation of quantum materials in the field of two-dimensional materials twistronics toward a fast and accurate configuration-to-performance map. Outcomes of this project are expected also to benefit the greater scientific community that utilizes supervised machine learning for parameterized models. Software associated with this project will be made freely available. The project involves development of graduate coursework and the training of undergraduate and graduate students through involvement in the research. <br/><br/>The need to understand the behavior of a system efficiently and accurately under variation of many underlying parameters is ubiquitous yet challenging due to the prohibitively high computational cost. Two techniques stand out in addressing this challenge, the more traditional reduced basis method and the newer deep neural networks. This project aims to combine these two techniques to build an analysis-driven computational emulator for the parameter-to-solution map of parameterized partial differential equations and to apply the resulting algorithm to the field of 2D materials twistronics. The first theme of the project involves reducing the generalization gap (performance of the trained network on data unseen during training) of certain machine learning algorithms by tapping the potential of a rigorous mathematical approach in judiciously generating computationally cheap training data in an intrinsically multi-level and multi-resolution fashion. The focus of the second theme is the development of novel numerical discretizations and their corresponding fast algorithms for a class of nonlinear partial differential equations that has direct application in optimal mass transport. Finally, the project aims to provide a systematic and rigorous study of parameterized 2D materials simulation, including the recently discovered magical angle twisted bilayer graphene.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208404","Finite Element Methods for Elliptic Least-Squares Problems with Inequality Constraints","DMS","COMPUTATIONAL MATHEMATICS","07/01/2022","05/26/2022","Susanne Brenner","LA","Louisiana State University","Standard Grant","Yuliya Gorb","06/30/2025","$361,251.00","Li-yeng Sung","brenner@math.lsu.edu","202 HIMES HALL","BATON ROUGE","LA","708030001","2255782760","MPS","1271","9150, 9263","$0.00","Least-squares problems appear naturally in data fitting, where the parameters in a mathematical model are calibrated by minimizing the discrepancy (measured by a sum of squares) between the observed data and the output predicted by the model.  They also appear naturally in solving nonlinear equations by optimization methods. The goal of this project is to develop novel numerical schemes for least-squares problems that appear in data fitting with infinitely many parameters, such as the determination of the flux of groundwater from the observed pressure, and for least-squares problems that appear in solving nonlinear equations with infinitely many unknowns, such as the equation for an optimal transport map. The equations in both settings are elliptic equations that describe steady-state problems in science and engineering, and a priori information on the underlying problems is included in the form of inequality constraints.  The numerical schemes are based on finite element methods, one of the leading methodologies in computational engineering and science. The outcomes of this project will provide new tools for the optimal design process in engineering and materials science, and new methodologies for image processing and data science. The project provides research training opportunities for graduate students.<br/><br/>Two classes of infinite dimensional least-squares problems with inequality constraints that involve elliptic partial differential equations will be investigated. The first class is concerned with elliptic distributed optimal control problems with pointwise state and control constraints. The second class is concerned with solving fully nonlinear elliptic boundary value problems with convexity constraints on the solutions. For the elliptic optimal control problems, novel finite element methods will be developed for problems with general cost functions that include point tracking problems for the state as a special case, problems with constraints on the gradient of the state, and problems constrained by elliptic equations with rough coefficients. For the fully nonlinear elliptic boundary value problems, finite element methods for their classical solutions will be investigated.  They include equations of the Monge-Ampere type where the convexity of the solutions plays a key role, such as the first and second boundary value problems for the Monge-Ampere equations in two and three dimensions, and the Dirichlet boundary value problem for the prescribed Gaussian curvature equation in two dimensions.  The 2-Hessin equation in three dimensions will also be treated, where the condition on the positivity of the Laplacian  of the solution is the analog of the convexity condition on the solutions of the Monge-Ampere equations. A common theme  for the research in these two classes of problems is the interplay among elliptic partial differential equations, optimization, and finite element technology such as discontinuous Galerkin methods, multiscale finite element methods, virtual element methods, and convexity enforcing finite element methods.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208314","Robust Preconditioned Gradient Descent Algorithms for Deep Learning","DMS","COMPUTATIONAL MATHEMATICS","08/01/2022","08/05/2022","Qiang Ye","KY","University of Kentucky Research Foundation","Standard Grant","Stacey Levine","07/31/2025","$335,978.00","","qye3@uky.edu","500 S LIMESTONE","LEXINGTON","KY","405260001","8592579420","MPS","1271","079Z, 9263","$0.00","Deep learning is at the forefront of research in artificial intelligence and machine learning, impacting a variety of applications in data science such as computer vision, speech recognition, natural language processing, and bioinformatics. A key challenge in deep neural network learning is model optimization, which is used for network training. However, traditional optimization algorithms are not applicable, primarily due to the high complexity and nonlinearity of deep neural networks. The goal of this project is to develop novel robust optimization algorithms that can effectively address these difficulties and can more efficiently train deep learning models in practice. The project also involves the application of this work to the translation of equivalent chemical representations used in drug design as well as  Bayesian inference for uncertainty quantification. As part of this project, graduate and undergraduate students will be trained in deep learning research, and software will be developed and made freely available.<br/><br/>This project includes the development of two new classes of optimization algorithms that are built on the frameworks of traditional preconditioning and conjugate gradient methods but incorporate ideas from some successful specialized deep learning optimizers such as normalization methods and momentum methods. Specifically, the project will develop a new class of preconditioning methods as a widely applicable alternative to the normalization methods and a new class of adaptive momentum methods as a robust alternative to the fixed momentum methods. Related convergence theory will be established, and the new methods will be adapted to state-of-the-art neural network architectures such as transformer and graph neural networks. The novel algorithms developed in this project intend to bring some of the most fruitful ideas in numerical analysis to the advancement of neural network optimization.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2245192","CAREER:  Integrated Approaches for Fast and Accurate Large-Scale Inversion","DMS","COMPUTATIONAL MATHEMATICS","12/01/2022","12/29/2022","Julianne Chung","GA","Emory University","Continuing Grant","Yuliya Gorb","08/31/2023","$20,237.00","","jmchung@emory.edu","201 DOWMAN DR","ATLANTA","GA","303221061","4047272503","MPS","1271","1045, 9263","$0.00","The ability to compute solutions to inverse problems is essential in various scientific applications (e.g., for cancer diagnosis or for crack detection in underground mines), but computing real-time solutions to large nonlinear problems that incorporate physics- or data-informed constraints is not feasible with current inversion algorithms. Moreover, as numerical solutions to inverse problems are increasingly being used for data analysis and to aid in decision-making, these computational limitations pose significant bottlenecks in algorithms for uncertainty quantification (e.g., for estimating solution variances). The overarching goal of this project is to significantly reduce the costs of numerical inversion and to enable statistical tools to aid scientists in making informed decisions.  These developments will lead to scientific advancement in many important fields. For example, existing collaborations with biomedical and mining engineers will ensure that the proposed research can result in improved medical diagnosis via advanced point-of-care imaging technologies, fewer injuries due to improved ground control monitoring of underground mines, and advanced signal estimation for real-time analysis of physiological systems. Moreover, the PI will continue to actively engage in activities that encourage students from historically under-represented groups.  The PI's focus on upper elementary to high school girls and on outreach that will feed back into the greater research and teaching communities (e.g., K-12 teachers) will contribute to the recruitment, training, and retention of a diverse next generation of computational scientists.<br/><br/>This research will advance knowledge in the field of computational inverse problems by developing faster methodologies and more robust frameworks for the design, computation, and analysis of solutions to inverse problems. An integrated framework will be adopted, where the main research thrusts are (i) to develop novel regularization methods and implementations to handle application-specific constraints, while simultaneously incorporating robust parameter selection methods; (ii) to advance technologies for real-time computation of solutions to large, nonlinear inverse problems (e.g., by integrating stochastic methods and update approaches); and (iii) to enable critical, yet previously unobtainable, quantitative diagnostics for complex, nonlinear systems by developing efficient error estimation methods."
"2208412","Collaborative Research: Robust Acceleration and Preconditioning Methods for Data-Related Applications: Theory and Practice","DMS","COMPUTATIONAL MATHEMATICS","09/01/2022","05/24/2022","Yuanzhe Xi","GA","Emory University","Standard Grant","Yuliya Gorb","08/31/2025","$200,000.00","","yxi26@emory.edu","201 DOWMAN DR","ATLANTA","GA","303221061","4047272503","MPS","1271","079Z, 9263","$0.00","In many disciplines of science and engineering one often encounters sequences of numbers or vectors or other mathematical objects. A common goal in these situations is to obtain the limit of the sequence inexpensively. As a simple example, there are several ways to generate a sequence of numbers that converge to the number pi and some sequences will reach the limit pi rather quickly. In some cases, it may be possible to modify the original method that produced the sequence to obtain a faster converging one. However, this is not always possible or cost-effective because the process by which the sequence is produced is not explicit or it may be too cumbersome for this approach to be practical. Another common solution is to transform the sequence, by 'accelerating it'. This usually entails combining the terms of the sequence to produce new entries that reach the limit faster. So far, acceleration methods were developed by mathematicians and (quantum) physicists to deal with a wide range of problems from the physical sciences. The primary goal of this project is to study such acceleration methods and to adapt them to the modern era by focusing on topics related to machine learning and, more generally, data sciences. This collaborative research project between researchers at Emory University and the University of Minnesota, will develop and study theoretically a number of robust acceleration algorithms with an emphasis on problems that stem from data-related applications, as well as train graduate students in this field of study. <br/><br/>The need to accelerate numerical sequences of various types has frequently been felt across a wide range of disciplines and it has been addressed by many researchers for quite some time. In the past, such acceleration or extrapolation schemes were targeted mainly toward sequences of vectors that arise from physical simulations, e.g., the sequence of potentials generated by the Self Consistent Field (SCF) iterations in quantum physics. In recent years, the rapid expansion of machine learning methodologies across a great variety of disciplines has generated new demand for algorithms to accelerate sequences of various types. However, the new type of sequences encountered in these applications differ in fundamental ways from their analogues in physical simulations. In contrast with the common setting required in, e.g., quantum physics, calculations in machine learning are often performed in single or half precision instead of double precision. Furthermore, in neural networks these sequences tend to be very irregular because they originate from stochastic gradient  approaches. The collaborative team from Emory University and the University of Minnesota, will develop and study theoretically a number of robust acceleration algorithms with an emphasis on their application to irregular sequences such as those encountered in data-related applications. The investigating team will study a number of strategies for improving the robustness of standard acceleration schemes, such as Anderson mixing, or the epsilon algorithm. A number of recently advocated second-order methods, based on (so-called) momentum ideas, have been shown to be of great help in accelerating standard stochastic gradient descent methods in Deep Learning. The investigators will add to these schemes another method of the same class that is grounded in Chebyshev acceleration. One advantage of the Chebyshev-based scheme is that it is fairly easy to study theoretically in part because it is well understood for linear problems. In a second research direction, the investigating team will study acceleration methods in the specific context of machine learning tasks. For example, inspired by recent advances in parameter averaging and variance reduction schemes they will explore the application of classical extrapolation methods to stochastic gradient sequences as an adaptive extrapolation procedure. Experiments show that parameter averaging is key to the success of acceleration procedures. Just as important is the selection of the vectors to accelerate. Along the same lines, robust acceleration schemes will be designed and studied for sequences hampered by low precision arithmetic.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208289","Dual Finite Element Methods for Challenging Computations","DMS","COMPUTATIONAL MATHEMATICS","09/01/2022","08/02/2022","JaEun Ku","OK","Oklahoma State University","Standard Grant","Yuliya Gorb","08/31/2025","$188,904.00","","jku@okstate.edu","401 WHITEHURST HALL","STILLWATER","OK","740781031","4057449995","MPS","1271","9263","$0.00","This research project develops a new finite element method(FEM) for the approximation solutions of partial differential equations.  FEMs are powerful tools in scientific computing and their applications include biomedical engineering, environmental engineering, material and manufacturing, structural engineering, and more.  While current methods are successfully used for many problems in these applications, there are plenty of numerically challenging problems such as interface problems arising from multiphysics and biological systems, and sign changing problems from the transmission problems with metamaterials.  In addition to advancing knowledge within the field of computational mathematics, this project will provide new efficient tools for the problems which current methods have difficulties calculating accurate and efficient approximations.  The success of this project will lead to new computational methods with a wide variety of applications. This project will also support education by training graduate and undergraduate students.<br/><br/>The purpose of this project is to develop a new finite element method for accurate and efficient approximations of dual variables.  For accurate approximations of the dual variables, traditional numerical methods such as least-squares or mixed FEMs increase the degrees of freedom significantly, and the resulting algebraic equations could be indefinite.  The proposed research develops a new method that approximates only the dual variables without approximating the primary variable.  This results in a smaller problem size and the resulting algebraic equations have symmetric and positive definite matrices.  Various error estimates will be developed, including a posteriori error estimates for adaptive procedures. This dual based FEM shows superior performance when it is applied to singularly perturbed problems.  This project will address the application of this approach to numerically challenging problems such as discontinuous coefficient, sign changing problems, linear elasticity, and Stokes equations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2245674","Scalable Computational Methods for Large-Scale Stochastic Optimization under High-Dimensional Uncertainty","DMS","COMPUTATIONAL MATHEMATICS","09/01/2022","02/10/2023","Peng Chen","GA","Georgia Tech Research Corporation","Continuing Grant","Yuliya Gorb","08/31/2024","$235,622.00","","pchen402@gatech.edu","926 DALNEY ST NW","ATLANTA","GA","30332","4048944819","MPS","1271","9263","$0.00","Large-scale simulation in computational science and engineering is often carried out not only to obtain insight about a system, but also as a basis for decision-making. When the decision variables represent the design or control of an engineered or natural system, and the system is governed by partial differential equations (PDEs) with uncertain input due to lack of knowledge or intrinsic variability, the task of determining the optimal design or control leads to a PDE-constrained stochastic optimization problem. Such problems abound across all areas of science and engineering. Examples include optimal control of subsurface flows, plasma fusion reactors, and chemical and materials processes; optimal structural design of aerospace, automotive, and civil infrastructure systems; and shape, layout, or topology optimization of biomedical, electronic, and nano-structured devices. There are several critical challenges in solving such problems including high dimensionality stemming from uncertainty and/or optimization variable spaces, and the need to solve large-scale PDEs with numerous  samples of the uncertain parameters. This project will develop, analyze, and implement scalable computational methods to make tractable the solution of large-scale PDE-constrained stochastic optimization problems under high-dimensional uncertainty. These methods will be applied to subsurface flow problems with societal impact; software will be developed and disseminated widely in open source form. Graduate students will be involved and will receive interdisciplinary training. <br/><br/>This project exploits the intrinsic structure of the stochastic optimization problems--in particular the intrinsic low dimensionality, smoothness, and geometry of the random parameter-to-objective map. Specifically, the components of the research include: (1) Analysis of the rank or spectrum decay of the Hessian of this map to prove intrinsic low-dimensionality for several classical stochastic PDE-constrained optimization problems. (2) Extension of local quadratic approximation-based stochastic optimization to that based on approximation of the Hessian as a translation invariant operator, higher order Taylor approximation, and multi-point Taylor approximation with mixture models. (3) Application to a specific large-scale and challenging problem of optimal flow control in a subsurface porous medium with a random permeability field. The methods developed in this project will apply to a wide class of PDE-constrained stochastic optimization problems. To make the methods accessible to broader communities and allow stochastic optimization specialists to prototype new algorithms and quickly run experiments, a Python library, SOUPy (Stochastic Optimization under high-dimensional Uncertainty in Python), will be implemented and released. Users will be able to rapidly prototype new PDE models and objective functions, as well as quickly implement new algorithms, conduct numerical experiments, and solve challenging problems in new domains in SOUPy.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208416","Towards Quantum Speedup for Solving High-Dimensional Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","08/15/2022","05/16/2023","Di Fang","CA","University of California-Berkeley","Continuing Grant","Yuliya Gorb","07/31/2025","$78,200.00","","difang@berkeley.edu","1608 4TH ST STE 201","BERKELEY","CA","947101749","5106433891","MPS","1271","9263","$0.00","Efficient simulation of high-dimensional partial differential equations has been one of the core tasks in many scientific areas. Recent advances of quantum technologies and algorithms revealed that quantum algorithms can be a new tool to overcome the curse of dimensionality, with the potential of achieving exponential speedups compared to classical implementations. The goal of this project is to investigate potential applications of quantum algorithms on efficiently solving high-dimensional differential equations. Taking advantage of the power of quantum mechanics, the newly proposed quantum algorithms and techniques are expected to significantly accelerate the simulation of such high-dimensional PDEs and give a cost depending poly-logarithmically on the total number of spatial grids and polynomially on the spatial dimension. The development of proposed projects will provide new prospects to overcome the curse of dimensionality in PDE simulations, to advance the state-of-the-art quantum algorithm designed for differential equations, and to help pave the path towards post-quantum scientific computing. On the educational side, the students involved will get good interdisciplinary training in both mathematics and quantum information science.<br/><br/>This project aims to develop efficient quantum algorithms for high-dimensional differential equations for both quantum and classical problems, and to establish rigorous error bounds and complexity estimates, and identify the problems that can and can not be efficiently handled quantumly. Such high-dimensional differential equations include the Schrodinger equation with applications to molecular dynamics, and other classical differential equations, such as reaction-diffusion equations emerging from biological applications. The following specific aspects will be addressed. For quantum dynamics simulation, the goal is to deal with dynamics simulation with unbounded operators, we explore techniques such as the vector norm scaling analysis, quantum highly oscillatory protocol in the interaction picture, and semiclassical/microlocal analysis addressing the multiscale aspects of the problem. For classical dynamics that can be non-unitary, we propose and explore time-marching strategies using block encoding oracles, and aim to provide a pedagogical description on quantum algorithms for stiff differential equations, pinpointing the differences between quantum algorithm design and classical numerical analysis.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2224003","Conference: The Seventh Annual Meeting of SIAM Central States Section","DMS","COMPUTATIONAL MATHEMATICS","09/01/2022","08/03/2022","Xu Zhang","OK","Oklahoma State University","Standard Grant","Stacey Levine","08/31/2023","$20,000.00","Xukai Yan","xzhang@okstate.edu","401 WHITEHURST HALL","STILLWATER","OK","740781031","4057449995","MPS","1271","7556, 9150, 9263","$0.00","The 7th Annual Meeting of Society of Industrial and Applied Mathematicians Central States Section (SIAM-CCS) will be held at the Stillwater campus of Oklahoma State University during October 1-2, 2022. The conference website is https://siamcss2022.okstate.edu/. The SIAM Central States Section (SIAM-CSS) was founded in 2014, and it serves SIAM members in eight central states in the United States, including Arkansas, Colorado, Iowa, Kansas, Mississippi, Missouri, Nebraska, and Oklahoma. The SIAM-CSS Annual Meeting has been held annually since 2015, with the primary goal of improving the development of applied and computational mathematics throughout all central states, as well as facilitating knowledge transfer and promoting interdisciplinary collaborations among applied mathematics and other disciplines in science and engineering. <br/><br/>The SIAM-CSS annual conference series provides an important forum for applied and computational mathematicians from central states to present their latest achievements, communicate and exchange ideas, and enhance collaborations. It provides an excellent opportunity for researchers in all stages of their careers, especially early career mathematicians, to establish interactions with researchers from all over the U.S. and other countries. It is essential in stimulating research activities in relatively less developed states. As the first face-to-face meeting after the pandemic, the conference will bring vitality to the applied math community in the region and promote the development of the discipline. This NSF grant will solely support the participation of students, postdoctoral scholars, early career faculty, and underrepresented groups in STEM.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2213723","Nonlocal School on Fractional Equations","DMS","COMPUTATIONAL MATHEMATICS","06/01/2022","05/20/2022","Harbir Antil","VA","George Mason University","Standard Grant","Yuliya Gorb","05/31/2023","$24,121.00","Pablo Raul Stinga","hantil@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","MPS","1271","7556, 9263","$0.00","This award supports participation in the Nonlocal School on Fractional Equations (NSFE) 2022, held on campus of Iowa State University on June 9 ? 11, 2022. Fractional (nonlocal) models in science and engineering can account for long range interactions and are notably flexible in being applicable to non-smooth scenarios. Motivated by these facts and several applications, this research area has attracted a significant amount of recent attention on both theoretical and computational fronts. Examples include novel fractional-derivative-based models in imaging, geophysics, plasmas, deep neural networks, minimal surfaces, and phase transitions. These emerging applications have created a need for development of a modern theory, new numerical methods, and subsequent control of the nonlocal fractional models. The NSFE 2022 meeting aims to address most of these topics. A primary goal of the school is to introduce students and early-career researchers to current trends in nonlocal equations, as well as to provide a vibrant networking environment. There will be two (three hour long) mini-tutorial style lectures and six invited talks from leading researchers in the field. <br/><br/>This meeting will advance knowledge in nonlocal modeling, optimal control, numerical analysis, implementation, and software development. These topics involve numerous aspects of probability theory, optimization and variational analysis, convex analysis, and applied and computational mathematics. The school aims to stimulate new developments in these important areas of mathematics and their application to finance, physics, biology, data science, and engineering. The meeting also aims to provide a unique opportunity for graduate students, postdocs, and other early career scientists to interact with leading researchers in fractional nonlocal models. The organizers are making a special effort to recruit participants from minority groups in STEM and from minority serving institutions. Videos of the lectures as well as lecture notes will be uploaded on the conference website: https://pabloraulstinga.github.io/NSFE2022.html<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2146191","CAREER: Towards Harnessing the Motility of Microorganisms: Fast Algorithms, Data-Driven Models, and 3D Interactive Visual Computing","DMS","COMPUTATIONAL MATHEMATICS, MATHEMATICAL BIOLOGY, MSPA-INTERDISCIPLINARY","08/01/2022","08/01/2023","Minghao Rostami","NY","Syracuse University","Continuing Grant","Stacey Levine","07/31/2027","$200,175.00","","mwrostam@syr.edu","900 S CROUSE AVE","SYRACUSE","NY","132440001","3154432807","MPS","1271, 7334, 7454","1045, 9263","$0.00","Due to their small size, microorganisms perceive a fluid as much ?stickier? than do fish or humans. Such small creatures must adopt a different strategy for efficient swimming. Many of them propel themselves in the fluid by wiggling micro-structures such as cilia and flagella. The remarkable efficiency of microorganisms at moving and navigating through a surrounding fluid has inspired recent construction of microfluidic devices for mixing and transport, and micro-machines for drug delivery and manipulation of cells. Since theoretical analyses and experimentation are challenging in this setting, mathematical modeling and numerical simulation have become indispensable in these developments. This project aims to create improved computational and visualization tools for advancing understanding of the motility of microorganisms and our capability to harness this process. The project will develop an interactive three-dimensional visual computing system to serve as (1) a research tool for studying the hydrodynamics of swimming microorganisms, (2) an engineering tool for testing and improving the design of artificial, bio-inspired micro-swimmers, and (3) an educational tool for introducing students of all levels to this field. The project will also provide direct training and research opportunities for undergraduate and graduate students, postdoctoral researchers, and high school teachers. The project includes plans to develop virtual reality games based on microswimmers to be exhibited at the Museum of Science & Technology as well as public libraries. <br/><br/>Research objectives in this project include the development of an efficient, multigrid-like method for manipulating the large, dense matrices arising from the simulation of interacting micro-swimmers, a data-driven, reduced order model for tracking fluid particles, an efficient numerical method for optimizing the design of bio-inspired swimmers given a task, and a three-dimensional interactive visual computing system for real-time fluid visualization and manipulation. Multigrid methods exploit the geometry of the swimmers and are therefore expected to be more efficient than current numerical approaches. An artificial neural network will be leveraged as a data-driven, reduced order model for the change in a fluid particle?s position. This approach is intended to simulate a fluid particle's trajectory very efficiently, since it does not require calculating fluid-structure interactions, an important aspect in real-time and/or multi-query scenarios. The planned numerical optimization method takes advantage of both the reliability of a genetic algorithm at finding global optima and the efficiency of a gradient-based method when a good initial guess is given. The interactive visual computing system is intended to serve as a virtual laboratory for analysis of the effects of parameter changes. This project is jointly funded by the Computational Mathematics and the Mathematical Biology Programs of the Division of Mathematical Science.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2144181","CAREER: Acceleration Methods, Iterative Solvers and Heterogeneous Architectures: The New Landscape of Large-Scale Scientific Simulations","DMS","COMPUTATIONAL MATHEMATICS, EPSCoR Co-Funding","09/01/2022","02/14/2022","Agnieszka Miedlar","KS","University of Kansas Center for Research Inc","Continuing Grant","Stacey Levine","05/31/2023","$237,272.00","","amiedlar@ku.edu","2385 IRVING HILL RD","LAWRENCE","KS","660457552","7858643441","MPS","1271, 9150","1045, 9150, 9263","$0.00","The rapidly changing landscape of traditional high-performance computing and the emerging technology of edge computing, used in smart grids, unmanned autonomous vehicles, and wearable healthcare devices, bring new challenges to modern scientific simulations. This project aims to enable new algorithmic and software advancements, particularly in the field of numerical linear algebra, to fully utilize these new heterogeneous architectures. The primary goal of this project is to provide computational building blocks for scalable implementation of numerical linear algebra, which is an essential and often indispensable component of simulation software. Methods developed as a part of this project will help computational physicists and chemists to efficiently identify and study promising novel materials and enable high fidelity numerical simulations to address the challenges at the frontiers of science and engineering. The research program is integrated with education and outreach activities that aim to build the future science and engineering workforce and stimulate public engagement with mathematics. The project provides undergraduate and graduate students with advanced training in critical science and technology skills as well as opportunities for interdisciplinary research on applications of global importance. The investigator also aims to increase local engagement and participation through STEM-promoting public events, provide K-12 students with hands-on computational mathematics education, as well as include members of underrepresented groups and enable their professional success.<br/><br/>The overarching goal of this research is to further the understanding of a broad class of extrapolation and nonlinear convergence acceleration techniques and explore their ability to enhance and extend existing solvers to fully utilize distributed and heterogeneous computing environments. Convergence acceleration methods have been successfully used in science and engineering for decades, but their rigorous mathematical underpinnings are still not fully understood. Moreover, iterative methods for computations in eigenvalue problems and general nonlinear systems are one of the most important research areas in computational mathematics. The project has the following research objectives: (1) provide a systematic mathematical study of nonlinear acceleration techniques; (2) develop accelerated, possibly asynchronous, iterative algorithms to solve linear systems with potential similar to the well-established Krylov subspace methods; (3) enable efficient and reliable eigenvalue computations by developing accelerated (block) iterative (non)linear eigenvalue/eigenvector solvers; (4) develop and validate new numerical linear algebra tools to support algorithmic developments in computational physics and chemistry. All the methods under development are intended for application to a wide range of complex science and engineering simulations in exascale and distributed computing environments.<br/><br/>This project is jointly funded by Computational Mathematics and the Established Program to Stimulate Competitive Research (EPSCoR).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208249","Collaborative Research: Adaptive Mixed-Dimensional Modeling and Simulation of Porous Media","DMS","COMPUTATIONAL MATHEMATICS","08/01/2022","07/27/2022","Ludmil Zikatanov","PA","Pennsylvania State Univ University Park","Standard Grant","Yuliya Gorb","07/31/2025","$210,272.00","Yuwen Li","ltz1@psu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271","9263","$0.00","The overall goal of this research project is to develop, analyze, and implement stable numerical methods for the simulation of flow in fractured porous media, based on mixed-dimensional modeling. Fractured porous media flow is multi-physics and multi-scale, and the development of robust and effective numerical tools for such systems represents a class of important challenges in computational mathematics. For example, in many practical applications fractures or other features, such as capillaries in the brain, are lower-dimensional and interact in a complex way through the three-dimensional domains encapsulating them. Important applications of fractured porous media include hydraulic fracturing, waste deposition, and models from biomechanics. The project aims to provide new computational paradigms, promote the usage of mixed-dimensional modeling in these and related fields, and alleviate current limitations in computer simulations. The techniques will be implemented in an open-source software package and will be made available to the scientific community. <br/><br/>In this project, three important aspects of mixed-dimensional modeling and simulation will be investigated. The first research objective is to design advanced stable discretizations, which couple stabilized schemes for linear elasticity with structure-preserving discretizations for Darcy flow in a mixed-dimensional setting.  Stability and mass conservation will be achieved using a minimal number of degrees of freedom. The second objective is adaptive approximations in the mixed-dimensional framework.  Space-time adaptivity will be developed and implemented to improve accuracy with solid theoretical foundations. The third objective is to study robust linear solvers for the resulting discrete linear systems.  Based on physical and mathematical properties of the mixed-dimensional models and their numerical discretizations, new block preconditioners and monolithic multigrid methods will be developed. Robustness with respect to physical and discretization parameters will be justified both theoretically and numerically. The main application of this project is linear poromechanics in fractured porous media, but possible generalizations to nonlinear formulations will also be investigated, including several applications in physics and engineering.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2212165","Conference: Women in Scientific Computing on Complex Physical and Biological Systems","DMS","COMPUTATIONAL MATHEMATICS, MSPA-INTERDISCIPLINARY","08/15/2022","08/03/2022","Chunmei Wang","FL","University of Florida","Standard Grant","Yuliya Gorb","07/31/2023","$27,445.00","Maia Martcheva, Sara Pollock","chunmei.wang@ufl.edu","1523 UNION RD RM 207","GAINESVILLE","FL","326111941","3523923516","MPS","1271, 7454","068Z, 1303, 5294, 7556, 9102, 9263","$0.00","The workshop ""Women in Scientific Computing on Complex Physical and Biological Systems'' will be held on the campus of the University of Florida (UF) in Gainesville, FL from Monday October 24 to Wednesday October 26, 2022. The workshop will bring together leading experts from various areas of computational mathematics, life science, computer science, and engineering to vigorously discuss recent developments in scientific computing on complex physical and biological systems with applications to climate change, clean energy, and biotechnology as well as to advance the state-of-the-art  developments in these rapidly developing fields. The workshop will provide a cross-disciplinary forum for catalyzing the research in scientific computing on complex physical and biological systems, facilitating rapid diffusion of new mathematical and computational methods into life science, computer science, and engineering,  and stimulating more researchers to work in these important areas. The workshop will consist of presentations, posters, panel discussions, group discussions and tutorial sessions which will stimulate an intensive exchange of ideas, foster fruitful interactions, identify challenges, promote interdisciplinary collaborations and initiate joint research projects. This award supports the attendance of both researchers and graduate students, with priorities given to female researchers, graduate students, postdoctoral scholars, early career researchers, minority researchers and researchers who do not have other federal support. <br/> <br/>Scientific computing is a combination of computing tools, techniques, and theories to solve mathematical models arising from real applications in science and engineering with the help of a computer.  Computational mathematics is not only the application of mathematics for solving challenging real-world problems but also the discovery of new mathematical theories originating from such applications. Mathematical modeling and simulations form a predictive methodology that supplements real experiments as indispensable power for new discoveries. Simulation performance relies not only on computational power but also on the algorithm efficiency and reliability for the underlying complex systems modeled by PDEs. Designing robust and efficient algorithms is crucial for characterizing many phenomena in science and engineering. Life science is an intellectually rich field that has been advanced remarkably through a synergistic interplay between the deep understanding of biology and mathematics. However, biologists are overwhelmed by the amount of experimental data. New methods for data-management and quantitative theories are needed to interpret and contextualize their observations. A variety of challenges in scientific computing related to problems in life science, such as developing predictive models for disorder detection, feature dimensionality reduction, have emerged in recent years. These issues and many other open problems will be discussed among the diverse group of scientists participating in the workshop.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208164","High Order Wave Equation Algorithms for the Frequency Domain","DMS","COMPUTATIONAL MATHEMATICS","09/15/2022","09/06/2022","Daniel Appelo","MI","Michigan State University","Standard Grant","Stacey Levine","09/30/2023","$283,456.00","","appelo@vt.edu","426 AUDITORIUM RD RM 2","EAST LANSING","MI","488242600","5173555040","MPS","1271","9263","$0.00","A defining feature of waves is their ability to carry information over large distances by propagating without changing their shape. It is this ability that allow waves to probe and image the human body, the interior of the earth and engineered structures like bridges and tunnels. Such images can then be turned into scientific and engineering knowledge that can be used to improve medical diagnostics and prevent failure of buildings and mechanical devices. In this project the principal investigator will develop computational simulation tools that increases our ability to exploit the properties of wave propagation for the common good. The tools developed in the project can also be used to design advanced materials that can enable better acoustic, elastic and electromagnetic components as well as faster and more accurate sensing technologies. Students will be trained as a part of this work. <br/><br/>The research will further develop and apply advanced computational methods for solving systems of partial differential equations modeling wave propagation. The approximation methods will be designed to be robust and flexible while effectively utilizing emerging computational architectures. The research will dramatically improve the WaveHoltz method, a recently discovered idea that enables the use of time domain methods for wave equations to design frequency domain Helmholtz type solvers. WaveHoltz is remarkable in that its underlying linear operator corresponds to a symmetric positive definite matrix and allows a coercive problem to be solved rather than a highly indefinite Helmholtz problem. The research will analyze and develop wavefront preconditioners and deflation techniques for preconditioning WaveHoltz; design implicit and explicit error corrected methods for removing the temporal error in the WaveHoltz method; and consider multi-frequency versions of the WaveHoltz method.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208293","Novel Sampling Methods for Electromagnetic Inverse Scattering Theory","DMS","COMPUTATIONAL MATHEMATICS","08/01/2022","05/20/2022","Dinh-Liem Nguyen","KS","Kansas State University","Standard Grant","Stacey Levine","07/31/2025","$198,480.00","","dlnguyen@ksu.edu","1601 VATTIER STREET","MANHATTAN","KS","665062504","7855326804","MPS","1271","9150, 9263","$0.00","The inverse electromagnetic scattering problem (IESP) aims to determine an unknown object from the electromagnetic fields scattered by that object. The IESP has been an active research topic in the engineering, mathematics, and physics communities for the past three decades due to its impact on a wide range of applications including radar, nondestructive testing, medical imaging, and geophysical exploration. However, solving the IESP is very challenging since this problem is in general highly nonlinear and severely ill-posed. Therefore, although computational algorithms have been extensively studied for the IESP, there is still a high demand for algorithms with improved efficiency and robustness. The project addresses this demand by developing new and highly efficient sampling-type algorithms for the IESP in the context of optics and radar. This project will also involve the training of undergraduate and graduate students in computational mathematics.   <br/><br/>Solving the IESP involves proper sampling methods to construct an approximate indicator function for the unknown scattering object. Ideally these sampling methods are fast, non-iterative, and do not require a priori information about the scattering object. In this project, the principal investigator and graduate students will develop new sampling-type methods for the IESP for both the Helmholtz equation and the system of Maxwell's equations in different types of scattering media, including infinite periodic media, small and point-like objects, bounded inhomogeneous media, and nonlinear media. In addition to the aforementioned features, the sampling-type methods that will be developed in this project will be simple to implement and extremely robust against noise in the data. The resolution and stability analysis of these sampling-type methods and their validation by experimental data will be investigated. The new methods are expected to provide a promising alternative tool to solve the IESP in optics and radar.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208460","Collaborative Research: Advancing the Data-to-Distribution Pipeline for Scalable Data-Consistent Inversion to Quantify Uncertainties in Coastal Hazards","DMS","COMPUTATIONAL MATHEMATICS, MSPA-INTERDISCIPLINARY","09/01/2022","06/21/2022","Troy Butler","CO","University of Colorado at Denver-Downtown Campus","Standard Grant","Yuliya Gorb","08/31/2025","$375,400.00","","butler.troy.d@gmail.com","1380 LAWRENCE ST STE 300","DENVER","CO","802042055","3037240090","MPS","1271, 7454","079Z, 1303, 5294, 9263","$0.00","Coastal hazards are a persistent threat to citizenry, industry, and governments worldwide. Of particular concern to US interests are storm surge and flooding from hurricanes in communities stretching from the Gulf of Mexico to the western North Atlantic, interactions between Arctic storms and evolving sea ice coverage impacting North American coastal communities, and oil spill spread from sources such as tankers and deep-water drilling rigs. The ability to quantify uncertainties in the modeling and simulation of these coastal hazards is therefore critical to making data-informed decisions about how to best prepare, mitigate, and respond to such hazards. The research team aims to advance state-of-the-art mathematical, statistical, and computational capabilities to address these applications of societal importance. Moreover, the mathematical, statistical, and computational research are broadly applicable to a wide range of applications of interest to both the scientific and engineering communities. Educational impacts include the training of undergraduate and graduate students in this field. <br/><br/>This project requires a multi-faceted research approach built upon a rigorous measure-theoretic foundation to expand the application of Data-Consistent Inversion (DCI), a methodology to identify, quantify, and reduce sources of uncertainty for inputs (parameters) of physics-based computational models, to a wide range of complex physical systems. One facet is the development and analysis of a deep learning based data-to-distribution pipeline to transform spatial-temporal data clouds into non-parametric distributions for DCI that can incorporate optimal experimental design criteria within the pipeline. Another facet is the development of a scalable approach to DCI that simultaneously addresses computational issues arising from high-dimensional feature-spaces as well as limited availability of simulated data due to computationally expensive models. A third facet is the development of an iterative approach to DCI that can be deployed in an operational setting to identify the most likely critical model parameters as data become available. The PIs will implement the algorithmic developments in public domain software for DCI and the data-to-distribution pipeline. The PIs will primarily utilize the state-of-the-art Advanced Circulation (ADCIRC) model and its variants for modeling coastal hazards.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2244988","CAREER: Deep Learning Based Scientific Computing: Mathematical Theory and Algorithms","DMS","COMPUTATIONAL MATHEMATICS","07/01/2022","07/28/2023","Haizhao Yang","MD","University of Maryland, College Park","Continuing Grant","Yuliya Gorb","06/30/2025","$301,410.00","","haizhaoyang@yahoo.com","3112 LEE BLDG 7809 REGENTS DR","College Park","MD","207420001","3014056269","MPS","1271","075Z, 079Z, 1045, 9263","$0.00","Deep learning has demonstrated remarkable, high fidelity performance on computer vision and natural language processing tasks that revolutionize manufacturing and social life. Recent applications of deep learning in scientific problems have also advanced scientific discovery via computational chemistry, materials science, medicine, immunology, climate sciences, etc. Understanding the mathematical principles of deep learning algorithms is crucial to validating and improving these algorithms, and will allow scientists and engineers to obtain more reliable predictions and perform a better risk assessment. The research goal is to develop a systematic deep learning analysis serving as the theoretical foundation of numerous scientific problems based on deep learning; cutting-edge algorithms for the efficient solutions of high-dimensional and highly nonlinear partial differential equations arising in various application domains will also be proposed with a theoretical guarantee. The proposed deep learning-based algorithms for high-dimensional and highly nonlinear problems will be expected to greatly advance the state-of-the-art simulations of complex physical systems arising in many fields in science and engineering. <br/><br/>The theoretical challenges of deep learning are largely due to the highly non-linear nature of deep neural networks (DNNs). As a function parametrization tool formulated as compositions of non-linear functions, DNNs are highly non-linear and require advanced mathematics to fully understand. Therefore, there is a critical need for new advances in mathematics for a better understanding of DNNs. The theoretical part of this project mainly focuses on the approximation and generalization capacity of DNNs. The central questions to be answered are whether DNN approximation conquers or lessens the curse of dimensionality, what is the optimal approximation rate of various function classes, and how to characterize the Rademacher complexity of various DNNs trained with state-of-the-art empirical regularization methods aiming at optimal generalization error bound. The computational part of this project concentrates on solving high dimensional and highly oscillatory partial differential equations. The specific approach of this project is to propose hybrid algorithms that combine the advantage of deep learning algorithms and traditional numerical techniques for more efficient computation and higher accuracy. The key idea is to treat deep learning solvers as a preconditioner of traditional numerical algorithms. The algorithms designed in the project will also be implemented in deep learning packages for numerical PDEs and made publicly available. Research outcomes of this project will be disseminated through conferences, publications (journal papers and textbooks), and new mathematical deep learning courses to a broad audience, especially for the next generation of computational scientists.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2143915","CAREER: Uncertainty Quantification for Quantum Computing Algorithms","DMS","FET-Fndtns of Emerging Tech, COMPUTATIONAL MATHEMATICS","09/01/2022","07/25/2023","Xiu Yang","PA","Lehigh University","Continuing Grant","Stacey Levine","08/31/2027","$155,911.00","","xiy518@lehigh.edu","526 BRODHEAD AVE","BETHLEHEM","PA","180153008","6107583021","MPS","089Y, 1271","102Z, 1045, 7203, 7928, 9263","$0.00","This award is funded in whole or in part under the American Rescue Plan Act of 2021 (Public Law 117-2). <br/><br/>Quantum computing harnesses properties of quantum states to enable computations that would be intractable using classical computing. It is widely established that, in the future, quantum computing can revolutionize the way one performs and thinks about computation and serve as the backbone of groundbreaking new technologies for scientific discovery, engineering design, national security, and business development, to name a few. Currently, the key barrier in the development of quantum computing is the error induced by the noise in the hardware. The research goal of this project is to develop methods to model the error propagation in quantum computing algorithms and filter the resulting noise in the outcomes. This study will help enhance the performance of general quantum computing algorithms in terms of accuracy and efficiency. The educational goals of this effort are to prepare students for interdisciplinary research and promote STEM participation and equity among underrepresented groups. Outreach activities also involve K-12 students. <br/><br/>The investigator will develop new uncertainty quantification methods in the following four directions to understand and alleviate the effect of noise on quantum computing algorithms: (1) describing propagation of gate error and readout error using epistemic uncertainty models; (2) mitigating errors using constrained optimization methods and Bayesian approaches; (3) analyzing asymptotic behavior of the propagation of the error; (4) developing an open-source software package to implement the uncertainty quantification algorithms. These new methods will leverage Bayesian inference approaches, tensor decomposition techniques, asymptotic analysis tools for stochastic differential equations, and high-performance computing packages to build the foundation of a ""quantum numerical analysis"" framework from a probabilistic perspective. This framework is general, and it can be used to assess the performance of real-world quantum processors and evaluate the suitability of specific quantum computing hardware architectures for a wide range of applications. This project is jointly supported by the Division of Mathematical Sciences: Computational Mathematics Program and the Division of Computing and Communication Foundations: Foundations of Emerging Technologies Program.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2145845","CAREER: Scalable Algorithms for Nonlinear, Large-Scale Inverse Problems Governed by Dynamical Systems","DMS","COMPUTATIONAL MATHEMATICS","08/01/2022","07/25/2023","Andreas Mang","TX","University of Houston","Continuing Grant","Stacey Levine","07/31/2027","$200,364.00","","andreas@math.uh.edu","4300 MARTIN LUTHER KING BLVD","HOUSTON","TX","772043067","7137435773","MPS","1271","1045, 9263","$0.00","Large-scale inverse problems governed by dynamical systems are of paramount importance in numerous scientific disciplines. Examples include geoscience, medicine, climate science, manufacturing, national security, and economics. Inversion is an indispensable tool to infer knowledge from data in a consistent and predictable way, enabling scientific discovery, decision-making, and ultimately dependable model- and data-informed predictions. However, the practical use of inversion remains limited unless uncertainties can be quantified as they propagate through models and algorithms, Uncertainty quantification adds significant mathematical complications and massive computational costs to an already challenging problem. This project will develop a generic mathematical framework for large-scale, statistical inverse problems alongside software infrastructure with algorithms that scale on modern and future computing architectures. It blends mathematical methods and theory with data-intensive applications and good algorithmic practices to advance the frontiers of computational and data-enabled sciences, with the ultimate aspiration to promote data-driven scientific discovery and model-based prediction and by that, science in general. Alongside research activities, an educational and dissemination program is developed to communicate the results under this work to STEM students and researchers, and a broad audience of computational scientists and application specialists. The project will train students in areas that have seen exceptionally high industry demand in the US in recent years, such as optimization, statistical inference, data-enabled science, performance evaluation, and workload characterization. Educational activities include hands-on research experiences for graduate and undergraduate students, explicitly encouraging participation by minorities and underrepresented groups. Public domain software modules will be made available to a broad STEM audience and practitioners. Applications of this work include medicine, imaging, and geosciences.<br/><br/>Fundamental mathematical and computational aspects of optimization under uncertainty, statistical inference, and the solution of large-scale inverse problems will be investigated in this project to promote the progress of scientific discovery and data exploration. The overarching aim is the design of fast computational kernels and scalable, black-box algorithms that rigorously follow mathematical and physical principles, have a sound theoretical basis, and provably converge to an optimal solution independent of the problem dimension. This includes the development of adaptive, hierarchical numerical schemes and mixed-precision algorithms, enabling high-accuracy computations if desired, and low-accuracy approximations when possible, targeting high data-throughput applications. The project explores (i) foundational mathematical aspects and the deployment of fast (scalable) algorithms for transport-based variational inference, (ii) the design of problem-informed regularization schemes for nonlinear inverse problems, and (iii) the integration of randomized algorithms and learning for the construction of low-order surrogate models for optimization, inference, sampling, and preconditioning. Effective numerical techniques and computational kernels for a fast evaluation of gradient and curvature information and their approximation are of paramount importance for the designed methodology.  The performance will be assessed for parabolic (diffusion-dominated) and hyperbolic (advection-dominated) dynamical systems of varying complexity with applications in computational medicine, climate science, and geoscience.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208361","Collaborative Research: Algorithms, Theory, and Validation of Deep Graph Learning with Limited Supervision: A Continuous Perspective","DMS","COMPUTATIONAL MATHEMATICS","09/01/2022","08/28/2023","Bao Wang","UT","University of Utah","Continuing Grant","Yuliya Gorb","08/31/2025","$155,719.00","","bwang@math.utah.edu","201 PRESIDENTS CIR","SALT LAKE CITY","UT","841129049","8015816903","MPS","1271","079Z, 9263","$0.00","Graph-structured data is ubiquitous in scientific and artificial intelligence applications, for instance, particle physics, computational chemistry, drug discovery, neural science, recommender systems, robotics, social networks, and knowledge graphs. Graph neural networks (GNNs) have achieved tremendous success in a broad class of graph learning tasks, including graph node classification, graph edge prediction, and graph generation. Nevertheless, there are several bottlenecks of GNNs: 1) In contrast to many deep networks such as convolutional neural networks, it has been noticed that increasing the depth of GNNs results in a severe accuracy degradation, which has been interpreted as over-smoothing in the machine learning community. 2) The performance of GNNs relies heavily on a sufficient number of labeled graph nodes; the prediction of GNNs will become significantly less reliable when less labeled data is available. This research aims to address these challenges by developing new mathematical understanding of GNNs and theoretically-principled algorithms for graph deep learning with less training data. The project will train graduate students and postdoctoral associates through involvement in the research. The project will also integrate the research into teaching to advance data science education.<br/><br/>This project aims to develop next-generation continuous-depth GNNs leveraging computational mathematics tools and insights and to advance data-driven scientific simulation using the new GNNs. This project has three interconnected thrusts that revolve around pushing the envelope of theory and practice in graph deep learning with limited supervision using PDE and harmonic analysis tools: 1) developing a new generation of diffusion-based GNNs that are certifiable to learning with deep architectures and less training data; 2) developing a new efficient attention-based approach for learning graph structures from the underlying data accompanied by uncertainty quantification; and 3) application validation in learning-assisted scientific simulation and multi-modal learning and software development.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208219","Collaborative Research: Time Accurate Fluid-Structure Interactions","DMS","COMPUTATIONAL MATHEMATICS","08/15/2022","08/02/2022","Martina Bukac","IN","University of Notre Dame","Standard Grant","Yuliya Gorb","07/31/2025","$224,923.00","","mbukac@nd.edu","940 Grace Hall","NOTRE DAME","IN","465565708","5746317432","MPS","1271","9263","$0.00","In realistic problems describing fluid flow, sometimes the dynamics are not known, or the variables are changing rapidly. Hence, to accurately compute the solution, one might need to use small temporal discretization parameters. For example, in simulations of blood flow, the pressure rapidly increases and then decreases during the systole, which lasts 3/8 of the cardiac cycle, followed by slower and smaller changes in the pressure during diastole, lasting 5/8 of the cardiac cycle. To accurately capture the peak systolic flow, a small time step has to be used in that interval. However, that same time step  might be unnecessary small during diastole and could lead to longer computational times. Therefore, robust adaptive time-stepping is central to accurate and efficient long-term predictions of the solution. The adaptive time-stepping methods for partial differential equations describing flow problems are under-investigated and this project will make a major contribution in that field. The methods developed in this project will be used to model problems involving transport  and fluid-elastic/poroelastic structure interaction, such as the transport of contaminants in hydrological systems where surface water percolates through rocks and sand, transport of nutrients and oxygen between capillaries and tissue, or spread of a disease across a border. This project will involve the training of graduate students. <br/><br/>The focus of this project is the development of adaptive time-stepping methods for two classes of coupled flow problems: the fluid-porous medium coupled problems and the fluid-structure interaction problems. A monolithic and a partitioned method will be developed for the fluid-porous medium problem described using the Stokes-Darcy system. Partitioned numerical methods will be developed for the fluid-structure interaction problems with both thin and thick structures. The proposed methods will be semi-discretized in time based on the refactorized Cauchy?s one-legged theta-like method, which is B-stable when used with a variable time step. Furthermore, when theta is 0.5, the method is also second-order accurate and conserves all linear and quadratic Hamiltonians. However, the application of this method to coupled problems, especially when partitioned methods are designed, has to be carefully performed to allow the use of black-box and legacy codes. The proposed methods will be mathematically and computationally analyzed. Various adaptive strategies will be considered. The performance of each method will be investigated with respect to the parameters in the problem. In both classes of multi-physics problems, the underlying equations will be coupled with a transport equation. The proposed techniques will also be applied to the transport problem, with a particular attention to mass and energy conservation. Conservative properties of the transport problem will be investigated.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2310340","Efficient Hybridizable Discontinuous Galerkin Methods for Phase Field Fluid Models","DMS","COMPUTATIONAL MATHEMATICS","12/01/2022","12/14/2022","Daozhi Han","NY","SUNY at Buffalo","Standard Grant","Yuliya Gorb","07/31/2025","$152,848.00","","daozhiha@buffalo.edu","520 LEE ENTRANCE STE 211","AMHERST","NY","142282577","7166452634","MPS","1271","9263","$0.00","Multiphase flow  is ubiquitous in natural phenomena and industrial applications.  Common examples include wave-breaking and sloshing, contaminant transport in aquifers, oil recovery in petroleum engineering, drug delivery in blood flow,  gas-particle flow in combustion reactors,  exhaust management in Polymer Electrolyte Membrane fuel cell technology, and so forth.   The diffuse interface fluid models have become increasingly popular in the numerical modeling of interfacial phenomena associated with multiphase flows. They are able to capture  smooth transitions of fluid interface, and simulations can be carried out on a fixed grid without explicit interface tracking.   A particular challenge in solving diffuse interface models is that the diffusive interface of small width often exhibits instability such as  bubble merging or splitting. Traditional high order methods  are prone to  spurious oscillations around diffusive interfaces  which can pollute the numerical solution beyond the interface region and even cause blow-up of the code  due to negative viscosity, density or mobility.  The aim of this project is to develop high order numerical methods that can accurately capture moving interfaces of multiphase flow.<br/><br/>Real-world applications see both diffusion dominated flows and advection dominated flows. The investigator first develops and  analyzes provably superconvergent hybridizable discontinuous Galerkin methods (HDG) for solving diffuse interface fluid models in the diffusion-dominated regime. The key idea in the design is to approximate solution variables by higher order polynomials than those for the numerical traces and gradient variables,  and to explore local projection based stabilization. The PI then  designs stabilized high order  HDG methods effected with the Scalar Auxiliary Variable (SAV) time-stepping schemes for advection-dominated flows. The methods  stabilize advection   in the  nonlinear fourth order advection-diffusion  equation while preserve the underlying energy laws.   The stabilized SAV-HDG algorithms enable diffuse interface methods to accurately capture sharp fronts and unstable interfaces in the advection-dominated regime, and allow efficient  parallel computation of smaller systems at each time step.  Finally the PI develops and implements fast nonlinear HDG multigrid  solvers for diffuse interface fluid models.  The practical solvers will further address the lack of efficient iterative solvers/preconditioners for HDG methods Graduate students participate in the work of this project.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2306064","Efficient Distribution Classification Tasks via Optimal Transport Embeddings","DMS","COMPUTATIONAL MATHEMATICS","12/01/2022","09/06/2023","Caroline Moosmueller","NC","University of North Carolina at Chapel Hill","Continuing Grant","Yuliya Gorb","06/30/2024","$87,406.00","","cmoosmueller@ucsd.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275995023","9199663411","MPS","1271","079Z, 9263","$0.00","Classification allows one to organize data based on similarities and can provide insight into underlying relationships in a large variety of fields, including cancer research, survey analysis, and image and text processing. As a result, the development of efficient algorithms for classification tasks is an important research area. One approach, machine learning,  has proved successful in classification tasks, but it is usually focused on data points in vector spaces. In many applications, however, instances of data are naturally interpreted as entire point clouds, or as distributions, and do not lie in a vector space. Furthermore, the high dimension of such datasets leads to theoretical and computational challenges. This project is devoted to the development of classification algorithms for high-dimensional datasets consisting of distributions, and will focus both on their theoretical analysis and computational efficiency. To this end, the principal investigator will use the framework of optimal transport, which provides a natural way of comparing distributions. Students will be involved and trained in interdisciplinary aspects of this project.<br/><br/>This project applies knowledge from computational optimal transport, such as linear embeddings and regularized optimization, and machine learning algorithms, to study classification tasks for datasets consisting of distributions. The main goal is to develop approximation methods with guaranteed error bounds that also allow for algorithmic insights and efficient implementation. Open problems on approximation power, computational feasibility, and numerical analysis will be addressed. Specifically, the project addresses four fundamental questions that arise in the field: (1) What are the types of distributions that can be classified with traditional machine learning techniques through linear embeddings, and how does the choice of a regularizer affect accuracy? (2) How well can the Wasserstein distance and Wasserstein barycenters be approximated through linear embeddings using Euclidean distances? (3) Under which conditions can we guarantee separability with simple classifiers in the embedding space for disjoint classes of distributions? (4) How can we tailor our framework to address various applications, such as classifying structures in audio or video segments?<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2304489","Collaborative Research: Nonconvex Models for Structured Sensing: Theory, Algorithms, and Applications","DMS","COMPUTATIONAL MATHEMATICS","10/01/2022","09/05/2023","HanQin Cai","FL","The University of Central Florida Board of Trustees","Continuing Grant","Yuliya Gorb","08/31/2025","$89,287.00","","hqcai@ucf.edu","4000 CENTRAL FLORIDA BLVD","ORLANDO","FL","328168005","4078230387","MPS","1271","9263","$0.00","The rapid advance of technology has enabled more than ever the ability to collect large amounts of data. While the abundance of such data is advantageous, it brings forth several computational challenges. One challenge is the fact that data might contain numerous missing entries. This is the case for instance when using physical measurement devices with a limited range or in collecting user preferences for a product where we lack complete information. One line of methods that has proved to be useful for this problem is matrix completion algorithms which predict missing entries with minimalistic assumptions on the data. However, in problems such as structure prediction and recommendation system with side information, the measurements are not entry-wise. Specifically, the observations are an aggregate of some entries of the underlying data, i.e., rather than directly observing the entries of the data, the user has access to certain combinations of these entries. This project aims to study this problem which is well known as the matrix sensing problem. The majority of previous works consider the case where measurements of the data are missing at random or assume that the measurement protocol itself is random. Motivated by practical applications, this project considers a realistic setup where the measurements are structured and deterministic. A key goal of this project is to advance the state of art theory and computation of matrix sensing by studying new optimization algorithms. Another aim of the project is to apply the constructed framework to robust structure prediction and machine learning. <br/><br/>This project seeks to study scalable non-convex methods for a class of generalized matrix recovery problems. In particular, PIs are interested in low-rank matrix sensing problems with deterministically structured measurements under various settings. The main approach is based on formulating the optimization problem with respect to a deterministic measurement basis and its associated dual basis. This yields a well-posed problem under some mild conditions. The project is centered on three objectives. In the first part, the project studies the local convergence of a Riemannian gradient descent algorithm that directly optimizes over the manifold of low-rank matrices. The recovery guarantee then will depend mainly on the spectral properties of the basis and the dual basis, the sampling scheme, and the initialization. Tight estimation of the spectral properties and effective initialization method will be investigated by bridging connections to spectral graph theory. The second objective is to design an algorithm tailored for the Euclidean distance geometry (EDG) problem which aims to estimate the configuration of points given partial information about pairwise distances. EDG is a representative problem that utilizes deterministically structured measurements. By leveraging the special structure of EDG, the project aims to design optimally efficient algorithms and establish theoretical analysis for the exact recovery of the point configuration. The third objective considers the setting where the measurements might be sparsely corrupted. The project aims to develop fast and robust algorithms tailored to this case and carry out the necessary analysis for recovery guarantees. To realize these objectives, the project leverages tools from high-dimensional probability, Riemannian optimization, numerical analysis, and spectral graph theory. The project will provide opportunities to train undergraduate and graduate students with interests in distance geometry, optimization theory, and computational science.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208272","Collaborative Research: Algorithms, Theory, and Validation of Deep Graph Learning with Limited Supervision: A Continuous Perspective","DMS","COMPUTATIONAL MATHEMATICS","09/01/2022","08/28/2023","Stanley Osher","CA","University of California-Los Angeles","Continuing Grant","Yuliya Gorb","08/31/2025","$184,198.00","","sjo@math.ucla.edu","10889 WILSHIRE BLVD STE 700","LOS ANGELES","CA","900244201","3107940102","MPS","1271","079Z, 9263","$0.00","Graph-structured data is ubiquitous in scientific and artificial intelligence applications, for instance, particle physics, computational chemistry, drug discovery, neural science, recommender systems, robotics, social networks, and knowledge graphs. Graph neural networks (GNNs) have achieved tremendous success in a broad class of graph learning tasks, including graph node classification, graph edge prediction, and graph generation. Nevertheless, there are several bottlenecks of GNNs: 1) In contrast to many deep networks such as convolutional neural networks, it has been noticed that increasing the depth of GNNs results in a severe accuracy degradation, which has been interpreted as over-smoothing in the machine learning community. 2) The performance of GNNs relies heavily on a sufficient number of labeled graph nodes; the prediction of GNNs will become significantly less reliable when less labeled data is available. This research aims to address these challenges by developing new mathematical understanding of GNNs and theoretically-principled algorithms for graph deep learning with less training data. The project will train graduate students and postdoctoral associates through involvement in the research. The project will also integrate the research into teaching to advance data science education.<br/><br/>This project aims to develop next-generation continuous-depth GNNs leveraging computational mathematics tools and insights and to advance data-driven scientific simulation using the new GNNs. This project has three interconnected thrusts that revolve around pushing the envelope of theory and practice in graph deep learning with limited supervision using PDE and harmonic analysis tools: 1) developing a new generation of diffusion-based GNNs that are certifiable to learning with deep architectures and less training data; 2) developing a new efficient attention-based approach for learning graph structures from the underlying data accompanied by uncertainty quantification; and 3) application validation in learning-assisted scientific simulation and multi-modal learning and software development.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208046","Numerical methods for incompressible multiphase flows applied to magnetohydrodynamics","DMS","COMPUTATIONAL MATHEMATICS","09/01/2022","08/04/2022","LOIC CAPPANERA","TX","University of Houston","Standard Grant","Stacey Levine","08/31/2025","$170,913.00","","lmcappanera@uh.edu","4300 MARTIN LUTHER KING BLVD","HOUSTON","TX","772043067","7137435773","MPS","1271","9263","$0.00","The development of Earth-friendly technologies such as electric cars leads to greater consumption of electric power. To address this, the development of renewable energies, such as wind, solar and tidal waves, is a key societal challenge. These sources of energies are highly intermittent by nature and bring more stress to an electric grid that needs to balance demand and supply with a limited or saturated energy storage capacity. Thus, the development of green energy is tied to the development of efficient large scale energy storage devices.  In this context, this project aims to develop efficient numerical tools that will help to design effective and robust liquid metal batteries, a promising type of battery that is considered for grid-scale energy storage devices. These numerical methods will model the action of various phenomena that arise in such batteries (e.g. multiphase flows, thermal-solutal convection, magnetohydrodynamics). Thus, this project also has applications in geophysics and metallurgy industry by improving our understanding of various instabilities that arises in liquid metals. This project will provide research training opportunities for graduate students to introduce them to the development, analysis and application of state of the art numerical methods in an interdisciplinary environment. <br/><br/>In this project, the PI will use theoretical and computational mathematics to develop and analyze numerical methods for solving multiphysics problems applied to magnetohydrodynamics setups in energy storage industry and geophysics. High-order numerical methods will be developed to approximate the solutions of nonlinear Partial Differential Equations in fluid dynamics that involve space-time dependent coefficients. These methods will use sequential semi-implicit algorithms and will be made suitable for spectral and high-order finite element methods. The objectives of this project are organized around four research directions: (1) Analysis and development of new numerical methods to approximate incompressible multiphase flows where the density and viscosity of fluids vary in space and time; (2) Modeling of multiphysics mechanisms that arise in a liquid metal battery, a promising grid-scale energy storage device. This includes the development of multiphase algorithms for thermodynamics and compositional (solutal) convection problems; (3) Integration of the above techniques in the massively parallel code SFEMaNS and their applications to liquid metal batteries and geophysics setups that involve magnetohydrodynamics effects; (4) Transition of the code SFEMaNS to current high performance computing standards (multithreading, cache handling, SIMD vectorisation, etc), and distribution to the magneto-hydrodynamic scientific community.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208385","Collaborative Research: Sparse Optimization for Machine Learning and Image/Signal Processing","DMS","COMPUTATIONAL MATHEMATICS","08/15/2022","08/02/2022","Lixin Shen","NY","Syracuse University","Standard Grant","Stacey Levine","07/31/2025","$155,783.00","","lshen03@syr.edu","900 S CROUSE AVE","SYRACUSE","NY","132440001","3154432807","MPS","1271","079Z, 9263","$0.00","Data sets involved in information technology, nanotechnology, biotechnology, civil infrastructure, environmental science, and other important areas are often extremely large. Due to growing quantities of data and related model sizes, demands for more competent data processing models continue to increase. Data sets in applications often have certain embedded sparsity structures, in the sense that their essential intrinsic characteristics can be represented by smaller amounts of information. Motivated by this observation, the aim of this project is to develop computationally efficient methods for non-smooth and non-convex optimization by exploring sparsity structures embedded in data sets. The investigators anticipate that the outcomes of this project will be of use in many application areas. The research and associated educational components in this project are expected to provide undergraduate and graduate students rigorous training so that they will have the skill sets needed to face the scientific and technological challenges of the big data era.  <br/><br/>This project will address several critical issues in non-smooth, non-convex optimization that result from sparse modeling of data in a range of applications, including machine learning and sparse image/signal restoration. For both learning and image/signal restoration, proper sparse regularization models will be developed. Suitable sparsity promoting functions will be designed for use in forming regularization terms, and appropriate bases/transforms will be constructed so that the resulting regularization algorithms compel their solutions to be sparse. For machine learning, appropriate reproducing kernel Banach spaces will be built up to allow for the representation of complex and rich geometric and topological structures of data and hence lead to improved learning outcomes. Representer theorems of the resulting learning methods in these spaces will be established so that the learning solutions can be expressed as a combination of a finite number of kernel sessions with the number equal to that of the data points used in training even though the hypothesis space is of infinite dimension. Geometric features of these spaces will be employed to induce sparsity of the learning solutions. The construction of bases or transforms via machine learning from data is expected to lead to improved methods for image/signal restoration.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208461","Collaborative Research: Advancing the Data-to-Distribution Pipeline for Scalable Data-Consistent Inversion to Quantify Uncertainties in Coastal Hazards","DMS","COMPUTATIONAL MATHEMATICS, MSPA-INTERDISCIPLINARY","09/01/2022","06/21/2022","Clinton Dawson","TX","University of Texas at Austin","Standard Grant","Yuliya Gorb","08/31/2025","$174,600.00","","clint@ices.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271, 7454","079Z, 1303, 5294, 9263","$0.00","Coastal hazards are a persistent threat to citizenry, industry, and governments worldwide. Of particular concern to US interests are storm surge and flooding from hurricanes in communities stretching from the Gulf of Mexico to the western North Atlantic, interactions between Arctic storms and evolving sea ice coverage impacting North American coastal communities, and oil spill spread from sources such as tankers and deep-water drilling rigs. The ability to quantify uncertainties in the modeling and simulation of these coastal hazards is therefore critical to making data-informed decisions about how to best prepare, mitigate, and respond to such hazards. The research team aims to advance state-of-the-art mathematical, statistical, and computational capabilities to address these applications of societal importance. Moreover, the mathematical, statistical, and computational research are broadly applicable to a wide range of applications of interest to both the scientific and engineering communities. Educational impacts include the training of undergraduate and graduate students in this field. <br/><br/>This project requires a multi-faceted research approach built upon a rigorous measure-theoretic foundation to expand the application of Data-Consistent Inversion (DCI), a methodology to identify, quantify, and reduce sources of uncertainty for inputs (parameters) of physics-based computational models, to a wide range of complex physical systems. One facet is the development and analysis of a deep learning based data-to-distribution pipeline to transform spatial-temporal data clouds into non-parametric distributions for DCI that can incorporate optimal experimental design criteria within the pipeline. Another facet is the development of a scalable approach to DCI that simultaneously addresses computational issues arising from high-dimensional feature-spaces as well as limited availability of simulated data due to computationally expensive models. A third facet is the development of an iterative approach to DCI that can be deployed in an operational setting to identify the most likely critical model parameters as data become available. The PIs will implement the algorithmic developments in public domain software for DCI and the data-to-distribution pipeline. The PIs will primarily utilize the state-of-the-art Advanced Circulation (ADCIRC) model and its variants for modeling coastal hazards.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208356","Collaborative Research: Algorithms, Theory, and Validation of Deep Graph Learning with Limited Supervision: A Continuous Perspective","DMS","COMPUTATIONAL MATHEMATICS","09/01/2022","08/28/2023","Thomas Strohmer","CA","University of California-Davis","Continuing Grant","Yuliya Gorb","08/31/2025","$180,674.00","","strohmer@math.ucdavis.edu","1850 RESEARCH PARK DR, STE 300","DAVIS","CA","956186153","5307547700","MPS","1271","079Z, 9263","$0.00","Graph-structured data is ubiquitous in scientific and artificial intelligence applications, for instance, particle physics, computational chemistry, drug discovery, neural science, recommender systems, robotics, social networks, and knowledge graphs. Graph neural networks (GNNs) have achieved tremendous success in a broad class of graph learning tasks, including graph node classification, graph edge prediction, and graph generation. Nevertheless, there are several bottlenecks of GNNs: 1) In contrast to many deep networks such as convolutional neural networks, it has been noticed that increasing the depth of GNNs results in a severe accuracy degradation, which has been interpreted as over-smoothing in the machine learning community. 2) The performance of GNNs relies heavily on a sufficient number of labeled graph nodes; the prediction of GNNs will become significantly less reliable when less labeled data is available. This research aims to address these challenges by developing new mathematical understanding of GNNs and theoretically-principled algorithms for graph deep learning with less training data. The project will train graduate students and postdoctoral associates through involvement in the research. The project will also integrate the research into teaching to advance data science education.<br/><br/>This project aims to develop next-generation continuous-depth GNNs leveraging computational mathematics tools and insights and to advance data-driven scientific simulation using the new GNNs. This project has three interconnected thrusts that revolve around pushing the envelope of theory and practice in graph deep learning with limited supervision using PDE and harmonic analysis tools: 1) developing a new generation of diffusion-based GNNs that are certifiable to learning with deep architectures and less training data; 2) developing a new efficient attention-based approach for learning graph structures from the underlying data accompanied by uncertainty quantification; and 3) application validation in learning-assisted scientific simulation and multi-modal learning and software development.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208581","Symmetric Tensors in Discrete Exterior Calculus and Linearized Elasticity in the Plane","DMS","COMPUTATIONAL MATHEMATICS","08/15/2022","08/28/2023","Anil Hirani","IL","University of Illinois at Urbana-Champaign","Continuing Grant","Yuliya Gorb","03/31/2024","$239,059.00","","hirani@illinois.edu","506 S WRIGHT ST","URBANA","IL","618013620","2173332187","MPS","1271","9263","$0.00","Many problems in science and engineering require calculus for their solution and for most of these one must rely on a computer. For this purpose, for decades the techniques of calculus have been approximated to make them suitable for use in computer algorithms. The more advanced techniques and mathematical structures of calculus are part of a field of mathematics called exterior calculus. This advanced form of calculus allows the techniques of calculus to be easily applied in situations where the space is curved, such as the surface of earth. Exterior calculus framework also allows the use of calculus in more dimensions than the familiar three dimensional world. Examples of this appear in physics, in engineering, and in many problems in data science. Discrete exterior calculus (DEC) is a computational framework for exterior calculus suitable for computer programs. The principle investigator (PI) will enrich the DEC framework by creating mathematical objects that are critical for many applications but are missing from DEC. Specifically, the PI will develop the mathematical techniques and algorithms needed to create approximations of objects called symmetric tensors, and calculus operations related to these objects. In order to test the validity of these constructions, the approximations will be developed in conjunction with solving equations for modeling elastic solids. While exterior calculus often requires graduate training in mathematics, one benefit of DEC is the simplicity of the final product. The resulting objects and operations can be explained in an elementary manner and this will be leveraged to introduce these topics in an undergraduate computer programing course.<br/><br/>The PI proposes to create discrete symmetric tensors such as the stress tensor and differential operators such as the curl curl, hessianand symmetric gradient in the DEC framework. The PI will carry out this discretization of symmetric tensors and related differential operators by using the Bernstein-Gelfand-Gelfand (BGG) construction, a tool from geometry. New DEC spaces and operators needed to carry out this construction will be developed as part of the project. The BGG construction can be used to combine differential complexes and in the process create symmetric tensors and higher order differential operators. The PI will use biharmonic equation and linearized elasticity in the plane as model problems to gauge the success of the BGG construction for DEC.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208438","Development and Application of Modern Numerical Methods for Nonlinear Hyperbolic Systems of Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","09/01/2022","08/05/2022","Alina Chertock","NC","North Carolina State University","Standard Grant","Yuliya Gorb","08/31/2025","$368,594.00","","chertock@math.ncsu.edu","2601 WOLF VILLAGE WAY","RALEIGH","NC","27607","9195152444","MPS","1271","5294, 9263","$0.00","The goal of this project is to develop new mathematical and computational tools for a large class of hyperbolic conservation and balance laws and related problems.  Such systems arise in a wide variety of applications ranging from classical fluid dynamics (gas dynamics including multicomponent and multiphase compressible flows, many shallow water models including rotating shallow water equations, thermal rotating shallow water equations, shallow magnetohydrodynamic equations, and others), astrophysics,  meteorology, oceanography, atmospheric sciences, to electromagnetism and modern biological models. While the PI is planning to work on several particular applications, the main focus of the research will be in the development of novel numerical methods and computational techniques that can be applied to a wide class of applied problems arising in today?s science. The project has also a potential to contribute to the emergence of accurate, robust and efficient algorithms and will overall increase the practical applicability on numerical methods. This project involves the training of graduate students. <br/><br/>Many practical applications, especially in the cases of high space dimensions, require development and implementation of special numerical methods that are not only consistent with the governing system of partial differential equations, but also preserve certain structural and asymptotic properties of the underlying problem at the discrete level. The project is aimed at the development of efficient high-order methods for systems of conservation and balance laws whose basic properties go beyond consistency, stability and convergence. This will be achieved by designing special numerical techniques for (i) finding a delicate balance between the numerical diffusion and dispersion to ensure sharp?yet non-oscillatory?resolution of shock and contact waves, while achieving a high order accuracy in smooth regions, (ii) exactly preserving physically relevant steady-state solutions and involution constraints, (iii) establishing asymptotic preserving properties in certain stiff regimes, and (iv) analyzing the influence of uncertainties in problems with random data. The design and implementation of the new numerical schemes will be based on high-order shock-capturing finite-volume and finite-difference methods, accurate and efficient time integrators, and stochastic Galerkin and collocation methods, utilizing the main advantages of each of these methods in the context of the studied problems. The derivation of such numerical techniques is fundamental for understanding many physical phenomena and will contribute to their quantitative and qualitative study.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208126","Algorithms and Theory for Compressing Deep Neural Networks","DMS","COMPUTATIONAL MATHEMATICS","09/01/2022","05/20/2022","Penghang Yin","NY","SUNY at Albany","Standard Grant","Stacey Levine","08/31/2025","$276,611.00","","pyin@albany.edu","1400 WASHINGTON AVE","ALBANY","NY","122220100","5184374974","MPS","1271","075Z, 079Z, 9263","$0.00","Deep neural networks (DNNs) have been the main driving force for recent advancements in artificial intelligence (AI) technology, profoundly impacting society in the areas of transportation, public safety, entertainment, health care, and other areas of public life. One of the biggest obstacles to AI's even broader impact on our daily lives is the typically enormous power consumption of DNNs upon deployment. The aim of this project is to develop mathematical and computational approaches for DNN compression to realize the fast and efficient deployment of AI systems on mobile platforms with low-power budgets such as smartphones. Results of this work will have a variety of applications which include video security systems, autopilot, smart robots, and face identification. The project will involve training of graduate students, development of data science courses, as well as collaboration with industry. <br/><br/>The PI plans to (1) develop and analyze coarse gradient algorithms, featuring a biased first-order oracle, for the discretization of various neural architectures including transformer-based networks; (2) develop and analyze efficient thresholding-based algorithms for compressing networks via structured sparsity on both balanced and unbalanced data; (3) investigate the model capacity of compressed DNNs and establish universal finite-sample expressivity theory. The proposed research will also explore the applications of coarse gradient algorithms to other machine learning problems with discrete-valued loss functions and advance knowledge in discrete optimization.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2211020","Summer Geometry Initiative 2022","DMS","INFRASTRUCTURE PROGRAM, ALGEBRA,NUMBER THEORY,AND COM, GEOMETRIC ANALYSIS, APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS","05/15/2022","05/13/2022","Justin Solomon","MA","Massachusetts Institute of Technology","Standard Grant","Pedro Embid","04/30/2023","$49,604.00","","jsolomon@mit.edu","77 MASSACHUSETTS AVE","CAMBRIDGE","MA","021394301","6172531000","MPS","1260, 1264, 1265, 1266, 1271","7556, 9263","$0.00","This award provides support for the 2022 Summer Geometry Initiative (SGI), a six-week summer workshop bringing a broad pool of students into geometry processing and related research disciplines.  A cohort of roughly 30 SGI Fellows will complete a week of intensive training in geometry processing research practices, followed by five weeks of collaboration with top researchers in the field, guest lectures, guidance on graduate admissions, and interaction with one another; an additional group of students is invited to participate in only the initial tutorial week.  Designed to broaden access to geometry processing research experiences, the program targets Fellows drawn from a diverse set of backgrounds, geographic locations, and institutions, with a focus on students otherwise unlikely to have access to this cutting-edge discipline. Fellows receive stipends to alleviate the opportunity cost of participating in the workshop.<br/><br/>The SGI 2022 offering aims to develop SGI as a supporter of the geometry processing community and as a model program for computational and mathematical disciplines seeking to broaden the diversity of future generations of researchers. Beyond community-building, SGI Fellows will tackle real-world research problems affecting applications like digital manufacturing, virtual reality, physical simulation, architecture, and autonomous driving using tools drawn from mathematical disciplines including differential geometry, partial differential equations, optimal transport, numerical analysis, and optimization. More information can be found on the program website, at: https://sgi.mit.edu/<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208386","Collaborative Research: Sparse Optimization for Machine Learning and Image/Signal Processing","DMS","COMPUTATIONAL MATHEMATICS","08/15/2022","08/02/2022","Yuesheng Xu","VA","Old Dominion University Research Foundation","Standard Grant","Stacey Levine","07/31/2025","$171,089.00","","y1xu@odu.edu","4111 MONARCH WAY","NORFOLK","VA","235082561","7576834293","MPS","1271","079Z, 9263","$0.00","Data sets involved in information technology, nanotechnology, biotechnology, civil infrastructure, environmental science, and other important areas are often extremely large. Due to growing quantities of data and related model sizes, demands for more competent data processing models continue to increase. Data sets in applications often have certain embedded sparsity structures, in the sense that their essential intrinsic characteristics can be represented by smaller amounts of information. Motivated by this observation, the aim of this project is to develop computationally efficient methods for non-smooth and non-convex optimization by exploring sparsity structures embedded in data sets. The investigators anticipate that the outcomes of this project will be of use in many application areas. The research and associated educational components in this project are expected to provide undergraduate and graduate students rigorous training so that they will have the skill sets needed to face the scientific and technological challenges of the big data era.  <br/><br/>This project will address several critical issues in non-smooth, non-convex optimization that result from sparse modeling of data in a range of applications, including machine learning and sparse image/signal restoration. For both learning and image/signal restoration, proper sparse regularization models will be developed. Suitable sparsity promoting functions will be designed for use in forming regularization terms, and appropriate bases/transforms will be constructed so that the resulting regularization algorithms compel their solutions to be sparse. For machine learning, appropriate reproducing kernel Banach spaces will be built up to allow for the representation of complex and rich geometric and topological structures of data and hence lead to improved learning outcomes. Representer theorems of the resulting learning methods in these spaces will be established so that the learning solutions can be expressed as a combination of a finite number of kernel sessions with the number equal to that of the data points used in training even though the hypothesis space is of infinite dimension. Geometric features of these spaces will be employed to induce sparsity of the learning solutions. The construction of bases or transforms via machine learning from data is expected to lead to improved methods for image/signal restoration.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208402","Collaborative Research: Physics-Preserving Adaptive Finite Element Methods for Thermo-Poroelasticity","DMS","COMPUTATIONAL MATHEMATICS, GOALI-Grnt Opp Acad Lia wIndus","07/01/2022","05/24/2023","Sanghyun Lee","FL","Florida State University","Standard Grant","Yuliya Gorb","06/30/2025","$281,504.00","","slee17@fsu.edu","874 TRADITIONS WAY","TALLAHASSEE","FL","323060001","8506445260","MPS","1271, 1504","019Z, 068P, 1504, 9263","$0.00","Geothermal energy is one of the most promising renewable energy sources and has proven to be reliable, clean, and safe. When designing enhanced geothermal systems (EGS), it is necessary to understand the multiscale, multiphysics, thermal-hydraulic-mechanical (THM) processes that impact the EGS dynamics and productivity. This project aims to gain a fundamental understanding of key mechanisms controlling the dynamics in EGS (solid displacement, fluid flow, and heat transfer) and sustainability of EGS reservoirs through numerical simulations. A novel numerical simulation framework to be built through this project will allow for designing, managing, and optimizing energy production from EGS.<br/> <br/>The THM processes in EGS can be described by Biot?s thermo-poroelasticity model, a coupled system of nonlinear partial differential equations. Any desirable numerical methods for THM systems should preserve the underlying physical laws, such as mass and energy conservation, and present no numerical instabilities for a wide range of physical and simulation parameters. This project seeks to develop a unified numerical modeling framework based on adaptive enriched Galerkin (EG) methods to provide robust and physics-preserving numerical methods whose numerical analysis is feasible. The proposed EG schemes are mass conservative and free of numerical instabilities commonly present in poroelasticity and coupled flow-transport problems. The mass conservation property, stability, and convergence behaviors of the proposed methods will be studied mathematically and confirmed numerically. Moreover, residual-based a posteriori error estimators will be derived and utilized for designing dynamic mesh adaptivity techniques. The developed EG algorithms will be implemented within finite element software packages to verify the theoretical results and validate the new numerical model's capabilities to capture the EGS dynamics. The performance of the new EG methods will be compared with that of state-of-the-art numerical methods.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2142672","CAREER: An Efficient Computational Framework for Data Driven Feedback Control","DMS","COMPUTATIONAL MATHEMATICS","09/01/2022","06/29/2023","Feng Bao","FL","Florida State University","Continuing Grant","Stacey Levine","08/31/2027","$164,055.00","","fbao@fsu.edu","874 TRADITIONS WAY","TALLAHASSEE","FL","323060001","8506445260","MPS","1271","1045, 9263","$0.00","Optimal control is a mathematical challenge that aims to find control actions that guide a controlled system to achieve optimal-cost performance. Most existing methods for optimal control assume that the state of the controlled system is fully observed, and therefore that the feedback from the controlled state is explicitly available. In many practical cases, however, the controlled system is not directly observable. In this project, the investigator aims to develop efficient and accurate data assimilation methods to analyze indirect observational data and to construct an efficient computational framework to design optimal control based on the information contained in the observational data. This new framework has the potential to benefit the control and design materials at the nano-scale as well as the controls of power systems at various scales to support reliable and an efficient electric grid. The project incorporates activities to train the next generation of data scientists with both mathematical insight and technical skills to address important practical challenges.<br/><br/>The goal of this project is to develop an efficient computational framework that will allow data to optimally drive control actions. The primary efforts will be dedicated to the development of data driven optimal control methods, incorporating state-of-the-art data assimilation methods into stochastic optimal control solvers. The research carried out in this project also aims to elucidate inherent connections between data and actions. The research has two thrusts. The first thrust will focus on the development of mathematical and computational methods to establish an efficient data driven feedback control framework. Then, the methods developed in the first thrust will be applied to solve practical scientific and engineering feedback control problems in the second thrust.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208267","Collaborative Research: Adaptive Mixed-Dimensional Modeling and Simulation of Porous Media","DMS","COMPUTATIONAL MATHEMATICS","08/01/2022","08/17/2023","Xiaozhe Hu","MA","Tufts University","Continuing Grant","Yuliya Gorb","07/31/2025","$278,130.00","James Adler","Xiaozhe.Hu@tufts.edu","169 HOLLAND ST","SOMERVILLE","MA","021442401","6176273696","MPS","1271","9263","$0.00","The overall goal of this research project is to develop, analyze, and implement stable numerical methods for the simulation of flow in fractured porous media, based on mixed-dimensional modeling. Fractured porous media flow is multi-physics and multi-scale, and the development of robust and effective numerical tools for such systems represents a class of important challenges in computational mathematics. For example, in many practical applications fractures or other features, such as capillaries in the brain, are lower-dimensional and interact in a complex way through the three-dimensional domains encapsulating them. Important applications of fractured porous media include hydraulic fracturing, waste deposition, and models from biomechanics. The project aims to provide new computational paradigms, promote the usage of mixed-dimensional modeling in these and related fields, and alleviate current limitations in computer simulations. The techniques will be implemented in an open-source software package and will be made available to the scientific community. <br/><br/>In this project, three important aspects of mixed-dimensional modeling and simulation will be investigated. The first research objective is to design advanced stable discretizations, which couple stabilized schemes for linear elasticity with structure-preserving discretizations for Darcy flow in a mixed-dimensional setting.  Stability and mass conservation will be achieved using a minimal number of degrees of freedom. The second objective is adaptive approximations in the mixed-dimensional framework.  Space-time adaptivity will be developed and implemented to improve accuracy with solid theoretical foundations. The third objective is to study robust linear solvers for the resulting discrete linear systems.  Based on physical and mathematical properties of the mixed-dimensional models and their numerical discretizations, new block preconditioners and monolithic multigrid methods will be developed. Robustness with respect to physical and discretization parameters will be justified both theoretically and numerically. The main application of this project is linear poromechanics in fractured porous media, but possible generalizations to nonlinear formulations will also be investigated, including several applications in physics and engineering.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208294","Mixed Precision Arithmetic for Large Scale Linear Inverse Problems","DMS","COMPUTATIONAL MATHEMATICS","07/01/2022","05/23/2022","James Nagy","GA","Emory University","Standard Grant","Stacey Levine","06/30/2025","$346,631.00","","jnagy@emory.edu","201 DOWMAN DR","ATLANTA","GA","303221061","4047272503","MPS","1271","079Z, 9263","$0.00","The gaming industry, machine learning (ML), and artificial intelligence (AI) are areas that require substantial computational resources and/or require very fast computations, but do not always require high accuracy in certain computational problems. This has motivated companies to manufacture computer chip hardware, such as graphical processing units (GPUs) that can perform very fast computations using low precision computer arithmetic formats. This can result in a 4-times speedup compared to high precision arithmetic used in typical scientific applications. The potential for much faster computations has fueled a growing interest in the last decade to use powerful GPU servers for scientific applications, and in particular to use mixed precision algorithms for problems that require high accuracy. That is, when possible, use low precision for speed, but mix in high precision computations when needed to maintain accuracy. Although previous work has been done for certain core linear algebra computations, relatively little has been done to exploit and understand the implications of using mixed precision arithmetic for the more challenging class of ill-posed problems.  The focus of this work is on developing methods for this frontier, so that efficient solvers can take advantage of modern GPUs with mixed precision computing capabilities.  Special considerations, which normally do not arise when solving well-conditioned problems, need to be considered.  Applications in machine learning, image restoration and image reconstruction, including breast imaging, will be used as target test problems, but an important aim of this work is to construct a computational platform that can be used to efficiently compute approximate solutions of large scale ill-posed inverse problems in a variety of applications. By developing a flexible and adaptable computational platform, the work produced from this project aims to have a broad scientific impact for applications where it is necessary to compute solutions of large-scale inverse problems with regularization, including astronomy, cosmology, geophysics, machine learning, microscopy, and medical imaging. Students and postdocs will be trained as part of this project.  <br/><br/>The potential for much faster computations has fueled a growing interest in the last decade to use powerful GPU servers for scientific applications, and in particular to use mixed precision algorithms for problems that require high accuracy; that is, when possible, use low precision for speed, but mix in high precision computations to improve accuracy. Recent previous work to develop mixed precision computational approaches for scientific applications have focused on general, well-conditioned linear systems, including iterative refinement, Cholesky factorization and least squares problems, QR factorization, and GMRES. The aim of this project is to focus on the development of mixed precision computations for the more challenging class of large-scale ill-posed inverse problems.  The approach will use a combination of operator approximation, using a low precision truncated singular value decomposition with iterative refinement exploiting mixed precision formats to ensure sufficient accuracy, or as preconditioners in Krylov subspace iterative methods. In addition, mixed precision, possibly with iterative refinement, will be applied within flexible and/or inexact hybrid Krylov subspace methods to reduce storage requirements and computational costs that increase at each iteration. The methods developed in this project can be used as tools to obtain approximate solutions of ill-posed inverse problems, or as solvers in machine learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208535","Machine Learning for Bayesian Inverse Problems","DMS","COMPUTATIONAL MATHEMATICS","09/01/2022","05/20/2022","Bamdad Hosseini","WA","University of Washington","Standard Grant","Stacey Levine","08/31/2025","$274,560.00","","bamdadh@uw.edu","4333 BROOKLYN AVE NE","SEATTLE","WA","981950001","2065434043","MPS","1271","075Z, 079Z, 9263","$0.00","Artificial intelligence (AI) has had a profound impact in information technology and commerce to the degree of in?uencing societal transformation over the last decade. The remarkable success of AI has led to a torrent of research aiming to use AI to solve challenging problems in science and engineering. Despite the empirical success of these methods, our mathematical understanding of the underlying algorithms is limited and we do not fully understand why and how these algorithms perform so well, making their predictability less certain. The aim of this project is to address these shortcomings as they pertain to AI algorithms for a large family of engineering problems called ""inverse problems"", where an unknown parameter is predicted from indirect measurements, such as MRI imaging. The project will also involve outreach activities organized through the University of Washington such as the training and retention of young researchers including explicit plans to involve underrepresented groups in the STEM fields.<br/><br/>Recent advances in Machine Learning (ML) have led to the development of novel techniques for the solution of inverse problems but our theoretical understanding of these methods is limited and the majority of them are incapable of uncertainty quanti?cation. The purpose of this project is to address these shortcomings by developing foundational theory for ML methods for Bayesian inverse problems and to design novel computational techniques that enable ML methods to quantify uncertainties. A measure theoretic interpretation of BIPs will be employed in our theoretical analysis to address the questions of well-posedness, stability, and consistency. New computational techniques will be developed using Markov chain Monte Carlo algorithms, data-driven construction of prior information, and recent variational inference techniques based on generative modeling and optimal transport.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2207164","The High-Order Shifted Boundary Method: A Finite Element Method for Complex Geometries without Boundary-Fitted Grids","DMS","COMPUTATIONAL MATHEMATICS","08/01/2022","08/17/2023","Guglielmo Scovazzi","NC","Duke University","Continuing Grant","Yuliya Gorb","07/31/2025","$252,954.00","","guglielmo.scovazzi@duke.edu","2200 W MAIN ST","DURHAM","NC","277054640","9196843030","MPS","1271","9263","$0.00","High fidelity computational methods are an invaluable tool for analysis, with many breakthroughs in the simulation and understanding of complex physics phenomena. However, over the past two decades, high-fidelity methods have faced the daunting challenge of an increasing geometric complexity of the shapes to be simulated. Additive manufacturing and optimization raised the geometric complexity of designs to new heights, and the current algorithms are lagging behind. Because of the specific computational infrastructure of a high-fidelity method, setting up the geometrical description of design shapes takes more time than the actual computation. Consequently, high-fidelity computational methods for physics modeling have often been confined to simple design shapes. This project is aimed at breaking this barrier, introducing a new way of computationally model the boundary surfaces of complex geometrical objects. This project aims to transform the field of computing as we know it, fostering a renaissance of high-fidelity methods in scientific computing, with broad benefits in all fields of science and engineering, including the interface of simulation with artificial intelligence and other meta-algorithms, digital twins, etc.<br/><br/>High-Order Finite Element Methods (HO-FEMs) were originally applied to computational physics problems, with the primary goal of supporting the scientific understanding of complex multi-scale phenomena. Later, HO-FEMs have extended their realm of applications to engineering simulations, in which geometrically complex design shapes are very frequent. In this case, mesh generation with curvilinear elements is necessary to retain optimal accuracy near boundaries. This task is rather involved, and low levels of automation are often experienced, with a consequent slow-down of the entire design and analysis cycle. In 2018, the Shifted Boundary Method (SBM) was developed as an alternative to traditional methods. In the SBM, which belongs to the broad class of approximate/immersed boundary methods, the location where boundary conditions are applied is shifted from the true boundary to an approximate (surrogate) boundary. At the same time, the value of boundary conditions, applied weakly, is modified (shifted) by means of Taylor expansions to maintain optimal accuracy. The SBM is a simple, robust, accurate and efficient algorithm for very complex geometries, including the case of non-watertight boundary surfaces. This project aims at developing the higher-order SBM (HO-SBM) and its mathematical analysis of numerical stability and accuracy, for the Poisson, Stokes, Darcy, and compressible Euler equations. HO-SBM has several advantages: first and foremost, it does not require curved grid edges along the surrogate boundary to obtain optimal accuracy. Complex geometries are characterized by the distance between the surrogate boundary and true boundary of the shapes to be simulated. Hence, the HO-SBM has a flexible integration with current CAD and mesh generation and can help the broad diffusion of reduced-order modeling, machine learning, uncertainty quantification, and optimization methods to complex engineering problems. Together with the education of a graduate student in computational mathematics and sciences, this projects also aims at attracting undergraduate students interested using computing for design, by exposing them to simplified, easy-to-use versions of the HO-SBM method.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208392","Collaborative Research: Nonconvex Models for Structured Sensing: Theory, Algorithms, and Applications","DMS","COMPUTATIONAL MATHEMATICS","09/01/2022","05/23/2022","Abiy Tasissa","MA","Tufts University","Standard Grant","Yuliya Gorb","08/31/2025","$199,968.00","","abiy.tasissa@tufts.edu","169 HOLLAND ST","SOMERVILLE","MA","021442401","6176273696","MPS","1271","075Z, 079Z, 9263","$0.00","The rapid advance of technology has enabled more than ever the ability to collect large amounts of data. While the abundance of such data is advantageous, it brings forth several computational challenges. One challenge is the fact that data might contain numerous missing entries. This is the case for instance when using physical measurement devices with a limited range or in collecting user preferences for a product where we lack complete information. One line of methods that has proved to be useful for this problem is matrix completion algorithms which predict missing entries with minimalistic assumptions on the data. However, in problems such as structure prediction and recommendation system with side information, the measurements are not entry-wise. Specifically, the observations are an aggregate of some entries of the underlying data, i.e., rather than directly observing the entries of the data, the user has access to certain combinations of these entries. This project aims to study this problem which is well known as the matrix sensing problem. The majority of previous works consider the case where measurements of the data are missing at random or assume that the measurement protocol itself is random. Motivated by practical applications, this project considers a realistic setup where the measurements are structured and deterministic. A key goal of this project is to advance the state of art theory and computation of matrix sensing by studying new optimization algorithms. Another aim of the project is to apply the constructed framework to robust structure prediction and machine learning. <br/><br/>This project seeks to study scalable non-convex methods for a class of generalized matrix recovery problems. In particular, PIs are interested in low-rank matrix sensing problems with deterministically structured measurements under various settings. The main approach is based on formulating the optimization problem with respect to a deterministic measurement basis and its associated dual basis. This yields a well-posed problem under some mild conditions. The project is centered on three objectives. In the first part, the project studies the local convergence of a Riemannian gradient descent algorithm that directly optimizes over the manifold of low-rank matrices. The recovery guarantee then will depend mainly on the spectral properties of the basis and the dual basis, the sampling scheme, and the initialization. Tight estimation of the spectral properties and effective initialization method will be investigated by bridging connections to spectral graph theory. The second objective is to design an algorithm tailored for the Euclidean distance geometry (EDG) problem which aims to estimate the configuration of points given partial information about pairwise distances. EDG is a representative problem that utilizes deterministically structured measurements. By leveraging the special structure of EDG, the project aims to design optimally efficient algorithms and establish theoretical analysis for the exact recovery of the point configuration. The third objective considers the setting where the measurements might be sparsely corrupted. The project aims to develop fast and robust algorithms tailored to this case and carry out the necessary analysis for recovery guarantees. To realize these objectives, the project leverages tools from high-dimensional probability, Riemannian optimization, numerical analysis, and spectral graph theory. The project will provide opportunities to train undergraduate and graduate students with interests in distance geometry, optimization theory, and computational science.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2204490","Spring Lecture Series in Computational and Applied Mathematics","DMS","COMPUTATIONAL MATHEMATICS","05/15/2022","05/03/2022","Tulin Kaman","AR","University of Arkansas","Standard Grant","Stacey Levine","07/31/2023","$25,369.00","","tkaman@uark.edu","1125 W MAPLE ST STE 316","FAYETTEVILLE","AR","727013124","4795753845","MPS","1271","7556, 9150, 9263","$0.00","This award provides participant support for the Spring Lecture Series (SLS) on `Numerical linear algebra: from scientific computing to data science applications' at the University of Arkansas in Fayetteville, Arkansas, on May 4-6, 2022.  Numerical linear algebra is at the core of many fields of science and engineering, whether in solving linear systems that arise from simulations of physical phenomena, or in obtaining various solutions of optimization problems in data related applications. As the world around us is progressively being analyzed or modeled with the help of available data, the types of computational problems encountered are changing, and as a result the field is currently undergoing a deep transformation. The principal speaker at the lecture series, Yousef Saad, will present an overview of methodologies that are used in both the scientific computing and data science disciplines in a series of five lectures. To build a bridge between Scientific Computing and Data Science, one of the goals of the lectures is to introduce data science techniques to non-specialists in scientific computing. Additionally, there will be ten one-hour lectures by invited speakers as well as poster and oral presentation sessions by young researchers which are intended to provide an opportunity for the exchange of ideas and expertise within and between the various computational science domains. Furthermore, a public lecture by Professor Sabine Van Huffel will be accessible to the community at large, and will focus on the power of matrix/tensor algebra and data-driven artificial intelligence (AI) in digital healthcare. A Women in STEM panel in intended to provide an environment for sharing of ideas and experiences with the goal of fostering diversity in research and promoting the participation of underrepresented groups in STEM.<br/><br/>The lectures will present fundamental ideas of numerical linear algebra with an emphasis on those methods that have the potential to play an important role in data science, including eigenvalue and singular value problems, sparse matrix techniques, graph-based methods, Krylov subspaces methods, and preconditioning. Part of the lectures will be devoted to specific problems of in data science, covering applications of graph-based methods, randomization methods, network analysis, dimension reduction, and neural networks, among other themes. This lecture series will provide unique opportunities for early career researchers and graduate students to interact with prominent experts in their research areas. More information is available at https://fulbright.uark.edu/departments/math/research/spring-lecture-series/index.php<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2207449","Deep Neural Network Machine Learning for Oscillatory Navier-Stokes Flows and Nonlinear Operators, and High Dimensional Fokker-Planck Equations","DMS","COMPUTATIONAL MATHEMATICS","08/01/2022","08/02/2022","Wei Cai","TX","Southern Methodist University","Standard Grant","Yuliya Gorb","07/31/2025","$348,805.00","","cai@smu.edu","6425 BOAZ LANE","DALLAS","TX","75205","2147684708","MPS","1271","075Z, 079Z, 9263","$0.00","The goal of this project is to develop machine learning (ML) technology with deep neural networks (DNNs) to study a wide range of physical and chemical phenomena. DNN has demonstrated its tremendous power in artificial intelligence (AI) applications such as speech recognition, automatic self-driving, image classification, etc. This research will attempt to harness the power of the DNN for scientific discoveries by increasing computational and simulation capabilities in learning and understanding complex phenomena such as fluid flows for ship building applications, seismic wave predictions, chemical reactions in drug designs.<br/> <br/>In this project, to address some of the key computational challenges in scientific computing, new classes of deep neural network (DNN) ML algorithms will be developed with capabilities for better frequency resolution for simulating oscillatory fluid flows in complex geometries and nonlinear operators in oscillatory function spaces, and increased powers for addressing the curse of dimensionality (CoD) in solving high dimensional Fokker-Planck equations (FPE) from transition path theory (TPT) of complex biochemical systems. Specifically, research will be carried out in three major computational issues relevant to scientific and engineering computing: (a) To develop multiscale DNNs as a viable meshless method for solving time dependent highly oscillatory Navier-Stokes flows in complex domains, and a practical alternative method to traditional numerical methods with no costly mesh generation or linear system solvers. (b) To develop multiscale DNN learning algorithms for nonlinear operators in highly oscillatory function spaces for seismic wave prediction, and forward and inverse scattering applications. (c) To develop forward and backward stochastic differential equation (FBSDE) based multiscale DNNs for boundary value problems of high dimensional PDEs such as Fokker-Planck equations arising from statistical description of physical systems with application in computing committor functions and transition rates in transition path sampling theory of complex chemical and biological systems. This research will have a broad impact in improving the capability of ML for scientific computing in many ways. Efficient meshless DNN algorithms for oscillatory flows in complex geometry and representation of nonlinear operator for physical qualities of highly oscillatory nature can reduce the cost of many optimization, and forward and inverse problems in scientific and engineering research. Overcoming the CoD in solving high dimensional Fokker-Planck equations with the multi-scale FBSDE DNN algorithms will have a wide range impact on both the ML research and many scientific areas such as material sciences and optimal control, financial engineering, as well as to biological system dynamics. Moreover, the project will place strong emphasis on data science education with new ML course development and activities in the Data Science Institute at SMU.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208465","Hybrid Computational Modeling and Advanced Numerical Methods for Biomolecular Interactions","DMS","COMPUTATIONAL MATHEMATICS, MSPA-INTERDISCIPLINARY","09/01/2022","08/17/2022","Li-Tien Cheng","CA","University of California-San Diego","Standard Grant","Yuliya Gorb","08/31/2025","$536,946.00","Bo Li","lcheng@math.ucsd.edu","9500 GILMAN DRIVE","LA JOLLA","CA","920930021","8585344896","MPS","1271, 7454","068Z, 9263","$0.00","This project develops rigorous scientific theories and powerful computational tools to investigate the principal mechanisms by which drug and protein molecules associate and dissociate. Often, a drug molecule moves around in a crowded environment, and finds a spot of the surface of a protein to bind to, stays there, and can also leave, unbinding from the protein. During such binding and unbinding events, often repeated, both molecules constantly change their internal atomic positions. They also interact with other molecules, particularly the water molecules, in the surrounding environment. There are two key scientific questions on such complex processes that are characterized by multiple spatiotemporal scales and many-body effects. One is how stable the drug-protein bound unit is. Such thermodynamic stability serves as a criterion for searching drug molecules capable of binding to targeted proteins. The other is how fast or slow the binding and unbinding can occur. Such kinetics has been found recently in experiments and computer simulations to be critical to the drug effectiveness and efficacy. For decades, the scientific communities have made an enormous amount of effect, searching the quantitative answers to these questions to guide the computer-aided drug design and discovery. A recent assessment by the National Institutes of Health of the existing such computer programs, however, has concluded that advanced scientific theories are needed urgently to improve the practice. The success of this project can therefore provide a solid theoretical foundation as well as computational algorithms for drug design and discovery, potentially helping reduce the very high cost often needed for laboratory experiments and speed up the process of drug discovery. In addition, this highly interdisciplinary research project provides unique opportunities for students at different levels to receive training at the interface of mathematical, computational, and biological sciences, keeping our nation's strength in scientific research in a highly competitive international environment.<br/><br/>To tackle the complex problem of molecular association and dissociation, the investigators will design, implement, and analyze a very fast binary level-set method for interface relaxation to capture the molecular interfacial structures in the framework of an advanced, variational molecular solvation theory. The new method combines the strength of the threshold dynamics and the binary level-set representation, and utilizes the locality of the underlying energy landscape, and new pixel-flipping techniques, to achieve very high efficiency.  They also develop a new and hybrid computational approach to the kinetics of interface stochastic dynamics, coupling the interfacial energy minimization by the fast algorithm, the string method for transition pathways, and a novel, multi-state Brownian dynamics simulations. All these are applied specifically to investigating the molecular binding and unbinding kinetics for which some of the conventional methods, such as the standard Brownian dynamics simulations, may fail. It is expected that this project will advance significantly basic research in scientific computing and numerical analysis, particularly at the interface of dynamics and stochastic modeling. This research will help resolve some of the bottle-neck issues in solving very complex scientific problems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208056","Computational Tools for Exploring Eigenvector Localization","DMS","COMPUTATIONAL MATHEMATICS","08/01/2022","08/02/2022","Jeffrey Ovall","OR","Portland State University","Standard Grant","Yuliya Gorb","07/31/2025","$381,179.00","","jovall@pdx.edu","1600 SW 4TH AVE","PORTLAND","OR","972015522","5037259900","MPS","1271","9263","$0.00","Vibrations in complex systems are best understood in terms of superpositions of stationary waves whose amplitudes vary in time. These stationary waves are eigenvectors (modes of vibration) of an associated time-independent differential operator, and their corresponding eigenvalues represent energies associated with these modes of vibration. A better understanding of where such eigenvectors are likely to localize, and for which eigenvalues this localization occurs, is of practical interest in the design of structures having desired acoustic or electro-magnetic properties: sound-mitigating outdoor barriers and next generation organic LEDs and solar cells are examples of this design principle in action. Computational tools for exploring eigenvector localization phenomena are an essential component of simulations guiding design decisions, but such tools are very new and very few. The work supported by this grant will provide new techniques for a much broader exploration of localization phenomena than is currently feasible, allowing for exploration much deeper into the spectrum for a broader class of operators/models, with built-in mechanisms for accepting/rejecting localization claims based on measurable quantities.<br/><br/>This project focuses on the following fundamental task: Given a subdomain, a small tolerance and a finite interval, find all eigenvalue/eigenvector pairs (eigenpairs) of the operator whose eigenvalue is in the interval and whose eigenvector is localized in the subdomain to within the given tolerance. A complex and compact perturbation of the original operator is constructed such that any eigenpair of the original operator satisfying the conditions above will have an ""echo"" for the new operator, i.e. there will be an eigenpair of the new operator whose eigenvalue is in a well-defined ""target region"" of the complex plane determined by the localization conditions, and most(!) eigenpairs of the original operator not satisfying the localization condition will not have such an echo. A contour-integral based eigenvalue solver is then used to efficiently identify eigenpairs of the new operator whose eigenvalues are within the target region. This constitutes the first phase of the method, and empirical evidence already strongly indicates that most unlikely candidates are filtered out in this phase, and all likely candidates are maintained. The remaining candidates are then (cheaply) post-processed to determine the eigenpairs of the original operator of which they were echos. A final simple check of these eigenpairs determines which are ultimately accepted. Several aspects of this approach are embarrassingly parallel, and that fact will be exploited to conduct more thorough investigations of localization than have been previously attempted. The project involves the development of software that will be made publicly available.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208163","New Algorithms for Markov Decision Processes and Reinforcement Learning","DMS","COMPUTATIONAL MATHEMATICS","09/01/2022","08/01/2023","Lexing Ying","CA","Stanford University","Continuing Grant","Stacey Levine","08/31/2025","$359,813.00","","lexing@math.stanford.edu","450 JANE STANFORD WAY","STANFORD","CA","943052004","6507232300","MPS","1271","079Z, 9263","$0.00","Markov decision processes and reinforcement learning have had significant recent success in applications, ranging from outperforming humans in Atari games to AlphaFold overshadowing competing methods in predicting protein folding. This success results from several fundamental developments, including deep neural networks providing a powerful mechanism for representing high dimensional functions, unprecedented computing power provided by graphical processing units and tensor processing units, and the development of novel algorithms for both prediction and control. However, there are still many challenges in applying these recent techniques to mission-critical applications in health, social and economic planning, and defense. This project aims to develop and analyze novel algorithms for Markov decision processes and reinforcement learning with the intention of making these approaches more broadly applicable. Educational impacts include postdoctoral and graduate student training, as well as undergraduate course development centered around machine learning.  <br/><br/>This project involves the development of a unified framework for Markov decision processes based on linear programming, where the primal, dual, and primal-dual problems are studied for both the regularized and non-regularized cases. Existing algorithms based on Markov decision processes will then be connected to this unified framework. For the tabular setting, a quasi-Newton type policy gradient algorithm will be developed for general entropic regularizers. For the primal-dual problem, a rapidly converging gradient ascent descent algorithm based on a strictly convexified formulation with a non-standard preconditioning metric will be developed.  The nonlinear approximation setting will be addressed by variational actor-critic algorithms that are stable and converge at least to a local minimum. Finally, to address the double sampling issue, new algorithms based on the borrowing-from-the-future idea will be developed to significantly reduce the bias.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2207207","Structure-Preserving Algorithms for Hyperbolic Balance Laws with Uncertainty","DMS","COMPUTATIONAL MATHEMATICS","07/01/2022","06/28/2022","Yekaterina Epshteyn","UT","University of Utah","Standard Grant","Yuliya Gorb","06/30/2025","$450,000.00","Akil Narayan","epshteyn@math.utah.edu","201 PRESIDENTS CIR","SALT LAKE CITY","UT","841129049","8015816903","MPS","1271","9263","$0.00","The project will make significant contributions to the design and analysis of novel stochastic models and numerical algorithms for hyperbolic conservation/balance laws with uncertainty. Such systems are the essential mathematical apparatus for modeling a variety of complex physical phenomena, including wave propagation and fluid flow. The developed stochastic models and numerical methods will improve the accuracy and predictive capabilities of the computational tools used in different areas of science and engineering with applications ranging from coastal and hydraulic engineering, to modeling atmospheric and oceanographic phenomena, including hurricanes, typhoons, tsunamis, and resulting storm surges. The obtained numerical algorithms and data will be made available to other researchers. For the training of the next-generation mathematical workforce, in addition to mentoring of graduate and undergraduate students, the PIs will participate in outreach activities and will continue to work towards increasing diversity and broadening participation within STEM.<br/><br/>The main objective of the project is the development and analysis of robust high-resolution structure-preserving stochastic models and numerical methods for hyperbolic conservation/balance laws with uncertainty. As a primary exemplar, the research will focus on the shallow water equations, but the designed tools will be applicable to a wider class of conservation/balance laws, as well as to convection-diffusion model problems, and problems more general than the shallow water equations will be investigated. Shallow water models and related systems are widely used in many important applications related to modeling and prediction of the dynamics of surface flows, such as water flows in rivers, lakes, and coastal areas. The classical system of deterministic shallow water equations, known as the Saint-Venant system, is a nonlinear hyperbolic system of conservation/balance laws. The Saint-Venant model can admit non-smooth solutions that may have shocks, rarefaction waves, and if the bottom topography is discontinuous, contact discontinuities. In the latter case, the solution may not be unique, which makes the development of accurate and efficient algorithms more challenging even in the one-dimensional deterministic case. Taking into account the effects of, for example, Coriolis forces, bottom friction stresses, and randomness/uncertainties in the data, on one hand is crucial for the design of models and simulations with improved predictive capabilities. On the other hand, such mathematical models can present a significant challenge for the construction of robust numerical algorithms. Therefore, the primary goals of this research are (1) to develop intrusive and non-intrusive robust uncertainty quantification (UQ) techniques that will lead to physically-relevant stochastic shallow water models and related systems; (2) to design and analyze adaptive high-order accurate structure-preserving deterministic and stochastic solvers for resulting models; (3) and to develop computationally efficient and parallelizable algorithms. Advances achieved by the project will tackle outstanding challenges in numerical methods for nonlinear conservation/balance laws and UQ for transport problems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2216799","US Participation at the Twenty-sixth International Domain Decomposition Conference","DMS","COMPUTATIONAL MATHEMATICS","08/01/2022","07/25/2022","Jonathan Siegel","PA","Pennsylvania State Univ University Park","Standard Grant","Yuliya Gorb","01/31/2024","$15,000.00","","jwsiegel@tamu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271","7556, 9263","$0.00","Since 1987, the International Conferences of Domain Decomposition Methods (DDM) have been held in 15 countries throughout Asia, Europe and North America. The 27th edition of this prestigious conference will be held at the Czech Technical University in Prague, Czech Republic, on July 25-29, 2022. The primary topic of the conference concerns large scale scientific computing problems, which are an important and very general interdisciplinary research field and plays a crucial role in many application areas, for example weather forecast, seismic predictions, fluid simulations, material industry, oil field exploration, medical imaging, among others. This project will enable US based junior researchers to travel to the conference, network, and present their research.<br/><br/>The International Conference of Domain Decomposition Methods is the only regularly occurring international forum dedicated to interdisciplinary technical interactions between theoreticians and practitioners working in the development, analysis, software implementation, and application of domain decomposition methods, which are important in scientific computing. The complexity and size of such problems often lead to very large systems, where massive computing resources and special computational approaches must be employed to obtain approximate solutions. As we approach the dawn of exascale computing, scalable techniques such as DDM are vital tools for solving complex problems that would otherwise be intractable.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208470","Efficient Solver Algorithms for Graphical Processing Units","DMS","COMPUTATIONAL MATHEMATICS","08/15/2022","08/12/2022","Eric de Sturler","VA","Virginia Polytechnic Institute and State University","Continuing Grant","Yuliya Gorb","07/31/2025","$278,632.00","Timothy Warburton","sturler@vt.edu","300 TURNER ST NW","BLACKSBURG","VA","240603359","5402315281","MPS","1271","9263","$0.00","The extensive use of graphical processing units (GPUs) for computer simulations is transforming large-scale simulations. With algorithms that run at a good fraction of peak performance, simulations that recently were only within reach for large multinational companies and national labs are now available even to small start-up companies. Unfortunately, it is not easy to write algorithms that can exploit the peak performance of GPUs. This project focuses on linear solvers, which generally account for a very large fraction of simulation time, with the goal of improving efficiency on GPU-based architectures. More specifically, the project aims to combine a range of techniques to reduce memory usage and data movement (which is time-consuming on GPUs), better initial guesses and better stopping criteria (to halt intermediate computations earlier at an appropriate precision), and dynamic updates to solver parameters to improve efficiency. Applications targeted in this project are primarily in computational fluid dynamics, but also include inverse problems and large-scale topology optimization. The latter plays a fundamental role in the development of new micro-structure/meta materials, their use in the design of optimal structures, and their manufacturing. The project will involve a graduate research assistant and a postdoc. The project will also develop a new graduate course that combines elements of numerical linear algebra, numerical ordinary and partial differential equations, and GPU computing, all with a focus on high performance.<br/><br/>This project involves developing iterative solvers for large-scale problems suitable for graphics processing unit (GPU) based architectures. The work aims to thoroughly reevaluate solver architecture to ensure that every part is optimized for GPUs, exposing massive fine grain parallelism in every component, maximizing throughput at every level of the GPU memory hierarchy, and minimizing data movement. This project focuses on algorithmic development that combines and analyzes three key strategies: mixed precision variants and inexact matrix-vector products and smoothers; computing better initial guesses and more effective stopping criteria and indicators; and dynamic solver optimization and flexible preconditioning strategies. The results will be tested on benchmarks developed by the Department of Energy's Center for Efficient Exascale Discretizations and similar benchmarks to be developed during this project. The theoretical underpinnings from this project will allow these solver strategies to have substantial impact beyond the immediate goals of this project. The open-source algorithms and software developed for this project will be made freely available to a wide group of potential users.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208590","Developing Efficient and Robust Computational Tools for Subdiffusive Transport in Poroelastic Media","DMS","COMPUTATIONAL MATHEMATICS","08/01/2022","08/01/2022","Jiangguo Liu","CO","Colorado State University","Standard Grant","Yuliya Gorb","07/31/2025","$234,907.00","","liu@math.colostate.edu","601 S HOWES ST","FORT COLLINS","CO","805212807","9704916355","MPS","1271","9263","$0.00","Transport in porous media occurs in a broad range of real world problems, e.g., CO2 sequestration and delivery of therapy agents to tumor sites. This project aims at development of robust and efficient numerical simulation toolboxes for such multi-scale multi-physics processes. This will enhance our understanding of these complicated phenomena and accordingly have further impact on better use of natural resources and cures for diseases. The project will also provide hands-on training opportunities for students.<br/><br/>The focus of this project is on design, analysis, implementation, and applications of a family of novel numerical methods for subdiffusive transport in poroelastic media. Novel finite element methods will be developed for approximating solid displacement, fluid pressure, and concentration of substance being transported. Conditions for stable coupling of sub-problem solvers will be investigated. These methods will be applied to simulations of drug delivery, tissue engineering, and reservoir engineering, and other similar multi-physics processes. These novel solvers will be implemented as C++ and Matlab code modules that are openly accessible to the scientific computing community.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2207328","Data-driven statistical dynamical modeling: Shortage of training data and high- dimensionality","DMS","COMPUTATIONAL MATHEMATICS","08/01/2022","05/27/2022","John Harlim","PA","Pennsylvania State Univ University Park","Standard Grant","Yuliya Gorb","07/31/2025","$300,000.00","","jharlim@psu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1271","075Z, 079Z, 9263","$0.00","Today, machine learning is a prominent scientific computing tool with many practical applications. Notable successes are the classification problems of identifying pictures and the Artificial Intelligence (AI) Go-player that beats the best human player in the world. While these successes are important milestones, there are emerging needs to replicate these successes in the statistical modeling of time-evolving complex systems, with examples ranging from predicting climate to nanomaterials under external disturbances. The goal of this project is to develop the next-generation mathematical and algorithmic tools to overcome two important issues in extending machine learning to such problems, namely a shortage of informative data for effective learning and the expensive computational costs. This objective will be addressed by a theoretical and algorithmic development in computational mathematics, leveraging the fundamental knowledge from the basic sciences, including geometry, dynamical systems, data sciences, and statistics. This project will contribute to the NSF mission of advancing STEM through the training of graduate students and curricular development through the design of courses in the mathematical theory of machine learning. In particular, this project will support one graduate student.<br/> <br/>The goals of this project are to overcome the shortage of training data and exploit the manifold assumption to avoid the curse of dimension in the statistical modeling of dynamical systems. Beyond uncertainty quantification (UQ) applications, a statistical closure model will be developed to enhance the training of ML-based prediction models when the observed time series is too short for accurate estimation. Specifically, the proposed projects are: 1) To develop a systematic reduced-order statistical closure model. This project extends the recently developed ML-based non-Markovian closure framework for accurate predictions of statistical responses subjected to unseen external forcings, which is important for UQ. 2) To develop a dimensionality reduction technique that respects the geometry of the data under a manifold assumption on the dynamical variables. The approach includes an accurate Radial Basis Function approximation to the Bochner Laplacian from the embedded data. Subsequently, the estimated eigen-vector-fields will be used as a frame to represent the vector fields corresponding to the unresolved dynamics. This model reduction framework provides a computationally cheaper alternative to deep learning. 3) To study the theoretical convergence property of a recently developed algorithm, Bayesian Machine Learning (BML), which uses solutions of a statistically consistent model to enhance the training of the neural network (NN) model in learning non-Markovian dynamics with a short observational time series. This study is motivated by a recent empirical finding that the NN model obtained from the BML training algorithm improves the accuracy of the El Nio prediction by at least two months compared to the same NN architecture trained using the standard stochastic gradient descent algorithm. The ultimate goal of this study is to evaluate and develop a theoretical understanding of the effectiveness of the statistical closure model from Task 1) to enhance Bayesian Machine Learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2143331","CAREER: New Algorithms and Models for Turbulence in Incompressible Fluids","DMS","COMPUTATIONAL MATHEMATICS","08/01/2022","07/26/2023","Nan Jiang","FL","University of Florida","Continuing Grant","Yuliya Gorb","07/31/2027","$184,646.00","","jiangn@ufl.edu","1523 UNION RD RM 207","GAINESVILLE","FL","326111941","3523923516","MPS","1271","1045, 9263","$0.00","Turbulence is ubiquitous in nature, and decisions that affect our life are made daily based on predictions of turbulent flows. Obtaining accurate predictions of turbulent flows is a central challenge in global change estimation, weather forecasting, freshwater supply, improving the energy efficiency of engines, controlling dispersal of contaminants, and designing biomedical devices. A turbulent flow is a highly irregular system, characterized by chaotic property changes involving a wide range of scales in nonlinear interaction with each other. These features yield a high computational complexity, which makes direct numerical simulations of turbulent flows that aim at resolving all features down to the smallest scales infeasible even with modern supercomputers. Instead, turbulence models are used for practical turbulence simulations to bypass the chaotic details and reduce the computational complexity. This project aims to develop a new family of ensemble averaged turbulence models and novel numerical methods for their solution, extending current applicability and computational limitations of effective turbulence simulations, which may have a great impact on numerous applications in aeronautics, hydraulics, chemical engineering, oceanography, meteorology, astrophysics, and geophysics, considering turbulence?s prominent influence in almost all geophysical and industrial flows. A comprehensive educational program will be developed to provide students with systematic training in computational fluid dynamics and bring them up to date on current research topics in this field. <br/><br/>Turbulence modeling remains one of the most important scientific challenges. The fundamental approach for turbulence modeling is to seek to approximate suitable (ensemble, time, or spatial) averages of fluid velocity instead of pointwise velocity itself. Ensemble averaging is the most intuitive approach from the statistical theory for turbulence, but it is currently not in use for practical turbulence simulations of industrial flows due to the extremely high computational cost associated with ensemble simulations. This deadlock is recently broken with newly developed ensemble algorithms that give access to the full ensemble at every time step and thus open new and direct possibilities for developing turbulence models for the ensemble averaged Navier-Stokes equations. In this project the investigator will develop a new family of ensemble-based variational multiscale method (VMS) turbulence models and novel numerical methods under the new framework of ensemble averaging for practical turbulent flow simulations. New unconditionally stable ensemble algorithms will be developed for fast solution of the new ensemble-based VMS turbulence models and to effectively overcome the backflow instability for turbulent flows with open boundary conditions. This project will provide new avenues to turbulence modeling and simulations and build a new rigorous numerical analysis addressing how to make effective approximations in the face of Newtonian chaos.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208303","The Heavy-Tailed Methods in Machine Learning","DMS","COMPUTATIONAL MATHEMATICS","07/01/2022","05/23/2022","Lingjiong Zhu","FL","Florida State University","Standard Grant","Stacey Levine","06/30/2025","$163,533.00","","zhu@math.fsu.edu","874 TRADITIONS WAY","TALLAHASSEE","FL","323060001","8506445260","MPS","1271","075Z, 079Z, 9263","$0.00","Stochastic gradient descent and its variants are core algorithms for solving machine learning problems and work remarkably well in practice. However, a general theory that explains their success is still lacking. One popular approach is to impose structure on the gradient noise, typically modeled by Gaussian or other light-tailed distributions. However, many empirical and some recent theoretical works challenge these assumptions, calling for an understanding of heavy-tailed distributions and resulting phenomena in machine learning. In this project, a theoretical framework will be built towards understanding and explaining why and how heavy tailed distributions arise in popular machine learning algorithms, and how heavy tails can better explain their success, bridging a gap between theory and practice. The results derived from this project are expected to impact the mathematics community as well as developers and  practitioners in the data science and machine learning communities.  <br/><br/>In this project, theoretical convergence properties and performance guarantees will be obtained for heavy-tailed stochastic gradient descent, their accelerated momentum-based methods, and continuous-time approximations. Further theoretical properties such as metastability will be studied to gain a further understanding of these heavy-tailed methods. A novel heavy-tailed adaptive Langevin algorithm and its variants will be developed and the theoretical guarantees will be studied for both sampling and non-convex stochastic optimization. Such an objective requires combining a broad set of ideas and mathematical tools from applied probability, continuous optimization, statistics and numerical analysis. Based on such mathematical developments the project will develop and study heavy-tailed algorithms with theoretical guarantees that can solve large-scale machine learning problems, ultimately building up a mathematical theory to explain the cause and implications of heavy-tailed distributions and other important phenomena that arise in machine learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208391","Runge-Kutta Discontinuous Galerkin Methods for Convection-Dominated Systems with Compact Stencils","DMS","COMPUTATIONAL MATHEMATICS","08/15/2022","08/03/2022","Zheng Sun","AL","University of Alabama Tuscaloosa","Standard Grant","Yuliya Gorb","07/31/2025","$158,030.00","","zsun30@ua.edu","301 ROSE ADMIN BLDG","TUSCALOOSA","AL","354870001","2053485152","MPS","1271","9150, 9263","$0.00","The main objective of this project is to systematically develop a novel class of efficient and high order accurate Runge?Kutta (RK) discontinuous Galerkin (DG) methods for convection-dominated problems and the related applications. The new methods feature improved compactness and local structures. They are expected to be more suitable for parallel computing and implicit time marching in computational fluid dynamics simulation. They have potential applications in diverse areas such as meteorology, oceanography, gas dynamics, aircraft design, hydraulic engineering, oil recovery simulation, and so on. The project will also provide research opportunities for graduate and/or undergraduate students interested in computational mathematics and benefit curriculum development in the PI?s department. <br/><br/>In more detail, the PI will investigate a novel approach to reduce the stencil size of the traditional RKDG methods, which typically grows with the number of RK stages. The resulting new methods are referred to as the compact RKDG methods. A comprehensive study of the methods will be carried out in the following directions. Firstly, high order compact RKDG methods will be designed for nonlinear hyperbolic conservation laws. Techniques for oscillation control, implicit time marching, and parallel computing will be investigated. Secondly, a rigorous theoretical framework for convergence, stability, and error analysis of the compact RKDG methods will be established. Thirdly, numerical techniques to preserve the solution bounds and investigate their applications to nonlinear hyperbolic systems in multidimensions will be developed. Finally, in addition to purely convection equations, the methods will be extended to convection-diffusion problems for simulation of viscous flow.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2331100","CAREER: Sparse Model Selection for Nonlinear Evolution Equations","DMS","COMPUTATIONAL MATHEMATICS","11/01/2022","07/14/2023","Hayden Schaeffer","CA","University of California-Los Angeles","Continuing Grant","Yuliya Gorb","05/31/2024","$62,087.00","","hayden@math.ucla.edu","10889 WILSHIRE BLVD STE 700","LOS ANGELES","CA","900244201","3107940102","MPS","1271","1045, 9263","$0.00","Extracting information from stationary and/or dynamic data is an important task in many scientific and industrial problems; including but not limited to, machine learning, data mining, image processing, and automated analysis of scientific data. This project focuses on learning the underlying process that generates observational data, in a sense, ""reverse-engineering"" models from data. These models are often used to gain insights on the data (for example, determining mathematical principles from experimental observations) or to make data-enabled decisions (for example, trend prediction). This is a challenging mathematical and computational problem, since one often has limited information on the process beforehand and real data is often noisy and/or incomplete. The research objective is to construct efficient computational methods for learning generating functions. This will involve a variety of mathematical techniques centered around optimization and sampling theory. The educational objective is to provide advanced training to undergraduate and graduate students in order to prepare them for the U.S. STEM workforce. In particular, students will be mentored and trained through mathematical and computational research projects, collaborative summer programs, working groups, and advanced courses that integrate education and research.<br/><br/>The goal is to develop computational methods for model learning, data analysis, and other machine learning tasks.  The overall objectives include: (i) the construction of optimization models that use sparsity, smoothness, and randomness to supplement the learning, (ii) the design of efficient and provably convergent numerical methods, (iii) the development of methods that are robust to sample size and outliers, and (iv) the creation and implementation of activities for undergraduate and graduate students that integrate education and research.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208518","Efficient Neural Network Based Numerical Schemes for Hyperbolic Conservation Laws","DMS","OFFICE OF MULTIDISCIPLINARY AC, COMPUTATIONAL MATHEMATICS","08/15/2022","07/14/2023","Xiangxiong Zhang","IN","Purdue University","Standard Grant","Yuliya Gorb","07/31/2025","$334,474.00","","zhan1966@purdue.edu","2550 NORTHWESTERN AVE STE 1900","WEST LAFAYETTE","IN","479061332","7654941055","MPS","1253, 1271","1515, 9263","$0.00","Neural network based methods have achieved success for many scientific computing problems, but for many other problems, they still lack satisfying and practical efficiency when compared to classical numerical methods. The PI will explore various approaches for enhancing efficiency of neural network based methods for solving hyperbolic conservation laws, which is a class of model equations used in many important applications including gas dynamics and basically describe transport. In addition, advanced optimization algorithms will be explored.  <br/> <br/>As a generic approach for solving PDEs, neural network based methods are still way less efficient than classical numerical methods in many applications, especially for hyperbolic conservation laws. The PI will explore methods for enhancing efficiency of neural network based methods for solving time-dependent hyperbolic conservation laws by using neural network as a spatial discretization along with suitable limiters for enforcing convex invariant domain by non-smooth convex optimization. A structured deterministic initialization of a neural network and a finite volume method for updating cell averages can be used to accelerate convergence of optimization for finding neural network solutions. Another focus of the project is to explore inspirations of recent breakthroughs in numerical PDEs toward designing more efficient optimization algorithms. In addition, optimization techniques from unconditionally stable schemes for gradient flow will be explored. A novel approach for constructing efficient neural network based numerical schemes for conservation laws will be investigated. A finite volume formulation will be used so that classical time marching tools can be easily combined with a neural network spatial discretization to simplify the optimization problem for acceleration of convergence. Rigorous analysis of non-smooth optimization algorithms for a limiter enforcing convex invariant domain along with efficient limiter implementation will be explored. Recent breakthroughs in unconditionally stable schemes for phase field equations will be applied to large scale optimization algorithms to seek possibly more efficient steady state solvers for gradient descent type algorithms in data science.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208321","Analysis and Novel Finite Element Methods for Elliptic Equations with Complex Boundary Conditions","DMS","COMPUTATIONAL MATHEMATICS","09/01/2022","08/01/2022","Hengguang Li","MI","Wayne State University","Standard Grant","Yuliya Gorb","08/31/2025","$220,347.00","","li@wayne.edu","5700 CASS AVE STE 4900","DETROIT","MI","482023692","3135772424","MPS","1271","9263","$0.00","Partial differential equations (PDEs) with complex boundary conditions (CBCs) are essential models across scientific disciplines. By CBCs, we mean boundary conditions (BCs) that are more complex than the basic Dirichlet or Neumann BC with regular boundary data that are usually adopted for the illustration and theoretical study of general-purpose numerical algorithms. These CBCs often lead to different types of singular solutions that severely deteriorate the efficacy of the numerical approximation. This project will develop simple, efficient, and robust numerical methods for problems with CBCs that appear in important applications. For example, in structural mechanics, low regularity boundary data (e.g., discontinuities or distributions) are used to model sudden changes of loads or concentrated forces acting on the boundary; the Robin BC, combined with the Dirichlet BC, is used to model the impedance BC that occurs in complete electrode models, in singularly perturbed radiation problems, and in embedding of quantum structures into a macroscopic flow; the Ventcel BCs are used to model heat conduction processes; and CBCs involving high-order differential operators are essential for biharmonic equations to model the static loading of a thin plate. It is also noted that different CBCs are important for models in fluid dynamics, electromagnetic fields, and fluid-structure interactions in hemodynamics applications. In addition, the PI expects that the project's educational component will demonstrate exciting innovations in scientific computing and encourage the future workforce from diverse backgrounds to pursue education in STEM fields.<br/><br/>The research project is on regularity analysis and on the development of finite element methods (FEMs) solving 2nd-order and 4th-order elliptic (PDEs) with CBCs. For 2nd-order PDEs, the CBCs include low regularity boundary data and various BCs (e.g., Dirichlet, Neumann, mixed, Robin, and Ventcel). For 4th-order PDEs, the CBCs under consideration are classical BCs especially associated with the biharmonic operator. These CBCs, together with the domain geometry, give rise to some of the most common solution singularities in practice. Addressing key analytical and computational issues, this research has two main components. (I) Innovative numerical algorithms. The PI will develop FEMs that are simple (easy to implement), efficient (effective in numerical approximation), and robust (applicable to general polygonal or polyhedral domains) for various singular solutions due to CBCs. (II) Rigorous theoretical investigation and applications. The PI will devise new analytical tools to justify and broaden the applications of the proposed FEMs. This includes (i) new well-posedness and regularity estimates for problems with CBCs; (ii) optimal error analysis; (iii) extensions to 3D and other practical models; (iv) efficient implementations in high-performance computing environments.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208256","Direct and Inverse Scattering in Biharmonic Waves: Analysis and Computation","DMS","COMPUTATIONAL MATHEMATICS","08/15/2022","06/29/2023","Peijun Li","IN","Purdue University","Continuing Grant","Stacey Levine","07/31/2025","$171,359.00","","lipeijun@math.purdue.edu","2550 NORTHWESTERN AVE STE 1900","WEST LAFAYETTE","IN","479061332","7654941055","MPS","1271","9263","$0.00","Scattering problems, which are concerned with the effect that an inhomogeneous medium has on an incident field, are fundamental in many scientific areas, including geophysical inspection, medical imaging, stealth technology, and nondestructive testing. As one of the key topics in modern mathematical physics, scattering problems have been widely investigated, and a large number of mathematical and numerical results are available, especially for acoustic, elastic, and electromagnetic waves. Recently, scattering problems for biharmonic waves have attracted much attention in the engineering and mathematical communities due to significant applications in thin plate elasticity, such as the design of platonic diffraction gratings and ultra-broadband elastic cloaking. The goal of this project is to address scientific challenges posed by scattering problems of the biharmonic plate wave equation. The nature of the proposed research is multidisciplinary, and the results of the proposed work will be actively shared with other researchers in mathematics, physics, engineering, and materials science. The educational plan is centered around providing interdisciplinary student training as well as developing an integrated curriculum from the undergraduate level to the graduate level. <br/><br/>Compared with the second-order acoustic, elastic, and electromagnetic wave equations, many direct and inverse scattering problems for the fourth-order biharmonic wave equation are not well understood. This project will further the modeling, theory, and algorithmic development of the direct and inverse scattering problems of the biharmonic plate wave equation, addressing scattering in periodic structures, scattering by multiple cavities, and inverse scattering for random sources. Specifically, the principal investigator will develop effective mathematical models and examine mathematical issues for the biharmonic plate wave equation in periodic structures, design an efficient computational approach for biharmonic wave propagation in multiple cavities, and establish mathematical theory on the uniqueness and stability of the inverse problems for the stochastic biharmonic wave equation. Results of this project are intended to contribute to our understanding of complex physical and mathematical problems in the scattering theory of thin plate elasticity. The research has the potential for evolving new science and providing the industry with guidance to design and fabricate new elastic devices in thin plates.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208339","Collaborative Research: Randomized Feature Methods for Modeling and Dynamics: Theory and Algorithms","DMS","COMPUTATIONAL MATHEMATICS","09/01/2022","06/03/2022","Hayden Schaeffer","PA","Carnegie-Mellon University","Standard Grant","Yuliya Gorb","06/30/2023","$234,994.00","","hayden@math.ucla.edu","5000 FORBES AVE","PITTSBURGH","PA","152133815","4122688746","MPS","1271","075Z, 079Z, 9251, 9263","$0.00","The objective of this research program is to develop consistent and theoretically validated machine learning algorithms for high-stakes decisions.  The project will study randomized feature networks as a simpler but equally powerful alternative to fully-trainable neural networks for high-dimensional function approximation. The long-term goal is to develop methods that integrate machine learning and dynamical systems, a challenging new frontier in data science for scientific problems. This project also provides research training opportunities for undergraduate students, graduate students, and postdoctoral fellows.<br/><br/>The main goal of this project is to develop new algorithms for data-driven function approximation, with the goal of using learning techniques for scientific modeling and dynamics. The focus is on the construction of randomized algorithms with complexity, accuracy, and/or stability guarantees. Rigorous algorithmic design and modeling is at the core of this scientific computing project, where we leverage advances in machine learning to augment simulations and extract better features for approximating dynamical systems. This project introduces a family of new algorithms based on randomized features with adaptive thresholding procedures to improve accuracy without overfitting.  By incorporating various structural information, this has the potential to avoid the curse-of-dimensionality for several physical problems of interest. The main test problems focus on scientific models, high-dimensional systems, and high-dimensional dynamical systems. In addition, by understanding random feature models, we provide one avenue toward a better understanding of neural network models.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208456","Collaborative Research: Robust Acceleration and Preconditioning Methods for Data-Related Applications: Theory and Practice","DMS","COMPUTATIONAL MATHEMATICS","09/01/2022","05/24/2022","Yousef Saad","MN","University of Minnesota-Twin Cities","Standard Grant","Yuliya Gorb","08/31/2025","$200,000.00","","saad@umn.edu","200 OAK ST SE","MINNEAPOLIS","MN","554552009","6126245599","MPS","1271","079Z, 9263","$0.00","In many disciplines of science and engineering one often encounters sequences of numbers or vectors or other mathematical objects. A common goal in these situations is to obtain the limit of the sequence inexpensively. As a simple example, there are several ways to generate a sequence of numbers that converge to the number pi and some sequences will reach the limit pi rather quickly. In some cases, it may be possible to modify the original method that produced the sequence to obtain a faster converging one. However, this is not always possible or cost-effective because the process by which the sequence is produced is not explicit or it may be too cumbersome for this approach to be practical. Another common solution is to transform the sequence, by 'accelerating it'. This usually entails combining the terms of the sequence to produce new entries that reach the limit faster. So far, acceleration methods were developed by mathematicians and (quantum) physicists to deal with a wide range of problems from the physical sciences. The primary goal of this project is to study such acceleration methods and to adapt them to the modern era by focusing on topics related to machine learning and, more generally, data sciences. This collaborative research project between researchers at Emory University and the University of Minnesota, will develop and study theoretically a number of robust acceleration algorithms with an emphasis on problems that stem from data-related applications, as well as train graduate students in this field of study. <br/><br/>The need to accelerate numerical sequences of various types has frequently been felt across a wide range of disciplines and it has been addressed by many researchers for quite some time. In the past, such acceleration or extrapolation schemes were targeted mainly toward sequences of vectors that arise from physical simulations, e.g., the sequence of potentials generated by the Self Consistent Field (SCF) iterations in quantum physics. In recent years, the rapid expansion of machine learning methodologies across a great variety of disciplines has generated new demand for algorithms to accelerate sequences of various types. However, the new type of sequences encountered in these applications differ in fundamental ways from their analogues in physical simulations. In contrast with the common setting required in, e.g., quantum physics, calculations in machine learning are often performed in single or half precision instead of double precision. Furthermore, in neural networks these sequences tend to be very irregular because they originate from stochastic gradient  approaches. The collaborative team from Emory University and the University of Minnesota, will develop and study theoretically a number of robust acceleration algorithms with an emphasis on their application to irregular sequences such as those encountered in data-related applications. The investigating team will study a number of strategies for improving the robustness of standard acceleration schemes, such as Anderson mixing, or the epsilon algorithm. A number of recently advocated second-order methods, based on (so-called) momentum ideas, have been shown to be of great help in accelerating standard stochastic gradient descent methods in Deep Learning. The investigators will add to these schemes another method of the same class that is grounded in Chebyshev acceleration. One advantage of the Chebyshev-based scheme is that it is fairly easy to study theoretically in part because it is well understood for linear problems. In a second research direction, the investigating team will study acceleration methods in the specific context of machine learning tasks. For example, inspired by recent advances in parameter averaging and variance reduction schemes they will explore the application of classical extrapolation methods to stochastic gradient sequences as an adaptive extrapolation procedure. Experiments show that parameter averaging is key to the success of acceleration procedures. Just as important is the selection of the vectors to accelerate. Along the same lines, robust acceleration schemes will be designed and studied for sequences hampered by low precision arithmetic.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208031","Collaborative Research: Dynamical Sampling on Graphs: Mathematical Framework and Algorithms","DMS","COMPUTATIONAL MATHEMATICS","07/01/2022","06/16/2022","Ilya Krishtal","IL","Northern Illinois University","Standard Grant","Stacey Levine","06/30/2025","$182,637.00","","ikrishtal@niu.edu","1425 W LINCOLN HWY","DEKALB","IL","601152828","8157531581","MPS","1271","9263","$0.00","Effective methods for analyzing data that evolve in time are crucial for solving some of the most relevant problems of society today. Such methods help identify the source and track the spread of a virus, detect and monitor dangerous pollutants, study neurological and other biomedical interactions, and design transportation networks for data, energy, or goods. In many applications, such as the ones mentioned above, data are often modeled by time-evolving functions on graphs. In this project, a diverse group of Ph.D. students, postdoctoral fellows, and senior researchers will develop novel mathematical techniques and algorithms for designing cost-effective space-time sampling, processing, and reconstruction strategies for such functions.  The algorithms will analyze and manage various time-evolving processes that are sampled under realistic conditions and corrupted by noise. The project will study the  optimal spatial placement of sensors for data collection, space-time trade-off between the number of sensors and the frequency of their activation, and ways of identifying various types of parameters of an evolution process driving the data. The research is expected to have a significant impact on sensing network design and implementation as well as other applications where signals on graphs are utilized. Broader impacts of the project will include developing and mentoring a diverse working group of junior researchers from several institutions and engagement in various outreach activities.<br/><br/>The project focuses on the development of a mathematical framework, tools, and algorithms for sampling and reconstruction of time-evolving functions on graphs. The investigators will solve several inverse problems such as the recovery of an initial state, an evolution operator, and/or a forcing source term of a dynamical system from space-time samples on graphs. For this purpose, they will extend the dynamical sampling framework for functions in graph Paley-Wiener spaces, set up and solve several optimization problems for finding robust and cost-effective sampling patterns, and create and study computationally efficient algorithms that implement the solutions of the above theoretical problems.  The researchers will use and combine results from sampling theory, dynamical systems, Fourier analysis, functional analysis, numerical linear algebra, and discrete optimization to create and sustain a fertile environment for theoretical and applied research.   The project will enhance existing approaches and provide new mathematical tools and computational schemes that offer practical solutions to basic inverse problems in signal processing and system identification on graphs. Some of the results of this investigation will also contribute to the understanding of several challenging and fundamental issues in optimization, frames, and graph theory. For example, the investigators will create fast algorithms for approximating solutions of certain NP-hard discrete optimization problems on graphs and provide theoretical guarantees for their performance.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208426","Collaborative Research: Physics-Preserving Adaptive Finite Element Methods for Thermo-Poroelasticity","DMS","COMPUTATIONAL MATHEMATICS","07/01/2022","05/20/2022","Son-Young Yi","TX","University of Texas at El Paso","Standard Grant","Yuliya Gorb","06/30/2025","$250,518.00","","syi@utep.edu","500 W UNIVERSITY AVE","EL PASO","TX","799680001","9157475680","MPS","1271","9263","$0.00","Geothermal energy is one of the most promising renewable energy sources and has proven to be reliable, clean, and safe. When designing enhanced geothermal systems (EGS), it is necessary to understand the multiscale, multiphysics, thermal-hydraulic-mechanical (THM) processes that impact the EGS dynamics and productivity. This project aims to gain a fundamental understanding of key mechanisms controlling the dynamics in EGS (solid displacement, fluid flow, and heat transfer) and sustainability of EGS reservoirs through numerical simulations. A novel numerical simulation framework to be built through this project will allow for designing, managing, and optimizing energy production from EGS.<br/> <br/>The THM processes in EGS can be described by Biot?s thermo-poroelasticity model, a coupled system of nonlinear partial differential equations. Any desirable numerical methods for THM systems should preserve the underlying physical laws, such as mass and energy conservation, and present no numerical instabilities for a wide range of physical and simulation parameters. This project seeks to develop a unified numerical modeling framework based on adaptive enriched Galerkin (EG) methods to provide robust and physics-preserving numerical methods whose numerical analysis is feasible. The proposed EG schemes are mass conservative and free of numerical instabilities commonly present in poroelasticity and coupled flow-transport problems. The mass conservation property, stability, and convergence behaviors of the proposed methods will be studied mathematically and confirmed numerically. Moreover, residual-based a posteriori error estimators will be derived and utilized for designing dynamic mesh adaptivity techniques. The developed EG algorithms will be implemented within finite element software packages to verify the theoretical results and validate the new numerical model's capabilities to capture the EGS dynamics. The performance of the new EG methods will be compared with that of state-of-the-art numerical methods.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208498","Temporal Splitting Methods for Multiscale Problems","DMS","COMPUTATIONAL MATHEMATICS","06/01/2022","01/23/2023","Yalchin Efendiev","TX","Texas A&M University","Continuing Grant","Stacey Levine","05/31/2025","$202,781.00","Sai Mang Pun","efendiev@math.tamu.edu","400 HARVEY MITCHELL PKY S STE 30","COLLEGE STATION","TX","778454375","9798626777","MPS","1271","9263","$0.00","In many physical systems of practical interest, phenomena occur in heterogeneous media with properties varying at multiple scales and having disparate values on each scale. Examples include multi-physics processes in filters, membranes, and Earth's subsurface. Standard numerical approaches for simulating these phenomena to obtain accurate predictions require tremendous computational effort. The goal of this project is to develop a unified framework for accurately and efficiently simulating complex multiscale, time dependent physical phenomena that involve flow, transport, and mechanical deformations that arise in porous media. The project will support education by training a new generation of computational mathematicians who work in multidisciplinary research.<br/><br/>This project involves the development and analyses of novel temporal splitting methods that are designed to overcome challenges that arise when simulating multiscale, time-dependent physical phenomena. The methods are based on solution decomposition for non-stationary multiscale models and will consider space and time heterogeneities that are highly coupled. The goal is to provide a general framework that combines temporal splitting algorithms and spatial multiscale decompositions with a rigorous theoretical analysis of the new algorithms. The specific objectives of the project are: (i) to study temporal splitting algorithms for simulations of non-stationary multiscale models; (ii) to understand space and time interaction in multiscale models; (iii) to analyze temporal splitting approaches to guide the choice for space decomposition; (iv) to design novel splitting approaches for nonlinear models; and (v) to test and demonstrate proposed approaches for improving predictions of multiscale, time-dependent physical phenomena in engineering and geosciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208499","Coupled Flow and Transport Modeling and Simulation of Complex Fluids and Extreme Weather Patterns by Harnessing Data","DMS","COMPUTATIONAL MATHEMATICS","06/01/2022","06/21/2023","Young-Ju Lee","TX","Texas State University - San Marcos","Standard Grant","Yuliya Gorb","05/31/2025","$352,852.00","","y_l39@txstate.edu","601 UNIVERSITY DR","SAN MARCOS","TX","786664684","5122452314","MPS","1271","9251, 9263","$0.00","Complex fluids and tornadoes can be understood mathematically by studying a coupled flow and transports. Complex fluids are used in many important areas, including medicine, the military, and the oil industry, to name a few. Recent experimental results by Shell groups show that the shear induced structure observed in the wormlike micellar fluids can be effectively used for enhanced oil recovery. The proposed research will provide a desired quantitative understanding of wormlike micellar fluids. Tornadoes are complex meteorological phenomena that are often associated with severe convective atmospheric conditions. According to NOAA/National Weather Service, more than 797 tornadoes occurrences have already been confirmed in 2021. Tornadoes are becoming more frequent and severe due to global warming as well. The proposed research will elucidate the understanding of tornadogenesis, which is crucial to make a proper tornado warning issue, thereby avoiding catastrophic damage and casualties. <br/><br/>This project will develop conservative, discrete maximum principle preserving, and efficient numerical schemes that can be used for simulating coupled flow and transports that arise in important areas of research, such as complex fluids and tornadoes. These new methods will be analyzed mathematically and enhanced by using a class of new fast solvers to drastically reduce the complexity of computational bottlenecks. The framework developed by the PI in this project will enable researchers to tackle a wide spectrum of physical parameters that have been elusive for computational rheologists for decades. Compatible window-wise physics informed neural network will be attempted to solve regularized complex fluids. The project will present a new tornado model for the understanding of extreme micro-weather patterns in vapor-to-particle reaction, convection, and diffusion. In particular, this project will elucidate and fill the gap between mathematical modeling and phenomena of tornadoes, thereby deepening the understanding of tornadogenesis. A data-driven deep neural networks will be designed for determining the unknown physical parameters in the tornado model as well.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208373","RUI: Geometric Optimization Involving Partial Differential Equations","DMS","COMPUTATIONAL MATHEMATICS","06/01/2022","05/25/2022","Chiu-Yen Kao","CA","Claremont McKenna College","Standard Grant","Yuliya Gorb","05/31/2025","$244,985.00","","ckao@claremontmckenna.edu","500 E 9TH ST","CLAREMONT","CA","917115929","9096077085","MPS","1271","9229, 9263","$0.00","Optimal geometric design provides a vast number of interesting and challenging mathematical problems. One of the famous problems goes back to 18th Century. J.-L. Lagrange formulated the problem to maximize the critical load of a rod of variable cross-sectional area with given length and volume. Another famous classic example is that L. Rayleigh conjectured that the disk should minimize the fundamental frequency of a membrane among all shapes of equal area, more than a century ago. Other recent applications include mechanical vibration, design of optical resonator, photonic crystal waveguides, determination of favorable and unfavorable regions in population dynamics, soap films and minimal surfaces, drug design, and image segmentation. Numerical approaches for these kinds of problems require both forward solvers and optimization solvers. The forward solvers are numerical approaches to solve problems on a given setting of geometric parameters or domain. The optimization solvers aim to find the optimal geometric design, which maximizes the design objective.  <br/><br/>In this proposal, the aim is to study geometric optimization of p-Laplacian Poisson?s equations, Laplace Beltrami operator, Steklov problems, and their applications in optimal radiotherapy design and free boundary minimal surfaces. The forward solvers are based on finite element methods and methods of particular solutions while the optimization solvers are based on rearrangement methods, shape derivatives, and sensitivity analysis of conformal factor, conformal classes, and metrics. The PI will study a wide class of problems arising from many applications including (1) optimization of total displacement, (2) convergence rate study of rearrangement methods for optimization problems, (3) optimal radiotherapy design, (4) maximizing conformal and topological Laplace-Beltrami eigenvalues on closed Manifolds, and (5) extremal Steklov eigenvalue problems and free boundary minimal surfaces. The project will advance the development of optimization solvers based on rearrangement methods, shape derivatives, and sensitivity analysis and provide tools to solve aforementioned applications. Also, the obtained results will be integrated to develop new curriculums on numerical analysis and partial differential equations at Claremont McKenna College. The PI will supervise both undergraduate and graduate students. In addition, the PI will organize applied math seminars, working group seminars, and a series of minisymposium at coming AIMS, ICIAM, SIAM, and other international conferences to engage interested scientists, including those from underrepresented groups. The PI and her students will also outreach to K-12 students via Gateway to Exploring Mathematical Sciences (GEMS) program at Claremont.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208030","Collaborative Research: Dynamical Sampling on Graphs: Mathematical Framework and Algorithms","DMS","COMPUTATIONAL MATHEMATICS","07/01/2022","06/16/2022","Akram Aldroubi","TN","Vanderbilt University","Standard Grant","Stacey Levine","06/30/2025","$292,872.00","","akram.aldroubi@vanderbilt.edu","110 21ST AVE S","NASHVILLE","TN","372032416","6153222631","MPS","1271","9263","$0.00","Effective methods for analyzing data that evolve in time are crucial for solving some of the most relevant problems of society today. Such methods help identify the source and track the spread of a virus, detect and monitor dangerous pollutants, study neurological and other biomedical interactions, and design transportation networks for data, energy, or goods. In many applications, such as the ones mentioned above, data are often modeled by time-evolving functions on graphs. In this project, a diverse group of Ph.D. students, postdoctoral fellows, and senior researchers will develop novel mathematical techniques and algorithms for designing cost-effective space-time sampling, processing, and reconstruction strategies for such functions.  The algorithms will analyze and manage various time-evolving processes that are sampled under realistic conditions and corrupted by noise. The project will study the  optimal spatial placement of sensors for data collection, space-time trade-off between the number of sensors and the frequency of their activation, and ways of identifying various types of parameters of an evolution process driving the data. The research is expected to have a significant impact on sensing network design and implementation as well as other applications where signals on graphs are utilized. Broader impacts of the project will include developing and mentoring a diverse working group of junior researchers from several institutions and engagement in various outreach activities.<br/><br/>The project focuses on the development of a mathematical framework, tools, and algorithms for sampling and reconstruction of time-evolving functions on graphs. The investigators will solve several inverse problems such as the recovery of an initial state, an evolution operator, and/or a forcing source term of a dynamical system from space-time samples on graphs. For this purpose, they will extend the dynamical sampling framework for functions in graph Paley-Wiener spaces, set up and solve several optimization problems for finding robust and cost-effective sampling patterns, and create and study computationally efficient algorithms that implement the solutions of the above theoretical problems.  The researchers will use and combine results from sampling theory, dynamical systems, Fourier analysis, functional analysis, numerical linear algebra, and discrete optimization to create and sustain a fertile environment for theoretical and applied research.   The project will enhance existing approaches and provide new mathematical tools and computational schemes that offer practical solutions to basic inverse problems in signal processing and system identification on graphs. Some of the results of this investigation will also contribute to the understanding of several challenging and fundamental issues in optimization, frames, and graph theory. For example, the investigators will create fast algorithms for approximating solutions of certain NP-hard discrete optimization problems on graphs and provide theoretical guarantees for their performance.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208231","Efficient Hybridizable Discontinuous Galerkin Methods for Phase Field Fluid Models","DMS","COMPUTATIONAL MATHEMATICS","08/15/2022","08/03/2022","Daozhi Han","MO","Missouri University of Science and Technology","Standard Grant","Yuliya Gorb","01/31/2023","$152,848.00","","daozhiha@buffalo.edu","300 W 12TH ST","ROLLA","MO","654096506","5733414134","MPS","1271","9263","$0.00","Multiphase flow  is ubiquitous in natural phenomena and industrial applications.  Common examples include wave-breaking and sloshing, contaminant transport in aquifers, oil recovery in petroleum engineering, drug delivery in blood flow,  gas-particle flow in combustion reactors,  exhaust management in Polymer Electrolyte Membrane fuel cell technology, and so forth.   The diffuse interface fluid models have become increasingly popular in the numerical modeling of interfacial phenomena associated with multiphase flows. They are able to capture  smooth transitions of fluid interface, and simulations can be carried out on a fixed grid without explicit interface tracking.   A particular challenge in solving diffuse interface models is that the diffusive interface of small width often exhibits instability such as  bubble merging or splitting. Traditional high order methods  are prone to  spurious oscillations around diffusive interfaces  which can pollute the numerical solution beyond the interface region and even cause blow-up of the code  due to negative viscosity, density or mobility.  The aim of this project is to develop high order numerical methods that can accurately capture moving interfaces of multiphase flow.<br/><br/>Real-world applications see both diffusion dominated flows and advection dominated flows. The investigator first develops and  analyzes provably superconvergent hybridizable discontinuous Galerkin methods (HDG) for solving diffuse interface fluid models in the diffusion-dominated regime. The key idea in the design is to approximate solution variables by higher order polynomials than those for the numerical traces and gradient variables,  and to explore local projection based stabilization. The PI then  designs stabilized high order  HDG methods effected with the Scalar Auxiliary Variable (SAV) time-stepping schemes for advection-dominated flows. The methods  stabilize advection   in the  nonlinear fourth order advection-diffusion  equation while preserve the underlying energy laws.   The stabilized SAV-HDG algorithms enable diffuse interface methods to accurately capture sharp fronts and unstable interfaces in the advection-dominated regime, and allow efficient  parallel computation of smaller systems at each time step.  Finally the PI develops and implements fast nonlinear HDG multigrid  solvers for diffuse interface fluid models.  The practical solvers will further address the lack of efficient iterative solvers/preconditioners for HDG methods Graduate students participate in the work of this project.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208394","Accelerated distributed stochastic optimization methods and applications in machine learning","DMS","COMPUTATIONAL MATHEMATICS","07/01/2022","05/20/2022","Yangyang Xu","NY","Rensselaer Polytechnic Institute","Standard Grant","Stacey Levine","06/30/2025","$250,000.00","","xuy21@rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","MPS","1271","075Z, 079Z, 9263","$0.00","Machine learning, and in particular, deep learning, has become increasingly impactful in a wide range of applications, including face recognition, digital image classification, natural language processing, self-driving vehicles, and scientific computing. The success of deep learning largely depends on the availability of a huge amount of data. This ""big"" data, on one hand, enables successful learning of the underlying distributions of the data, and thus the learned model can yield high prediction accuracy on new data points that follow similar distributions. On the other hand, the huge amount of data raises great challenges when designing efficient numerical approaches. This project focuses on addressing the challenges that are caused by distributed ""big"" data that can contain private information, from the computational and mathematical perspectives. Research findings from this project will be included in graduate-level topics courses, undergraduate and graduate students will be trained in this field and will participate in this research, and a weekly seminar will be organized to exchange ideas relevant to this project.  <br/><br/>New computational approaches will be developed for training machine learning models on a cluster of computing nodes as well as solving decentralized multi-agent optimization problems that have the capacity to handle coupling constraints. The main goal is to design fast-convergent and communication-efficient optimization methods with theoretical guarantees for solving large-scale distributed machine learning problems. Accelerated compressed proximal stochastic gradient methods will be designed for distributed composite smooth stochastic problems, accelerated compressed stochastic subgradient methods will be designed for distributed nonconvex nonsmooth problems, optimal decentralized stochastic gradient methods will be designed for solving multi-agent optimization with nonlinear coupling constraints, and asynchronous implementations will be performed in the proposed methods in order to have high parallelization speed up.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208612","Collaborative Research: Nonconvex Models for Structured Sensing: Theory, Algorithms, and Applications","DMS","COMPUTATIONAL MATHEMATICS","09/01/2022","05/23/2022","HanQin Cai","CA","University of California-Los Angeles","Continuing Grant","Yuliya Gorb","12/31/2022","$57,563.00","","hqcai@ucf.edu","10889 WILSHIRE BLVD STE 700","LOS ANGELES","CA","900244201","3107940102","MPS","1271","075Z, 079Z, 9263","$0.00","The rapid advance of technology has enabled more than ever the ability to collect large amounts of data. While the abundance of such data is advantageous, it brings forth several computational challenges. One challenge is the fact that data might contain numerous missing entries. This is the case for instance when using physical measurement devices with a limited range or in collecting user preferences for a product where we lack complete information. One line of methods that has proved to be useful for this problem is matrix completion algorithms which predict missing entries with minimalistic assumptions on the data. However, in problems such as structure prediction and recommendation system with side information, the measurements are not entry-wise. Specifically, the observations are an aggregate of some entries of the underlying data, i.e., rather than directly observing the entries of the data, the user has access to certain combinations of these entries. This project aims to study this problem which is well known as the matrix sensing problem. The majority of previous works consider the case where measurements of the data are missing at random or assume that the measurement protocol itself is random. Motivated by practical applications, this project considers a realistic setup where the measurements are structured and deterministic. A key goal of this project is to advance the state of art theory and computation of matrix sensing by studying new optimization algorithms. Another aim of the project is to apply the constructed framework to robust structure prediction and machine learning. <br/><br/>This project seeks to study scalable non-convex methods for a class of generalized matrix recovery problems. In particular, PIs are interested in low-rank matrix sensing problems with deterministically structured measurements under various settings. The main approach is based on formulating the optimization problem with respect to a deterministic measurement basis and its associated dual basis. This yields a well-posed problem under some mild conditions. The project is centered on three objectives. In the first part, the project studies the local convergence of a Riemannian gradient descent algorithm that directly optimizes over the manifold of low-rank matrices. The recovery guarantee then will depend mainly on the spectral properties of the basis and the dual basis, the sampling scheme, and the initialization. Tight estimation of the spectral properties and effective initialization method will be investigated by bridging connections to spectral graph theory. The second objective is to design an algorithm tailored for the Euclidean distance geometry (EDG) problem which aims to estimate the configuration of points given partial information about pairwise distances. EDG is a representative problem that utilizes deterministically structured measurements. By leveraging the special structure of EDG, the project aims to design optimally efficient algorithms and establish theoretical analysis for the exact recovery of the point configuration. The third objective considers the setting where the measurements might be sparsely corrupted. The project aims to develop fast and robust algorithms tailored to this case and carry out the necessary analysis for recovery guarantees. To realize these objectives, the project leverages tools from high-dimensional probability, Riemannian optimization, numerical analysis, and spectral graph theory. The project will provide opportunities to train undergraduate and graduate students with interests in distance geometry, optimization theory, and computational science.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208159","The Carleman Contraction Principle for Three-Dimensional Phased and Phaseless Inverse Scattering","DMS","COMPUTATIONAL MATHEMATICS","07/01/2022","05/20/2022","Loc Nguyen","NC","University of North Carolina at Charlotte","Standard Grant","Stacey Levine","06/30/2025","$246,641.00","","lnguye50@uncc.edu","9201 UNIVERSITY CITY BLVD","CHARLOTTE","NC","282230001","7046871888","MPS","1271","9263","$0.00","The identification from only external measurements of unknown targets that are fully occluded inside a region is a challenging interdisciplinary research effort among mathematicians, physicists, and engineers. Important applications of this field include nondestructive testing, for example, checking for cracks inside a product, seismic exploration, for example, searching for oil under the sea, security, for example, the identification of buried anti-personnel explosive devices, and others. Current, widely used optimization-based methods for such tasks require some a priori knowledge about the true solution, which is not always available, and their computational cost is expensive. This project aims to develop new, theoretically sound techniques that are designed to quickly deliver reliable solutions for estimating occluded targets that are independent of the initial estimates. Both undergraduate and graduate students will be trained through involvement in this research. <br/><br/>In this project, data for identifying unknown targets inside a medium will be collected through a measured scattering wave.  The methodology to be developed in this work will be able to handle data where the phase may or may not be able to be measured, the latter which occurs in many challenging situations, such as the case of nano imaging, where the wavelength of the incident wave is particularly small. The new methods combine Carleman estimates, the contraction mapping principle, and an algebraic formula to retrieve the lost phase when needed. The use of the contraction mapping principle will guarantee key strengths of the new approach: relaxed requirements on the initial guesses and inexpensive computational cost. These new methods will be applied to partial differential equations that govern wave propagation, including the three-dimensional Helmholtz equation and Maxwell?s system. The new methods will be tested on both simulated and experimental data.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208220","Collaborative Research: Time Accurate Fluid-Structure Interactions","DMS","COMPUTATIONAL MATHEMATICS","08/15/2022","08/02/2022","Catalin Trenchea","PA","University of Pittsburgh","Standard Grant","Yuliya Gorb","07/31/2025","$225,000.00","","trenchea@pitt.edu","4200 FIFTH AVENUE","PITTSBURGH","PA","152600001","4126247400","MPS","1271","9263","$0.00","In realistic problems describing fluid flow, sometimes the dynamics are not known, or the variables are changing rapidly. Hence, to accurately compute the solution, one might need to use small temporal discretization parameters. For example, in simulations of blood flow, the pressure rapidly increases and then decreases during the systole, which lasts 3/8 of the cardiac cycle, followed by slower and smaller changes in the pressure during diastole, lasting 5/8 of the cardiac cycle. To accurately capture the peak systolic flow, a small time step has to be used in that interval. However, that same time step  might be unnecessary small during diastole and could lead to longer computational times. Therefore, robust adaptive time-stepping is central to accurate and efficient long-term predictions of the solution. The adaptive time-stepping methods for partial differential equations describing flow problems are under-investigated and this project will make a major contribution in that field. The methods developed in this project will be used to model problems involving transport  and fluid-elastic/poroelastic structure interaction, such as the transport of contaminants in hydrological systems where surface water percolates through rocks and sand, transport of nutrients and oxygen between capillaries and tissue, or spread of a disease across a border. This project will involve the training of graduate students. <br/><br/>The focus of this project is the development of adaptive time-stepping methods for two classes of coupled flow problems: the fluid-porous medium coupled problems and the fluid-structure interaction problems. A monolithic and a partitioned method will be developed for the fluid-porous medium problem described using the Stokes-Darcy system. Partitioned numerical methods will be developed for the fluid-structure interaction problems with both thin and thick structures. The proposed methods will be semi-discretized in time based on the refactorized Cauchy?s one-legged theta-like method, which is B-stable when used with a variable time step. Furthermore, when theta is 0.5, the method is also second-order accurate and conserves all linear and quadratic Hamiltonians. However, the application of this method to coupled problems, especially when partitioned methods are designed, has to be carefully performed to allow the use of black-box and legacy codes. The proposed methods will be mathematically and computationally analyzed. Various adaptive strategies will be considered. The performance of each method will be investigated with respect to the parameters in the problem. In both classes of multi-physics problems, the underlying equations will be coupled with a transport equation. The proposed techniques will also be applied to the transport problem, with a particular attention to mass and energy conservation. Conservative properties of the transport problem will be investigated.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208340","Collaborative Research: Randomized Feature Methods for Modeling and Dynamics: Theory and Algorithms","DMS","COMPUTATIONAL MATHEMATICS","09/01/2022","06/03/2022","Rachel Ward","TX","University of Texas at Austin","Standard Grant","Yuliya Gorb","08/31/2025","$214,574.00","","rward@math.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271","075Z, 079Z, 9263","$0.00","The objective of this research program is to develop consistent and theoretically validated machine learning algorithms for high-stakes decisions.  The project will study randomized feature networks as a simpler but equally powerful alternative to fully-trainable neural networks for high-dimensional function approximation. The long-term goal is to develop methods that integrate machine learning and dynamical systems, a challenging new frontier in data science for scientific problems. This project also provides research training opportunities for undergraduate students, graduate students, and postdoctoral fellows.<br/><br/>The main goal of this project is to develop new algorithms for data-driven function approximation, with the goal of using learning techniques for scientific modeling and dynamics. The focus is on the construction of randomized algorithms with complexity, accuracy, and/or stability guarantees. Rigorous algorithmic design and modeling is at the core of this scientific computing project, where we leverage advances in machine learning to augment simulations and extract better features for approximating dynamical systems. This project introduces a family of new algorithms based on randomized features with adaptive thresholding procedures to improve accuracy without overfitting.  By incorporating various structural information, this has the potential to avoid the curse-of-dimensionality for several physical problems of interest. The main test problems focus on scientific models, high-dimensional systems, and high-dimensional dynamical systems. In addition, by understanding random feature models, we provide one avenue toward a better understanding of neural network models.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208504","Machine Learning for Effective Computation in Multiscale Hyperbolic Systems","DMS","COMPUTATIONAL MATHEMATICS","07/15/2022","07/13/2022","Bjorn Engquist","TX","University of Texas at Austin","Standard Grant","Yuliya Gorb","06/30/2025","$449,995.00","Yen-Hsi Tsai","engquist@math.utexas.edu","110 INNER CAMPUS DR","AUSTIN","TX","787121139","5124716424","MPS","1271","075Z, 079Z, 9263","$0.00","In physical science and engineering applications, it is often necessary to solve systems of differential equations that involve many temporal and length scales. Direct numerical simulations for these equations are often computationally infeasible. This research program aims to reduce the overall wall-clock computation time for simulations of multiscale dynamical systems found in applications by developing algorithms that leverage recent advancements in machine learning and parallel-in-time algorithms. The goal is to provide a systematic approach that can be generalized to other multiscale time-dependent problems and improve the efficacy of a class of existing methodologies. The algorithms will enable realistic computer simulations in a class of important applications, including molecular dynamics and seismic imaging, on massively parallel exascale computer architectures. The machine learning aspects of this project will attract students to scientific computing and stimulate further interdisciplinary work. Such training will be essential for preparing the future generation of researchers in scientific computing in the era of data science and artificial intelligence. <br/><br/>This project concerns multiscale oscillatory dynamical systems, in which phase errors typically dominate the numerical solutions and do not dissipate in time, making accurate long-time simulations very difficult. This research program aims to construct effective solution operators for multiscale dynamical systems by using modern machine learning approaches combined with good training examples that properly sample the physics and causality in the system. Accordingly, a central focus of this research program is to develop a framework for the generation of effective training data that correctly sample the strong causality in the hyperbolic systems. The flow-based ensemble sampling strategy under study exploits the physical properties of the targeted systems. The program also includes a ?self-improving? iterative procedure, which not only enables massive parallel-in-time computation but also improves the accuracy of machine learning-based computations. The project will directly involve two graduate students and the mentoring of undergraduate students.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208551","Structure-Preserving Hybrid Finite Element Methods","DMS","COMPUTATIONAL MATHEMATICS","09/01/2022","08/02/2022","Ari Stern","MO","Washington University","Standard Grant","Yuliya Gorb","08/31/2025","$237,648.00","","stern@wustl.edu","ONE BROOKINGS DR","SAINT LOUIS","MO","631304862","3147474134","MPS","1271","9263","$0.00","Finite element methods are among the cornerstones of modern scientific computing, combining high performance with strong theoretical guarantees of accuracy and stability. Their applications include several areas of Federal strategic interest: materials and manufacturing, biomedical engineering and biotechnology, structural engineering and civil infrastructure, environmental engineering, and more. They are widely used by scientists and engineers in academia, industry, and national laboratories to simulate large, complex physical systems. However, in order for the simulations produced by these methods to be physically meaningful and trustworthy, it is desirable that they capture certain fundamental physical laws present in the original systems. Certain systems satisfy ""conservation laws,"" which state that some quantity (like mass, energy, or charge) can move through space but not appear or disappear spontaneously, while other systems satisfy ""dissipation laws"" that require these quantities to grow or decay at a certain rate (e.g., decay of energy due to friction). Although classical finite element methods make it difficult to express these physical laws, the PI has shown that ""hybrid"" finite element methods provide a way to do so. In this project, the PI will conduct further investigations into hybrid finite element methods, developing and analyzing computational techniques for preserving these important physical structures. The success of this project would lead to new computational methods and improved understanding of current methods for a wide variety of high-value scientific applications, with important ramifications for computational physics and engineering.<br/><br/>Many partial differential equations (PDEs), particularly those encountered in physical applications, contain local symmetries, conservation laws, and related structures. At first glance, some of these local structures appear difficult for a finite element method to capture, and consequently, much of the research in this direction has been restricted to finite difference methods on rectangular grids. However, in recent years, the PI has developed a successful research program showing that hybridization provides a route around the apparent obstacles to local-structure-preserving finite elements. This project will investigate several new questions in this direction, organized around two main themes. (1) Local conservation laws with quadratic densities are common in Hamiltonian PDEs, because they arise from linear point symmetries. However, conventional finite element discretization breaks local symmetry, resulting only in global conservation laws. The PI aims to circumvent this obstacle by using hybrid methods, and to extend this to non-conservative systems where a quadratic quantity is dissipated rather than conserved. (2) The PI and his collaborators have recently succeeded in hybridizing finite element exterior calculus (FEEC), which uses differential forms to unify several families of methods for Laplace-type operators. The PI will investigate the application of hybridized FEEC methods to Hamiltonian PDEs, specifically focusing on multisymplectic structure preservation, and to investigate hybrid FEEC methods with strongly (rather than merely weakly) conservative fluxes, including nonconforming and hybridizable discontinuous Galerkin (HDG) methods.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2232812","Foundations of Computational Mathematics Conference ? FoCM 2023","DMS","PROBABILITY, ALGEBRA,NUMBER THEORY,AND COM, GEOMETRIC ANALYSIS, APPLIED MATHEMATICS, STATISTICS, COMPUTATIONAL MATHEMATICS, Combinatorics","12/01/2022","08/04/2022","Peter Binev","SC","University of South Carolina at Columbia","Standard Grant","Stacey Levine","11/30/2023","$49,500.00","","binev@math.sc.edu","1600 HAMPTON ST # 414","COLUMBIA","SC","292083403","8037777093","MPS","1263, 1264, 1265, 1266, 1269, 1271, 7970","7556, 9150, 9263","$0.00","The next triennial international conference in the series Foundations of Computational Mathematics, FoCM 2023, will be hosted at the Sorbonne University in Paris, France, June 12?21, 2023. The Foundations of Computational Mathematics (FoCM) conferences aim to be a main vehicle in the exploration of the broad interface between mathematics and contemporary computation, a subject area of importance both intellectually and for practical applications. It is expected that about 500 researchers will attend the conference from around the world, and about a third of them will be from the US. This project will partially cover travel and lodging costs for a diverse group of US researchers attending the conference. The majority of the funds will be distributed on a competitive basis to junior US participants, including graduate students, postdocs, and tenure track faculty.<br/><br/>The conference will follow the format of former FoCM conferences: plenary lectures in the mornings and theme-centered parallel workshops in the afternoons. Each workshop extends over three days, and the conference will consist of three periods, each period featuring 7 mathematically diverse but interconnected workshops, with 21 workshops in total. These activities combined with poster sessions and informal interactions among participants all synthesize forefront research with mentoring and training opportunities for young participants, helping them develop networks that include the world?s leading researchers. A number of themes connect the diverse workshop topics, such as learning from computation to automate, adapt and optimize the computational process which by itself becomes an analysis tool, ties from homotopy methods used in computational algebraic geometry for systems of algebraic equations and interior point methods in continuous optimization to numerical methods for differential equations and aspects of differential geometry, machine learning and signal processing cast as very large and challenging convex optimization problems, common themes among symbolic algorithms used for the solution of algebraic and differential equations, and relationships between decidability and tractability in real/complex arithmetic computational models and the Turing machine models considered in the context of combinatorics and intractability as well as discrete optimization.  More information about the FoCM 2023 conference can be found at https://focm2023.org<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2207971","Domain Decomposition Methods for Coupled Models of Non-Newtonian Fluids and Solid Structures","DMS","COMPUTATIONAL MATHEMATICS","08/15/2022","08/03/2022","Hyesuk Lee","SC","Clemson University","Standard Grant","Leland Jameson","07/31/2025","$244,828.00","","hklee@clemson.edu","201 SIKES HALL","CLEMSON","SC","296340001","8646562424","MPS","1271","9150, 9263","$0.00","There has been increasing interest in numerical studies on fluids interacting with poroelastic structures; however, most numerical and analytical studies in this area have been focused on Newtonian fluids coupled with solid structures, and few analytical and numerical studies have been undertaken on the interaction of non-Newtonian fluids and elastic/poroelastic solids. Non-Newtonian fluid-poroelastic structure interaction (FPSI) problems are themselves of interest to related scientific and engineering communities, as the study of these strongly coupled nonlinear problems leads to a better understanding and a unifying description of complex real-life processes. This research will provide an underlying mathematical foundation for non-Newtonian flows in a multi-physical setting while promoting teaching, training graduate students, and involving undergraduates in research experiences. The proposed research will also benefit the biomedical, polymer, material, and oil industries by providing improved algorithms for the numerical simulation of important processes. <br/><br/>The research activity lies in the development of rigorous, efficient, and stable numerical schemes for FPSI problems. Most current research results of FPSI problems discuss numerical methods with matching grids and time steps between subproblems in either a monolithic or partitioned setting. The goal of the research is to design domain decomposition methods for non-Newtonian FPSI systems that allow local space and time discretization. At the same time, the theoretical accuracy and stability properties of the numerical schemes will be analyzed. Specifically, we have five main objectives for this project: (i) develop and analyze parallel, accurate, efficient decoupling algorithms based on global-in-time, non-overlapping domain decomposition for non-Newtonian FPSI systems; (ii) develop and analyze accurate discretization and projection methods in time to effectively handle non-Newtonian FPSI systems with a large difference in local time scales; (iii) study the well-posedness of the viscoelastic FPSI system; (iv) develop and analyze accurate and efficient discretization methods for viscoelastic FPSI systems based on weighted least-squares finite element methods; (v) educate and train graduate and undergraduate students.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2208541","Shape-Morphing Modes for Efficient Computation of Multiscale Evolution Partial Differential Equations with Conserved Quantities","DMS","COMPUTATIONAL MATHEMATICS","08/15/2022","08/03/2022","Mohammad Farazmand","NC","North Carolina State University","Standard Grant","Leland Jameson","07/31/2025","$196,255.00","","farazmand@ncsu.edu","2601 WOLF VILLAGE WAY","RALEIGH","NC","27607","9195152444","MPS","1271","1303, 9263","$0.00","Large-scale computations are needed in many areas of science and engineering, such as climate modeling, weather forecast, and design of sustainable structures. The corresponding mathematical models often involve a wide range of time and spatial scales which the simulations need to resolve. Efficiently resolving these multiscale structures has been a long-standing challenge in scientific computing. This project proposes shape-morphing modes as a new computational method that will drastically reduce the computational time and memory requirements of simulating multiscale systems. Shape-morphing modes are computational elements that adaptively change their shape and location to efficiently capture various temporal and spatial scales. The resulting computational speedup will enable us to perform real-time prediction, optimization, and control tasks that had been inaccessible to previous methods. <br/> <br/>The dynamics of spatiotemporal systems are routinely described by time-dependent partial differential equations (PDEs). The solutions of these PDEs often exhibit time-varying localized structures, with sharp gradients, surrounded by regions of large-scale motion. Such multiscale PDEs arise in numerous applications, such as aircraft design, weather prediction, ocean and climate modeling, where resolving small scale structures remains a major challenge. Currently, there are two broad classes of methods for addressing this challenge: 1. Adaptive methods which dynamically evolve the spatial discretization so that the computational grid is refined around the localized structure and less so in the quiescent regions. 2. Multiresolution methods, such as wavelets, which encode various scales in the basis instead of the discretization. This project will develop a new and computationally efficient method called shape-morphing modes. The main idea behind this method is to use a time-dependent basis of functions that automatically morph their shapes over time and space in order to efficiently resolve all scales. Being mesh-free, the proposed method substantially reduces the computational cost as compared to existing adaptive methods. Furthermore, since the modes adapt themselves to the solution of the PDE, far fewer modes are needed to resolve all scales. This significantly reduces the memory requirements, thus outperforming the existing multiresolution methods.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
