"AwardNumber","Title","NSFOrganization","Program(s)","StartDate","LastAmendmentDate","PrincipalInvestigator","State","Organization","AwardInstrument","ProgramManager","EndDate","AwardedAmountToDate","Co-PIName(s)","PIEmailAddress","OrganizationStreet","OrganizationCity","OrganizationState","OrganizationZip","OrganizationPhone","NSFDirectorate","ProgramElementCode(s)","ProgramReferenceCode(s)","ARRAAmount","Abstract"
"9206369","Mathematical Sciences: Postdoctoral Research Fellowship","DMS","COMPUTATIONAL BIOLOGY ACTIVITI, INFRASTRUCTURE PROGRAM, APPLIED MATHEMATICS, STATISTICS, COMPUTATIONAL MATHEMATICS","09/01/1992","04/09/1992","Christopher Raphael","VA","Fellowships","Fellowship Award","Deborah Lockhart","08/31/1996","$75,000.00","","craphael@indiana.edu","","Arlington","VA","22230","","MPS","1107, 1260, 1266, 1269, 1271","","$0.00","     The Mathematical Sciences Postdoctoral Research Fellowships                are awards to recent recipients of doctoral degrees in the                      mathematical sciences.  These awards are a means of contributing to             the future vitality of the scientific effort of the nation.  As                 researchers in the mathematical sciences expand their interactions              with other disciplines, and as the interplay increases between the              various areas of mathematics itself, opportunities for postdoctoral             research and training are becoming increasingly important.  The                 fellowships are designed to permit awardees to choose research                  environments that will have maximal impact on their future                      scientific development.  The fellowship is designed to provide 24               months of support divided into 18 academic-year months and 3                    periods of two summer months.  The recipient may choose (1) the                 Research Fellowship option which allows for full-time support for               any 18 academic-year months in a three-year period, in intervals                not shorter than 3 consecutive months or (2) the Research                       Instructorship option which allows the 18 months of academic year               support to be taken as 9 months of full-time support and 18 months              of half-time support.  Not more than two months of summer support               from this Fellowship may be received in any calendar year.                           Christopher Raphael received his doctoral degree from Brown                University, and will pursue research under the guidance of Bradley              Efron at Stanford University.  The research will be conducted in                the area of probabilistic models in radiation therapy treatment                 planning."
"9216158","Mathematical Sciences: Image Analysis, Spatial Statistics,  and Bayesian Inference","DMS","STATISTICS","08/15/1992","06/15/1994","Julian Besag","WA","University of Washington","Continuing Grant","James E. Gentle","07/31/1996","$248,155.00","","","4333 BROOKLYN AVE NE","SEATTLE","WA","981950001","2065434043","MPS","1269","0000, OTHR","$0.00","     Markov chain Monte Carlo methods will be applied to problems               in statistical inference with particular emphasis on spatial                    statistics and Bayesian computation.  This project is highly                    interdisciplinary with target areas that include image analysis,                whether from medical imaging, remote sensing or surface                         reconstruction and mapping, the analysis of data from                           agricultural experiments and from geographical epidemiology.                    There are general mathematical and computational implications for               difficult issues such as multi-modality and robustness in                       Bayesian posterior distributions.                                                    Markov chain Monte Carlo methods have a long history in                    statistical physics and subsequently in spatial statistics.  Now                these are being applied with spectacular success to a vast range                of mainstream statistical problems that have remained numerically               intractable otherwise.  This project, which is highly                           interdisciplinary because of the nature of spatial data and                     mapping problems, focuses on the solutions to some of the hardest               problems in the analysis of data which carry spatial                            connotations."
"9200610","Mathematical Sciences: Some Problems in Saddlepoint         Approximations in Statistics","DMS","STATISTICS","09/01/1992","08/20/1992","Suojin Wang","TX","Texas A&M Research Foundation","Standard Grant","Sallie Keller-McNulty","08/31/1994","$30,000.00","","sjwang@stat.tamu.edu","400 HARVEY MITCHELL PKWY S STE 3","COLLEGE STATION","TX","778454375","9798626777","MPS","1269","","$0.00","     The goal of this project is to develop new saddlepoint                     theory and methods, branching into areas not attacked in any                    depth to date.  In particular, attention will be directed toward                the use of saddlepoint approximations in the analysis of sample                 survey data, to saddlepoint expansions for resampling problems,                 and to saddlepoint expansions for a general quadratic form to be                used in constructing confidence regions for nonparametric                       function estimation.                                                                 For many modern statistical techniques employing                           sophisticated and often complicated estimators, there is an                     important technical difficulty in assessing the accuracy and                    precision of statistical estimators. For example, complex surveys               yield data which usually require complicated mathematical forms                 for estimators of the quantities of interest.  Making a clear                   statement about the amount of variability inherent in the                       estimation process is hindered by the intractability of the exact               distributions of these estimators.  Close approximations may                    replace these distributions; this work will utilize saddlepoint                 theory to develop such satisfactory approximate distributions."
"9122723","Mathematical Sciences: Renewal of Development of CalibrationCurve Methods and an Investigation of Their Properties","DMS","STATISTICS","08/01/1992","08/31/1992","Clifford Spiegelman","TX","Texas A&M Research Foundation","Standard Grant","Sallie Keller-McNulty","07/31/1995","$45,000.00","","cliff@stat.tamu.edu","400 HARVEY MITCHELL PKWY S STE 3","COLLEGE STATION","TX","778454375","9798626777","MPS","1269","","$0.00","     This research project produces new methods for high                        dimensional multivariate calibration curves.  It will address                   methods that are robust with respect to interaction effects.  In                addition, it will advance calibration methods with errors in the                calibration standards.  Methods from chemistry and environmental                chemistry will be the focus.                                                         Important policy and legal decisions often depend upon                     accurate measurements.  These in turn depend upon good                          calibration of the instruments.  For example, the knowledge of                  the extent or rate of the ozone depletion depends upon ground-                  based Dobson measurements which are suspect due to poor                         calibration.  The problem of improving calibration methods is one               of several to be considered in this research."
"9122250","Mathematical Sciences: Sixteenth International Biometrics   Conference, December 7-11, 1992, Hamilton, New Zealand.","DMS","INFRASTRUCTURE PROGRAM, STATISTICS","08/01/1992","07/27/1992","Lynne Billard","GA","University of Georgia Research Foundation Inc","Standard Grant","Jean Thiebaux","01/31/1994","$32,000.00","","lynne@stat.uga.edu","310 E CAMPUS RD RM 409","ATHENS","GA","306021589","7065425939","MPS","1260, 1269","","$0.00","        This award will  partially support the travel of                        approximately 16 scientists from the United States to attend the                16th International Biometric Conference, which is to be held 7-11               December, 1992 in Hamilton, New Zealand.  The strength of the                   meetings lies in the broad international participation of                       statisticians, biologists, and mathematicians interested in                     quantitative and statistical aspects of biology, genetics,                      envirnomental science, and other fields.  Topics to be discussed                on statistical areas directly related to these issues include                   survival analysis, epidemiology, genetics, molecular biology,                   environmental pollution monitoring, modeling metabolism and                     pharmacokinetics;  all of which have direct bearing on solutions                to the major concerns of today including AIDS, cancer and heart                 diseases, plant science epidemiology and agriculture.  In                       addition, discussions on fundamental statistical issues of                      repeated measures, structural inference, image processing and                   causal inference all have direct application to current health                  related and agricultural sciences.  It is anticipated that the                  Conference, which is the major international meeting of                         biostatisticians and biometricians throughout the world will be                 attended by 500 or more scientists from the international                       community.                                                                           This award will  partially support the travel of                           approximately 16 scientists from the United States to attend the                16th International Biometric Conference, which is to be held 7-11               December, 1992 in Hamilton, New Zealand.  The strength of the                   meetings lies in the broad international participation of                       statisticians, biologists, and mathematicians interested in                     quantitative and statistical aspects of biology, genetics,                      environmental sciences, and other fields."
"9200915","Mathematical Sciences: Statistics Inference in the Presence of Measurement Error: II","DMS","PROBABILITY, STATISTICS, COMPUTATIONAL MATHEMATICS","09/01/1992","06/22/1993","Leonard Stefanski","NC","North Carolina State University","Continuing Grant","Sallie Keller-McNulty","08/31/1995","$67,000.00","Pawel Hitczenko","stefansk@ncsu.edu","2601 WOLF VILLAGE WAY","RALEIGH","NC","27607","9195152444","MPS","1263, 1269, 1271","9263","$0.00","     This research will cover two major topics, inference                       problems when data are corrupted by errors of measurement and                   inequalities for martingale type sequences of random variables.                 The first topic focusses primarily on instrumental variable                     estimation in generalized linear and nonlinear measurement error                regression models.  Inference methods to be studied include                     maximum likelihood, conditional likelihood and quasilikelihood                  estimation based on approximate data models.  The second topic                  involves comparison methods for tangent sequences of martingale                 differences.  Special attention will be given to problems                       involving domination of martingales by martingales with                         conditionally independent increments.  Specific topics to be                    investigated include norm inequalities, exponential inequalities                and stability properties for martingale type sequences.                              This research is focussed on two different topics.  The                    first area involves problems of inference and data analysis when                data are not measured precisely.  The second topic is concerned                 with comparison methods for sums of random variables.  These                    methods provide a better understanding of modern probability                    theory."
"9203920","Mathematical Sciences:  Topics in Nested Row and Column     Design","DMS","STATISTICS","08/01/1992","09/15/1992","John Morgan","VA","Old Dominion University Research Foundation","Standard Grant","Stephen M. Samuels","01/31/1995","$20,560.00","","jpmorgan@vt.edu","4111 MONARCH WAY","NORFOLK","VA","235082561","7576834293","MPS","1269","","$0.00","     This research involves the study of nested row and column                  designs.  The investigator will study optimal design using                      spatial correlation models rather than the classical model                      formulation.  The spatial processes to be employed will be                      members of the autonormal family, a two-dimensional                             generalization of the one-dimensional autoregressive processes.                      Experimental design has long been used in agriculture to                   improve crop production.  It is now being used in manufacturing                 to improve product quality.  This research will study optimality                of certain types of designs."
"9221287","Mathematical Sciences: Modern Interdisciplinary University  Statistics Education","DMS","INFRASTRUCTURE PROGRAM, STATISTICS, DUE COURSE & CURRICULUM PROG","09/01/1992","03/09/1993","Gary Dwoskin","DC","National Academy of Sciences","Standard Grant","Stephen M. Samuels","08/31/1994","$95,000.00","","","2101 CONSTITUTION AVE NW","WASHINGTON","DC","204180007","2023342254","MPS","1260, 1269, 7410","1990, 7419, 9179, 9269","$0.00","     The Board on Mathematical Sciences (BMS), National Research                Council (NRC) through its Committee on Applied and Theoretical                  Statistics (CATS) will convene two 1-1/2 day symposia on the                    topic Modern Interdisciplinary University Statistics Education,                 one at the National Academy of Sciences in Washington, DC, and                  one at the Beckman Center in Irvine, CA.  The topics of                         discussion at these symposia will be what changes in statistics                 education are needed to: (1) incorporate interdisciplinary                      training into upper-undergraduate, graduate, and postdoctoral                   statistics programs, (2) bring upper-undergraduate and graduate                 statistics curricula up to date, and (3) improve apprenticing of                statistics graduate and postdoctoral students and appropriately                 reward faculty mentors.  Proceedings based upon the presentations               and discussions at both symposia will be produced and                           disseminated after the second symposium."
"9204380","Mathematical Sciences: Computers for Statistical Research","DMS","STATISTICS, COMPUTATIONAL MATHEMATICS","07/01/1992","06/19/1992","Arnold Stromberg","KY","University of Kentucky Research Foundation","Standard Grant","Sallie Keller-McNulty","12/31/1994","$65,000.00","Cidambi Srinivasan, Mai Zhou, William Rayens","stromberg@uky.edu","500 S LIMESTONE","LEXINGTON","KY","405260001","8592579420","MPS","1269, 1271","9263","$0.00","     This project will examine robust regression procedures for                 multiple linear regression and for nonlinear regression.   In the               first case, methods will be developed for the exact computations                of least median of squares estimators.  The theory and                          computation will be extended to the case when responses are                     arbitrarily censored; and bootstrap methods will be used to                     generate confidence intervals.  In the case of nonlinear                        regression, the project will focus on determining the robustness                of MM-estimation, which has been shown to be robust in the linear               case.                                                                                Predictions are often calculated from data using regression                functions, which relate the value of the observation of interest                to values of other features or attributes.  Traditional                         computations used to derive the regression function itself are                  vulnerable to fairly rare but quite aberrant single data points                 (outliers).  More robust alternative methods reduce the impact of               individual unusual or bizarre data points; hence these methods                  should give more stable predictions."
"9208819","Mathematical Sciences: Diagnostics and Graphics for         Structured Data","DMS","STATISTICS","08/15/1992","09/22/1992","Douglas Hawkins","MN","University of Minnesota-Twin Cities","Standard Grant","Sallie Keller-McNulty","07/31/1995","$55,000.00","Sanford Weisberg","doug@stat.umn.edu","200 OAK ST SE","MINNEAPOLIS","MN","554552009","6126245599","MPS","1269","","$0.00","     This project will develop numeric measures and real-time                   graphical procedures for diagnostic use with regression models,                 generalized linear models, multivariate data and other structured               data.  Graphical methods will combine parametric estimation and                 kernel smoothers to make these methods useful and intuitively                   sensible beyond the linear model case.  Numeric case diagnostics                will be based on multiple subsetting of the data to extend the                  sensitivity to outliers beyond the single outlier-simple random                 sample case.                                                                         When analyzing data by fitting models, one of the most                     important tasks is to check for failures of the model to describe               the behavior of the data.  For linear models, for example                       multiple linear regression models, both numerical and graphical                 diagnostics successfully identify aberrant individual                           observations or ""outliers.""  This research will develop                         diagnostics for the much larger group of models which are used                  appropriately for more highly structured or more complicated                    situations."
"9204521","Mathematical Sciences: Spatial Statistics with Image Algebra","DMS","STATISTICS, Geography and Spatial Sciences","08/15/1992","04/14/1994","Noel Cressie","IA","Iowa State University","Continuing Grant","Sallie Keller-McNulty","01/31/1996","$96,013.00","Jennifer Davidson","ncressie@uow.edu.au","1350 BEARDSHEAR HALL","AMES","IA","500112103","5152945225","MPS","1269, 1352","0000, 1269, 9218, HPCC, OTHR","$0.00","     Statistics for spatial data has important application in                   many sciences including astronomy, biology, earth, environmental,               atmospheric, oceanographic and elsewhere when spatial location is               important.  Image algebra was developed to provide a common                     mathematical environment for algorithm development for images.                  Its operands can be identified readily within a spatial statisti-               cal context allowing the strengths of both technologies to be                   combined.  In principle, spatial statistics can be used to                      analyze phenomena as patterns or objects; image algebraic                       operations permit implementation of such analyses.                                   For recorded phenomena as complex as patterns or objects,                  analysis depends on defining useful principles, in this case,                   spatial statistical principles which treat the recorded obser-                  vation as random examples of the underlying phenomena.  For                     example, in hazardous waste site characterization, efficient                    sampling and inference about the size, pattern and nature of the                contamination can allow efficient planning for cleanup.  The                    particular spatial statistical methods to be developed and                      implemented here are natural to use when the data are in the form               of images."
"9114027","Mathematical Sciences: Data Visualization using Focusing andLinking","DMS","STATISTICS, COMPUTATIONAL MATHEMATICS","09/01/1992","05/17/1994","Werner Stuetzle","WA","University of Washington","Continuing Grant","Michael Steuerwalt","08/31/1996","$118,000.00","John McDonald","wxs@stat.washington.edu","4333 BROOKLYN AVE NE","SEATTLE","WA","981950001","2065434043","MPS","1269, 1271","0000, 9218, 9263, HPCC, OTHR","$0.00","     To display complicated information, a common instinct is to                draw a picture that is equally complicated.  Yet, minimizing                    distraction by details is the goal.  Translating natural and                    effective renderings of unembellished important structures to                   computer presentation is conceptually and practically a very                    difficult problem.  Two basic ideas underlie the approach here:                 First, depicting several views and then drawing the links to                    identify the same object in the several views gives a sense of                  the position of the object vis a vis others even in many                        dimensions.                                                                          Second, taking natural groupings of objects and examining                  their interrelationships allows focusing on the finer structure                 of the group.  From these two basic principles, a conceptually                  coherent approach to viewing multidimensional data can be                       derived.  Then actual methodology based on focusing and linking                 can be developed; user interface architectures to make efficient                use of these techniques can be tried and prototypes can be                      implemented."
"9211629","Mathematical Sciences: Computing Environments for Graphical Models","DMS","STATISTICS, COMPUTATIONAL MATHEMATICS","09/01/1992","09/17/1992","David Madigan","WA","University of Washington","Standard Grant","James E. Gentle","02/29/1996","$45,000.00","Adrian Raftery","madigan@stat.columbia.edu","4333 BROOKLYN AVE NE","SEATTLE","WA","981950001","2065434043","MPS","1269, 1271","","$0.00","     Graphical models can be defined as statistical models                      structured in terms of conditional independencies.  These models                are particularly successful in representing expert systems.  This               research will develop Bayesian methodology including elicitation                of informative prior distributions, model updating and expression               of model uncertainty for expert systems and some generalized                    applications.                                                                        Expert systems, which are computer programs which mimic                    human experts, have found both commercial and scientific research               application over the last decade.  Their actual use in some areas               has been limited because of the high level of uncertainty problem               solvers must deal with in problematic areas.  A rigorous                        probabilistic basis for expressing uncertainty can be incor-                    porated into these systems which will allow automated modifica-                 tion of the system in response to new information."
"9201056","Mathematical Sciences: Foundations and Applications of      Bayesian Inference and Decision Theory","DMS","STATISTICS","08/15/1992","08/11/1992","Bruce Hill","MI","Regents of the University of Michigan - Ann Arbor","Standard Grant","Sallie Keller-McNulty","07/31/1995","$60,000.00","","Bruce M. Hill@um.cc.umich.edu","1109 GEDDES AVE, SUITE 3300","ANN ARBOR","MI","481091079","7347636438","MPS","1269","","$0.00","     This project addresses Bayesian nonparametric procedures                   which  incorporate information about the mean and about the tail                behavior of the sampling distribution.  Extensions to non-random                samples from finite populations may be developed, drawing on a                  Bayesian theory of randomization.  Extensions for censored data                 in the presence of covariates should also follow.                                    Foundational issues for Bayesian theory of statistical                     inference revolve around assembling past information or prior                   opinion with new information or data and then presenting the                    amalgamated view.  The inclusion of subjective views with                       information from observations has important implications for                    the applications of Bayesian inference and for effective                        statistically-based prediction and decisions.  This research                    examines both fundamental mathematical issues and their                         applications to specific scientific questions."
"9203357","Mathematical Sciences: Non Parametric Inference and         Sequential Design","DMS","STATISTICS","08/01/1992","03/30/1994","Michael Woodroofe","MI","Regents of the University of Michigan - Ann Arbor","Continuing Grant","James E. Gentle","06/30/1996","$216,000.00","Jiayang Sun","michaelw@umich.edu","1109 GEDDES AVE, SUITE 3300","ANN ARBOR","MI","481091079","7347636438","MPS","1269","0000, OTHR","$0.00","     The primary objectives of the proposal are to study biased                 sampling models and tests of significance in projection pursuit.                For biased sampling models, penalized maximum likelihood                        estimators will be sought and their properties analyzed through a               combination of simulation and asymptotic analysis.  Techniques                  from isotonic estimation are expected to be useful and new                      techniques will be developed as well.  Significance tests for                   projection pursuit will be studied through simulation and                       asymptotic analysis, probably drawing on recent work on the                     maxima of Gaussian random fields.  It is conjectured that                       coupling methods may yield a proof of the Markov Renewal Theorem.                    Observational studies often encounter or utilize purposively               unequal probability sampling models (referred to as biased                      sampling models).  A long term goal of this research is the                     development of methodology for inference when the (unequal                      probability) selection mechanism can be modeled.  A second aspect               of this research considers projection pursuit, that is, the                     search for underlying relationships in large complex data sets                  with many cases and with many variables.  In particular, criteria               for determining when relationships have been recognized                         accurately will be sought."
"9203922","Mathematical Sciences:  Research in Multivariate StatisticalAnalysis","DMS","STATISTICS","08/01/1992","09/02/1992","Robb Muirhead","MI","Regents of the University of Michigan - Ann Arbor","Standard Grant","Sallie Keller-McNulty","07/31/1995","$40,000.00","","robb@stat.lsa.umich.edu","1109 GEDDES AVE, SUITE 3300","ANN ARBOR","MI","481091079","7347636438","MPS","1269","","$0.00","     A central question in multivariate data analysis is the                    number of factors, usually couched in terms of the ""true"" rank of               the covariance matrix.  A variety of optimality criteria can be                 applied to the sample covariance matrix; and these are in fact                  the basis for many standard multivariate inferential procedures                 including principal components analysis, factor analysis,                       multivariate analysis of variance and discriminant procedures.                  This research will examine various model selection methods,                     giving special attention to robustness.  New approaches to                      discriminant analysis will be drawn using ideas from projection                 pursuit.                                                                             Researchers analyzing observations on many variables simul-                taneously face the problem of deciding how many factors are                     really important.  The statistical procedures used to assess the                e number of important factors needs to be stable in the presence                of normal variation present in the data.  This research focusses                on desirable new methods to determine the number of such factors                and also on methodology to identify interesting features in the                 data when many variables are observed at the same time for only a               moderate number of individuals."
"9208656","Mathematical Sciences: The Statistical Analysis of Shape","DMS","STATISTICS, COMPUTATIONAL MATHEMATICS","07/01/1992","08/16/1993","Colin Goodall","PA","Pennsylvania State Univ University Park","Standard Grant","James E. Gentle","06/30/1996","$77,000.00","","","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1269, 1271","9218, 9251, 9263","$0.00","     This research project has three parts; the first is to                     develop a general class of models and inferential techniques for                shape analysis.  The second aspect is the development of a theory               for the case when the least-squares estimate of mean shape can be               written as the principal eigenvector of a certain matrix.  Then                 highly interactive software can be written for visualization of                 shape spaces and shape differences.                                                  The shape of a physical object is defined as whatever                      remains after the position of the object, its size and its                      orientation are accounted for.  In many fields including                        medicine, biology, imaging, computer vision, industrial                         engineering, psychology, much of the data is spatial and is often               in the form of images.  This research will develop statistical                  and high-performance graphical methods for analyzing and                        visualizing shapes when these are of principal interest."
"9205885","Mathematical Sciences: Seventh International Conference on  Multivariate Analysis","DMS","STATISTICS","06/15/1992","06/05/1992","C. Rao","PA","Pennsylvania State Univ University Park","Standard Grant","Alan Izenman","05/31/1993","$7,500.00","","crr1@psu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1269","","$0.00","     Many of the really exciting advances in sciences are now                   being made in highly interdisciplinary environments; and many of                the important aspects revolve around statistical issues. This                   conference will provide a forum in which to examine three broad                 directions of expansion of multivariate analysis.  These include                new directions in graphics, robust estimation, multiple time                    series, bootstrapping and meta analysis.  The impact of                         multivariate environmental statistics on environmental research,                policy and management is a second focus of the conference which                 will also address contemporary statistical issues relating to the               environment, to ecology and to environmental health.  Technical                 sessions are planned on multidimensional signal processing with                 participation of specialists in this area with expertise in                     statistics and probability and from engineering."
"9208066","Mathematical Sciences: Multivariate and Censored Data       Analysis Methods for Astronomy","DMS","EXTRAGALACTIC ASTRON & COSMOLO, ADVANCED TECHNOLOGIES & INSTRM, STATISTICS","08/15/1992","05/15/1995","Michael Akritas","PA","Pennsylvania State Univ University Park","Continuing Grant","James E. Gentle","07/31/1996","$180,000.00","Gutti Babu, Eric Feigelson","mga@stat.psu.edu","201 OLD MAIN","UNIVERSITY PARK","PA","168021503","8148651372","MPS","1217, 1218, 1269","0000, OTHR","$0.00","     This project continues collaborative research between                      astronomers and statisticians with the objective of developing                  specifically useful statistical procedures for the analysis of                  multivariate data sets that arise in observational astronomy.  It               addresses the statistical problems of estimation of a bivariate                 distribution function under random censoring, censored                          regression, testing for multivariate normality under random                     censoring and a new analysis for statistical independence.                           Statistical analysis can elucidate astrophysical processes                 which are detectable only from data obtained from a sample of                   celestial objects.  Using modern statistical theory and                         methodology, some of the obscuring distortions which are                        inevitable in such data can be ""removed"" to make the most                       physically meaningful relations more apparent.  For example, the                relations between luminosity, size, rotation and metallicity in                 elliptical galaxies can be examined and described.  This                        collaborative research focuses on the development of new methods                that carry the potential for major advances in both statistics                  and astronomy."
"9220941","Mathematical Sciences: Physically Based Stochastic Models ofFractures and Fluid Flow in Rock","DMS","STATISTICS","08/15/1992","08/18/1992","Stephen Martel","HI","University of Hawaii","Standard Grant","Sallie Keller-McNulty","07/31/1995","$21,376.00","","smartel@hawaii.edu","2425 CAMPUS RD SINCLAIR RM 1","HONOLULU","HI","968222247","8089567800","MPS","1269","","$0.00","     This interdisciplinary effort will examine geologic                        processes, such as hydrogeologic processes of coupled fracture                  growth and fluid flow, that are directly influenced by the                      spatial structure and evolution of rack fractures.  Modelling                   will incorporate physical models of fracture formation and                      stochastic process models.                                                           This award supports the cross-disciplinary efforts and the                 development of a research collaboration involving quantitative                  modelling in the geosciences.  In particular, the mathematician                 statistician and the geoscientists will focus their attention on                developing a physically-based stochastic model for rock                         fractures.  This will meld probabilistic ideas with geologic                    understanding to address the phenomena of rock fractures and                    fluid flow through them."
"9123166","Mathematical Sciences: Statistical Methods for Incomplete   and Biased Data with New Applications","DMS","STATISTICS","08/15/1992","04/12/1994","Yehuda Vardi","NJ","Rutgers University New Brunswick","Continuing Grant","James E. Gentle","01/31/1996","$110,014.00","","vardi@stat.rutgers.edu","3 RUTGERS PLZ","NEW BRUNSWICK","NJ","089018559","8489320150","MPS","1269","0000, 9218, HPCC, OTHR","$0.00","     The problem of recovering an input signal from a blurred                   output, in an input-output system with linear distortion, is                    ubiquitous in science and technology.  When the blurred output is               not corrupted by statistical noise, the problem is entirely                     deterministic and amounts to a mathematical inversion of a linear               system with positive parameters, subject to positivity con-                     straints on the solution.  By showing that all such linear                      inverse problems with positivity constraints can be interpreted                 as statistical estimation problems, extremely simple algorithms                 can be developed for finding the problems' maximum likelihood                   solutions.  Extensions to specific problems like noise degrada-                 tion,  estimation of blurring parameters (parameters of the point               spread function) and regularization techniques will follow.  The                methodology will be applied to new problems including restoration               of images blurred by relative motion between the subject and the                camera lens.                                                                         The blurring of a signal (sound, image, etc.) is common in                 science and technology, for example the systematic distort                      observed signal becomes what mathematicians call linear inverse                 problems with positivity constraints.  This research will develop               methods of solution which are broadly applicable to such                        problems.  The basis for this approach is to draw on statistical                principles and exploit the connection between such linear inverse               problems and statistical estimation problems for incomplete data                where methods already exist."
"9208141","Mathematical Sciences: Workshop on Writing Skills for Young Investigators","DMS","INFRASTRUCTURE PROGRAM, STATISTICS","06/01/1992","04/29/1994","Arthur Cohen","NJ","Rutgers University New Brunswick","Continuing Grant","Lloyd E. Douglas","11/30/1995","$60,000.00","William Strawderman","artcohen@rci.rutgers.edu","3 RUTGERS PLZ","NEW BRUNSWICK","NJ","089018559","8489320150","MPS","1260, 1269","0000, OTHR","$0.00","     This award will support a series of annual Workshops on                    Writing Skills for Young Investigators. These workshops will                    be held at annual meetings of the Institute of Mathematical                     Statistics or the American Statistical Association. The goal of                 the workshop is to improve the technical writing skills of                      junior investigators by their interactions with senior                          investigators and editors of journals.                                               This award will support a series of annual Workshops on                    Writing Skills for Young Investigators. The first of these will                 be held in Boston, Massachusetts in August, 1992. There will be                 two more workshops, one held in each of the subsequent years in                 various locations."
"9212411","Mathematical Sciences: Statistical Methods of Scientific    Interest Requiring Heavy Computer Usage","DMS","STATISTICS, COMPUTATIONAL MATHEMATICS","09/15/1992","09/15/1992","Javier Cabrera","NJ","Rutgers University New Brunswick","Standard Grant","James E. Gentle","02/29/1996","$55,000.00","","cabrera@stat.rutgers.edu","3 RUTGERS PLZ","NEW BRUNSWICK","NJ","089018559","8489320150","MPS","1269, 1271","9263","$0.00","     This research addresses a series of problems arising in                    industry, in geophysics  and in statistics; all require intensive               computational efforts and most have a strong geometric aspect.                  Whether the topic is geometric work associated with the design of               molecules, the timing of folding and magnetization of the earth                 or dynamical systems of fractals, the emphasis and the novelty                  will be found in the formulation of the problems.  The methods of               attack will draw on computational mathematics, as in the                        computation of fractal dimensions and the fractal pursuit index.                     Access to affordable computing means that ""solutions"" for                  practical problems can be found.  More than ever before, the                    important step is that of expressing the problem precisely and                  correctly in mathematical terms in order to execute correct                     computations.  This means capturing the scientific essence of the               problem, which is not always what it at first appears to be.                    Then, with careful selection of mathematical and computational                  methods, simulation and other procedures can yield good working                 solutions or even exact ones."
"9212413","Mathematical Sciences: Statistical Graphics: Foundations of Regression Graphics","DMS","STATISTICS, COMPUTATIONAL MATHEMATICS","06/15/1992","08/23/1996","Ralph Cook","MN","University of Minnesota-Twin Cities","Continuing Grant","James E. Gentle","11/30/1997","$126,000.00","","dennis@stat.umn.edu","200 OAK ST SE","MINNEAPOLIS","MN","554552009","6126245599","MPS","1269, 1271","0000, 9263, OTHR","$0.00","     Real-time, computationally intensive, graphical methods for                regression are the focus of this research.  In particular, it                   will emphasize the theoretical statistical foundations and the                  implications of standard displays such as the family of plots                   based on residuals for a broad class of peri-parametric models                  including generalized linear models.  One goal of this research                 is to develop a purely graphical analysis with model assessment                 methods that do not originate in residuals.  These developments                 will be available as extensions of the LISP-based computing                     environment XLISP-STAT.                                                              Graphical displays of quantitative data are a central tool                 of scientific inquiry.  Although these have historically been                   limited to whatever could be presented on a two-dimensional sheet               of paper, computing technology now routinely allows three-                      dimensional graphical displays.  How to make effective and                      technically valid scientific use of this technology needs careful               thought and a logical treatment.  In turn, this should result in                both a better understanding of standard displays and the                        construction of still more effective ones."
"9257006","Mathematical Sciences: NSF Young Investigator","DMS","STATISTICS","08/15/1992","08/20/1993","Kathryn Roeder","CT","Yale University","Continuing Grant","Alan Izenman","01/31/1995","$65,000.00","","roeder@stat.cmu.edu","105 WALL ST","NEW HAVEN","CT","065118917","2037854689","MPS","1269","0000, 9297, OTHR","$0.00","     This research, supported by a National Science Foundation                  Young Investigator award, involves the study of mixture models,                 including the development of graphical diagnostics and formal                   tests for identifying the presence of mixing in generalized                     linear models, determining the numbers of components in finite                  mixture models, and the development of methods to incorporate the               full information available in case-control studies with errors in               variables.                                                                           The National Science Foundation Young Investigator award                   recognizes outstanding young faculty.  This award recognizes the                recipient's strong potential for continued professional growth as               a research mathematician and for significant development as a                   teacher and academic leader."
"9201211","Mathematical Sciences: Semiparametric Mixture Models","DMS","STATISTICS","08/01/1992","07/30/1992","Kathryn Roeder","CT","Yale University","Standard Grant","James E. Gentle","01/31/1996","$50,000.00","","roeder@stat.cmu.edu","105 WALL ST","NEW HAVEN","CT","065118917","2037854689","MPS","1269","","$0.00","     This research on mixture models will develop graphical                     diagnostics and formal tests to identify the presence of mixing                 in generalized linear models and to determine the number of                     mixing components for finite mixtures. Methods will also be                     developed to incorporate full information for case-control                      studies with errors in variables.  The theory will draw on ideas                and techniques from nonparametric maximum likelihood, empirical                 processes, asymptotics, convex geometry, total positivity and                   from simulation.                                                                     Mixture distributions arise when homogeneous populations are               combined in such a way that the origins of individuals are lost.                A fundamental problem involves determining whether or not this                  combining has occurred and if so, how many different originating                populations there were.  This research will investigate graphical               techniques and will use mathematical theory to develop practical                statistical methods to answer these kinds of questions in many                  scientific applications."
"9207730","Mathematical Sciences: Stochastic Modelling and Inference","DMS","STATISTICS","09/15/1992","06/13/1995","Dennis Cox","IL","University of Illinois at Urbana-Champaign","Continuing Grant","James E. Gentle","02/29/1996","$120,000.00","Zhiliang Ying","dcox@stat.rice.edu","506 S WRIGHT ST","URBANA","IL","618013620","2173332187","MPS","1269","0000, OTHR","$0.00","     Stochastic models and methodologies for statistical                        inference will be developed in the context of modern                            instrumentation-intensive experimentation.  Bayesian, likelihood-               based, semi- and non-parametric methods will be investigated for                prediction, calibration, testing and constructing confidence                    intervals.  Efficient and numerically stable computational                      algorithms will be developed and statistical properties will be                 investigated both theoretically and via computer experimentation.                    Much modern science relies on instrumentation-intensive                    experimentation.  With instrument-generated data, the problem may               be prediction of responses for new inputs or untried experimental               conditions, or calibration of the responses for the test                        settings, or understanding which components of the response bear                a scientific relationship to the input variables.  A variety of                 processes may influence each observed response; the simplest is                 simple random error, others include deliberate or accidental                    censoring, and the limitations due the precision of the measuring               instrument.  Proper, efficient and valuable inferences require                  statistical models and inferential methodologies with correct                   understandings of all these processes."
"9209130","Mathematical Sciences: Exploiting Hidden Sparsity in        Statistical Estimation","DMS","STATISTICS, COMPUTATIONAL MATHEMATICS, EAST ASIA AND PACIFIC PROGRAM","08/01/1992","02/28/1995","David Donoho","CA","Stanford University","Continuing Grant","James E. Gentle","01/31/1996","$381,519.00","Iain Johnstone","donoho@stat.stanford.edu","450 JANE STANFORD WAY","STANFORD","CA","943052004","6507232300","MPS","1269, 1271, 5978","0000, 5912, 9218, 9263, HPCC, OTHR","$0.00","     The aim of this project is to develop new methods for                      recovering curves, spectra, signals and images from indirect,                   noisy observations.  This work is based on the discovery that the               minimax principle requires one to act as if the object to be                    recovered is sparse - mostly zero - when viewed in the                          appropriate transform domain, so that nonlinear methods derived                 from the minimax principle can exploit this sparsity much better                than traditional linear methods.  The basic theory of recovering                sparse sequences in noise will be expanded and applications to                  specific scientific settings will be developed using the wavelet                transform, Fourier transform and wavelet-vaguelette                             decomposition.  Results are expected for tomography, inversion of               Abel transforms and time series spectral analysis; also                         foundational arguments for the white noise model will be                        constructed, with particular reference to nonlinearity.                              When data are recorded for high dimensions, as for example                 in the form of pictures or images, recovering an exact                          description or identifying the parameters of the process that                   produced the data can be exceedingly difficult.  This work will                 consider some remarkable new mathematical and statistical                       techniques which should enable such a reconstruction efficiently                and with as much accuracy as the quality of the data permit.                    Both the mathematical theory and the practical implementation                   will be undertaken as part of this project."
"9204864","Mathematical Sciences: Statistifcal Theory and Methodology","DMS","STATISTICS, COMPUTATIONAL MATHEMATICS","08/01/1992","05/06/1994","Bradley Efron","CA","Stanford University","Continuing Grant","Michael Steuerwalt","01/31/1996","$344,000.00","","brad@stat.stanford.edu","450 JANE STANFORD WAY","STANFORD","CA","943052004","6507232300","MPS","1269, 1271","0000, 9218, 9263, OTHR","$0.00","     The general goal of this project is the development of                     statistical theory that is likely to be of direct use to                        statistical practitioners.  Specific projects are developed                     around the theme of computer-intensive statistical inference.                   Special topics include bootstrap, jackknife and related                         resampling methods, permutation tests and group theoretic testing               procedures, Gibbs sampling and Markov chains.  All these topics                 concern data mappings of special interest to statisticians.                     Historically, permutations were the first such mappings studied.                Methods like the bootstrap generalize permutations to wider                     classes of statistical problems, at the expense of less                         mathematical neatness and greater computational expense.  This                  project addresses ways to overcome these obstacles.                                  Statistical inference is the science of generalization from                observed data, often just a small amount, to the larger                         population from which the data were drawn.  The basic principles                of statistical inference were laid down before World War II.  The               basic theory was built around classical mathematics and the bell-               shaped curve.  Computer-intensive methods, developed in the last                15 years, aim to extend the range, ease, and plausibility of                    statistical arguments.  They substitute specially-developed                     computer algorithms of classical mathematical approximations                    relating to the bell-shaped curve.  Our research aims to justify                these algorithms.  Mathematical and computational arguments are                 used to show that the algorithms automatically produce the                      classical answers when such answers exist, and still give good                  answers in the much more common circumstance of problems having                 no classical solution."
"9214497","Mathematical Sciences: Women and Minorities Mentoring       Project","DMS","STATISTICS","09/01/1992","06/20/1996","Ingram Olkin","CA","Stanford University","Continuing Grant","James E. Gentle","02/28/1998","$275,000.00","","IOLKIN@STAT.STANFORD.EDU","450 JANE STANFORD WAY","STANFORD","CA","943052004","6507232300","MPS","1269","0000, OTHR","$0.00","     This project will sponsor a mentoring program for women and                minority researchers in statistics to help launch them in their                 research careers.  During each summer, when the Department of                   Statistics at Stanford hosts 20 to 40 visitors, many from abroad,               three statistical researchers from underrepresented groups will                 work with mentors to develop their own research.  The mentoring                 responsibilities of the faculty toward these summer post-doctoral               fellows will include collaborative work, advice on research                     avenues and on publication, and introduction to the active                      research community in the particular subspecialty.  Continuity in               the mentoring relationship is expected between the two summers of               the post-doctoral fellows residency as well."
"9209378","Mathematical Sciences: Bayesian Experimental Design and     Prior Elicitation in Response to Surface Models","DMS","STATISTICS","07/15/1992","08/25/1992","Blaza Toman","DC","George Washington University","Standard Grant","Sallie Keller-McNulty","12/31/1994","$17,808.00","","","1918 F ST NW","WASHINGTON","DC","200520042","2029940728","MPS","1269","9221","$0.00","     This project begins the preliminary research in the                        development and implementation of optimal Bayesian experimental                 designs based on expert opinion and informative priors.  Expansions             from fixed designs derived from fractional factorial designs will               include sequential designs for response surfaces and designs for                yield optimization.  The role and practicalities of prior                       elicitation processes will also be examined.                                         Bayesian statistical methodology allows direct incorporation               of expert opinion or of good prior information, as is often                     available for experiments in physical science and manufacturing.                This project will develop Bayesian optimal designs for experiments              for response surface models, for yield optimization and for                     particular application with the Taguchi method."
"9218206","Mathematical Sciences: Sensitivity of Solutions to Problem  of Locating Interacting Hub Facilities","DMS","APPLIED MATHEMATICS, COMPUTATIONAL MATHEMATICS, Geography and Spatial Sciences","07/01/1992","07/07/1992","Darko Skorin-Kapov","NY","SUNY at Stony Brook","Standard Grant","Sallie Keller-McNulty","06/30/1995","$62,740.00","Jadranka Skorin-Kapov","dskorin@edge.har.sunysb.edu","W5510 FRANKS MELVILLE MEMORIAL L","STONY BROOK","NY","117940001","6316329949","MPS","1266, 1271, 1352","1269, 9263","$0.00","     The problem of hub location can be viewed as a nonconvex                   optimization problem which has parallels in other applications as               well.  Here, the critical input parameters may be dynamic, so                   this work will consider sensitivity analysis for heuristic                      solutions.                                                                           This award supports the cross-disciplinary efforts and the                 development of a research collaboration involving quantitative                  modelling in the geosciences.  In particular the mathematicians                 and the geographer will focus their attention on the development                of new optimization algorithms for the problem of assigning hub                 facilities when these are restricted to specific available                      locations and when the flow of activity from one point or node to               another is known or can be modelled mathematically."
"9205038","Mathematical Sciences: Statistical Methods in Image         Processing","DMS","STATISTICS","07/01/1992","06/29/1992","Chengda Yang","AZ","University of Arizona","Standard Grant","Sallie Keller-McNulty","12/31/1994","$40,000.00","","chengda@convx1.ccit.arizona.edu","845 N PARK AVE RM 538","TUCSON","AZ","85721","5206266000","MPS","1269","9218","$0.00","     This project deals with three related problems in the                      general area of image processing.  The first is a dramatic                      increase in the efficiency of the Gibbs Sampler and Metropolis                  Dynamic algorithms from restricting the algorithms to a locally                 bounded image space.  The second develops a special estimation                  method for astronomical image data of a faint disk, where the                   data has significant blur (e.g., Hubble telescope data).  Here                  the use of a suitable lower dimensional linear function improves                efficiency. The third addresses data compression using a Markov                 random field model and subdividing the original large image and                 forming optimal representative subimages.                                            Statistical image analysis uses statistical principles to                  ""guess"" the real image when only poor quality image data is                     available.  The quality of a particular algorithm is depends upon               how good the chosen ""guess"" is and how quickly it is achieved.                  This project focusses on increasing the speed of the algorithms                 by trying to get the most pertinent information rather than                     working on the whole image at once."
"9201283","Mathematical Sciences: Bifurcation from Infinity for        Semilinear Elliptic PDE - The Influence of Nonlinear Growth and Domain Geometry","DMS","APPLIED MATHEMATICS, STATISTICS","07/01/1992","05/18/1992","Renate Schaaf","UT","Utah State University","Standard Grant","","12/31/1994","$72,000.00","Zhi-Qiang Wang","","1000 OLD MAIN HILL","LOGAN","UT","843221000","4357971226","MPS","1266, 1269","","$0.00","     The principal investigators will use bifurcation from                      infinity techniques to study the asymptotic behavior of                         bifurcating branches of solutions of semilinear elliptic                        equations to get detailed information about the existence and                   multiplicity of solutions for such problems as well as stability                information for the associated time-evolution problems.                              Solution structure is strongly dependent on the spatial                    dimension and the geometry of the domain.  The stability of                     steady state solutions in the case where multiple solutions exist               is extemely delicate and important in most physical situations."
"9200254","Mathematical Sciences: Physically Based Stochastic Models ofFractures and Fluid Flow in Rock","DMS","STATISTICS, SPECIAL PROGRAMS-RESERVE","08/01/1992","12/06/1995","Kevin Hestir","UT","Utah State University","Standard Grant","James E. Gentle","01/31/1996","$78,686.00","James Evans, Craig Forster, Stephen Martel, Koebbe Joseph","hestir@markov.math.usu.edu","1000 OLD MAIN HILL","LOGAN","UT","843221000","4357971226","MPS","1269, 9145","1269","$0.00","     This interdisciplinary effort will examine geologic                        processes, such as hydrogeologic processes of coupled fracture                  growth and fluid flow, that are directly influenced by the                      spatial structure and evolution of rack fractures.  Modelling                   will incorporate physical models of fracture formation and                      stochastic process models.                                                           This award supports the cross-disciplinary efforts and the                 development of a research collaboration involving quantitative                  modelling in the geosciences.  In particular, the mathematician,                statistician and the geoscientists will focus their attention on                developing a physically-based stochastic model for rock                         fractures.  This will meld probabilistic ideas with geologic                    understanding to address the phenomena of rock fractures and                    fluid flow through them."
"9217868","Mathematical Sciences:  Analysis of Ice Core Time Series andPaleoclimate Modeling","DMS","STATISTICS, ANT Earth Sciences, ANS-Arctic Natural Sciences","09/15/1992","07/29/1993","Loren Meeker","NH","University of New Hampshire","Continuing Grant","Sallie Keller-McNulty","08/31/1995","$106,000.00","Paul Mayewski","dave meeker@grg.sr.unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","MPS","1269, 5112, 5280","","$0.00","     This award supports the cross-disciplinary efforts and the                 development of a research collaboration involving quantitative                  modelling in the geosciences.  In particular the mathematician(s)               and the GEO scientist research will focus their attention on the                statistical and scientific analysis of records arising from ice                 cores taken from the Greenland ice sheet.  The two-phase                        interdisciplinary research will begin with the development of                   scientifically and statistically valid exploratory and                          confirmatory statistical techniques for assessing the record of                 the paleoclimate as recorded in the Greenland ice sheet.  The                   second phase will address the development of mathematical models                relating the environmental signals deposited in polar ice sheets                to important paleoclimate factors.  This project presents                       significant mathematical and statistical challenges to provide                  geoscientists with tools to be applied to the task of                           understanding the approximately 200,000 years od Earth's climatic               history."
"9205159","Mathematical Sciences: Gordon Research Conference on        Statistics in Chemistry and Chemical Engineering","DMS","STATISTICS, Atmospheric Chemistry","07/15/1992","08/31/1992","Richard De Veaux","RI","Gordon Research Conferences","Standard Grant","Alan Izenman","06/30/1993","$7,000.00","Alexander Cruickshank","deveaux@williams.edu","5586 POST RD","EAST GREENWICH","RI","028183454","4017834011","MPS","1269, 1524","","$0.00","     Statistical methodology provides important quantitative                    tools in numerous areas of research including meeting national                  goals for improved quality and productivity, the evaluation of                  environmental hazards and technological progress coming from                    research in chemistry and chemical engineering.  This conference                will involve leading statisticians, chemists and chemical                       engineers from industry, government and universities to examine                 the ways in which the most meaningful data can be obtained and                  transformed into useful information for research and new                        developments in chemistry and chemical engineering.  Important                  problems of high priority in these areas will be presented to                   research statisticians; and in their turn, applied chemists and                 statisticians can learn firsthand about new statistical research                results to apply in their work.  Together these groups may                      formulate priorities for future statistical research directions                 in this interface."
"9208820","Mathematical Sciences: Robust Estimation and Testing of     Econometric Models for Panel Data","DMS","STATISTICS, Economics","08/01/1992","05/26/1993","Joel Horowitz","IA","University of Iowa","Continuing Grant","Sallie Keller-McNulty","01/31/1995","$52,000.00","Marianthi Markatou","joel-horowitz@northwestern.edu","105 JESSUP HALL","IOWA CITY","IA","522421316","3193352123","MPS","1269, 1320","0000, OTHR","$0.00","     This award will support a collaborative effort in the areas                of econometrics and statistics.  In particular, the investigators               will develop robust techniques for panel data.  Panel data                      consist of a time series of observations on each of several                     individuals.  Such data are used frequently in economics and                    certain biostatistical contexts.  Standard methods for analysis                 of panel data are not robust to gross measurement errors in the                 data, and the results of analyses based on these methods can be                 highly sensitive to gross errors.  This is well known to                        investigators who use panel data from sources such as the Current               Population Survey.  These investigators routinely use a variety                 of informal methods to ""clean"" the data before estimating models                and testing hypotheses.  The research proposed will proved formal               methods for doing this.                                                              This award will support a collaborative effort in the areas                of econometrics and statistics.  In particular, the investigators               will develop robust techniques for panel data.  Panel data                      consist of a time series of observations on each of several                     individuals.  Such data are used frequently in economics and                    certain biostatistical contexts."
"9206966","Mathematical Sciences: Tests for Direction-Invariance and   Separability of the Second-Order Variation of Spatial RandomFields","DMS","STATISTICS","07/01/1992","07/27/1992","Dale Zimmerman","IA","University of Iowa","Standard Grant","Sallie Keller-McNulty","12/31/1994","$30,000.00","","dale-zimmerman@uiowa.edu","105 JESSUP HALL","IOWA CITY","IA","522421316","3193352123","MPS","1269","","$0.00","     The objective of this research is to develop statistical                   tests for some important properties of stationary spatial random                fields.  The properties to be considered are those of direction-                invariance (isotropy) and separability, and variations thereof,                 of the second-order variation.  In addition to having important                 scientific meaning in many situations, these properties, when                   they hold, can greatly simplify both the computations involved                  in, and conclusions made from, the analysis of spatial data.                    Parametric testing approaches, which are based on a parametric                  model for the semivariogram or covariance function, and                         nonparametric approaches, which utilize method-of-moments                       estimators for sempiparametric approach will also receive                       attention.  Biological environmental, and physical scientists who               analyze spatial data will find the testing procedures useful.                        The objective of this research is to develop statistical                   tests for some important properties of stationary spatial random                fields.  The properties to be considered are those of direction-                invariance (isotropy) and separability, and variations thereof,                 of the second-order variation.  This work will have potential                   impact on fields of biological, environmental and physical                      sciences."
"9204812","Mathematical Sciences: Bayesian Methods for the Analysis of Categorical Data from Similar Sources & Nonlinear Time      Series Analyses-Theory & Applications","DMS","STATISTICS","08/15/1992","08/20/1992","Balgobin Nandram","MA","Worcester Polytechnic Institute","Standard Grant","Sallie Keller-McNulty","01/31/1996","$49,900.00","Mei-Hui Guo","balnan@wpi.edu","100 INSTITUTE RD","WORCESTER","MA","016092247","5088315000","MPS","1269","","$0.00","     This award will support the research of two individuals in                 the area of statistical sciences.  Dr. Nandram will develop                     bayesian methods for the analysis of categorical data from                      similar sources.  Dr. Guo will work on three different problems                 in the analysis of non-linear time series.  Together, these two                 projects represent interesting problems in modern statistics.                        This award will support the research of two individuals in                 the area of statistical sciences.  Dr. Nandram will develop                     bayesian methods for the analysis of categorical data from                      similar sources.  One example of categorical data would be ""yes""                or ""no"" responses in questionnaires.  Dr. Guo will work on three                different problems in the analysis of non-linear time series.                   Together, these two projects represent interesting problems in                  modern statistics."
"9202070","Mathematical Sciences: Semiparametric Models & Estimation   of Survival Functions","DMS","STATISTICS","09/01/1992","09/02/1992","Qiqing Yu","NY","SUNY at Stony Brook","Standard Grant","Sallie Keller-McNulty","08/31/1995","$30,000.00","Hung Chen","qyu@math.binghamton.edu","W5510 FRANKS MELVILLE MEMORIAL L","STONY BROOK","NY","117940001","6316329949","MPS","1269","","$0.00","     The two aspects of this research focus on semiparametric                   regression modeling and the properties of estimators and the                    comparative merits of different approaches.  In the context of                  survival function analysis, the estimation problem focuses on the               information in the censoring distribution and/or the observed                   censoring times.  In the industrial context, the problem focuses                on describing the behavior of the bootstrap methodology as used                 in smoothing and in determining conditions under which this is                  the superior methodology.                                                            Situations in which statistical models or functions can be                 described only partially in terms of identified factors or                      attributes occur widely.  This project considers applications to                data from medical trials and, separately, from industrial                       experimentation.  When known features only specify part of the                  model, the unexplained part can be described in a number of                     different ways.  This proposal seeks to identify the conditions                 which make each particular choice of methodology are sufficiently               superior to make its use important."
"9203179","Mathematical Sciences:  Cross-Disciplinary Workshops in     Statistics","DMS","STATISTICS","05/15/1992","05/13/1992","Jerome Sacks","NC","National Institute of Statistical Sciences","Standard Grant","Alan Izenman","10/31/1993","$15,000.00","","sacks@niss.org","19 TW ALEXANDER DR","RESEARCH TRIANGLE PARK","NC","277090152","9196859300","MPS","1269","","$0.00","     Many of the really exciting advances in sciences are now                   being made in highly interdisciplinary environments; and many of                the important aspects revolve around statistical issues.  This                  research project will bring together statisticians and scientists               from academic, governmental, laboratory and industrial setting to               delineate crucial problems in several scientific areas and to                   identify and formulate the needed statistical research.."
"9210131","Mathematical Sciences: Complexity and Information Based     Criteria for Model Selection","DMS","STATISTICS","07/15/1992","07/21/1992","Dominique Haughton","MA","Bentley University","Standard Grant","Sallie Keller-McNulty","12/31/1993","$17,400.00","","dhaughto@bentley","175 FOREST ST","WALTHAM","MA","024524705","7818912660","MPS","1269","9221","$0.00","     This research will deal with the properties of information as              used in model selection.  New information criteria have been                    developed which deal with situations of multiple data sets and/or               with models which may have the same dimension.  This research will              expand on recent results for these criteria, and in particular will             establish asymptotic properties.                                                     This research will deal with statistical model selection.  The             area, generally speaking, is concerned with the choice of the best              model to fit a dat set among a set of candidate models.  Issues of              interest include problems of overfitting and the selection of                   variables in regression."
"9204950","Mathematical Sciences: Inverse Estimation Problems","DMS","APPLIED MATHEMATICS, STATISTICS","08/01/1992","08/11/1994","Frits Ruymgaart","TX","Texas Tech University","Continuing Grant","James E. Gentle","07/31/1996","$86,000.00","","ruymg@math.ttu.edu","2500 BROADWAY","LUBBOCK","TX","79409","8067423884","MPS","1266, 1269","0000, 9251, OTHR","$0.00","     Many problems in science and engineering share the common                  form that an unknown ""signal"" has to be restored from blurred                   observations on a known transformation of the signal.                           Mathematically this requires solving a (linear) system of                       equations, typically in an infinite dimensional space, where the                data only suffice to construct a noisy approximation of the                     transformed signal.  Solution depends upon the inversion of the                 operator.  Studying this inversion problem in a Hilbert space                   setting can provide a unifying approach for constructing                        solutions, by exploiting techniques from spectral and harmonic                  analysis.  Then statistical aspects such as error analysis and                  cross-validation can be examined.                                                    A famous example of this kind of problem is the technique of               computerized tomography used in medical practice to recover an                  image of internal structures in the body.  Because in practice,                 measurements are blurred by errors, and because only a limited x-               ray exposure is possible, measurement of the ""signal"" (in this                  case the attenuation of the x-rays passing through the body) is                 imperfect indeed.  Still, very refined images can be                            reconstructed and are very useful.  Other well-known applications               are image reconstruction and all kinds of deconvolution problems."
"9203369","Mathematical Sciences: Statistical Theory and Procedures forErrors in Variables Regression and Related Reliability","DMS","STATISTICS","08/01/1992","03/31/1994","Leon Gleser","PA","University of Pittsburgh","Continuing Grant","James E. Gentle","07/31/1996","$133,270.00","","gleser@pitt.edu","4200 FIFTH AVENUE","PITTSBURGH","PA","152600001","4126247400","MPS","1269","0000, OTHR","$0.00","     Ignoring the errors in the explanatory variables, as in                    classical least squares, can introduce serious bias in the fitted               function.  This research will incorporate partial information                   from various sources using either Bayesian or frequentist                       techniques or combinations, will evaluate the resultant                         methodologies, and will apply these methods to measurement error                problems arising in chemistry and environmental monitoring.                          Regression models describe relationships among explanatory                 and response variables.  When the explanatory variables are also                subject to random error, the regression model may be                            systematically distorted unless special analyses are used.  This                research will extend these special analyses to incorporate                      information about the reliability of the explanatory variables.                 The new methods for analysis should find application in chemistry               and environmental monitoring (to be tried as part of this                       research), astronomy, medicine and behavioral science."
"9201705","Mathematical Sciences: General Global Criteria for SelectingClustering Algorithms","DMS","STATISTICS","09/01/1992","07/30/1992","John Van Ness","TX","University of Texas at Dallas","Standard Grant","Sallie Keller-McNulty","08/31/1994","$40,000.00","","ness@utdallas.edu","800 WEST CAMPBELL RD.","RICHARDSON","TX","750803021","9728832313","MPS","1269","","$0.00","     This project will develop global criteria for selecting                    clustering procedures using the admissible clustering approach of               Fisher and Van Ness with extended definitions of admissibility                  conditions.  These admissibility conditions will be applied to                  the general infinite parameterized family of clustering                         procedures proposed by Lance and Williams; and for each                         condition, the corresponding subset of the family's parameter                   space yielding admissible algorithms will be determined.                             Clustering is a heavily used tool for partitioning a group                 of objects into subgroups or species.  It is used by taxonomists,               librarians, epidemiologists, bankers, scientists and many others                to classify large, complex sets of objects into homogeneous                     groups which can be comprehended and handled better.  Numerous                  clustering methods have been proposed over the years, with each                 giving a different clustering; hence, the choice of algorithm is                important.  The work here is to codify the various algorithms                   according to the properties needed for a specific application."
"9206972","Mathematical Sciences: Random Variables and Computers","DMS","STATISTICS, COMPUTATIONAL MATHEMATICS","08/15/1992","01/30/1996","George Marsaglia","FL","Florida State University","Continuing Grant","Michael Steuerwalt","02/29/1996","$186,000.00","Arif Zaman","","874 TRADITIONS WAY","TALLAHASSEE","FL","323060001","8506445260","MPS","1269, 1271","0000, 9218, 9263, HPCC, OTHR","$0.00","     The generating and testing of random variables has provided                some of the most widely used methods for Monte Carlo simulation.                Several new methods have been developed for new kinds of computer               architectures, notably the subtract-with-borrow method that is                  very fast, requires few memory locations, has extremely long                    periods and provable uniformity.  Current efforts are directed                  toward methods that will take advantage of massively parallel                   systems, new mass storage devices and other supercomputer                       features so that software for statistical computing can keep up                 with and take advantage of the remarkable advances in hardware.                      Many computer simulation studies call for random input at                  various point because of uncertainties or complexities of the                   underlying models.  The construction of ""pseudo-random"" numbers                 can be  sufficiently sophisticated to give workable substitutes                 for true random observations from a natural process. At the same                time these generated numbers are readily available and can, when                needed be reproduced exactly for testing purposes or to compare                 two different computing approaches to the solution of extremely                 large and complicated mathematical problems."
"9212415","Mathematical Sciences: Statistical Methods of Scientific    Interest Requiring Heavy Computer Usage","DMS","STATISTICS","08/01/1992","12/15/1993","Geoffrey Watson","NJ","Princeton University","Continuing Grant","James E. Gentle","01/31/1996","$90,000.00","","gsw@math.princeton.edu","1 NASSAU HALL","PRINCETON","NJ","085442001","6092583090","MPS","1269","0000, OTHR","$0.00","     This research addresses a series of problems arising in                    industry, in geophysics  and in statistics; all require intensive               computational efforts and most have a strong geometric aspect.                  Whether the topic is geometric work associated with the design of               molecules, the timing of folding and magnetization of the earth                 or dynamical systems of fractals, the emphasis and the novelty                  will be found in the formulation of the problems.  The methods of               attack will draw on computational mathematics, as in the                        computation of fractal dimensions and the fractal pursuit index.                     Access to affordable computing means that ""solutions"" for                  practical problems can be found.  More than ever before, the                    important step is that of expressing the problem precisely and                  correctly in mathematical terms in order to execute correct                     computations.  This means capturing the scientific essence of the               problem, which is not always what it at first appears to be.                    Then, with careful selection of mathematical and computational                  methods, simulation and other procedures can yield good working                 solutions or even exact ones."
"9223559","Mathematical Sciences: On-Site Research to Advance          Industrial Quality and Productivity","DMS","INFRASTRUCTURE PROGRAM, STATISTICS, INTEGRATION ENGINEERING, , ","10/01/1992","04/01/1996","Barbara Bailar","VA","American Statistical Association","Continuing Grant","K Crank","12/31/1996","$465,340.00","","BarbaraB@ASA.MHS.Compuserve.Com","732 N WASHINGTON ST","ALEXANDRIA","VA","223141925","7036841221","MPS","1260, 1269, 1463, 4558, 6438","1269, 9146, 9179, MANU, SMET","$0.00","     Continued funding is provided for a fellowship program                     entitled ""On-Site Research to Advance Industrial Quality and                    Productivity.""  Jointly sponsored by the National Science                       Foundation and the National Institute of Standards and Technology               (NIST), the program will be administered by the American                        Statistical Association while NIST acts as the host agency.  This               program is designed to bridge gaps between quality assurance                    efforts in industry, academia and government through the                        formation of research teams of industrial, academic, and NIST                   statisticians and engineers.  Possible areas of research for                    Fellows ar statistical design of industrial experiments, process                control, studies of advanced manufacturing systems, computing for               engineering and industrial statistics, and calibration of                       manufacturing process control.                                                       Continued funding is provided for a fellowship program,                    designed to have academic statisticians and engineers studying                  industrial problems, especially in the area of quality assurance."
"9205112","Mathematical Sciences: Chaotic Time Series and              Environmental Extremes","DMS","STATISTICS","07/15/1992","05/31/1994","Richard Smith","NC","University of North Carolina at Chapel Hill","Continuing Grant","Stephen M. Samuels","12/31/1995","$72,500.00","","rls@email.unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275995023","9199663411","MPS","1269","1577, GLCH","$0.00","     Previous research on threshold methods and extreme values is               in the process of being extended from the case of univariate time               series, to multivariate or spatial data.  This is particularly                  relevant in climatological research because of the need to                      combine data from many measuring stations.  The climatological                  objective is to come up with measures of trend among the                        crossings by a temperature series of a very high or very low                    threshold.  A second objective is to look at alternatives to the                standard models for time series.  In particular the concept of                  long-range dependence appears to be important in climatology, and               the research will explore methods of measuring this from the low-               frequency behavior of the periodogram.                                               An important theme of current climate research is the need                 for reliable statistical measures of greenhouse-gas-induced                     climate change.  Global warming would cause an increase in                      extreme temperatures.  This research will study the statistical                 aspects of these extreme values, paying particular attention to                 the problem of efficiently combining information from a number of               measuring stations."
"9203347","Mathematical Sciences: Regression and Time Series Model     Selection in Small Samples","DMS","STATISTICS","07/01/1992","07/09/1992","Clifford Hurvich","NY","New York University","Standard Grant","Stephen M. Samuels","12/31/1994","$31,000.00","","churvich@stern.nyu.edu","70 WASHINGTON SQ S","NEW YORK","NY","100121019","2129982121","MPS","1269","","$0.00","     In a recent series of papers, the principal investigaors                   have explored the use of a correction to the Akaike Information                 Criterion, AICc, and a further-improved version AICi, for model                 selection in linear regression and artoregressive time series                   analysis.  Substantial small-sample improvements in model                       selection performance are found in all cases as the bias of the                 estimator for Kullback-Leibler discrepancy is greatly reduced.                  The investigators propose to build on the above work by                         developing a general theoretical and pracitcal foundation for                   AICc as it applies to small-sample model selection problems in                  time series and regression.                                                          A central problem in statistics is that of selecting an                    appropriate model from a potentially large class of candidate                   models to apply in a particular situation of practical interest.                The selection of an inadequate model can have very serious                      consequences: forecasts of future events may be substantially                   distorted and inaccurate, resulting in incorrect decisions, and                 financial losses.  The development of an effective decision-                    making process therefore depends on the ability to decide which                 model seems best for the data at hand.  The investigators propose               to develop and test improved methods of selecting a model on the                basis of a reasonably small amount of observed data."
"9124009","Mathematical Sciences: Statistical Problems with Nuisance   Parameters","DMS","STATISTICS","06/15/1992","06/26/1992","Andrew Rukhin","MD","University of Maryland Baltimore County","Standard Grant","Stephen M. Samuels","11/30/1994","$40,151.00","","rukhin@math.umbc.edu","1000 HILLTOP CIR","BALTIMORE","MD","212500001","4104553140","MPS","1269","","$0.00","     The project's goal is to investigate the asymptotic                        estimation problem when the number of nuisance parameters                       increases with the number of observations. The application of the               obtained results to multidimensional sensor array processing is                 expected. The aim here is to determine the best possible                        asymptotic performance and to give a method for constructing an                 estimator exhibiting this behavior.  Similar questions will be                  studied in a version of the change-point estimation problem and                 admissibility conditions under Pitman closeness for generalized                 Bayes estimators will be derived. The relationship between prior                distribution and the shape of the frequentist risk of the                       corresponding Bayes estimator will be also investigated.                             This proposal is directed towards finding new methods of                   obtaining optimal statistical procedures with the application to                signal processing."
"9204504","Mathematical Sciences: Statistical Inference for General    Models","DMS","STATISTICS, Hist & Philosophy of SET","09/01/1992","03/23/1994","Stephen Stigler","IL","University of Chicago","Continuing Grant","James E. Gentle","08/31/1996","$367,500.00","Wing Hung Wong, Michael Stein","","5801 S ELLIS AVE","CHICAGO","IL","606375418","7737028669","MPS","1269, 1353","0000, 9178, 9251, OTHR, SMET","$0.00","     Research efforts under this award lie in three areas:                      nonparametric and semiparametric estimation, stationary point                   processes and the history of twentieth century statistics.                      Specific goals for estimation of functionals in nonparametric                   models include a study of convergence rates for sieve estimators,               the construction of optimal or near-optimal estimators, and an                  examination of ways to reduce the dimensionality of the covariate               space.  The study of stationary point processes will examine                    methods of inference for these, also for stationary random sets                 and for the prediction of areal averages of random fields.                           One facet of this research involves the development of                     methods of accurate estimation based on complex data from the                   physical sciences.  These new methods should reduce the                         assumptions needed for the statistical analysis to proceed                      correctly.  The research will also investigate the effect of mild               errors in even those necessary assumptions.  A second aspect of                 this project focusses on the analytic techniques for data                       gathered over wide areas, for example, measurements of                          atmospheric ozone.  The goal of this work is to develop                         statistical analytical methods which can be used to evaluate                    relationships among different measurements and to examine                       potential causal mechanisms.  The third aspect of this project is               the historical study of the relationship of the conceptual                      structure of mathematical theories to their areas of scientific                 and policy applications."
"9203135","Mathematical Sciences: Nonparametric Curve Estimation","DMS","STATISTICS","08/01/1992","06/22/1994","James Marron","NC","University of North Carolina at Chapel Hill","Continuing Grant","James E. Gentle","01/31/1996","$168,276.00","Jianqing Fan","marron@unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275995023","9199663411","MPS","1269","0000, 9260, OTHR","$0.00","     This project addresses the theory and application of                       smoothing methods in nonparametric curve estimation. The focus                  here is on bandwidth selection with exact risk calculation and                  qualitative smoothing and on an examination of the superiority of               local polynomial smoothers to more commonly used methods.  For                  local polynomial smoothers, this project will address issues of                 boundary effects, percentile regression and robustification,                    variable order of fit, goodness-of-fit testing and local weighted               likelihood.                                                                          Smoothing methods in nonparametric curve estimation                        constitute a flexible and powerful approach to data analysis                    which is of particular use in complicated situations where an                   exact or even useful model is unavailable.  Such problems arise,                for example, in economics, zoology, and marketing among other                   areas.Effective practical implementation of smoothing methods                   requires analytic understanding of their properties."
"9205881","Mathematical Sciences: Nonparametrics and Resampling for    Spatial Data","DMS","STATISTICS","07/01/1992","06/29/1992","Edward Carlstein","NC","University of North Carolina at Chapel Hill","Standard Grant","James E. Gentle","12/31/1995","$45,000.00","","uedcar@unc.bitnet","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275995023","9199663411","MPS","1269","","$0.00","     Nonparametric statistical methods will be developed for                    spatial data arising from random fields and point processes.  A                 nonparametric approach is appealing for analyzing spatial data                  because it avoids detailed assumptions about the typically                      unknown and usually complicated underlying probability structure                in terms of marginal distributions of the observations or shapes                of spatial boundaries that partition the observations into                      homogeneous groups.  Two specific types of nonparametric methods                will be developed: resampling methods, which describe the                       sampling distribution of a general statistic computed from                      spatial data; and boundary estimators, which separate                           nonhomogeneous spatial data into homogeneous subsets.                                Spatial data is data that is laid out on a map or grid; it                 arises naturally in geology, ecology, meteorology, agriculture,                 epidemiology, medical imaging and other areas of scientific                     investigation.  Often there is a natural boundary running through               spatial data such as a seismic fault line or the edge of an                     object in an image.  One goal of this project is to develop                     methods for identifying such boundaries accurately; another is to               develop methods for assessing the sampling error in quantities                  calculated from spatial data."
"9201304","Mathematical Sciences: Fractal Encoding of Rock Fractures","DMS","CLASSICAL ANALYSIS, APPLIED MATHEMATICS, TEACHER ENHANCEMENT PROGRAM, SPECIAL PROGRAMS-RESERVE","09/01/1992","06/24/1994","Ronald Shonkwiler (Shenk)","GA","Georgia Tech Research Corporation","Standard Grant","James E. Gentle","02/29/1996","$107,614.00","Anca Deliu, Leland Long, Robert Lowell","shenk@math.gatech.edu","926 DALNEY ST NW","ATLANTA","GA","30332","4048944819","MPS","1261, 1266, 7300, 9145","1269, 9177, SMET","$0.00","     This project unites the mathematical theory of iterated                    functions systems with the geophysical (observable) phenomena of                rack fractures.  The aim is to determine whether or not rock                    fractures can be characterized by iterated function system codes,               and if so, what predictive validity these codes might then have                 for fracture-related phenomena.                                                      This award supports the cross-disciplinary efforts and the                 development of a research collaboration involving quantitative                  modelling in the geosciences.  In particular the mathematicians                 and the geophysicists will focus their attention on mathematical                models derived from chaotic dynamics to model and predict rock                  fractures and related phenomena."
"9214775","Mathematical Sciences: Numerical Assessments of Goodness-of Fit Tests based on Statistically Equivalent Blocks","DMS","STATISTICS","09/01/1992","05/09/1994","Calvin Williams","SC","Clemson University","Continuing Grant","Jean Thiebaux","02/28/1997","$119,232.00","","calvinw@clemson.edu","230 Kappa Street","CLEMSON","SC","296340001","8646562424","MPS","1269","0000, 9135, OTHR","$0.00","     This research will examine goodness-of-fit tests for                       multivariate data modeled using distribution-free or                            nonparametric models.  The small sample behavior of test                        statistics based on spacings will be investigated using Monte                   Carlo methods and will be compared to limiting distribution                     theoretical results.  By constructing statistically equivalent                  blocks, test statistics can be extended to the multidimensional                 case.                                                                                When trying to represent an underlying explanatory or                      descriptive model for real multivariate data, a crucial                         difficulty is to determine when a postulated model is adequate.                 The fewer the mathematical assumptions made initially, the more                 difficult in general to be sure that the model does represent the               important features, but not any artifacts of a particular sample.               Some mathematical theory has been developed for the case of an                  arbitrarily large sample; some theory has been developed when the               data is assumed to follow a Gaussian (normal) distribution.  This               project will examine tests of model adequacy when the samples are               not extremely large and at the same time the distribution cannot                be assumed to be normal.  The work will concentrate on multi-                   variate observations."
"9204007","Mathematical Sciences: Topics in Economical Experimental    Designs","DMS","STATISTICS","09/01/1992","08/19/1992","Dennis Lin","TN","University of Tennessee Knoxville","Standard Grant","Sallie Keller-McNulty","02/28/1995","$12,000.00","","dkjlin@purdue.edu","1331 CIR PARK DR","Knoxville","TN","379163801","8659743466","MPS","1269","","$0.00","     This research examines the roles of first-order saturated,                 supersaturated and minimal level change designs in the problem of               minimizing the number of experiments required to differentiate                  the influential factors from those only contributing noise.                          Optimal experimental design in an industrial setting may                   also have as an objective the minimization of the number of                     experiments.  Theoretical solutions have often depended upon                    unrealistic assumptions about the likely number of influential                  factors and their interactions.  This research focuses on an                    efficient and effective approach to the design of a minimal                     series of experiments to identify those factors with the goal of                predicting the optimal combination of factors or factor settings                for full-scale production."
"9206634","Mathematical Sciences: Statistical Inference for Monotone   Regression","DMS","STATISTICS","07/15/1992","07/21/1992","Hari Mukerjee","KS","Wichita State University","Standard Grant","Stephen M. Samuels","12/31/1994","$28,000.00","","mukerjee@math.twsu.edu","1845 Fairmount","Wichita","KS","672600007","3169783285","MPS","1269","","$0.00","     The present body of knowledge in monotone regression is                    confined to some isolated existence theorems about point                        estimation and hypothesis testing.  The investigator plans to                   implement these general methods for as many aspects of regression               analysis as possible.  In particular, formulas for confidence and               prediction intervals will be derived by inverting hypothesis                    tests, since usual methods are inapplicable because of lack of                  pivotals.  The proposed study will also involve construction of                 user-oriented tables to bring the restricted procedures to a                    level comparable to the unrestricted ones.                                           In regression analysis one tries to predict one variable in                terms of another.  In many applications, especially in social                   sciences and economics, it is reasonable to assume that the                     predicted variable tends to increase (or decrease) as the                       predictor variable increases.  Statistical inferences under such                assumptions are at a very primitive stage at present, and consist               primarily of some general mathematical theorems.  The proposed                  study aims at developing concrete formulas and tables so that                   users can apply them directly to real-life problems."
"9220324","Mathematical Sciences: Topics in Nested Row and Column      Design","DMS","STATISTICS","08/01/1992","09/15/1992","Nizam Uddin","ME","University of Southern Maine","Standard Grant","Stephen M. Samuels","01/31/1995","$19,440.00","","nuddin@mail.ucf.edu","96 Falmouth St","Portland","ME","041049300","2072288536","MPS","1269","9229","$0.00","     This research involves the study of nested row and column                  designs.  The investigator will study optimal design using                      spatial correlation models rather than the classical model                      formulation.  The spatial processes to be employed will be                      members of the autonormal family, a two-dimensional                             generalization of the one-dimensional autoregressive processes.                      Experimental design has long been used in agriculture to                   improve crop production.  It is now being used in manufacturing                 to improve product quality.  This research will study optimality                of certain types of designs."
"9121003","Mathematical Sciences: Statistical Model Building with      Generalized Splines","DMS","STATISTICS, COMPUTATIONAL MATHEMATICS","07/01/1992","02/27/1996","Grace Wahba","WI","University of Wisconsin-Madison","Continuing Grant","James E. Gentle","06/30/1998","$249,500.00","","wahba@stat.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","MPS","1269, 1271","0000, 1317, 9218, 9263, EGCH, HPCC, OTHR","$0.00","     This project develops further new mathematical, statistical                and computational methods for the empirical estimation of                       response functions of several to many variables.  Data may be                   direct, indirect or only on functions implicitly defined.  The                  new spline smoothing will be extended to analysis of variance                   techniques.  Particular problems include model selection (choice                of model components to include), improved computational methods                 to allow efficient fitting with many variables and very large                   data sets, development of methods appropriate to binomial and                   other non-Gaussian responses and to implicit problems.                               Statistical models are intended to predict outcomes given                  specified values of the predictor variables or to describe the                  relationships between predictors and outcomes, or to see how                    responses may change as predicting factors or attributes change.                Developing empirical statistical models using smoothing splines                 promises to be widely applicable in scientific research, ranging                from the search for risk factors in large scale demographic data                or for risk factors in environmental degradation, to aspects of a               numerical weather forecasting system, to machine learning."
"9206138","Mathematical Sciences: On the Construction of Efficient     Estimates in Semi-Parametric and Nonparametric Models","DMS","STATISTICS","08/15/1992","09/14/1992","Anton Schick","NY","SUNY at Binghamton","Standard Grant","Sallie Keller-McNulty","07/31/1994","$12,000.00","","anton@math.binghamton.edu","4400 VESTAL PKWY E","BINGHAMTON","NY","139026000","6077776136","MPS","1269","","$0.00","     A general abstract theory has been developed for the                       construction of efficient estimates of the parameter of interest                in semiparametric models when the data are independently and                    identically distributed.  This project will expand this theory in               two directions.  First is the development of a satisfactory                     calculus for the construction of the efficient influence                        function.  Second is the extension of the theory for dependent                  data.                                                                                This research will provide a unified view and a rigorous                   mathematical basis for constructing estimators for a large class                of statistical models.  When models are only partially specified                in terms of the determining features or attributes, the                         anticipated behavior for new observations can be modeled                        nonetheless using so-called semiparametric or nonparametric                     models.  How well this is done depends on how fully the                         information in the data is utilized and on how precisely the                    model can be expressed given the data.  This research focuses on                abstracting the necessary mathematical properties for good                      estimates and good predictions for future observations.  Then the               mathematical requirements for these desired properties can be                   derived."
"9202382","Mathematical Sciences: Contributions to the Theory and      Methods of Empirical Bayes Estimation","DMS","STATISTICS","09/15/1992","09/14/1992","Francisco Samaniego","CA","University of California-Davis","Standard Grant","Sallie Keller-McNulty","08/31/1994","$50,000.00","","fjsamaniego@ucdavis.edu","OR/Sponsored Programs","Davis","CA","956186134","5307547700","MPS","1269","","$0.00","     Most procedures labeled ""Empirical Bayes"" that are in use at               present are frequentist rather than Bayesian; although often the                motivation for employing Empirical Bayes procedures is the                      conceptual or the computational difficulty of the analogous Bayes               procedures.  This research broadens the  Empirical Bayes                        framework and then examines the  comparative behaviors of the                   several methodologies with respect their performance and their                  feasibility.  Theoretical results defining conditions of                        superiority for Empirical Bayes methods will be sought.                         Empirical results from simulations and theoretical results for                  properties of Empirical Bayes estimators will be applied to                     reliability theory.                                                                  Statistical analyses draw on models or on prior information                and expert opinion to set the framework for analyzing data.  In                 certain circumstances the data itself can be used to determine                  the framework as well as be analyzed within the framework.                      Procedures of this type are called ""Empirical Bayes;"" and these                 can be viewed in some sense as a hybrid of model-based                          (frequentist) and prior information-based (Bayesian) procedures.                This research will investigate the circumstances under which each               class of procedures is significantly superior to the others for                 applications in reliability testing and estimation."
"9205687","Mathematical Sciences: Smoothing Parameter Selection and    Related Topic","DMS","PROBABILITY, STATISTICS","08/01/1992","05/23/1994","Shean-Tsong Chiu","CO","Colorado State University","Continuing Grant","Stephen M. Samuels","01/31/1996","$111,000.00","Richard Tweedie","chiu@stat.colostate.edu","601 S Howes St","Fort Collins","CO","805232002","9704916355","MPS","1263, 1269","0000, OTHR","$0.00","     The statistical part of this project will be to study a                    number of estimation methods using nonparametric approaches.  In                particular kernel estimation and related areas of nonparametric                 and density estimation applications will be studied, and the                    smoothing parameter selection problem addressed.  Problems to be                considered include those of discontinuities or rough density                    functions, selection for ridge regression, and the effect of                    discretization.  The modelling part of this project involves new                developments of the theory and applications of Markov models in                 both discrete and continuous time.  The investigator will                       concentrate on rates of convergence results and on state and                    history dependent criteria for such stability.  These results                   will be incorporated into a new approach to Markov decisions                    processes where the state space is extended to include the                      decision set into the overall Markovian structure. Stability                    properties of such general processes will then be established in                quite complex environments.                                                          Probabilistic modelling and statistical estimation                         techniques encompass two separate parts of the same activity.                   The first part endeavors to describe, in manageable terms, models               of real and often complex systems in such a way that the inherent               randomness in the system is properly represented.  The second                   endeavors to use these models, and data gathered to describe real               systems, in such a way that one can estimate the parameters that                actually describe what is happening in practice.  In the                        modelling part of this project the investigators will study                     important models in operations research, time series, and finance               and economics, with a focus on developing methods for stability                 of such systems.  In the statistics part of the proposal, the                   investigators will look at a number of computer intensive ways of               estimating parameters with a goal of finding methods which give                 good estimates quickly."
"9202857","Mathematical Sciences: Some Topics in Generalized RegressionModels","DMS","STATISTICS","08/01/1992","03/30/1994","Donald Pierce","OR","Oregon State University","Continuing grant","James E. Gentle","01/31/1996","$180,000.00","Daniel Schafer, Dawn Peters","","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","MPS","1269","0000, OTHR","$0.00","     For generalized linear models, including those for survival                analysis, improved asymptotic methods based on saddlepoint and                  related methods will be developed and evaluated.  These improve-                ments are a natural extension of the asymptotic methods ordinari-               ly used for generalized linear models and should come into                      routine use to verify or to improve on application of standard                  methods.  Aside from practical import, these developments provide               insight into the basic nature of asymptotic methods particularly                in regard to the effects of nuisance parameters.  Closely related               Laplace approximations will also be developed for likelihood                    calculations in generalized mixed linear models involving                       additional random effects in linear predictors.                                      Statistical regression models relate a response variable to                a set of explanatory variables and factors or attributes.  A                    major development in statistics during the past 15 years has been               the expansion of classical regression modeling to a much broader                field of applications often involving more complicated dependen-                cies on the explanatory variables and factors.  The aim of this                 project is to continue the development of this broader theory for               generalized regression modeling, emphasizing two directions:                    first, improvement on necessary approximations in the analysis                  calculations and second, allowance for still more general                       dependencies reflected in the variability of the data."
"9208683","Mathematical Sciences: Statistical Inference for Some       Dynamic and Spatial Phenomena","DMS","STATISTICS","08/01/1992","07/31/1992","David Brillinger","CA","University of California-Berkeley","Standard Grant","Alan Izenman","01/31/1994","$55,000.00","","brill@stat.berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947101749","5106433891","MPS","1269","","$0.00","     This project addresses the mathematical representation of                  arrays of biological neurons that are firing simultaneously with                the goal of inferring their causal connections or influence                     diagram on the basis of firing times.  The methodology of point                 processes of several types will be extended to include full                     likelihood and second-order procedures to extend the results from               social scientists' path analysis and causal modeling.  For small                net works of two or three neurons, partial coherence analysis and               threshold modeling have proved effective; however, for data for a               larger network with eight neurons, nontrivial extensions are                    needed for display and for analysis.                                                 Physiologically, neurons communicate with each other via                   spike trains, emitting pulses that go on to influence other                     neurons; and the neurons are themselves influenced.  The goal of                this research is to infer the connection lines or ""wiring                       diagram"" of a network of neurons by observing their individual                  firing times."
"9204247","Mathematical Sciences: The Use of Polynomial Splines in     Statistical Modelling","DMS","STATISTICS","09/01/1992","04/22/1994","Charles Stone","CA","University of California-Berkeley","Continuing grant","Sallie Keller-McNulty","08/31/1995","$105,000.00","","stone@stat.berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947101749","5106433891","MPS","1269","0000, OTHR","$0.00","     Polynomial splines and their tensor products ar natural                    building blocks for constructing finite-dimensional estimates of                infinite-dimensional main effects and low-order interactions; and               the resulting analysis of variance decompositions provide an                    insightful tool for data analysis.  The corresponding theory,                   methodology and software will be developed in a variety of                      settings, including regressions with application to time series                 and stochastic processes, logistic regression, Poisson regres-                  sion, proportional hazards modeling and modeling of multivariate                and conditional distributions.  Theoretical results will focus on               rates of convergence, both locally and in various global norms.                 Methodology will be highly adaptive and computationally inten-                  sive.                                                                                The overall goal of this research is to develop, justify,                  explain and make available a systematic extension of generalized                linear models used by many scientists in drawing inferences from                their data.  Expanding the kinds of models to include multi-                    variate data that includes both continuous variables and                        variables with only a few possible values should make this                      methodology still more broadly useful."
"9115577","Mathematical Sciences: Studies in Theoretical Statistics","DMS","STATISTICS","06/01/1992","05/19/1992","Peter Bickel","CA","University of California-Berkeley","Standard Grant","Alan Izenman","10/31/1993","$62,000.00","","bickel@stat.berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947101749","5106433891","MPS","1269","","$0.00","     The focus of this project is to examine situations where                   finite- or infinite-dimensional parameters are to be estimated                  from i.i.d variables from a common distribution and to apply a                  generalized theory of adaptive and efficient estimation.                        Specific applications include inference for software reliability                and field testing, response functions under shape restrictions,                 gene mapping procedures and the construction of similarity                      indices in molecular biology.                                                        This project will take some very general theoretical results               and refine these for specialized complexities seen in particular                circumstances."
"9208677","Mathematical Sciences: Chance Processes and the Foundation  of Statistics","DMS","STATISTICS","07/15/1992","05/17/1993","David Freedman","CA","University of California-Berkeley","Continuing grant","Stephen M. Samuels","12/31/1994","$60,000.00","","","Sponsored Projects Office","BERKELEY","CA","947101749","5106433891","MPS","1269","","$0.00","     Prior beliefs can be characterized using ideas of partial                  exchangeability by describing certain convex sets of proba-                     bilities in terms of their symmetry properties using deFinetti's                theorem as a paradigm.  Statistical procedures suggested by                     priors will also be examined using usual frequentist criteria                   like consistency and asymptotic normality.  Tests of the                        assumptions for statistical models useful for policy analysis                   will be considered and the performance of such models under                     failure of these assumptions will evaluated.                                         The foundations of statistics include concepts of prior                    beliefs and their characterization and their relation to good                   statistical procedures.  How standard statistical procedures                    behave under nonstandard conditions and how to test the                         conditions to verify assumptions are other basic issues to be                   considered in this project."
"9210042","Mathematical Sciences:  Growth Curve Marginal Models","DMS","STATISTICS","08/15/1992","08/20/1992","Jane Pendergast","FL","University of Florida","Standard Grant","Alan Izenman","07/31/1993","$20,000.00","","","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","MPS","1269","9222","$0.00","     Marginal Models refer to models built on the structure of                  generalized linear models, but extended beyond the Gaussian case                to a wide class of distributions for discrete or continuous-                    valued variables.  This project will extend these models to                     growth curve models with particular emphasis on discrete data.                  Implementation of software, particularly for modest computing                   support will be undertaken as part of this project.                                  When individuals are observed over a period of time, the                   objective of the data analysis is usually both to examine the                   pattern of change for the individuals and to examine the                        commonalities of these patterns among individuals.  Often this                  leads to distinctions among groups of individuals or to                         associating features of these patterns with particular attributes               of the groups.  This research will develop statistical procedures               for this kind of analysis."
"9123956","Mathematical Sciences: Adaptive estimation of nonparametric curves","DMS","STATISTICS","07/01/1992","06/29/1992","Sam Efromovich","NM","University of New Mexico","Standard Grant","Sallie Keller-McNulty","05/31/1995","$35,000.00","","efrom@utdallas.edu","1700 Lomas Blvd. NE, Suite 2200","Albuquerque","NM","871310001","5052774186","MPS","1269","","$0.00","     This research examines sharp risk convergence for adaptive                 estimates of nonparametric curves in the absence of prior                       information on nuisance parameters.Since optimal risk convergence               in this context depends crucially on the smoothness of the                      estimated curve, the goal is to develop a suitable estimator                    without a priori knowledge of the smoothness.  Particular areas                 of application are probability density estimation, nonparametric                regression, filtering and spectral density estimation.                               Most (optimal) estimates of curves from data rely on                       assumptions about the smoothness of the curve to be estimated.                  Adaptive estimation allows information about the smoothness to be               built up as observations (data) are gathered.  This is done at                  the same time and as part of the process of estimating the curve                itself.  For sequential methods of this kind, the amount of data                required (sample size) depends on the observations and the                      underlying curve.  Both theoretical approaches to an optimal                    overall strategy and some applications will be considered."
"9213264","Mathematical Sciences: Statistics and Statistical Computing","DMS","STATISTICS","08/15/1992","02/17/1994","N Ylvisaker","CA","University of California-Los Angeles","Continuing grant","James E. Gentle","07/31/1996","$330,000.00","Ker-Chau Li","","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","MPS","1269","9218, HPCC","$0.00","     A major challenge to statistics is the analysis and                        visualization of high-dimensional data.  Theoretical foundation                 and software implementation are among the facets of this                        challenge to be undertaken as part of this project.  In a                       separate venue, fundamental problems in experimental design are                 to be examined with attention to Bayesian design, design for                    computer experimentation, nonparametric analysis and response                   surfaces.                                                                            Increasingly, statistics as a discipline has been moved by                 the computer: experiments and data structures grow increasingly                 ambitious and sophisticated as computers gain in power.  This                   research links the concepts of effective design and analysis of                 experiments with the visualization of complex information and                   methodologic advances in computational statistics."
"9202759","Mathematical Sciences: Regression and Time Series Model     Selection in Small Samples","DMS","STATISTICS","07/01/1992","06/29/1992","Chih-Ling Tsai","CA","University of California-Davis","Standard Grant","Stephen M. Samuels","06/30/1994","$28,920.00","","cltsai@ucdavis.edu","OR/Sponsored Programs","Davis","CA","956186134","5307547700","MPS","1269","","$0.00","     In a recent series of papers, the principal investigaors                   have explored the use of a correction to the Akaike Information                 Criterion, AICc, and a further-improved version AICi, for model                 selection in linear regression and artoregressive time series                   analysis.  Substantial small-sample improvements in model                       selection performance are found in all cases as the bias of the                 estimator for Kullback-Leibler discrepancy is greatly reduced.                  The investigators propose to build on the above work by                         developing a general theoretical and pracitcal foundation for                   AICc as it applies to small-sample model selection problems in                  time series and regression.                                                          A central problem in statistics is that of selecting an                    appropriate model from a potentially large class of candidate                   models to apply in a particular situation of practical interest.                The selection of an inadequate model can have very serious                      consequences: forecasts of future events may be substantially                   distorted and inaccurate, resulting in incorrect decisions, and                 financial losses.  The development of an effective decision-                    making process therefore depends on the ability to decide which                 model seems best for the data at hand.  The investigators propose               to develop and test improved methods of selecting a model on the                basis of a reasonably small amount of observed data."
"9207072","Mathematical Sciences: Mathematical Statistics on Singular  Problems","DMS","STATISTICS","08/15/1992","08/11/1992","Richard Liu","NY","Cornell University","Standard Grant","James E. Gentle","07/31/1996","$55,000.00","","","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","MPS","1269","9218","$0.00","     Singular functional estimation problems cover an extremely                 large portion of statistical theory.  Some procedures with                      optimal rates have been well established; but recent work on                    white noise problems has led to a unified approach based on the                 modulus of the functional.  This approach gives optimal or near                 optimal procedures quite simply for many important statistical                  problems.                                                                            For some statistical estimation problems, optimal methods                  are well known, but for many more either optimality of the                      methodology is uncertain or its efficiency is unknown.  This                    research will produce generally efficient procedures which can                  have many scientific applications, for example complex problems                 like reconstruction of the ""true image"" from tomography or other                imaging techniques. This unified approach to estimation should                  find applications in engineering, biology, economics and other                  fields where practical and theoretical scientific problems are                  framed in terms of statistical models."
"9202161","Mathematical Sciences: Topics in Projection Pursuit, Neural Networks and Pattern Recognition","DMS","STATISTICS, COMPUTATIONAL MATHEMATICS","09/15/1992","09/14/1992","Lee Jones","MA","University of Massachusetts Lowell Research Foundation","Standard Grant","Sallie Keller-McNulty","08/31/1994","$65,000.00","Tom Jiang","Lee_Jones@uml.edu","600 Suffolk Street","Lowell","MA","018543692","9789344723","MPS","1269, 1271","9263","$0.00","Problems in the interface of statistics, mathematics and computational science will be studied, focusing on Fourier approximation and ridge estimation of regression and density functions and, in a separate context, on filtered Dirichlet distributions for local smoothing. In particular, preference orders will be studied for the frequency weights in multiple Fourier expansions and for the connection weights in single hidden-layer neural networks. Properties will be derived and applications such as feature extraction and projection pursuit will be considered in detail. This research will aid in automated learning from large data sets such as those arising in robotics, medicine and artificial intelligence. One aspect of the work will develop sophisticated mathematical techniques for application to problems in statistics and electrical engineering. A second aspect of the work will develop statistical methods to utilize an expert's knowledge directly without restricting the form in which the expert must express this information."
"9211640","Mathematical Sciences: Statistical Multiple Numerical Integration","DMS","STATISTICS, COMPUTATIONAL MATHEMATICS","08/01/1992","07/30/1992","Alan Genz","WA","Washington State University","Standard Grant","Sallie Keller-McNulty","01/31/1995","$65,000.00","Robert Kass","alangenz@wsu.edu","280 Lighty","PULLMAN","WA","991641060","5093359661","MPS","1269, 1271","9263","$0.00","This research focuses on the efficient evaluation of multidimensional integrals that arise in Bayesian analysis. The basic approach is first to select a problem-specific transformation to precondition the integrands, and then to use an adaptive integration method. The primary objective now is to investigate how best to choose transformations which will allow adaptive numerical integration algorithms to be used effectively. So far, transformations based on a modal approximation transformation have been shown to reduce computation time significantly for some problems. These approximations need to be refined and tested on practical statistical problems and made to interface with standard statistical software packages. Integrals play a very important role in a wide variety of practical statistical calculations; but often these integrals are defined over regions in multiple dimension and do not have values that can be obtained from formulas or tables. In this case, the integrals must be estimated numerically, often with time intensive computation. New methods and refinements to be developed here will take account of special features of these statistical problems to give efficient adaptive integration algorithms."
